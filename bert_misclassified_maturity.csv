,include,feature,predicted
112930,0,"Fuzzy logic based anaesthesia monitoring systems for the detection of absolute hypovolaemia. Anaesthesia monitoring involves critical diagnostic tasks carried out amongst lots of distractions. Computers are capable of handling large amounts of data at high speed and therefore decision support systems and expert systems are now capable of processing many signals simultaneously in real time. We have developed two fuzzy logic based anaesthesia monitoring systems; a real time smart anaesthesia alarm system (RT-SAAM) and fuzzy logic monitoring system-2 (FLMS-2), an updated version of FLMS for the detection of absolute hypovolaemia. This paper presents the design aspects of these two systems which employ fuzzy logic techniques to detect absolute hypovolaemia, and compares their performances in terms of usability and acceptability. The interpretation of these two systems of absolute hypovolaemia was compared with clinicians' assessments using Kappa analysis, RT-SAAM K=0.62, FLMS-2 K=0.75; an improvement in performance by FLMS-2.",1.0
48496,0,"Radiomics-Based Machine Learning Technology Enables Better Differentiation Between Glioblastoma and Anaplastic Oligodendroglioma. <b>Purpose:</b> The aim of this study was to test whether radiomics-based machine learning can enable the better differentiation between glioblastoma (GBM) and anaplastic oligodendroglioma (AO). <b>Methods:</b> This retrospective study involved 126 patients histologically diagnosed as GBM (<i>n</i> = 76) or AO (<i>n</i> = 50) in our institution from January 2015 to December 2018. A total number of 40 three-dimensional texture features were extracted from contrast-enhanced T1-weighted images using LIFEx package. Six diagnostic models were established with selection methods and classifiers. The optimal radiomics features were separately selected into three datasets with three feature selection methods [distance correlation, least absolute shrinkage and selection operator (LASSO), and gradient boosting decision tree (GBDT)]. Then datasets were separately adopted into linear discriminant analysis (LDA) and support vector machine (SVM) classifiers. Specificity, sensitivity, accuracy, and area under curve (AUC) of each model were calculated to evaluate their diagnostic performances. <b>Results:</b> The diagnostic performance of machine learning models was superior to human readers. Both classifiers showed promising ability in discrimination with AUC more than 0.900 when combined with suitable feature selection method. For LDA-based models, the AUC of models were 0.986, 0.994, and 0.970 in the testing group, respectively. For the SVM-based models, the AUC of models were 0.923, 0.817, and 0.500 in the testing group, respectively. The over-fitting model was GBDT + SVM, suggesting that this model was too volatile that unsuitable for classification. <b>Conclusion:</b> This study indicates radiomics-based machine learning has the potential to be utilized in clinically discriminating GBM from AO.",1.0
1044,1,"Do AI models recognise rare, aggressive skin cancers? An assessment of a direct-to-consumer app in the diagnosis of Merkel cell carcinoma and amelanotic melanoma. Machine learning (ML) models for skin cancer recognition have reported comparable or superior performance to dermatologists in controlled or restricted settings.<sup>1</sup> One restriction is the number of disease classes. When trained models are deployed into real-world contexts, an important challenge will be the detection of rare but aggressive skin cancers that are not well-covered in training datasets, such as Merkel cell carcinoma (MCC) and amelanotic melanoma.",0.0
6439,1,"Assessing Ischemic Stroke with Convolutional Image Features in Carotid Color Doppler. Stroke is a leading cause of disability and death worldwide. Early and accurate recognition of acute stroke is critical for achieving a good prognosis. The novel automated system proposed in this study was based on convolutional neural networks (CNNs), which were used to identify lesion findings on carotid color Doppler (CCD) images in patients with acute ischemic stroke. An image database composed of 1032 CCD images from 106 patients with acute ischemic stroke (549 images) and from 79 normal controls (483 images) was retrospectively analyzed. Taking the consensus of two neuroradiologists as the gold standard, different CNN models with and without transfer learning were evaluated with 10-fold cross-validation. The diagnostic information provided from individual color channels was also explored. AlexNet, which was trained from scratch, achieved an accuracy of 91.67%, a sensitivity of 93.33%, a specificity of 90.20% and an area under the receiver operating characteristic curves (AUC) of 0.9432. Other transferred models achieved accuracies between 77.69% and 83.94%. In channel comparisons, the green channel had the best performance, with an accuracy of 87.50%, a sensitivity of 97.78%, a specificity of 78.43% and an AUC of 0.9507. The proposed CNN architecture, as a computer-aided diagnosis system, suggests using automatic feature extraction from CCD images to predict ischemic stroke. The developed scheme has the potential to provide diagnostic suggestions in clinical use.",0.0
9038,0,"Using nursing notes to improve clinical outcome prediction in intensive care patients: A retrospective cohort study. Electronic health record documentation by intensive care unit (ICU) clinicians may predict patient outcomes. However, it is unclear whether physician and nursing notes differ in their ability to predict short-term ICU prognosis. We aimed to investigate and compare the ability of physician and nursing notes, written in the first 48 hours of admission, to predict ICU length of stay and mortality using 3 analytical methods.",1.0
1000000050,0,"[A novel attention fusion network-based multiple instance learning framework to automate diagnosis of chronic gastritis with multiple indicators]. <b>Objective:</b> To explore the performance of the attention-multiple instance learning (MIL) framework, an attention fusion network-based MIL, in the automated diagnosis of chronic gastritis with multiple indicators. <b>Methods:</b> A total of 1 015 biopsy cases of gastritis diagnosed in Fudan University Cancer Hospital, Shanghai, China and 115 biopsy cases of gastritis diagnosed in Shanghai Pudong Hospital, Shanghai, China were collected from January 1st to December 31st in 2018. All pathological sections were digitally converted into whole slide imaging (WSI). The WSI label was based on the corresponding pathological report, including ""activity"" ""atrophy"" and ""intestinal metaplasia"". The WSI were divided into a training set, a single test set, a mixed test set and an independent test set. The accuracy of automated diagnosis for the Attention-MIL model was validated in three test sets. <b>Results:</b> The area under receive-operator curve (AUC) values of Attention-MIL model in single test sets of 240 WSI were: activity 0.98, atrophy 0.89, and intestinal metaplasia 0.98; the average accuracy of the three indicators was 94.2%. The AUC values in mixed test sets of 117 WSI were: activity 0.95, atrophy 0.86, and intestinal metaplasia 0.94; the average accuracy of the three indicators was 88.3%. The AUC values in independent test sets of 115 WSI were: activity 0.93, atrophy 0.84, and intestinal metaplasia 0.90; the average accuracy of the three indicators was 85.5%. <b>Conclusions:</b> To assist in pathological diagnosis of chronic gastritis, the diagnostic accuracy of Attention-MIL model is very close to that of pathologists. Thus, it is suitable for practical application of artificial intelligence technology.",1.0
1000000343,1,"The Reproducibility of Deep Learning-Based Segmentation of the Prostate Gland and Zones on T2-Weighted MR Images. Volume of interest segmentation is an essential step in computer-aided detection and diagnosis (CAD) systems. Deep learning (DL)-based methods provide good performance for prostate segmentation, but little is known about the reproducibility of these methods. In this work, an in-house collected dataset from 244 patients was used to investigate the intra-patient reproducibility of 14 shape features for DL-based segmentation methods of the whole prostate gland (WP), peripheral zone (PZ), and the remaining prostate zones (non-PZ) on T2-weighted (T2W) magnetic resonance (MR) images compared to manual segmentations. The DL-based segmentation was performed using three different convolutional neural networks (CNNs): V-Net, nnU-Net-2D, and nnU-Net-3D. The two-way random, single score intra-class correlation coefficient (ICC) was used to measure the inter-scan reproducibility of each feature for each CNN and the manual segmentation. We found that the reproducibility of the investigated methods is comparable to manual for all CNNs (14/14 features), except for V-Net in PZ (7/14 features). The ICC score for segmentation volume was found to be 0.888, 0.607, 0.819, and 0.903 in PZ; 0.988, 0.967, 0.986, and 0.983 in non-PZ; 0.982, 0.975, 0.973, and 0.984 in WP for manual, V-Net, nnU-Net-2D, and nnU-Net-3D, respectively. The results of this work show the feasibility of embedding DL-based segmentation in CAD systems, based on multiple T2W MR scans of the prostate, which is an important step towards the clinical implementation.",0.0
119596,0,"A new approach to the detection of lesions in mammography using fuzzy clustering. Breast cancer is a leading cause of female mortality and its early detection is an important means of reducing this. The present study investigated an approach, based on fuzzy clustering, to detect small lesions, such as microcalcifications and other masses, that are hard to recognize  in breast cancer screening. A total of 180 mammograms were analysed and classified by radiologists into three groups (n = 60 per group): those with microcalcifications; those with tumours; and those with no lesions. Twenty mammograms were taken as training data sets from each of the  groups. The algorithm was then applied to the data not taken for training. Analysis by fuzzy clustering achieved a mean accuracy of 99.7% compared with the radiologists' findings. It was concluded that the fuzzy clustering algorithm allowed for more efficient and accurate detection of breast  lesions and may improve the early detection of breast tumours.",1.0
1000000000,1,"We predict the risk of organ failure in a cohort of intensive care patients by using rich electronic health record data and longitudinal physiology. A deep learning framework was adopted, using features from the first 48 hours of admission. Our risk prediction model performed better than APACHE-II or SOFA score for predicting risk of organ failure. ",0.0
17715,0,"DeepCAT: Deep Computer-Aided Triage of Screening Mammography. Although much deep learning research has focused on mammographic detection of breast cancer, relatively little attention has been paid to mammography triage for radiologist review. The purpose of this study was to develop and test DeepCAT, a deep learning system for mammography triage based on suspicion of cancer. Specifically, we evaluate DeepCAT's ability to provide two augmentations to radiologists: (1) discarding images unlikely to have cancer from radiologist review and (2) prioritization of images likely to contain cancer. We used 1878 2D-mammographic images (CC & MLO) from the Digital Database for Screening Mammography to develop DeepCAT, a deep learning triage system composed of 2 components: (1) mammogram classifier cascade and (2) mass detector, which are combined to generate an overall priority score. This priority score is used to order images for radiologist review. Of 595 testing images, DeepCAT recommended low priority for 315 images (53%), of which none contained a malignant mass. In evaluation of prioritizing images according to likelihood of containing cancer, DeepCAT's study ordering required an average of 26 adjacent swaps to obtain perfect review order. Our results suggest that DeepCAT could substantially increase efficiency for breast imagers and effectively triage review of mammograms with malignant masses.",1.0
26326,1,"A Convolutional Neural Network based system for Colorectal cancer segmentation on MRI images. The aim of the study is to present a new Convolutional Neural Network (CNN) based system for the automatic segmentation of the colorectal cancer. The algorithm implemented consists of several steps: a pre-processing to normalize and highlights the tumoral area, the classification based on CNNs, and a post-processing aimed at reducing false positive elements. The classification is performed using three CNNs: each of them classifies the same regions of interest acquired from three different MR sequences. The final segmentation mask is obtained by a majority voting. Performances were evaluated using a semi-automatic segmentation revised by an experienced radiologist as reference standard. The system obtained Dice Similarity Coefficient (DSC) of 0.60, Precision (Pr) of 0.76 and Recall (Re) of 0.55 on the testing set. After applying the leave-one-out validation, we obtained a median DSC=0.58, Pr=0.74, Re=0.54. The promising results obtained by this system, if validated on a larger dataset, could strongly improve personalized medicine.",0.0
29209,1,"3D Virtual Pancreatography. We present 3D virtual pancreatography (VP), a novel visualization procedure and application for non-invasive diagnosis and classification of pancreatic lesions, the precursors of pancreatic cancer. Currently, non-invasive screening of patients is performed through visual inspection of 2D axis-aligned CT images, though the relevant features are often not clearly visible nor automatically detected. VP is an end-to-end visual diagnosis system that includes: a machine learning based automatic segmentation of the pancreatic gland and the lesions, a semi-automatic approach to extract the primary pancreatic duct, a machine learning based automatic classification of lesions into four prominent types, and specialized 3D and 2D exploratory visualizations of the pancreas, lesions and surrounding anatomy. We combine volume rendering with pancreas- and lesion-centric visualizations and measurements for effective diagnosis. We designed VP through close collaboration and feedback from expert radiologists, and evaluated it on multiple real-world CT datasets with various pancreatic lesions and case studies examined by the expert radiologists.",0.0
25582,0,"Training a computer-aided polyp detection system to detect sessile serrated adenomas using public domain colonoscopy videos. <b>BackgroundÃ¢â‚¬â€š</b> Colorectal cancer (CRC) is a major public health burden worldwide, and colonoscopy is the most commonly used CRC screening tool. Still, there is variability in adenoma detection rate (ADR) among endoscopists. Recent studies have reported improved ADR using deep learning models trained on videos curated largely from private in-house datasets. Few have focused on the detection of sessile serrated adenomas (SSAs), which are the most challenging target clinically. <b>MethodsÃ¢â‚¬â€š</b> We identified 23 colonoscopy videos available in the public domain and for which pathology data were provided, totaling 390 minutes of footage. Expert endoscopists annotated segments of video with adenomatous polyps, from which we captured 509 polyp-positive and 6,875 polyp-free frames. Via data augmentation, we generated 15,270 adenomatous polyp-positive images, of which 2,310 were SSAs, and 20,625 polyp-negative images. We used the CNN AlexNet and fine-tuned its parameters using 90Ã¢â‚¬Å % of the images, before testing its performance on the remaining 10Ã¢â‚¬Å % of images unseen by the model. <b>ResultsÃ¢â‚¬â€š</b> We trained the model on 32,305 images and tested performance on 3,590 images with the same proportion of SSA, non-SSA polyp-positive, and polyp-negative images. The overall accuracy of the model was 0.86, with a sensitivity of 0.73 and a specificity of 0.96.Ã¢â‚¬Å Positive predictive value was 0.93 and negative predictive value was 0.96.Ã¢â‚¬Å The area under the curve was 0.94.Ã¢â‚¬Å SSAs were detected in 93Ã¢â‚¬Å % of SSA-positive images. <b>ConclusionsÃ¢â‚¬â€š</b> Using a relatively small set of publicly-available colonoscopy data, we obtained sizable training and validation sets of endoscopic images using data augmentation, and achieved an excellent performance in adenomatous polyp detection.",1.0
11685,1,"COVID_SCREENET: COVID-19 Screening in Chest Radiography Images Using Deep Transfer Stacking. Infectious diseases are highly contagious due to rapid transmission and very challenging to diagnose in the early stage. Artificial Intelligence and Machine Learning now become a strategic weapon in assisting infectious disease prevention, rapid-response in diagnosis, surveillance, and management. In this paper, a bifold COVID_SCREENET architecture is introduced for providing COVID-19 screening solutions using Chest Radiography (CR) images. Transfer learning using nine pre-trained ImageNet models to extract the features of Normal, Pneumonia, and COVID-19 images is adapted in the first fold and classified using baseline Convolutional Neural Network (CNN). A Modified Stacked Ensemble Learning (MSEL) is proposed in the second fold by stacking the top five pre-trained models, and then the predictions resulted. Experimentation is carried out in two folds: In first fold, open-source samples are considered and in second fold 2216 real-time samples collected from Tamilnadu Government Hospitals, India, and the screening results for COVID data is 100% accurate in both the cases. The proposed approach is also validated and blind reviewed with the help of two radiologists at Thanjavur Medical College & Hospitals by collecting 2216 chest X-ray images between the month of April and May. Based on the reports, the measures are calculated for COVID_SCREENET and it showed 100% accuracy in performing multi-class classification.",0.0
49565,0,"A human-in-the-loop deep learning paradigm for synergic visual evaluation in children. Visual development during early childhood is a vital process. Examining the visual acuity of children is essential for early detection of visual abnormalities, but performing visual examination in children is challenging. Here, we developed a human-in-the-loop deep learning (DL) paradigm that combines traditional vision examination and DL with integration of software and hardware, thus facilitating the execution of vision examinations, offsetting the shortcomings of human doctors, and improving the abilities of both DL and doctors to evaluate the vision of children. Because this paradigm contains two rounds (a human round and DL round), doctors can learn from DL and the two can mutually supervise each other such that the precision of the DL system in evaluating the visual acuity of children is improved. Based on DL-based object localization and image identification, the experiences of doctors and the videos captured in the first round, the DL system in the second round can simulate doctors in evaluating the visual acuity of children with a final accuracy of 75.54%. For comparison, we also assessed an automatic deep learning method that did not consider the experiences of doctors, but its performance was not satisfactory. This entire paradigm can evaluate the visual acuity of children more accurately than humans alone. Furthermore, the paradigm facilitates automatic evaluation of the vision of children with a wearable device.",1.0
141338,0,"Deep learning approach for guiding three-dimensional computed tomography reconstruction of lower limbs for robotically-assisted total knee arthroplasty. BACKGROUND: Robotic-assisted total knee arthroplasty (TKA) was performed to promote the accuracy of bone resection and mechanical alignment. Among these TKA system procedures, 3D reconstruction of CT data of lower limbs consumes significant manpower. Artificial intelligence (AI) algorithms applying deep learning has been proved efficient in automated identification and visual processing. METHODS: CT data of a total of 200 lower limbs scanning were used for AI-based 3D model construction and CT data of 20 lower limbs scanning were utilised for verification. RESULTS: We showed that the performance of an AI-guided 3D reconstruction of CT data of lower limbs for robotic-assisted TKA was similar to that of the operator-based approach. The time of 3D lower limb model construction using AI was 4.7 min. AI-based 3D models can be used for surgical planning. CONCLUSION: AI was used for the first time to guide the 3D reconstruction of CT data of lower limbs for facilitating robotic-assisted TKA. Incorporation of AI in 3D model reconstruction before TKA might reduce the workload of radiologists.",1.0
