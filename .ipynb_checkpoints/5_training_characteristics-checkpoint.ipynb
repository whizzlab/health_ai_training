{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640e362b-546d-4fb6-92ec-7d6ce637f028",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43e4fe2-a195-4618-a34e-56a97657e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d23efe5-bb10-4c43-807b-1fd60cd820cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import datetime\n",
    "\n",
    "#for BERT\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776b6f88-94f2-4f3c-b5bf-cb1d33ab6e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365799ab-c96d-47cc-b1a9-c70b50a24533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3231291913769821192\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22723493888\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17866220592368552074\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "]\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b73f5-05a3-46f3-a208-ee70ea77fa0b",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31821440-3f3b-4132-a3c7-5d0aeabb4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_labelled = pd.read_csv('training_data/training_chars.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37810b79-9e5f-4cc6-adf7-8f759f917020",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ner_labelled.columns[1:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "509d1a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbe2da-fb70-44e7-99e2-4e902fc7fc96",
   "metadata": {},
   "source": [
    "#### Train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9efae5-826f-4b57-92f9-375cfbee6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df, test_df = train_test_split(ner_labelled, test_size=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4745459c-cebc-45bb-b9bd-401541214c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(temp_df, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa0212-d6cf-4151-bf3f-2187ec23bb4a",
   "metadata": {},
   "source": [
    "#### Create TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39672dac-67e0-47a4-8740-3da98d0a166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_df['text'].to_numpy().reshape(-1,1),\n",
    "                                              train_df[labels].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd355499-6c4f-48b0-aa9e-5cbd7850ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices((val_df['text'].to_numpy().reshape(-1,1),\n",
    "                                             val_df[labels].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9983ce0-7a66-46c1-8a0c-5bcb3eae4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = tf.data.Dataset.from_tensor_slices((test_df['text'].to_numpy().reshape(-1,1),\n",
    "                                              test_df[labels].to_numpy().reshape(-1,1,35)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4a12473-4337-4606-9435-b525a64e7a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((1,), (35,)), types: (tf.string, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483ff4cd-88c8-4064-af40-fa1965d0c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.cache()\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77003334-7d19-4423-84e3-4d8a732065da",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_ds_batched = configure_for_performance(train_ds)\n",
    "val_ds_batched = configure_for_performance(val_ds)\n",
    "test_ds_batched = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95cafcf-fc28-44ff-a910-e0cafe894860",
   "metadata": {},
   "source": [
    "#### Configure BERT Models for preprocessing and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c245440-254e-4185-b2ae-619a92fde704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using C:\\Users\\JOEZ~1\\AppData\\Local\\Temp\\tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# BERT model for vectorization\n",
    "\n",
    "bert_vec_model = 'experts_pubmed'\n",
    "\n",
    "map_name_to_handle = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_vec_model]\n",
    "\n",
    "bert_model = hub.KerasLayer(tfhub_handle_encoder) #wraps this as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a68d496-d44a-4d9c-b5c5-165f472d8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT model for pre-processing\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_vec_model]\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess) #wraps this as a Keras layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d8013f8-c865-4a9e-b6fa-016bcab32170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected: https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Pre-process model selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "print(f'BERT model selected: {tfhub_handle_encoder}')\n",
    "print(f'Pre-process model selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e37ce-ac03-4617-ab40-65ed58f879d2",
   "metadata": {},
   "source": [
    "#### Construct the multilabel classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3218f16b-9a0b-40b3-acd2-2b5df6722bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model(seq_length=256):\n",
    "\n",
    "    # Define input layer\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
    "    \n",
    "    # Load the pretrained preprocessor\n",
    "    bert_preprocessor = hub.load(tfhub_handle_preprocess)\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    tokenizer = hub.KerasLayer(bert_preprocessor.tokenize, name='tokenizer')\n",
    "    tokenized_inputs = [tokenizer(text_input)]\n",
    "\n",
    "    # Pack the tokenized input for the encoder\n",
    "    bert_pack_inputs = hub.KerasLayer(bert_preprocessor.bert_pack_inputs,\n",
    "                                      arguments=dict(seq_length=seq_length), name='packer')\n",
    "    \n",
    "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
    "    \n",
    "    #BERT encoding layer\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    \n",
    "    #Output layers\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(len(labels), activation='sigmoid', name='classifier')(net)\n",
    "    \n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d8b00a5-8082-4b08-8e7e-ae48145d1db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tokenizer (KerasLayer)          (None, None, None)   0           text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "packer (KerasLayer)             {'input_mask': (None 0           tokenizer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "BERT_encoder (KerasLayer)       {'sequence_output':  109482241   packer[0][0]                     \n",
      "                                                                 packer[0][1]                     \n",
      "                                                                 packer[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           BERT_encoder[0][13]              \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 35)           26915       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,509,156\n",
      "Trainable params: 109,509,155\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "693453aa-057d-4a8c-9056-021fe7b7b630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n",
      "INFO:absl:gradient_clip_norm=1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3361\n",
      "13444\n",
      "1344\n"
     ]
    }
   ],
   "source": [
    "#loss\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "#metrics\n",
    "metrics = ['BinaryAccuracy']\n",
    "\n",
    "#epochs\n",
    "epochs = 4\n",
    "\n",
    "#optimization\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds_batched).numpy()\n",
    "print(steps_per_epoch)\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "print(num_train_steps)\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "print(num_warmup_steps)\n",
    "init_lr = 1e-5\n",
    "\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "\n",
    "# models.optimization dependent on tf-official-models, which depends on pycococo which does not install on windows without workaround:\n",
    "# https://github.com/philferriere/cocoapi\n",
    "# 1) upgrade visual basic to 2019 and install C++ tools in that library\n",
    "# 2) install pycococo using direct from git installation in the github link (may need git library first)\n",
    "# 3) then install tf-official-models using pip\n",
    "\n",
    "##alternative optimizer\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "#                                        name='Adam'\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06c7570c-64c7-49d9-aee5-43f05c6470f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e45f57-1478-4528-b224-ffd757e4732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')\n",
    "history = classifier_model.fit(x=train_ds_batched,\n",
    "                               validation_data=val_ds_batched,\n",
    "                               epochs=epochs\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb654233-363f-4d06-9cb0-dd89152ff4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcce8e3-861c-4e6d-b427-fb5fcdf84706",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a7f4b-d923-4a3e-8cb0-759316886505",
   "metadata": {},
   "outputs": [],
   "source": [
    "##re-test on test_ds\n",
    "\n",
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c20e4ca3-abbf-473e-87d1-09fd63b51b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_model.predict(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f4628f0-10c9-4865-8418-5aeabe29e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0735ab4a-5a9f-45cc-91c8-21704d11fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0b592cd-c38b-4d8c-8b16-e55ad67fff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      1276\n",
      "           1       1.00      0.92      0.95       449\n",
      "           2       0.96      0.86      0.91       176\n",
      "           3       0.95      0.82      0.88       258\n",
      "           4       0.96      0.83      0.89        54\n",
      "           5       0.00      0.00      0.00        24\n",
      "           6       1.00      0.90      0.94        67\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.91      0.80      0.85        51\n",
      "           9       0.57      0.64      0.60        70\n",
      "          10       0.94      0.89      0.91      1020\n",
      "          11       0.98      1.00      0.99       107\n",
      "          12       0.91      0.97      0.94       290\n",
      "          13       0.97      0.98      0.97       362\n",
      "          14       0.97      0.99      0.98       171\n",
      "          15       0.97      0.91      0.94       101\n",
      "          16       0.95      0.92      0.93       151\n",
      "          17       0.96      0.79      0.86        28\n",
      "          18       0.88      0.94      0.91       206\n",
      "          19       0.98      0.96      0.97        56\n",
      "          20       1.00      1.00      1.00        69\n",
      "          21       1.00      0.93      0.96        57\n",
      "          22       0.84      0.90      0.87        30\n",
      "          23       0.91      0.91      0.91       172\n",
      "          24       0.94      0.87      0.90       290\n",
      "          25       1.00      0.96      0.98        50\n",
      "          26       0.93      0.92      0.93       262\n",
      "          27       0.86      0.88      0.87        90\n",
      "          28       0.96      1.00      0.98        24\n",
      "          29       0.95      0.88      0.91        72\n",
      "          30       0.96      0.93      0.95        29\n",
      "          31       0.96      0.70      0.81       291\n",
      "          32       0.96      0.96      0.96        24\n",
      "          33       1.00      1.00      1.00        13\n",
      "          34       0.99      0.99      0.99        94\n",
      "          35       1.00      0.75      0.86        16\n",
      "          36       1.00      1.00      1.00         7\n",
      "          37       0.94      0.85      0.89        80\n",
      "          38       0.98      0.91      0.94        56\n",
      "          39       0.99      0.98      0.99       988\n",
      "          40       0.92      1.00      0.96        68\n",
      "          41       0.88      0.97      0.93        39\n",
      "          42       0.95      0.97      0.96       121\n",
      "          43       0.99      1.00      0.99        86\n",
      "          44       0.96      0.99      0.97        94\n",
      "          45       0.94      0.96      0.95        70\n",
      "          46       0.97      0.99      0.98        75\n",
      "          47       1.00      0.85      0.92        26\n",
      "          48       0.92      0.97      0.94        35\n",
      "          49       0.99      0.98      0.99       231\n",
      "          50       0.94      0.90      0.92       278\n",
      "          51       0.99      0.93      0.96        71\n",
      "          52       0.90      0.85      0.88        88\n",
      "          53       1.00      0.89      0.94        18\n",
      "          54       1.00      0.80      0.89        20\n",
      "          55       0.96      0.95      0.96       154\n",
      "          56       0.99      0.95      0.97       129\n",
      "          57       0.98      0.90      0.94       328\n",
      "          58       0.83      0.83      0.83        42\n",
      "          59       0.96      0.97      0.96       696\n",
      "          60       1.00      0.97      0.98        92\n",
      "          61       0.89      0.93      0.91        87\n",
      "          62       0.98      0.96      0.97       138\n",
      "          63       0.95      0.92      0.93       344\n",
      "          64       0.88      0.81      0.84        83\n",
      "          65       0.94      0.88      0.91        33\n",
      "          66       0.98      0.91      0.94       155\n",
      "          67       0.99      0.91      0.95       109\n",
      "          68       0.98      0.97      0.97       125\n",
      "          69       1.00      0.95      0.97        38\n",
      "          70       0.96      0.82      0.89        62\n",
      "          71       0.89      0.84      0.86       102\n",
      "          72       0.96      0.95      0.96        58\n",
      "          73       0.76      0.72      0.74        18\n",
      "          74       0.99      0.93      0.96       211\n",
      "          75       0.80      0.51      0.62        39\n",
      "          76       1.00      0.69      0.82        13\n",
      "          77       1.00      0.30      0.46        27\n",
      "          78       0.71      0.74      0.72        23\n",
      "          79       1.00      0.96      0.98        27\n",
      "          80       0.00      0.00      0.00        18\n",
      "          81       0.61      0.41      0.49        34\n",
      "          82       0.00      0.00      0.00        29\n",
      "\n",
      "   micro avg       0.96      0.92      0.94     12166\n",
      "   macro avg       0.90      0.85      0.87     12166\n",
      "weighted avg       0.95      0.92      0.93     12166\n",
      " samples avg       0.93      0.90      0.91     12166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe Z\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Joe Z\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Joe Z\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_df[labels], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86669817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['algo_neural_net',\n",
       " 'algo_support_vector',\n",
       " 'algo_regression',\n",
       " 'algo_decision_tree',\n",
       " 'algo_discriminant',\n",
       " 'algo_naive_bayes',\n",
       " 'algo_transfer',\n",
       " 'algo_federated',\n",
       " 'algo_k_nearest',\n",
       " 'algo_unsupervised',\n",
       " 'feat_imaging',\n",
       " 'feat_xr',\n",
       " 'feat_ct',\n",
       " 'feat_mri',\n",
       " 'feat_eeg',\n",
       " 'feat_ecg',\n",
       " 'feat_us',\n",
       " 'feat_echo',\n",
       " 'feat_histo',\n",
       " 'feat_oct',\n",
       " 'feat_mamm',\n",
       " 'feat_endoscop',\n",
       " 'feat_derm',\n",
       " 'feat_gene',\n",
       " 'feat_bio',\n",
       " 'feat_nlp',\n",
       " 'feat_ehr',\n",
       " 'feat_sensor',\n",
       " 'feat_phone',\n",
       " 'subspec_icu',\n",
       " 'subspec_ed',\n",
       " 'spec_id',\n",
       " 'subspec_sepsis',\n",
       " 'subspec_hiv',\n",
       " 'subspec_cov19',\n",
       " 'subspec_tb',\n",
       " 'subspec_malaria',\n",
       " 'spec_derm',\n",
       " 'subspec_dermca',\n",
       " 'spec_onc',\n",
       " 'subspec_rx',\n",
       " 'subspec_gynonc',\n",
       " 'subspec_lungca',\n",
       " 'subspec_brainca',\n",
       " 'subspec_gica',\n",
       " 'subspec_hepca',\n",
       " 'subspec_prosca',\n",
       " 'subspec_renalca',\n",
       " 'subspec_haemonc',\n",
       " 'subspec_breast',\n",
       " 'spec_psych',\n",
       " 'subspec_suicide',\n",
       " 'spec_msk',\n",
       " 'subspec_frac',\n",
       " 'spec_rheum',\n",
       " 'spec_gi',\n",
       " 'spec_hep',\n",
       " 'spec_resp',\n",
       " 'subspec_pneum',\n",
       " 'spec_neuro',\n",
       " 'subspec_epilep',\n",
       " 'subspec_cva',\n",
       " 'subspec_alzh',\n",
       " 'spec_cvs',\n",
       " 'subspec_ihd',\n",
       " 'subspec_hf',\n",
       " 'spec_endo',\n",
       " 'subspec_dm',\n",
       " 'spec_eye',\n",
       " 'subspec_retina',\n",
       " 'spec_haem',\n",
       " 'spec_obs',\n",
       " 'spec_renal',\n",
       " 'subspec_ackd',\n",
       " 'spec_paeds',\n",
       " 'spec_dent',\n",
       " 'spec_audio',\n",
       " 'spec_pubh',\n",
       " 'subspec_bci',\n",
       " 'subspec_prosth',\n",
       " 'subspec_assist',\n",
       " 'subspec_activity',\n",
       " 'lmic_flag']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11534762-0f2b-468a-a682-e45d5a1ca7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 900). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "#EXPORT MODEL\n",
    "\n",
    "saved_model_path = 'models/multilabel_charactersitics_bert'\n",
    "\n",
    "classifier_model.save(saved_model_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1e630-1fcd-48f9-8c77-2d84fadf1e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
