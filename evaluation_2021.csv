,feature,include,reference
16,"Cardiometabolic risk factors associated with brain age and accelerate brain ageing. The structure and integrity of the ageing brain is interchangeably linked to physical health, and cardiometabolic risk factors (CMRs) are associated with dementia and other brain disorders. In this mixed cross-sectional and longitudinal study (interval meanÂ =Â 19.7â€‰months), including 790 healthy individuals (mean ageÂ =Â 46.7â€‰years, 53% women), we investigated CMRs and health indicators including anthropometric measures, lifestyle factors, and blood biomarkers in relation to brain structure using MRI-based morphometry and diffusion tensor imaging (DTI). We performed tissue specific brain age prediction using machine learning and performed Bayesian multilevel modeling to assess changes in each CMR over time, their respective association with brain age gap (BAG), and their interaction effects with time and age on the tissue-specific BAGs. The results showed credible associations between DTI-based BAG and blood levels of phosphate and mean cell volume (MCV), and between T1-based BAG and systolic blood pressure, smoking, pulse, and C-reactive protein (CRP), indicating older-appearing brains in people with higher cardiometabolic risk (smoking, higher blood pressure and pulse, low-grade inflammation). Longitudinal evidence supported interactions between both BAGs and waist-to-hip ratio (WHR), and between DTI-based BAG and systolic blood pressure and smoking, indicating accelerated ageing in people with higher cardiometabolic risk (smoking, higher blood pressure, and WHR). The results demonstrate that cardiometabolic risk factors are associated with brain ageing. While randomized controlled trials are needed to establish causality, our results indicate that public health initiatives and treatment strategies targeting modifiable cardiometabolic risk factors may also improve risk trajectories and delay brain ageing.",0,0
20,"Predicting cognitive impairment in outpatients with epilepsy using machine learning techniques. Many studies report predictions for cognitive function but there are few predictions in epileptic patients; therefore, we established a workflow to efficiently predict outcomes of both the Mini-Mental State Examination (MMSE) and Montreal Cognitive Assessment (MoCA) in outpatients with epilepsy. Data from 441 outpatients with epilepsy were included; of these, 433 patients met the 12 clinical characteristic criteria and were divided into training (nâ€‰=â€‰304) and experimental (nâ€‰=â€‰129) groups. After descriptive statistics were analyzed, cross-validation was used to select the optimal model. The random forest (RF) algorithm was combined with the redundancy analysis (RDA) algorithm; then, optimal feature selection and resampling were carried out after removing linear redundancy information. The features that contributed more to multiple outcomes were selected. Finally, the external traceability of the model was evaluated using the follow-up data. The RF algorithm was the best prediction model for both MMSE and MoCA outcomes. Finally, seven markers were screened by overlapping the top ten important features for MMSE ranked by RF modeling, those ranked for MoCA ranked by RF modeling, and those for both assessments ranked by RDA. The optimal combination of features were namely, sex, age, age of onset, seizure frequency, brain MRI abnormalities, epileptiform discharge in EEG and usage of drugs. which was the most efficient in predicting outcomes of MMSE, MoCA, and both assessments.",0,0
24,Machine learning for outcome predictions of patients with trauma during emergency department care. To develop and evaluate a machine learning model for predicting patient with trauma mortality within the US emergency departments.,0,0
31,"COVID-19 screening using breath-borne volatile organic compounds. Rapid screening of COVID-19 is key to controlling the pandemic. However, current nucleic acid amplification involves lengthy procedures in addition to discomfort of taking throat/nasal swabs. Here we describe potential breath-borne volatile organic compound (VOC) biomarkers together with machine learning that can be used for point-of-care screening of COVID-19. Using a commercial gas chromatograph-ion mobility spectrometer (GC-IMS), higher levels of propanol were detected in exhaled breath of COVID-19 patients (N=74) and non-COVID-19 respiratory infections (RI) (N=30) than those of non-COVID-19 controls (NC) / health care workers (HCW) (N=87), and backgrounds (N=87). In contrast, breath-borne acetone was found to be significantly lower for COVID-19 patients than other subjects. Twelve key endogenous VOC species using supervised machine learning models (Support Vector Machines (SVM), Gradient Boosting Machines (GBM) and Random Forests) were shown to exhibit strong capabilities in discriminating COVID-19 from (HCW+NC) and RI with a precision ranging from 91% to 100%. GBM and Random Forests models can also discriminate RI patients from healthy subjects with a precision of 100%. In addition, the developed models using breath-borne VOC could also detect a confirmed COVID-19 patient but with a false negative throat swab PCR test. It takes ten minutes to allow an entire breath test to finish, including analysis of the 12 key VOC species. The developed technology provides a novel concept for non-invasive rapid point-of-care-test (POCT) screening for COVID-19 in various scenarios. Keywords: COVID-19, Exhaled Breath, Biomarkers, Volatile Organic Compounds (VOCs), Propanol, Acetone, Machine Learning.",0,0
35,"AI-based radiation dose quantification for estimation of heart disease risk in breast cancer survivors after radiotherapy. To investigate whether dose planned to cardiac structures is associated with the risk of heart disease (HD) in breast cancer patients treated with radiotherapy, and whether this association is modified by presence of coronary artery calcification (CAC).",0,0
37,"Expert Performance in Visual Differentiation of Bacterial and Fungal Keratitis. This study quantifies the performance of an international cohort of cornea specialists in image-based differentiation of bacterial and fungal keratitis, identifying significant regional variation and establishing a reference standard for comparison against machine learning models.",1,1
40,The performance of artificial intelligence supported Thoracic CT to evaluate the radiologic improvement in patients with COVID-19 pneumonia: comparision pirfenidon vs. corticosteroid. We aimed to investigate the effect of short-term pirfenidone treatment on prolonged COVID-19 pneumonia.,0,0
46,Performance of a convolutional neural network algorithm for tooth detection and numbering on periapical radiographs. The present study aimed to evaluate the performance of a Faster Region-based Convolutional Neural Network (R-CNN) algorithm for tooth detection and numbering on periapical images.,0,0
49,"Deep learning-based classification and structure name standardization for organ at risk and target delineations in prostate cancer radiotherapy. Radiotherapy (RT) datasets can suffer from variations in annotation of organ at risk (OAR) and target structures. Annotation standards exist, but their description for prostate targets is limited. This restricts the use of such data for supervised machine learning purposes as it requires properly annotated data. The aim of this work was to develop a modality independent deep learning (DL) model for automatic classification and annotation of prostate RT DICOM structures. Delineated prostate organs at risk (OAR), support- and target structures (gross tumor volume [GTV]/clinical target volume [CTV]/planning target volume [PTV]), along with or without separate vesicles and/or lymph nodes, were extracted as binary masks from 1854 patients. An image modality independent 2D InceptionResNetV2 classification network was trained with varying amounts of training data using four image input channels. Channel 1-3 consisted of orthogonal 2D projections from each individual binary structure. The fourth channel contained a summation of the other available binary structure masks. Structure classification performance was assessed in independent CT (nÂ =Â 200 pat) and magnetic resonance imaging (MRI) (nÂ =Â 40 pat) test datasets and an external CT (nÂ =Â 99 pat) dataset from another clinic. A weighted classification accuracy of 99.4% was achieved during training. The unweighted classification accuracy and the weighted average F1 score among different structures in the CT test dataset were 98.8% and 98.4% and 98.6% and 98.5% for the MRI test dataset, respectively. The external CT dataset yielded the corresponding results 98.4% and 98.7% when analyzed for trained structures only, and results from the full dataset yielded 79.6% and 75.2%. Most misclassifications in the external CT dataset occurred due to multiple CTVs and PTVs being fused together, which was not included in the training data. Our proposed DL-based method for automated renaming and standardization of prostate radiotherapy annotations shows great potential. Clinic specific contouring standards however need to be represented in the training data for successful use. Source code is available at https://github.com/jamtheim/DicomRTStructRenamerPublic.",0,0
51,Hypernatremia subgroups among hospitalized patients by machine learning consensus clustering with different patient survival. The objective of this study was to characterize hypernatremia patients at hospital admission into clusters using an unsupervised machine learning approach and to evaluate the mortality risk among these distinct clusters.,0,0
52,"Validation of an artificial intelligence solution for acute triage and rule-out normal of non-contrast CT head scans. Non-contrast CT head scans provide rapid and accurate diagnosis of acute head injury; however, increased utilisation of CT head scans makes it difficult to prioritise acutely unwell patients and places pressure on busy emergency departments (EDs). This study validates an AI algorithm to triage patients presenting with Intracranial Haemorrhage (ICH) or Acute Infarct whilst also identifying a subset of patients as Normal, with the potential to function as a rule-out test.",0,0
60,"Transfer Learning Improves Accelerometer-Based Child Activity Recognition via Subject-Independent Adult-Domain Adaption. Wearable activity recognition can collate the type, intensity, and duration of each childs physical activity profile, which is important for exploring underlying adolescent health mechanisms. Traditional machine-learning-based approaches require large labeled data sets; however, child activity data sets are typically small and insufficient. Thus, we proposed a transfer learning approach that adapts adult-domain data to train a high-fidelity, subject-independent model for child activity recognition. Twenty children and twenty adults wore an accelerometer wristband while performing walking, running, sitting, and rope skipping activities. Activity classification accuracy was determined via the traditional machine learning approach without transfer learning and with the proposed subject-independent transfer learning approach. Results showed that transfer learning increased classification accuracy to 91.4% as compared to 80.6% without transfer learning. These results suggest that subject-independent transfer learning can improve accuracy and potentially reduce the size of the required child data sets to enable physical activity monitoring systems to be adopted more widely, quickly, and economically for children and provide deeper insights into injury prevention and health promotion strategies.",0,0
61,"A Machine-learning Based Assessment Method for Early-stage Neurocognitive Impairment by an Immersive Virtual Supermarket. Alzheimer's disease (AD) is a neurodegenerative disorder. Though it is not yet curable or reversible, research has shown that clinical intervention or intensive cognitive training at an early stage may effectively delay the progress of the disease. As a result, screening populations with mild cognitive impairment (MCI) or early AD via efficient, effective and low-cost cognitive assessments is important. Currently, a cognitive assessment relies mostly on cognitive tests, such as the Mini-Mental State Examination (MMSE) or the Montreal Cognitive Assessment (MoCA), which must be performed by therapists. Also, cognitive functions can be divided into a variety of dimensions, such as memory, attention, executive function, visual spatial and so on. Executive functions (EF), also known as executive control or cognitive control, refer to a set of skills necessary to perform higher-order cognitive processes, including working memory, planning, attention, cognitive flexibility, and inhibitory control. Along with the fast progress of virtual reality (VR) and artificial intelligence (AI), this study proposes an intelligent assessment method aimed at assessing executive functions. Utilizing machine learning to develop an automatic evidence-based assessment model, behavioral information is acquired through performing executive-function tasks in a VR supermarket. Clinical trials were performed individuals with MCI or early AD and six healthy participants. Statistical analysis showed that 45 out of 46 indices derived from behavioral information were found to differ significantly between individuals with neurocognitive disorder and healthy participants. This analysis indicates these indices may be potential bio-markers. Further, machine-learning methods were applied to build classifiers that differentiate between individuals with MCI or early AD and healthy participants. The accuracy of the classifier is up to 100%, demonstrating the derived features from the VR system were highly related to diagnosis of individuals with MCI or early AD.",0,0
66,"Deep Learning for nasopharyngeal Carcinoma Identification Using Both White Light and Narrow-Band Imaging Endoscopy. To develop a deep-learning-based automatic diagnosis system for identifying nasopharyngeal carcinoma (NPC) from noncancer (inflammation and hyperplasia), using both white light imaging (WLI) and narrow-band imaging (NBI) nasopharyngoscopy images.",0,0
68,[Early Assessment of Myocardial Fibrosis of Hypertrophic Cardiomyopathy with Native-T1-Mapping-Based Deep Learning: A Preliminary Study]. To explore the diagnostic performance of deep learning (DL) model in early detection of the interstitial myocardial fibrosis using native T1 maps of hypertrophic cardiomyopathy (HCM) without late gadolinium enhancement (LGE).,0,0
70,"[Application of Deep Learning Reconstruction Algorithm in Low-Dose Thin-Slice Liver CT of Healthy Volunteers]. To explore the clinical feasibility of applying deep learning (DL) reconstruction algorithm in low-dose thin-slice liver CT examination of healthy volunteers by comparing the reconstruction algorithm based on DL, filtered back projection (FBP) reconstruction algorithm and iterative reconstruction (IR) algorithm.",0,0
78,"Machine Learning Predictions of Cancer Driver Mutations. A method to predict the activation status of kinase domain mutations in cancer is presented. This method, which makes use of the machine learning technique support vector machines (SVM), has applications to cancer treatment, as well as numerous other diseases that involve kinase misregulation.",0,0
79,"Predicting endometrial cancer subtypes and molecular features from histopathology images using multi-resolution deep learning models. The determination of endometrial carcinoma histological subtypes, molecular subtypes, and mutation status is critical for the diagnostic process, and directly affects patients' prognosis and treatment. Sequencing, albeit slower and more expensive, can provide additional information on molecular subtypes and mutations that can be used to better select treatments. Here, we implement a customized multi-resolution deep convolutional neural network, Panoptes, that predicts not only the histological subtypes but also the molecular subtypes and 18 common gene mutations based on digitized H&E-stained pathological images. The model achieves high accuracy and generalizes well on independent datasets. Our results suggest that Panoptes, with further refinement, has the potential for clinical application to help pathologists determine molecular subtypes and mutations of endometrial carcinoma without sequencing.",0,0
80,"Predictive models of response to neoadjuvant chemotherapy in muscle-invasive bladder cancer using nuclear morphology and tissue architecture. Characterizing likelihood of response to neoadjuvant chemotherapy (NAC) in muscle-invasive bladder cancer (MIBC) is an important yet unmet challenge. In this study, a machine-learning framework is developed using imaging of biopsy pathology specimens to generate models of likelihood of NAC response. Developed using cross-validation (evaluable NÂ = 66) and an independent validation cohort (evaluable NÂ = 56), our models achieve promising results (65%-73% accuracy). Interestingly, one model-using features derived from hematoxylin and eosin (H&E)-stained tissues in conjunction with clinico-demographic features-is able to stratify the cohort into likely responders in cross-validation and the validation cohort (response rate of 65% for predicted responder compared with the 41% baseline response rate in the validation cohort). The results suggest that computational approaches applied to routine pathology specimens of MIBC can capture differences between responders and non-responders to NAC and should therefore be considered in the future design of precision oncology for MIBC.",0,0
81,"Extracellular vesicles as distinct biomarker reservoirs for mild traumatic brain injury diagnosis. Mild traumatic brain injury does not currently have a clear molecular diagnostic panel to either confirm the injury or to guide its treatment. Current biomarkers for traumatic brain injury rely mainly on detecting circulating proteins in blood that are associated with degenerating neurons, which are less common in mild traumatic brain injury, or with broad inflammatory cascades which are produced in multiple tissues and are thus not brain specific. To address this issue, we conducted an observational cohort study designed to measure a protein panel in two compartments-plasma and brain-derived extracellular vesicles-with the following hypotheses: (i) each compartment provides independent diagnostic information and (ii) algorithmically combining these compartments accurately classifies clinical mild traumatic brain injury. We evaluated this hypothesis using plasma samples from mild (Glasgow coma scale scores 13-15) traumatic brain injury patients (<i>nâ€‰</i>=<i>â€‰</i>47) and healthy and orthopaedic control subjects (<i>nâ€‰</i>=<i>â€‰</i>46) to evaluate biomarkers in brain-derived extracellular vesicles and plasma. We used our Track Etched Magnetic Nanopore technology to isolate brain-derived extracellular vesicles from plasma based on their expression of GluR2, combined with the ultrasensitive digital enzyme-linked immunosorbent assay technique, Single-Molecule Array. We quantified extracellular vesicle-packaged and plasma levels of biomarkers associated with two categories of traumatic brain injury pathology: neurodegeneration and neuronal/glial damage (ubiquitin C-terminal hydrolase L1, glial fibrillary acid protein, neurofilament light and Tau) and inflammation (interleukin-6, interleukin-10 and tumour necrosis factor alpha). We found that GluR2+ extracellular vesicles have distinct biomarker distributions than those present in the plasma. As a proof of concept, we showed that using a panel of biomarkers comprised of both plasma and GluR2+ extracellular vesicles, injured patients could be accurately classified versus non-injured patients.",0,0
91,A fully deep learning model for the automatic identification of cephalometric landmarks. This study aimed to propose a fully automatic landmark identification model based on a deep learning algorithm using real clinical data and to verify its accuracy considering inter-examiner variability.,0,0
93,"Interactive Machine Learning-Based Multi-Label Segmentation of Solid Tumors and Organs. We seek the development and evaluation of a fast, accurate, and consistent method for general-purpose segmentation, based on interactive machine learning (IML). To validate our method, we identified retrospective cohorts of 20 brain, 50 breast, and 50 lung cancer patients, as well as 20 spleen scans, with corresponding ground truth annotations. Utilizing very brief user training annotations and the adaptive geodesic distance transform, an ensemble of SVMs is trained, providing a patient-specific model applied to the whole image. Two experts segmented each cohort twice with our method and twice manually. The IML method was faster than manual annotation by 53.1% on average. We found significant (<i>p</i> < 0.001) overlap difference for spleen (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.91/0.87), breast tumors (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.84/0.82), and lung nodules (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.78/0.83). For intra-rater consistency, a significant (<i>p</i> = 0.003) difference was found for spleen (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.91/0.89). For inter-rater consistency, significant (<i>p</i> < 0.045) differences were found for spleen (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.91/0.87), breast (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.86/0.81), lung (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.85/0.89), the non-enhancing (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.79/0.67) and the enhancing (Dice<sub>IML</sub>/Dice<sub>Manual</sub> = 0.79/0.84) brain tumor sub-regions, which, in aggregation, favored our method. Quantitative evaluation for speed, spatial overlap, and consistency, reveals the benefits of our proposed method when compared with manual annotation, for several clinically relevant problems. We publicly release our implementation through CaPTk (Cancer Imaging Phenomics Toolkit) and as an MITK plugin.",1,1
99,"Facial Emotion Recognition Predicts Alexithymia Using Machine Learning. Alexithymia, as a fundamental notion in the diagnosis of psychiatric disorders, is characterized by deficits in emotional processing and, consequently, difficulties in emotion recognition. Traditional tools for assessing alexithymia, which include interviews and self-report measures, have led to inconsistent results due to some limitations as insufficient insight. Therefore, the purpose of the present study was to propose a new screening tool that utilizes machine learning models based on the scores of facial emotion recognition task.",0,0
106,"Intelligent Dermatologist Tool for Classifying Multiple Skin Cancer Subtypes by Incorporating Manifold Radiomics Features Categories. The rates of skin cancer (SC) are rising every year and becoming a critical health issue worldwide. SC's early and accurate diagnosis is the key procedure to reduce these rates and improve survivability. However, the manual diagnosis is exhausting, complicated, expensive, prone to diagnostic error, and highly dependent on the dermatologist's experience and abilities. Thus, there is a vital need to create automated dermatologist tools that are capable of accurately classifying SC subclasses. Recently, artificial intelligence (AI) techniques including machine learning (ML) and deep learning (DL) have verified the success of computer-assisted dermatologist tools in the automatic diagnosis and detection of SC diseases. Previous AI-based dermatologist tools are based on features which are either high-level features based on DL methods or low-level features based on handcrafted operations. Most of them were constructed for binary classification of SC. This study proposes an intelligent dermatologist tool to accurately diagnose multiple skin lesions automatically. This tool incorporates manifold radiomics features categories involving high-level features such as ResNet-50, DenseNet-201, and DarkNet-53 and low-level features including discrete wavelet transform (DWT) and local binary pattern (LBP). The results of the proposed intelligent tool prove that merging manifold features of different categories has a high influence on the classification accuracy. Moreover, these results are superior to those obtained by other related AI-based dermatologist tools. Therefore, the proposed intelligent tool can be used by dermatologists to help them in the accurate diagnosis of the SC subcategory. It can also overcome manual diagnosis limitations, reduce the rates of infection, and enhance survival rates.",0,0
112,"Prediction of osteoporosis from simple hip radiography using deep learning algorithm. Despite being the gold standard for diagnosis of osteoporosis, dual-energy X-ray absorptiometry (DXA) could not be widely used as a screening tool for osteoporosis. This study aimed to predict osteoporosis via simple hip radiography using deep learning algorithm. A total of 1001 datasets of proximal femur DXA with matched same-side cropped simple hip bone radiographic images of female patients agedâ€‰â‰¥â€‰55Â years were collected. Of these, 504 patients had osteoporosis (T-scoreâ€‰â‰¤ -Â 2.5), and 497 patients did not have osteoporosis. The 1001 images were randomly divided into three sets: 800 images for the training, 100 images for the validation, and 101 images for the test. Based on VGG16 equipped with nonlocal neural network, we developed a deep neural network (DNN) model. We calculated the confusion matrix and evaluated the accuracy, sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). We drew the receiver operating characteristic (ROC) curve. A gradient-based class activation map (Grad-CAM) overlapping the original image was also used to visualize the model performance. Additionally, we performed external validation using 117 datasets. Our final DNN model showed an overall accuracy of 81.2%, sensitivity of 91.1%, and specificity of 68.9%. The PPV was 78.5%, and the NPV was 86.1%. The area under the ROC curve value was 0.867, indicating a reasonable performance for screening osteoporosis by simple hip radiography. The external validation set confirmed a model performance with an overall accuracy of 71.8% and an AUC value of 0.700. All Grad-CAM results from both internal and external validation sets appropriately matched the proximal femur cortex and trabecular patterns of the radiographs. The DNN model could be considered as one of the useful screening tools for easy prediction of osteoporosis in the real-world clinical setting.",0,0
118,"A bioinspired neural architecture search based convolutional neural network for breast cancer detection using histopathology images. The design of neural architecture to address the challenge of detecting abnormalities in histopathology images can leverage the gains made in the field of neural architecture search (NAS). The NAS model consists of a search space, search strategy and evaluation strategy. The approach supports the automation of deep learning (DL) based networks such as convolutional neural networks (CNN). Automating the process of CNN architecture engineering using this approach allows for finding the best performing network for learning classification problems in specific domains and datasets. However, the engineering process of NAS is often limited by the potential solutions in search space and the search strategy. This problem often narrows the possibility of obtaining best performing networks for challenging tasks such as the classification of breast cancer in digital histopathological samples. This study proposes a NAS model with a novel search space initialization algorithm and a new search strategy. We designed a block-based stochastic categorical-to-binary (BSCB) algorithm for generating potential CNN solutions into the search space. Also, we applied and investigated the performance of a new bioinspired optimization algorithm, namely the Ebola optimization search algorithm (EOSA), for the search strategy. The evaluation strategy was achieved through computation of loss function, architectural latency and accuracy. The results obtained using images from the BACH and BreakHis databases showed that our approach obtained best performing architectures with the top-5 of the architectures yielding a significant detection rate. The top-1 CNN architecture demonstrated a state-of-the-art performance of base on classification accuracy. The NAS strategy applied in this study and the resulting candidate architecture provides researchers with the most appropriate or suitable network configuration for using digital histopathology.",0,0
119,"Multi-omics driven predictions of response to acute phase combination antidepressant therapy: a machine learning approach with cross-trial replication. Combination antidepressant pharmacotherapies are frequently used to treat major depressive disorder (MDD). However, there is no evidence that machine learning approaches combining multi-omics measures (e.g., genomics and plasma metabolomics) can achieve clinically meaningful predictions of outcomes to combination pharmacotherapy. This study examined data from 264 MDD outpatients treated with citalopram or escitalopram in the Mayo Clinic Pharmacogenomics Research Network Antidepressant Medication Pharmacogenomic Study (PGRN-AMPS) and 111 MDD outpatients treated with combination pharmacotherapies in the Combined Medications to Enhance Outcomes of Antidepressant Therapy (CO-MED) study to predict response to combination antidepressant therapies. To assess whether metabolomics with functionally validated single-nucleotide polymorphisms (SNPs) improves predictability over metabolomics alone, models were trained/tested with and without SNPs. Models trained with PGRN-AMPS' and CO-MED's escitalopram/citalopram patients predicted response in CO-MED's combination pharmacotherapy patients with accuracies of 76.6% (pâ€‰<â€‰0.01; AUC: 0.85) without and 77.5% (pâ€‰<â€‰0.01; AUC: 0.86) with SNPs. Then, models trained solely with PGRN-AMPS' escitalopram/citalopram patients predicted response in CO-MED's combination pharmacotherapy patients with accuracies of 75.3% (pâ€‰<â€‰0.05; AUC: 0.84) without and 77.5% (pâ€‰<â€‰0.01; AUC: 0.86) with SNPs, demonstrating cross-trial replication of predictions. Plasma hydroxylated sphingomyelins were prominent predictors of treatment outcomes. To explore the relationship between SNPs and hydroxylated sphingomyelins, we conducted multi-omics integration network analysis. Sphingomyelins clustered with SNPs and metabolites related to monoamine neurotransmission, suggesting a potential functional relationship. These results suggest that integrating specific metabolites and SNPs achieves accurate predictions of treatment response across classes of antidepressants. Finally, these results motivate functional investigation into how sphingomyelins might influence MDD pathophysiology, antidepressant response, or both.",0,0
122,Comparing machine learning to a rule-based approach for predicting suicidal behavior among adolescents: Results from a longitudinal population-based survey. Suicidal thoughts and suicide attempts are one of the most prominent public health concerns in adolescents and therefore early detection is important to initiate preventive interventions and closer monitoring.,1,1
125,Subphenotyping of Patients With Aortic Stenosis by Unsupervised Agglomerative Clustering of Echocardiographic and Hemodynamic Data. The aim of this retrospective analysis was to categorize patients with severe aortic stenosis (AS) according to clinical presentation by applying unsupervised machine learning.,0,0
126,"Explainable machine learning model to predict refeeding hypophosphatemia. Refeeding syndrome (RFS) is a disease that occurs when feeding is restarted and metabolism changes from catabolic to anabolic status. RFS can manifest variously, ranging from asymptomatic to fatal, therefore it may easily be overlooked. RFS prediction using explainable machine learning can improve diagnosis and treatment. Our study aimed to propose a machine learning model for RFS prediction, specifically refeeding hypophosphatemia, to evaluate its performance compared with conventional regression models, and to explain the machine learning classification through Shapley additive explanations (SHAP) values.",0,0
127,"Machine learning algorithms for predicting undernutrition among under-five children in Ethiopia. Child undernutrition is a global public health problem with serious implications. In this study, estimate predictive algorithms for the determinants of childhood stunting by using various machine learning (ML) algorithms.",0,0
129,"A machine learning model to predict critical care outcomes in patient with chest pain visiting the emergency department. Currently, the risk stratification of critically ill patient with chest pain is a challenge. We aimed to use machine learning approach to predict the critical care outcomes in patients with chest pain, and simultaneously compare its performance with HEART, GRACE, and TIMI scores.",1,1
133,"[A novel attention fusion network-based multiple instance learning framework to automate diagnosis of chronic gastritis with multiple indicators]. <b>Objective:</b> To explore the performance of the attention-multiple instance learning (MIL) framework, an attention fusion network-based MIL, in the automated diagnosis of chronic gastritis with multiple indicators. <b>Methods:</b> A total of 1 015 biopsy cases of gastritis diagnosed in Fudan University Cancer Hospital, Shanghai, China and 115 biopsy cases of gastritis diagnosed in Shanghai Pudong Hospital, Shanghai, China were collected from January 1st to December 31st in 2018. All pathological sections were digitally converted into whole slide imaging (WSI). The WSI label was based on the corresponding pathological report, including ""activity"" ""atrophy"" and ""intestinal metaplasia"". The WSI were divided into a training set, a single test set, a mixed test set and an independent test set. The accuracy of automated diagnosis for the Attention-MIL model was validated in three test sets. <b>Results:</b> The area under receive-operator curve (AUC) values of Attention-MIL model in single test sets of 240 WSI were: activity 0.98, atrophy 0.89, and intestinal metaplasia 0.98; the average accuracy of the three indicators was 94.2%. The AUC values in mixed test sets of 117 WSI were: activity 0.95, atrophy 0.86, and intestinal metaplasia 0.94; the average accuracy of the three indicators was 88.3%. The AUC values in independent test sets of 115 WSI were: activity 0.93, atrophy 0.84, and intestinal metaplasia 0.90; the average accuracy of the three indicators was 85.5%. <b>Conclusions:</b> To assist in pathological diagnosis of chronic gastritis, the diagnostic accuracy of Attention-MIL model is very close to that of pathologists. Thus, it is suitable for practical application of artificial intelligence technology.",1,0
137,"Unsupervised domain adaptation model for lesion detection in retinal OCT images. Background and objective Optical Coherence Tomography (OCT) is one of the most used retinal imaging modalities in the clinic as it can provide high-resolution anatomical images. The huge number of OCT images has significantly advanced the development of deep learning methods for automatic lesion detection to ease the doctor's workload. However, it has been frequently revealed that the deep neural network (DNN) model has difficulty handling the domain discrepancies, which widely exist in medical images captured from different devices. Many works have been proposed to solve the domain shift issue in deep learning tasks such as disease classification and lesion segmentation, but few works focused on lesion detection, especially for OCT images. Methods In this work, we proposed a faster-RCNN based, unsupervised domain adaptation model to address the lesion detection task in cross-device retinal OCT images. The domain shift is minimized by reducing the image-level shift and instance-level shift at the same time. We combined a domain classifier with a Wasserstein distance (WD) critic to align the shifts at each level. Results The model was tested on two sets of OCT image data captured from different devices, obtained an average accuracy improvement of more than 8% over the method without domain adaptation, and outperformed other comparable domain adaptation methods. Conclusion The results demonstrate the proposed model is more effective in reducing the domain shift than advanced methods.",0,0
138,"Personalised predictive modelling with brain-inspired spiking neural networks of longitudinal MRI neuroimaging data and the case study of dementia. Longitudinal neuroimaging provides spatiotemporal brain data (STBD) measurement that can be utilised to understand dynamic changes in brain structure and/or function underpinning cognitive activities. Making sense of such highly interactive information is challenging, given that the features manifest intricate temporal, causal relations between the spatially distributed neural sources in the brain.",0,0
139,Machine learning to predict individual patient-reported outcomes at 2-year follow-up for women undergoing cancer-related mastectomy and breast reconstruction (INSPiRED-001). Women undergoing cancer-related mastectomy and reconstruction are facing multiple treatment choices where post-surgical satisfaction with breasts is a key outcome. We developed and validated machine learning algorithms to predict patient-reported satisfaction with breasts at 2-year follow-up to better inform the decision-making process for women with breast cancer.,0,0
140,"Examining the predictability and prognostication of multimorbidity among older Delayed-Discharge Patients: A Machine learning analytics. Patient complexity among older delayed-discharge patients complicates discharge planning, resulting in a higher rate of adverse outcomes, such as readmission and mortality. Early prediction of multimorbidity, as a common indicator of patient complexity, can support proactive discharge planning by prioritizing complex patients and reducing healthcare inefficiencies.",0,0
142,Identifying the neurophysiological effects of memory-enhancing amygdala stimulation using interpretable machine learning. Direct electrical stimulation of the amygdala can enhance declarative memory for specific events. An unanswered question is what underlying neurophysiological changes are induced by amygdala stimulation.,0,0
144,"A Deep-Learning Algorithm-Enhanced System Integrating Electrocardiograms and Chest X-rays for Diagnosing Aortic Dissection. Chest pain is the most common symptom of aortic dissection (AD), but it is often confused with other prevalent cardiopulmonary diseases. We aimed to develop deep-learning models (DLMs) with ECG and CXR features to detect AD and evaluate their performance.",0,0
145,"Prediction of GABA receptor antagonist-induced convulsion in cynomolgus monkeys by combining machine learning and heart rate variability analysis. Drug-induced convulsion is a severe adverse event; however, no useful biomarkers for it have been discovered. We propose a new method for predicting drug-induced convulsions in monkeys based on heart rate variability (HRV) and a machine learning technique. Because autonomic nervous activities are altered around the time of a convulsion and such alterations affect HRV, they may be predicted by monitoring HRV. In the proposed method, anomalous changes in multiple HRV parameters are monitored by means of a convulsion prediction model, and convulsion alarms are issued when abnormal changes in HRV are detected. The convulsion prediction model is constructed based on multivariate statistical process control (MSPC), a well-known anomaly detection algorithm in machine learning. In this study, HRV data were collected from four cynomolgus monkeys administered with multiple doses of pentylenetetrazol (PTZ) and picrotoxin (PTX), which are GABA receptor antagonists, as convulsant agents. In addition, low doses of pilocarpine (PILO) were administered as a negative control. Twelve HRV parameters in three hours after drug administration were monitored by means of the prediction model. The number and duration of convulsion alarms from HRV increased at medium and high doses of PTZ and PTX (1/3 or 1/4 of convulsion dose). On the other hand, the frequency of convulsion alarms did not increase with PILO. Although vomiting was observed in all drugs, convulsion alarms were not associated with the vomiting. Thus, convulsion alarms can be used as a biomarker for convulsions induced by GABA receptor antagonists.",0,0
146,"Digital Gonioscopy based on Three-dimensional Anterior Segment Optical Coherence Tomography: an international multicenter study. To develop and evaluate the performance of a three-dimensional deep-learning based automated digital gonioscopy system (3D DGS) in detecting two major characteristics in eyes suspected to have primary angle closure glaucoma (PACG): 1) narrow iridocorneal angles (static gonioscopy, Task I) and; 2) peripheral anterior synechiae (PAS) (dynamic gonioscopy, Task II) on optical coherence tomography scans.",0,0
154,"Hypotension Prediction Index with non-invasive continuous arterial pressure waveforms (ClearSight): clinical performance in Gynaecologic Oncologic Surgery. Intraoperative hypotension (IOH) is common during major surgery and is associated with a poor postoperative outcome. Hypotension Prediction Index (HPI) is an algorithm derived from machine learning that uses the arterial waveform to predict IOH. The aim of this study was to assess the diagnostic ability of HPI working with non-invasive ClearSight system in predicting impending hypotension in patients undergoing major gynaecologic oncologic surgery (GOS). In this retrospective analysis hemodynamic data were downloaded from an Edwards Lifesciences HemoSphere platform and analysed. Receiver operating characteristic curves were constructed to evaluate the performance of HPI working on the ClearSight pressure waveform in predicting hypotensive events, defined as mean arterial pressure <â€‰65Â mmHg forâ€‰>â€‰1Â min. Sensitivity, specificity, positive predictive value and negative predictive value were computed at a cutpoint (the value which minimizes the difference between sensitivity and specificity). Thirty-one patients undergoing GOS were included in the analysis, 28 of which had complete data set. The HPI predicted hypotensive events with a sensitivity of 0.85 [95% confidence interval (CI) 0.73-0.94] and specificity of 0.85 (95% CI 0.74-0.95) 15Â min before the event [area under the curve (AUC) 0.95 (95% CI 0.89-0.99)]; with a sensitivity of 0.82 (95% CI 0.71-0.92) and specificity of 0.83 (95% CI 0.71-0.93) 10Â min before the event [AUC 0.9 (95% CI 0.83-0.97)]; and with a sensitivity of 0.86 (95% CI 0.78-0.93) and specificity 0.86 (95% CI 0.77-0.94) 5Â min before the event [AUC 0.93 (95% CI 0.89-0.97)]. HPI provides accurate and continuous prediction of impending IOH before its occurrence in patients undergoing GOS in general anesthesia.",0,0
156,"Acral melanoma detection using dermoscopic images and convolutional neural networks. Acral melanoma (AM) is a rare and lethal type of skin cancer. It can be diagnosed by expert dermatologists, using dermoscopic imaging. It is challenging for dermatologists to diagnose melanoma because of the very minor differences between melanoma and non-melanoma cancers. Most of the research on skin cancer diagnosis is related to the binary classification of lesions into melanoma and non-melanoma. However, to date, limited research has been conducted on the classification of melanoma subtypes. The current study investigated the effectiveness of dermoscopy and deep learning in classifying melanoma subtypes, such as, AM. In this study, we present a novel deep learning model, developed to classify skin cancer. We utilized a dermoscopic image dataset from the Yonsei University Health System South Korea for the classification of skin lesions. Various image processing and data augmentation techniques have been applied to develop a robust automated system for AM detection. Our custom-built model is a seven-layered deep convolutional network that was trained from scratch. Additionally, transfer learning was utilized to compare the performance of our model, where AlexNet and ResNet-18 were modified, fine-tuned, and trained on the same dataset. We achieved improved results from our proposed model with an accuracy of more than 90â€‰% for AM and benign nevus, respectively. Additionally, using the transfer learning approach, we achieved an average accuracy of nearly 97â€‰%, which is comparable to that of state-of-the-art methods. From our analysis and results, we found that our model performed well and was able to effectively classify skin cancer. Our results show that the proposed system can be used by dermatologists in the clinical decision-making process for the early diagnosis of AM.",0,0
165,"Detecting Subclinical Social Anxiety Using Physiological Data From a Wrist-Worn Wearable: Small-Scale Feasibility Study. Subclinical (ie, threshold) social anxiety can greatly affect young people's lives, but existing solutions appear inadequate considering its rising prevalence. Wearable sensors may provide a novel way to detect social anxiety and result in new opportunities for monitoring and treatment, which would be greatly beneficial for persons with social anxiety, society, and health care services. Nevertheless, indicators such as skin temperature measured by wrist-worn sensors have not been used in prior work on physiological social anxiety detection.",0,0
166,"Cross-Modal Cortical Activity in the Brain Can Predict Cochlear Implantation Outcome in Adults: A Machine Learning Study. Prediction of cochlear implantation (CI) outcome is often difficult because outcomes vary among patients. Though the brain plasticity across modalities during deafness is associated with individual CI outcomes, longitudinal observations in multiple patients are scarce. Therefore, we sought a prediction system based on cross-modal plasticity in a longitudinal study with multiple patients.",0,0
168,"A Clinical Study to Evaluate Autofluorescence Imaging of Diabetic Foot Ulcers Using a Novel Artificial Intelligence Enabled Noninvasive Device. Diabetic foot ulcers, with worldwide prevalence ranging from 12%-25%, are an important cause of nontraumatic lower limb amputation. Evidence-based assessment of early infection can help the clinician provide the right first line treatment thus helping improve the wound closure rate. Illuminate<sup>Â®</sup>, a novel point of care device working on multispectral autofluorescence imaging, helps in the rapid identification and classification of bacteria. This study was aimed to evaluate the diagnostic accuracy of the device in detecting bacterial gram type against standard culture methods. A total of 178 patients from a tertiary care center for diabetes was recruited and 203 tissue samples were obtained from the wound base by the plastic surgeon. The device was handled by the trained investigator to take wound images. The tissue samples were taken from the color-coded infected region as indicated by the device's Artificial Intelligence algorithm and sent for microbial assessment. The results were compared against the Gram type inferred by the device and the device was found to have an accuracy of 89.54%, a positive predictive value of 86.27% for detecting Gram-positive bacteria, 80.77% for Gram-negative bacteria, and 91.67% for no infection. The negative predictive value corresponded to 87.25% for Gram-positive, 92% for Gram-negative, and 96.12% for no infection. The Results exhibited the accuracy of this novel autofluorescence device in identifying and classifying the gram type of bacteria and its potential in significantly aiding clinicians towards early infection assessment and treatment.",1,1
169,Clinical evaluation of AI software for rib fracture detection and its impact on junior radiologist performance. The detection of rib fractures (RFs) on computed tomography (CT) images is time-consuming and susceptible to missed diagnosis. An automated artificial intelligence (AI) detection system may be helpful to improve the diagnostic efficiency for junior radiologists.,1,1
178,"Prediction of liver Dmean for proton beam therapy using deep learning and contour-based data augmentation. The prediction of liver Dmean with 3-dimensional radiation treatment planning (3DRTP) is time consuming in the selection of proton beam therapy (PBT), and deep learning prediction generally requires large and tumor-specific databases. We developed a simple dose prediction tool (SDP) using deep learning and a novel contour-based data augmentation (CDA) approach and assessed its usability. We trained the SDP to predict the liver Dmean immediately. Five and two computed tomography (CT) data sets of actual patients with liver cancer were used for the training and validation. Data augmentation was performed by artificially embedding 199 contours of virtual clinical target volume (CTV) into CT images for each patient. The data sets of the CTVs and OARs are labeled with liver Dmean for six different treatment plans using two-dimensional calculations assuming all tissue densities as 1.0. The test of the validated model was performed using 10 unlabeled CT data sets of actual patients. Contouring only of the liver and CTV was required as input. The mean relative error (MRE), the mean percentage error (MPE) and regression coefficient between the planned and predicted Dmean was 0.1637, 6.6%, and 0.9455, respectively. The mean time required for the inference of liver Dmean of the six different treatment plans for a patient was 4.47Â±0.13 seconds. We conclude that the SDP is cost-effective and usable for gross estimation of liver Dmean in the clinic although the accuracy should be improved further if we need the accuracy of liver Dmean to be compatible with 3DRTP.",0,0
179,"Machine deep learning accurately detects endoleak after endovascular abdominal aortic aneurysm repair. The objective of this study was to develop a machine deep learning algorithm for endoleak detection and measurement of aneurysm diameter, area, and volume from computed tomography angiography (CTA).",0,0
185,"MRI-based Identification and Classification of Major Intracranial Tumor Types by Using a 3D Convolutional Neural Network: A Retrospective Multi-institutional Analysis. To develop an algorithm to classify postcontrast T1-weighted MRI scans by tumor classes (high-grade glioma, low-grade glioma [LGG], brain metastasis, meningioma, pituitary adenoma, and acoustic neuroma) and a healthy tissue (HLTH) class.",0,0
187,Feasibility of Simulated Postcontrast MRI of Glioblastomas and Lower-Grade Gliomas by Using Three-dimensional Fully Convolutional Neural Networks. To evaluate the feasibility and accuracy of simulated postcontrast T1-weighted brain MR images generated by using precontrast MR images in patients with brain glioma.,0,0
188,Development and Evaluation of a Deep Learning Algorithm for Rib Segmentation and Fracture Detection from Multicenter Chest CT Images. To evaluate the performance of a deep learning-based algorithm for automatic detection and labeling of rib fractures from multicenter chest CT images.,0,0
190,Automated Segmentation and Volume Measurement of Intracranial Internal Carotid Artery Calcification at Noncontrast CT. To develop and evaluate a fully-automated deep learning-based method for assessment of intracranial internal carotid artery calcification (ICAC).,0,0
192,Landmark Detection in Cardiac MRI by Using a Convolutional Neural Network. To develop a convolutional neural network (CNN) solution for landmark detection in cardiac MRI (CMR).,0,0
193,"Accelerated Brain Aging in Amnestic Mild Cognitive Impairment: Relationships with Individual Cognitive Decline, Risk Factors for Alzheimer Disease, and Clinical Progression. To determine whether a brain age prediction model could quantify individual deviations from a healthy brain-aging trajectory (predicted age difference [PAD]) in patients with amnestic mild cognitive impairment (aMCI) and to determine if PAD was associated with individual cognitive impairment.",0,0
194,Synthesizing Quantitative T2 Maps in Right Lateral Knee Femoral Condyles from Multicontrast Anatomic Data with a Conditional Generative Adversarial Network. To develop a proof-of-concept convolutional neural network (CNN) to synthesize T2 maps in right lateral femoral condyle articular cartilage from anatomic MR images by using a conditional generative adversarial network (cGAN).,0,0
198,"Real-Time Gait Phase Estimation for Robotic Hip Exoskeleton Control During Multimodal Locomotion. We developed and validated a gait phase estimator for real-time control of a robotic hip exoskeleton during multimodal locomotion. Gait phase describes the fraction of time passed since the previous gait event, such as heel strike, and is a promising framework for appropriately applying exoskeleton assistance during cyclic tasks. A conventional method utilizes a mechanical sensor to detect a gait event and uses the time since the last gait event to linearly interpolate the current gait phase. While this approach may work well for constant treadmill walking, it shows poor performance when translated to overground situations where the user may change walking speed and locomotion modes dynamically. To tackle these challenges, we utilized a convolutional neural network-based gait phase estimator that can adapt to different locomotion mode settings to modulate the exoskeleton assistance. Our resulting model accurately predicted the gait phase during multimodal locomotion without any additional information about the user's locomotion mode, with a gait phase estimation RMSE of 5.04 Â± 0.79%, significantly outperforming the literature standard (<i>p</i> < 0.05). Our study highlights the promise of translating exoskeleton technology to more realistic settings where the user can naturally and seamlessly navigate through different terrain settings.",0,0
207,"An ensemble machine learning model based on multiple filtering and supervised attribute clustering algorithm for classifying cancer samples. Machine learning is one kind of machine intelligence technique that learns from data and detects inherent patterns from large, complex datasets. Due to this capability, machine learning techniques are widely used in medical applications, especially where large-scale genomic and proteomic data are used. Cancer classification based on bio-molecular profiling data is a very important topic for medical applications since it improves the diagnostic accuracy of cancer and enables a successful culmination of cancer treatments. Hence, machine learning techniques are widely used in cancer detection and prognosis.",0,0
213,"Blockchain-Secured Recommender System for Special Need Patients Using Deep Learning. Recommender systems offer several advantages to hospital data management units and patients with special needs. These systems are more dependent on the extreme subtle hospital-patient data. Thus, disregarding the confidentiality of patients with special needs is not an option. In recent times, several proposed techniques failed to cryptographically guarantee the data privacy of the patients with special needs in the diet recommender systems (RSs) deployment. In order to tackle this pitfall, this paper incorporates a blockchain privacy system (BPS) into deep learning for a diet recommendation system for patients with special needs. Our proposed technique allows patients to get notifications about recommended treatments and medications based on their personalized data without revealing their confidential information. Additionally, the paper implemented machine and deep learning algorithms such as RNN, Logistic Regression, MLP, etc., on an Internet of Medical Things (IoMT) dataset acquired <i>via</i> the internet and hospitals that comprises the data of 50 patients with 13 features of various diseases and 1,000 products. The product section has a set of eight features. The IoMT data features were analyzed with BPS and further encoded prior to the application of deep and machine learning-based frameworks. The performance of the different machine and deep learning methods were carried out and the results verify that the long short-term memory (LSTM) technique is more effective than other schemes regarding prediction accuracy, precision, F1-measures, and recall in a secured blockchain privacy system. Results showed that 97.74% accuracy utilizing the LSTM deep learning model was attained. The precision of 98%, recall, and F1-measure of 99% each for the allowed class was also attained. For the disallowed class, the scores were 89, 73, and 80% for precision, recall, and F1-measure, respectively. The performance of our proposed BPS is subdivided into two categories: the secured communication channel of the recommendation system and an enhanced deep learning approach using health base medical dataset that spontaneously identifies what food a patient with special needs should have based on their disease and certain features including gender, weight, age, etc. The proposed system is outstanding as none of the earlier revised works of literature described a recommender system of this kind.",0,0
217,"An Automatic Knee Osteoarthritis Diagnosis Method Based on Deep Learning: Data from the Osteoarthritis Initiative. Osteoarthritis (OA) is the most common form of arthritis. According to the evidence presented on both sides of the knee bones, radiologists assess the severity of OA based on the Kellgren-Lawrence (KL) grading system. Recently, computer-aided methods are proposed to improve the efficiency of OA diagnosis. However, the human interventions required by previous semiautomatic segmentation methods limit the application on large-scale datasets. Moreover, well-known CNN architectures applied to the OA severity assessment do not explore the relations between different local regions. In this work, by integrating the object detection model, YOLO, with the visual transformer into the diagnosis procedure, we reduce human intervention and provide an end-to-end approach to automatic osteoarthritis diagnosis. Our approach correctly segments 95.57% of data at the expense of training on 200 annotated images on a large dataset that contains more than 4500 samples. Furthermore, our classification result improves the accuracy by 2.5% compared to the traditional CNN architectures.",0,0
227,"Classification of Alzheimer's Disease Leveraging Multi-task Machine Learning Analysis of Speech and Eye-Movement Data. Alzheimer's disease (AD) is a progressive neurodegenerative condition that results in impaired performance in multiple cognitive domains. Preclinical changes in eye movements and language can occur with the disease, and progress alongside worsening cognition. In this article, we present the results from a machine learning analysis of a novel multimodal dataset for AD classification. The cohort includes data from two novel tasks not previously assessed in classification models for AD (pupil fixation and description of a pleasant past experience), as well as two established tasks (picture description and paragraph reading). Our dataset includes language and eye movement data from 79 memory clinic patients with diagnoses of mild-moderate AD, mild cognitive impairment (MCI), or subjective memory complaints (SMC), and 83 older adult controls. The analysis of the individual novel tasks showed similar classification accuracy when compared to established tasks, demonstrating their discriminative ability for memory clinic patients. Fusing the multimodal data across tasks yielded the highest overall AUC of 0.83 Â± 0.01, indicating that the data from novel tasks are complementary to established tasks.",0,0
234,"Machine learning identifies the independent role of dysplasia in the prediction of response to chemotherapy in AML. The independent prognostic impact of specific dysplastic features in acute myeloid leukemia (AML) remains controversial and may vary between genomic subtypes. We apply a machine learning framework to dissect the relative contribution of centrally reviewed dysplastic features and oncogenetics in 190 patients with de novo AML treated in ALFA clinical trials. One hundred and thirty-five (71%) patients achieved complete response after the first induction course (CR). Dysgranulopoiesis, dyserythropoiesis and dysmegakaryopoiesis were assessable in 84%, 83% and 63% patients, respectively. Multi-lineage dysplasia was present in 27% of assessable patients. Micromegakaryocytes (qâ€‰=â€‰0.01), hypolobulated megakaryocytes (qâ€‰=â€‰0.08) and hyposegmented granulocytes (qâ€‰=â€‰0.08) were associated with higher ELN-2017 risk. Using a supervised learning algorithm, the relative importance of morphological variables (34%) for the prediction of CR was higher than demographic (5%), clinical (2%), cytogenetic (25%), molecular (29%), and treatment (5%) variables. Though dysplasias had limited predictive impact on survival, a multivariate logistic regression identified the presence of hypolobulated megakaryocytes (pâ€‰=â€‰0.014) and micromegakaryocytes (pâ€‰=â€‰0.035) as predicting lower CR rates, independently of monosomy 7 (pâ€‰=â€‰0.013), TP53 (pâ€‰=â€‰0.004), and NPM1 mutations (pâ€‰=â€‰0.025). Assessment of these specific dysmegakarypoiesis traits, for which we identify a transcriptomic signature, may thus guide treatment allocation in AML.",0,0
240,Anterior segment biometric measurements explain misclassifications by a deep learning classifier for detecting gonioscopic angle closure. To identify biometric parameters that explain misclassifications by a deep learning classifier for detecting gonioscopic angle closure in anterior segment optical coherence tomography (AS-OCT) images.,0,0
242,Prediction of oral squamous cell carcinoma based on machine learning of breath samples: a prospective controlled study. The aim of this study was to evaluate the possibility of breath testing as a method of cancer detection in patients with oral squamous cell carcinoma (OSCC).,0,0
271,"Retrospective identification of latent subgroups of emergency department patients: A machine learning approach. This research aims to (i) identify latent subgroups of ED presentations in Australian public EDs using a data-driven approach and (ii) compare clinical, socio-demographic and time-related characteristics of ED presentations broadly using the subgroups.",0,0
272,"NENet: Nested EfficientNet and adversarial learning for joint optic disc and cup segmentation. Glaucoma is an ocular disease threatening irreversible vision loss. Primary screening of Glaucoma involves computation of optic cup (OC) to optic disc (OD) ratio that is widely accepted metric. Recent deep learning frameworks for OD and OC segmentation have shown promising results and ways to attain remarkable performance. In this paper, we present a novel segmentation network, Nested EfficientNet (NENet) that consists of EfficientNetB4 as an encoder along with a nested network of pre-activated residual blocks, atrous spatial pyramid pooling (ASPP) block and attention gates (AGs). The combination of cross-entropy and dice coefficient (DC) loss is utilized to guide the network for accurate segmentation. Further, a modified patch-based discriminator is designed for use with the NENet to improve the local segmentation details. Three publicly available datasets, REFUGE, Drishti-GS, and RIM-ONE-r3 were utilized to evaluate the performances of the proposed network. In our experiments, NENet outperformed state-of-the-art methods for segmentation of OD and OC. Additionally, we show that NENet has excellent generalizability across camera types and image resolution. The obtained results suggest that the proposed technique has potential to be an important component for an automated Glaucoma screening system.",0,0
274,"Kidney Age Index (KAI): A novel age-related biomarker to estimate kidney function in patients with diabetic kidney disease using machine learning. With aging, patients with diabetic kidney disease (DKD) show progressive decrease in kidney function. We investigated whether the deviation of biological age (BA) from the chronological age (CA) due to DKD can be used (denoted as Kidney Age Index; KAI) to quantify kidney function using machine learning algorithms.",0,0
275,"End-to-end multimodal clinical depression recognition using deep neural networks: A comparative analysis. Major Depressive Disorder is a highly prevalent and disabling mental health condition. Numerous studies explored multimodal fusion systems combining visual, audio, and textual features via deep learning architectures for clinical depression recognition. Yet, no comparative analysis for multimodal depression analysis has been proposed in the literature.",0,0
276,"A novel combined dynamic ensemble selection model for imbalanced data to detect COVID-19 from complete blood count. As blood testing is radiation-free, low-cost and simple to operate, some researchers use machine learning to detect COVID-19 from blood test data. However, few studies take into consideration the imbalanced data distribution, which can impair the performance of a classifier.",0,0
280,Can 3D artificial intelligence models outshine 2D ones in the detection of intracranial metastatic tumors on magnetic resonance images? This study aimed to compare the prediction performance of two-dimensional (2D) and three-dimensional (3D) semantic segmentation models for intracranial metastatic tumors with a volume â‰¥ 0.3â€‰mL.,0,0
290,"Artificial intelligence and infrared thermography as auxiliary tools in the diagnosis of temporomandibular disorder. To assess three machine learning (ML) attribute extraction methods: radiomic, semantic and radiomic-semantic association on temporomandibular disorder (TMD) detection using infrared thermography (IT); and to determine which ML classifier, KNN, SVM and MLP, is the most efficient for this purpose.",0,0
291,Can artificial intelligence replace ultrasound as a complementary tool to mammogram for the diagnosis of the breast cancer? to study the impact of artificial intelligence (AI) on the performance of mammogram with regard to the classification of the detected breast lesions in correlation to ultrasound aided mammograms.,0,0
294,"Active neural networks to detect mentions of changes to medication treatment in social media. We address a first step toward using social media data to supplement current efforts in monitoring population-level medication nonadherence: detecting changes to medication treatment. Medication treatment changes, like changes to dosage or to frequency of intake, that are not overseen by physicians are, by that, nonadherence to medication. Despite the consequences, including worsening health conditions or death, 50% of patients are estimated to not take medications as indicated. Current methods to identify nonadherence have major limitations. Direct observation may be intrusive or expensive, and indirect observation through patient surveys relies heavily on patients' memory and candor. Using social media data in these studies may address these limitations.",0,0
296,"Cast suppression in radiographs by generative adversarial networks. Injured extremities commonly need to be immobilized by casts to allow proper healing. We propose a method to suppress cast superimpositions in pediatric wrist radiographs based on the cycle generative adversarial network (CycleGAN) model. We retrospectively reviewed unpaired pediatric wrist radiographs (n = 9672) and sampled them into 2 equal groups, with and without cast. The test subset consisted of 718 radiographs with cast. We evaluated different quadratic input sizes (256, 512, and 1024 pixels) for U-Net and ResNet-based CycleGAN architectures in cast suppression, quantitatively and qualitatively. The mean age was 11 Â± 3 years in images containing cast (n = 4836), and 11 Â± 4 years in castless samples (n = 4836). A total of 5956 X-rays had been done in males and 3716 in females. A U-Net 512 CycleGAN performed best (P â‰¤ .001). CycleGAN models successfully suppressed casts in pediatric wrist radiographs, allowing the development of a related software tool for radiology image viewers.",0,0
321,"Deep learning enabled classification of real-time respiration signals acquired by MoSSe quantum dot-based flexible sensors. Respiration rate is a vital parameter which is useful for the earlier identification of diseases. In this context, various types of devices have been fabricated and developed to monitor different breath rates. However, the disposability and biocompatibility of such sensors and the poor classification of different breath rates from sensor data are significant issues in medical services. This report attempts to focus on two important things: the classification of respiration signals from sensor data using deep learning and the disposability of devices. The use of the novel Janus MoSSe quantum dot (MoSSe QD) structure allows for stable respiration sensing because of unchanged wear rates under humid conditions, and also, the electron affinity and work function values suggest that MoSSe has a higher tendency to donate electrons and interact with the hydrogen molecule. Furthermore, for the real-time classification of different respiration signals, a 1D convolutional neural network (1D CNN) was incorporated. This algorithm was applied to four different breath patterns which achieved a state-of-the-art 10-trial accuracy of 98.18% for normal, 95.25% for slow, 97.64% for deep, and 98.18% for fast breaths. The successful demonstration of a stable, low-cost, and disposable respiration sensor with a highly accurate classification of signals is a major step ahead in developing wearable respiration sensors for future personal healthcare monitoring systems.",0,0
324,"Machine learning predictive models of LDL-C in the population of eastern India and its comparison with directly measured and calculated LDL-C. LDL-C is a strong risk factor for cardiovascular disorders. The formulas used to calculate LDL-C showed varying performance in different populations. Machine learning models can study complex interactions between the variables and can be used to predict outcomes more accurately. The current study evaluated the predictive performance of three machine learning models-random forests, XGBoost, and support vector Rregression (SVR) to predict LDL-C from total cholesterol, triglyceride, and HDL-C in comparison to linear regression model and some existing formulas for LDL-C calculation, in eastern Indian population.",0,0
325,Stress cardiomyopathy in hospitalized patients with cancer: machine learning analysis by primary malignancy type. Previous studies have shown that patients with stress (Takotsubo) cardiomyopathy (SC) and cancer have higher in-hospital mortality than patients with SC alone. No studies have examined outcomes in patients with active cancer and SC compared to patients with active cancer without SC. We aimed to assess the potential association between primary malignancy type and SC and their shared interaction with inpatient mortality.,0,0
327,Predicting obesity and smoking using medication data: a machine-learning approach. Administrative health datasets are widely used in public health research but often lack information about common confounders. We aimed to develop and validate machine learning (ML)-based models using medication data from Australia's Pharmaceutical Benefits Scheme (PBS) database to predict obesity and smoking.,0,0
332,Diagnostic charting of panoramic radiography using deep-learning artificial intelligence system. The goal of this study was to develop and evaluate the performance of a new deep-learning (DL) artificial intelligence (AI) model for diagnostic charting in panoramic radiography.,0,0
333,"Machine learning-guided, big data-enabled, biomarker-based systems pharmacology: modeling the stochasticity of natural history and disease progression. The incidence of systemic and metabolic co-morbidities increases with aging. The purpose was to investigate a novel paradigm for modeling the orchestrated changes in many disease-related biomarkers that occur during aging. A hybrid strategy that integrates machine learning and stochastic modeling was evaluated for modeling the long-term dynamics of biomarker systems. Bayesian networks (BN) were used to identify quantitative systems pharmacology (QSP)-like models for the inter-dependencies for three disease-related datasets of metabolic (MB), metabolic with leptin (MB-L), and cardiovascular (CVB) biomarkers from the NHANES database. Biomarker dynamics were modeled using discrete stochastic vector autoregression (VAR) equations. BN were used to derive the topological order and connectivity of a data driven QSP model structure for inter-dependence of biomarkers across the lifespan. The strength and directionality of the connections in the QSP models were evaluated using bootstrapping. VAR models based on QSP model structures from BN were assessed for modeling biomarker system dynamics. BN-restricted VAR models of order 1 were identified as parsimonious and effective for characterizing biomarker system dynamics in the MB, MB-L and CVB datasets. Simulation of annual and triennial data for each biomarker provided good fits and predictions of the training and test datasets, respectively. The novel strategy harnesses machine learning to construct QSP model structures for inter-dependence of biomarkers. Stochastic modeling with the QSP models was effective for predicting the age-varying dynamics of disease-relevant biomarkers over the lifespan.",0,0
342,Predicting Sarcopenia of Female Elderly from Physical Activity Performance Measurement Using Machine Learning Classifiers. Sarcopenia is a symptom in which muscle mass decreases due to decreasing in the number of muscle fibers and muscle cross-sectional area as aging. This study aimed to develop a machine learning classification model for predicting sarcopenia through a inertial measurement unit (IMU)-based physical performance measurement data of female elderly.,0,0
345,Deep learning for predicting uncorrected refractive error using posterior segment optical coherence tomography images. This study aimed to evaluate a deep learning model for estimating uncorrected refractive error using posterior segment optical coherence tomography (OCT) images.,0,0
350,"A transfer learning framework based on motor imagery rehabilitation for stroke. Deep learning networks have been successfully applied to transfer functions so that the models can be adapted from the source domain to different target domains. This study uses multiple convolutional neural networks to decode the electroencephalogram (EEG) of stroke patients to design effective motor imagery (MI) brain-computer interface (BCI) system. This study has introduced 'fine-tune' to transfer model parameters and reduced training time. The performance of the proposed framework is evaluated by the abilities of the models for two-class MI recognition. The results show that the best framework is the combination of the EEGNet and 'fine-tune' transferred model. The average classification accuracy of the proposed model for 11 subjects is 66.36%, and the algorithm complexity is much lower than other models.These good performance indicate that the EEGNet model has great potential for MI stroke rehabilitation based on BCI system. It also successfully demonstrated the efficiency of transfer learning for improving the performance of EEG-based stroke rehabilitation for the BCI system.",0,0
353,"Risk factor assessments of temporomandibular disorders via machine learning. This study aimed to use artificial intelligence to determine whether biological and psychosocial factors, such as stress, socioeconomic status, and working conditions, were major risk factors for temporomandibular disorders (TMDs). Data were retrieved from the fourth Korea National Health and Nutritional Examination Survey (2009), with information concerning 4744 participants' TMDs, demographic factors, socioeconomic status, working conditions, and health-related determinants. Based on variable importance observed from the random forest, the top 20 determinants of self-reported TMDs were body mass index (BMI), household income (monthly), sleep (daily), obesity (subjective), health (subjective), working conditions (control, hygiene, respect, risks, and workload), occupation, education, region (metropolitan), residence type (apartment), stress, smoking status, marital status, and sex. The top 20 determinants of temporomandibular disorders determined via a doctor's diagnosis were BMI, age, household income (monthly), sleep (daily), obesity (subjective), working conditions (control, hygiene, risks, and workload), household income (subjective), subjective health, education, smoking status, residence typeÂ (apartment), region (metropolitan), sex, marital status, and allergic rhinitis. This study supports the hypothesis, highlighting the importance of obesity, general health, stress, socioeconomic status, and working conditions in the management of TMDs.",0,0
367,"3D multi-scale, multi-task, and multi-label deep learning for prediction of lymph node metastasis in T1 lung adenocarcinoma patients' CT images. The diagnosis of preoperative lymph node (LN) metastasis is crucial to evaluate possible therapy options for T1 lung adenocarcinoma patients. Radiologists preoperatively diagnose LN metastasis by evaluating signs related to LN metastasis, like spiculation or lobulation of pulmonary nodules in CT images. However, this type of evaluation is subjective and time-consuming, which may result in poor consistency and low efficiency of diagnoses. In this study, a 3D Multi-scale, Multi-task, and Multi-label classification network (3M-CN) was proposed to predict LN metastasis, as well as evaluate multiple related signs of pulmonary nodules in order to improve the accuracy of LN metastasis prediction. The following key approaches were adapted for this method. First, a multi-scale feature fusion module was proposed to aggregate the features from different levels for which different labels be best modeled at different levels; second, an auxiliary segmentation task was applied to force the model to focus more on the nodule region and less on surrounding unrelated structures; and third, a cross-modal integration module called the refine layer was designed to integrate the related risk factors into the model to further improve its confidence level. The 3M-CN was trained using data from 401 cases and then validated on both internal and external datasets, which consisted of 100 cases and 53 cases, respectively. The proposed 3M-CN model was then compared with existing state-of-the-art methods for prediction of LN metastasis. The proposed model outperformed other methods, achieving the best performance with AUCs of 0.945 and 0.948 in the internal and external test datasets, respectively. The proposed model not only obtain strong generalization, but greatly enhance the interpretability of the deep learning model, increase doctors' confidence in the model results, conform to doctors' diagnostic process, and may also be transferable to the diagnosis of other diseases.",0,0
377,"Machine learning-driven identification of early-life air toxic combinations associated with childhood asthma outcomes. Air pollution is a well-known contributor to asthma. Air toxics are hazardous air pollutants that cause or may cause serious health effects. While individual air toxics have been associated with asthma, only a limited number of studies have specifically examined combinations of air toxics associated with the disease. We geocoded air toxic levels from the US National Air Toxics Assessment (NATA) to residential locations for participants of our AiRway in Asthma (ARIA) study. We then applied Data-driven ExposurE Profile extraction (DEEP), a novel machine learning-based method, to discover combinations of early-life air toxics associated with current use of daily asthma controller medication, lifetime emergency department visit for asthma, and lifetime overnight hospitalization for asthma. We discovered 20 multi-air toxic combinations and 18 single air toxics associated with at least one outcome. The multi-air toxic combinations included those containing acrylic acid, ethylidene dichloride, and hydroquinone, and they were significantly associated with asthma outcomes with odds ratios of 1.60 to 3.19. Several air toxic members of the combinations would not have been identified by single air toxic analyses, supporting the use of machine learning-based methods designed to detect combinatorial effects. Our findings provide knowledge about air toxic combinations associated with childhood asthma.",0,0
378,Value of machine learning to predict functional outcome of endovascular treatment for acute ischaemic stroke of the posterior circulation. Clinical outcomes vary considerably among individuals with vessel occlusion of the posterior circulation. In the present study we evaluated machine learning algorithms in their ability to discriminate between favourable and unfavourable outcomes in patients with endovascular treatment of acute ischaemic stroke of the posterior circulation.,0,0
381,"Fully automated multi-organ segmentation of female pelvic magnetic resonance images with coarse-to-fine convolutional neural network. Brachytherapy (BT) combined with external beam radiotherapy (EBRT) is the standard treatment for cervical cancer and has been shown to improve overall survival rates compared to EBRT only. Magnetic resonance (MR) imaging is used for radiotherapy (RT) planning and image guidance due to its excellent soft tissue image contrast. Rapid and accurate segmentation of organs at risk (OAR) is a crucial step in MR image-guided RT. In this paper, we propose a fully automated two-step convolutional neural network (CNN) approach to delineate multiple OARs from T2-weighted (T2W) MR images.",0,0
382,An Optimized Radiomics Model Based on Automated Breast Volume Scan Images to Identify Breast Lesions: Comparison of Machine Learning Methods. To develop and test an optimized radiomics model based on multi-planar automated breast volume scan (ABVS) images to identify malignant and benign breast lesions.,0,0
384,"Synthetic CT-aided multi-organ segmentation for CBCT-guided adaptive pancreatic radiotherapy. The delineation of organs-at-risk (OARs) is fundamental to cone-beam CT (CBCT)-based adaptive radiotherapy treatment planning, but is time-consuming, labor-intensive, and subject to inter-operator variability. We investigated a deep learning-based rapid multi-organ delineation method for use in CBCT-guided adaptive pancreatic radiotherapy.",0,0
386,"AI-based diagnosis of COVID-19 patients using X-ray scans with stochastic ensemble of CNNs. According to the World Health Organization (WHO), novel coronavirus (COVID-19) is an infectious disease and has a significant social and economic impact. The main challenge in fighting against this disease is its scale. Due to the outbreak, medical facilities are under pressure due to case numbers. A quick diagnosis system is required to address these challenges. To this end, a stochastic deep learning model is proposed. The main idea is to constrain the deep-representations over a Gaussian prior to reinforce the discriminability in feature space. The model can work on chest X-ray or CT-scan images. It provides a fast diagnosis of COVID-19 and can scale seamlessly. The work presents a comprehensive evaluation of previously proposed approaches for X-ray based disease diagnosis. The approach works by learning a latent space over X-ray image distribution from the ensemble of state-of-the-art convolutional-nets, and then linearly regressing the predictions from an ensemble of classifiers which take the latent vector as input. We experimented with publicly available datasets having three classes: COVID-19, normal and pneumonia yielding an overall accuracy and AUC of 0.91 and 0.97, respectively. Moreover, for robust evaluation, experiments were performed on a large chest X-ray dataset to classify among Atelectasis, Effusion, Infiltration, Nodule, and Pneumonia classes. The results demonstrate that the proposed model has better understanding of the X-ray images which make the network more generic to be later used with other domains of medical image analysis.",0,0
392,"Predicting Prolonged Apnea During Nurse-Administered Procedural Sedation: Machine Learning Study. Capnography is commonly used for nurse-administered procedural sedation. Distinguishing between capnography waveform abnormalities that signal the need for clinical intervention for an event and those that do not indicate the need for intervention is essential for the successful implementation of this technology into practice. It is possible that capnography alarm management may be improved by using machine learning to create a ""smart alarm"" that can alert clinicians to apneic events that are predicted to be prolonged.",0,0
393,Optimal triage for COVID-19 patients under limited healthcare resources: Development of a parsimonious machine learning prediction model and threshold optimization using discrete-event simulation. The coronavirus disease 2019 (COVID-19) pandemic has placed an unprecedented burden on healthcare systems.,0,0
397,"Coronary CT Fractional Flow Reserve before Transcatheter Aortic Valve Replacement: Clinical Outcomes. Background The role of CT angiography-derived fractional flow reserve (CT-FFR) in pre-transcatheter aortic valve replacement (TAVR) assessment is uncertain. Purpose To evaluate the predictive value of on-site machine learning-based CT-FFR for adverse clinical outcomes in candidates for TAVR. Materials and Methods This observational retrospective study included patients with severe aortic stenosis referred to TAVR after coronary CT angiography (CCTA) between September 2014 and December 2019. Clinical end points comprised major adverse cardiac events (MACE) (nonfatal myocardial infarction, unstable angina, cardiac death, or heart failure admission) and all-cause mortality. CT-FFR was obtained semiautomatically using an on-site machine learning algorithm. The ability of CT-FFR (abnormal if â‰¤0.75) to predict outcomes and improve the predictive value of the current noninvasive work-up was assessed. Survival analysis was performed, and the C-index was used to assess the performance of each predictive model. To compare nested models, the likelihood ratio Ï‡<sup>2</sup> test was performed. Results A total of 196 patients (mean age Â± standard deviation, 75 years Â± 11; 110 women [56%]) were included; the median time of follow-up was 18 months. MACE occurred in 16% (31 of 196 patients) and all-cause mortality in 19% (38 of 196 patients). Univariable analysis revealed CT-FFR was predictive of MACE (hazard ratio [HR], 4.1; 95% CI: 1.6, 10.8; <i>P</i> = .01) but not all-cause mortality (HR, 1.2; 95% CI: 0.6, 2.2; <i>P</i> = .63). CT-FFR was independently associated with MACE (HR, 4.0; 95% CI: 1.5, 10.5; <i>P</i> = .01) when adjusting for potential confounders. Adding CT-FFR as a predictor to models that include CCTA and clinical data improved their predictive value for MACE (<i>P</i> = .002) but not all-cause mortality (<i>P</i> = .67), and it showed good discriminative ability for MACE (C-index, 0.71). Conclusion CT angiography-derived fractional flow reserve was associated with major adverse cardiac events in candidates for transcatheter aortic valve replacement and improved the predictive value of coronary CT angiography assessment. Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Choe in this issue.",0,0
398,"Deep Learning for Automated Triaging of 4581 Breast MRI Examinations from the DENSE Trial. Background Supplemental screening with MRI has proved beneficial in women with extremely dense breasts. Most MRI examinations show normal anatomic and physiologic variation that may not require radiologic review. Thus, ways to triage these normal MRI examinations to reduce radiologist workload are needed. Purpose To determine the feasibility of an automated triaging method using deep learning (DL) to dismiss the highest number of MRI examinations without lesions while still identifying malignant disease. Materials and Methods This secondary analysis of data from the Dense Tissue and Early Breast Neoplasm Screening, or DENSE, trial evaluated breast MRI examinations from the first screening round performed in eight hospitals between December 2011 and January 2016. A DL model was developed to differentiate between breasts with lesions and breasts without lesions. The model was trained to dismiss breasts with normal phenotypical variation and to triage lesions (Breast Imaging Reporting and Data System [BI-RADS] categories 2-5) using eightfold internal-external validation. The model was trained on data from seven hospitals and tested on data from the eighth hospital, alternating such that each hospital was used once as an external test set. Performance was assessed using receiver operating characteristic analysis. At 100% sensitivity for malignant disease, the fraction of examinations dismissed from radiologic review was estimated. Results A total of 4581 MRI examinations of extremely dense breasts from 4581women (mean age, 54.3 years; interquartile range, 51.5-59.8 years) were included. Of the 9162 breasts, 838 had at least one lesion (BI-RADS category 2-5, of which 77 were malignant) and 8324 had no lesions. At 100% sensitivity for malignant lesions, the DL model considered 90.7% (95% CI: 86.7, 94.7) of the MRI examinations with lesions to be nonnormal and triaged them to radiologic review. The DL model dismissed 39.7% (95% CI: 30.0, 49.4) of the MRI examinations without lesions. The DL model had an average area under the receiver operating characteristic curve of 0.83 (95% CI: 0.80, 0.85) in the differentiation between normal breast MRI examinations and MRI examinations with lesions. Conclusion Automated analysis of breast MRI examinations in women with dense breasts dismissed nearly 40% of MRI scans without lesions while not missing any cancers. ClinicalTrials.gov: NCT01315015 Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Joe in this issue.",0,0
402,The preoperative machine learning algorithm for extremity metastatic disease can predict 90-day and 1-year survival: An external validation study. The prediction of survival is valuable to optimize treatment of metastatic long-bone disease. The Skeletal Oncology Research Group (SORG) machine-learning (ML) algorithm has been previously developed and internally validated. The purpose of this study was to determine if the SORG ML algorithm accurately predicts 90-day and 1-year survival in an external metastatic long-bone disease patient cohort.,0,0
406,ResectVol: a tool to automatically segment and characterize lacunas in brain images. To assess and validate the performance of a new tool developed for segmenting and characterizing lacunas in postoperative MR images of epilepsy patients.,0,0
408,"A deep learning-based model for prediction of hemorrhagic transformation after stroke. Hemorrhagic transformation (HT) is one of the most serious complications after endovascular thrombectomy (EVT) in acute ischemic stroke (AIS) patients. The purpose of this study is to develop and validate deep-learning (DL) models based on multiparametric magnetic resonance imaging (MRI) to automatically predict HT in AIS patients. Multiparametric MRI and clinical data of AIS patients with EVT from two centers (data set 1 for training and testing: nÂ =Â 338; data set 2 for validating: nÂ =Â 54) were used in the DL models. The acute infarction area of diffusion-weighted imaging (DWI) and hypoperfusion of perfusion-weighted imaging (PWI) was labeled manually. Two forms of data sets (volume of interest [VOI] data sets and slice data sets) were analyzed, respectively. The models based on single parameter and multiparameter models were developed and validated to predict HT in AIS patients after EVT. Performance was evaluated by area under the receiver-operating characteristic curve (AUC), accuracy (ACC), sensitivity, specificity, negative predictive value, and positive predictive value. The results showed that the performance of single parameter model based on MTT (VOI data set: AUCÂ =Â 0.933, ACCÂ =Â 0.843; slice data set: AUCÂ =Â 0.945, ACCÂ =Â 0.833) and TTP (VOI data set: AUCÂ =Â 0.916, ACCÂ =Â 0.873; slice data set: AUCÂ =Â 0.889, ACCÂ =Â 0.818) were better than the other single parameter model. The multiparameter model based on DWI & MTT & TTP & Clinical (DMTC) had the best performance for predicting HT (VOI data set: AUCÂ =Â 0.948, ACCÂ =Â 0.892; slice data set: AUCÂ =Â 0.932, ACCÂ =Â 0.873). The DMTC model in the external validation set achieved similar performance with the testing set (VOI data set: AUCÂ =Â 0.939, ACCÂ =Â 0.884; slice data set: AUCÂ =Â 0.927, ACCÂ =Â 0.871) (pÂ >Â 0.05). The proposed clinical, DWI, and PWI multiparameter DL model has great potential for assisting the periprocedural management in the early prediction HT of the AIS patients with EVT.",0,0
416,"Application of the Preoperative Assistant System Based on Machine Learning in Hepatocellular Carcinoma Resection. To conduct better research in hepatocellular carcinoma resection, this paper used 3D machine learning and logistic regression algorithm to study the preoperative assistance of patients undergoing hepatectomy. In this study, the logistic regression model was analyzed to find the influencing factors for the survival and recurrence of patients. The clinical data of 50 HCC patients who underwent extensive hepatectomy (â‰¥4 segments of the liver) admitted to our hospital from June 2020 to December 2020 were selected to calculate the liver volume, simulated surgical resection volume, residual liver volume, surgical margin, etc. The results showed that the simulated liver volume of 50 patients was 845.2â€‰+â€‰285.5â€‰mL, and the actual liver volume of 50 patients was 826.3â€‰Â±â€‰268.1â€‰mL, and there was no significant difference between the two groups (<i>t</i>â€‰=â€‰0.425; <i>P</i>â€‰>â€‰0.05). Compared with the logistic regression model, the machine learning method has a better prediction effect, but the logistic regression model has better interpretability. The analysis of the relationship between the liver tumour and hepatic vessels in practical problems has specific clinical application value for accurately evaluating the volume of liver resection and surgical margin.",0,0
417,"Breast Cancer Classification Prediction Based on Ultrasonic Image Feature Recognition. Exploring an effective method to manage the complex breast cancer clinical information and selecting a suitable classifier for predictive modeling still require continuous research and verification in the actual clinical environment. This paper combines the ultrasound image feature algorithm to construct a breast cancer classification model. Furthermore, it combines the motion process of the ultrasound probe to accurately connect the ultrasound probe to the breast tumor. Moreover, this paper constructs a hardware and software system structure through machine vision algorithms and intelligent motion algorithms. Furthermore, it combines coordinate transformation and image recognition algorithms to expand the recognition process to realize automatic and intelligent real-time breast cancer diagnosis. In addition, this paper combines machine learning algorithms to process data and obtain an intelligent system model. Finally, this paper designs experiments to verify the intelligent system of this paper. Through experimental research, it can be seen that the breast cancer classification prediction system based on ultrasonic image feature recognition has certain effects.",0,0
418,"Early MCI-to-AD Conversion Prediction Using Future Value Forecasting of Multimodal Features. In Alzheimer's disease (AD) progression, it is imperative to identify the subjects with mild cognitive impairment before clinical symptoms of AD appear. This work proposes a technique for decision support in identifying subjects who will show transition from mild cognitive impairment (MCI) to Alzheimer's disease (AD) in the future. We used robust predictors from multivariate MRI-derived biomarkers and neuropsychological measures and tracked their longitudinal trajectories to predict signs of AD in the MCI population. Assuming piecewise linear progression of the disease, we designed a novel weighted gradient offset-based technique to forecast the future marker value using readings from at least two previous follow-up visits. Later, the complete predictor trajectories are used as features for a standard support vector machine classifier to identify MCI-to-AD progressors amongst the MCI patients enrolled in the Alzheimer's disease neuroimaging initiative (ADNI) cohort. We explored the performance of both unimodal and multimodal models in a 5-fold cross-validation setup. The proposed technique resulted in a high classification AUC of 91.2% and 95.7% for 6-month- and 1-year-ahead AD prediction, respectively, using multimodal markers. In the end, we discuss the efficacy of MRI markers as compared to NM for MCI-to-AD conversion prediction.",0,0
421,"A CNN-LSTM network with multi-level feature extraction-based approach for automated detection of coronavirus from CT scan and X-ray images. Auto-detection of diseases has become a prime issue in medical sciences as population density is fast growing. An intelligent framework for disease detection helps physicians identify illnesses, give reliable and consistent results, and reduce death rates. Coronavirus (Covid-19) has recently been one of the most severe and acute diseases in the world. An automatic detection framework should therefore be introduced as the fastest diagnostic alternative to avoid Covid-19 spread. In this paper, an automatic Covid-19 identification in the CT scan and chest X-ray is obtained with the help of a combined deep learning and multi-level feature extraction methodology. In this method, the multi-level feature extraction approach comprises GIST, Scale Invariant Feature Transform (SIFT), and Convolutional Neural Network (CNN) extract features from CT scans and chest X-rays. The objective of multi-level feature extraction is to reduce the training complexity of CNN network, which significantly assists in accurate and robust Covid-19 identification. Finally, Long Short-Term Memory (LSTM) along the CNN network is used to detect the extracted Covid-19 features. The Kaggle SARS-CoV-2 CT scan dataset and the Italian SIRM Covid-19 CT scan and chest X-ray dataset were employed for testing purposes. Experimental outcomes show that proposed approach obtained 98.94% accuracy with the SARS-CoV-2 CT scan dataset and 83.03% accuracy with the SIRM Covid-19 CT scan and chest X-ray dataset. The proposed approach helps radiologists and practitioners to detect and treat Covid-19 cases effectively over the pandemic.",0,0
428,"Detection and analysis of COVID-19 in medical images using deep learning techniques. The main purpose of this work is to investigate and compare several deep learning enhanced techniques applied to X-ray and CT-scan medical images for the detection of COVID-19. In this paper, we used four powerful pre-trained CNN models, VGG16, DenseNet121, ResNet50,and ResNet152, for the COVID-19 CT-scan binary classification task. The proposed Fast.AI ResNet framework was designed to find out the best architecture, pre-processing, and training parameters for the models largely automatically. The accuracy and F1-score were both above 96% in the diagnosis of COVID-19 using CT-scan images. In addition, we applied transfer learning techniques to overcome the insufficient data and to improve the training time. The binary and multi-class classification of X-ray images tasks were performed by utilizing enhanced VGG16 deep transfer learning architecture. High accuracy of 99% was achieved by enhanced VGG16 in the detection of X-ray images from COVID-19 and pneumonia. The accuracy and validity of the algorithms were assessed on X-ray and CT-scan well-known public datasets. The proposed methods have better results for COVID-19 diagnosis than other related in literature. In our opinion, our work can help virologists and radiologists to make a better and faster diagnosis in the struggle against the outbreak of COVID-19.",0,0
435,"Predicting cardiac adverse events in patients receiving immune checkpoint inhibitors: a machine learning approach. Treatment with immune checkpoint inhibitors (ICIs) has been associated with an increased rate of cardiac events. There are limited data on the risk factors that predict cardiac events in patients treated with ICIs. Therefore, we created a machine learning (ML) model to predict cardiac events in this at-risk population.",0,0
443,"Comparison of machine learning algorithms applied to symptoms to determine infectious causes of death in children: national survey of 18,000 verbal autopsies in the Million Death Study in India. Machine learning (ML) algorithms have been successfully employed for prediction of outcomes in clinical research. In this study, we have explored the application of ML-based algorithms to predict cause of death (CoD) from verbal autopsy records available through the Million Death Study (MDS).",0,0
449,Artificial intelligence versus expert endoscopists for diagnosis of gastric cancer in patients who underwent upper gastrointestinal endoscopy. To compare endoscopy gastric cancer images diagnosis rate between artificial intelligence (AI) and expert endoscopists.,1,1
455,Machine learning with a reduced dimensionality representation of comprehensive Pentacam tomography parameters to identify subclinical keratoconus. To investigate the performance of a machine learning model based on a reduced dimensionality parameter space derived from complete Pentacam parameters to identify subclinical keratoconus (KC).,0,0
463,"Predicting Potential Palliative Care Beneficiaries for Health Plans: A Generalized Machine Learning Pipeline. Recognizing that palliative care improves the care quality and reduces the healthcare costs for individuals in their end of life, health plan providers strive to better enroll the appropriate target population for palliative care. Current research has not adequately addressed challenges related to proactively select potential palliative care beneficiaries from a population health perspective. This study presents a Generalized Machine Learning Pipeline (GMLP) to predict palliative needs in patients using administrative claims data. The GMLP has five steps: data cohort creation, feature engineering, predictive modeling, scoring beneficiaries, and model maintenance. It encapsulates principles of population health management, business domain knowledge, and machine learning (ML) process knowledge with an innovative data pull strategy. The GMLP was applied in a regional health plan using a data cohort of 17,197 patients. Multiple ML models were turned and evaluated against a custom performance metric based on the business requirement. The best model was an AdaBoost model with a precision of 71.43% and a recall of 67.98%. The post-implementation evaluation of the GMLP showed that it increased the recall of high mortality risk patients, improved their quality of life, and reduced the overall cost. The GMLP is a novel approach that can be applied agnostically to the data and specific ML algorithms. To the best of our knowledge, it is the first attempt to continuously score palliative care beneficiaries using administrative data. The GMLP and its use case example presented in the paper can serve as a methodological guide for different health plans and healthcare policymakers to apply ML in solving real-world clinical challenges, such as palliative care management and other similar risk-stratified care management workflows.",0,0
464,An artificial intelligence model to predict hepatocellular carcinoma risk in Korean and Caucasian patients with chronic hepatitis B. Several risk models were recently developed to predict risk of hepatocellular carcinoma (HCC) in patients with chronic hepatitis B (CHB). Our aims were to develop and validate an artificial intelligence-assisted prediction model of HCC risk.,0,0
473,"Semi-Supervised Segmentation of Radiation-Induced Pulmonary Fibrosis from Lung CT Scans with Multi-Scale Guided Dense Attention. Computed Tomography (CT) plays an important role in monitoring radiation-induced Pulmonary Fibrosis (PF), where accurate segmentation of the PF lesions is highly desired for diagnosis and treatment follow-up. However, the task is challenged by ambiguous boundary, irregular shape, various position and size of the lesions, as well as the difficulty in acquiring a large set of annotated volumetric images for training. To overcome these problems, we propose a novel convolutional neural network called PF-Net and incorporate it into a semi-supervised learning framework based on Iterative Confidence-based Refinement And Weighting of pseudo Labels (I-CRAWL). Our PF-Net combines 2D and 3D convolutions to deal with CT volumes with large inter-slice spacing, and uses multi-scale guided dense attention to segment complex PF lesions. For semi-supervised learning, our I-CRAWL employs pixel-level uncertainty-based confidence-aware refinement to improve the accuracy of pseudo labels of unannotated images, and uses image-level uncertainty for confidence-based image weighting to suppress low-quality pseudo labels in an iterative training process. Extensive experiments with CT scans of Rhesus Macaques with radiation-induced PF showed that: 1) PF-Net achieved higher segmentation accuracy than existing 2D, 3D and 2.5D neural networks, and 2) I-CRAWL outperformed state-of-the-art semi-supervised learning methods for the PF lesion segmentation task. Our method has a potential to improve the diagnosis of PF and clinical assessment of side effects of radiotherapy for lung cancers.",0,0
474,"Multitask Deep Learning Reconstruction and Localization of Lesions in Limited Angle Diffuse Optical Tomography. Diffuse optical tomography (DOT) leverages near-infrared light propagation through tissue to assess its optical properties and identify abnormalities. DOT image reconstruction is an ill-posed problem due to the highly scattered photons in the medium and the smaller number of measurements compared to the number of unknowns. Limited-angle DOT reduces probe complexity at the cost of increased reconstruction complexity. Reconstructions are thus commonly marred by artifacts and, as a result, it is difficult to obtain an accurate reconstruction of target objects, e.g., malignant lesions. Reconstruction does not always ensure good localization of small lesions. Furthermore, conventional optimization-based reconstruction methods are computationally expensive, rendering them too slow for real-time imaging applications. Our goal is to develop a fast and accurate image reconstruction method using deep learning, where multitask learning ensures accurate lesion localization in addition to improved reconstruction. We apply spatial-wise attention and a distance transform based loss function in a novel multitask learning formulation to improve localization and reconstruction compared to single-task optimized methods. Given the scarcity of real-world sensor-image pairs required for training supervised deep learning models, we leverage physics-based simulation to generate synthetic datasets and use a transfer learning module to align the sensor domain distribution between in silico and real-world data, while taking advantage of cross-domain learning. Applying our method, we find that we can reconstruct and localize lesions faithfully while allowing real-time reconstruction. We also demonstrate that the present algorithm can reconstruct multiple cancer lesions. The results demonstrate that multitask learning provides sharper and more accurate reconstruction.",0,0
475,"WDCCNet: Weighted Double-Classifier Constraint Neural Network for Mammographic Image Classification. The early detection and timely treatment of breast cancer can save lives. Mammography is one of the most efficient approaches to screening early breast cancer. An automatic mammographic image classification method could improve the work efficiency of radiologists. Current deep learning-based methods typically use the traditional softmax loss to optimize the feature extraction part, which aims to learn the features of mammographic images. However, previous studies have shown that the feature extraction part cannot learn discriminative features from complex data using the standard softmax loss. In this paper, we design a new architecture and propose respective loss functions. Specifically, we develop a double-classifier network architecture that constrains the extracted features' distribution by changing the classifiers' decision boundaries. Then, we propose the double-classifier constraint loss function to constrain the decision boundaries so that the feature extraction part can learn discriminative features. Furthermore, by taking advantage of the architecture of two classifiers, the neural network can detect the difficult-to-classify samples. We propose a weighted double-classifier constraint method to make the feature extract part pay more attention to learning difficult-to-classify samples' features. Our proposed method can be easily applied to an existing convolutional neural network to improve mammographic image classification performance. We conducted extensive experiments to evaluate our methods on three public benchmark mammographic image datasets. The results showed that our methods outperformed many other similar methods and state-of-the-art methods on the three public medical benchmarks. Our code and weights can be found on GitHub.",0,0
478,"Transient Noise Reduction Using a Deep Recurrent Neural Network: Effects on Subjective Speech Intelligibility and Listening Comfort. A deep recurrent neural network (RNN) for reducing transient sounds was developed and its effects on subjective speech intelligibility and listening comfort were investigated. The RNN was trained using sentences spoken with different accents and corrupted by transient sounds, using the clean speech as the target. It was tested using sentences spoken by unseen talkers and corrupted by unseen transient sounds. A paired-comparison procedure was used to compare all possible combinations of three conditions for subjective speech intelligibility and listening comfort for two relative levels of the transients. The conditions were: no processing (NP); processing using the RNN; and processing using a multi-channel transient reduction method (MCTR). Ten participants with normal hearing and ten with mild-to-moderate hearing loss participated. For the latter, frequency-dependent linear amplification was applied to all stimuli to compensate for individual audibility losses. For the normal-hearing participants, processing using the RNN was significantly preferred over that for NP for subjective intelligibility and comfort, processing using the RNN was significantly preferred over that for MCTR for subjective intelligibility, and processing using the MCTR was significantly preferred over that for NP for comfort for the higher transient level only. For the hearing-impaired participants, processing using the RNN was significantly preferred over that for NP for both subjective intelligibility and comfort, processing using the RNN was significantly preferred over that for MCTR for comfort, and processing using the MCTR was significantly preferred over that for NP for comfort.",0,0
483,"Effective methods of diabetic retinopathy detection based on deep convolutional neural networks. Diabetic retinopathy (DR) has become the leading cause of blindness worldwide. In clinical practice, the detection of DR often takes a lot of time and effort for ophthalmologist. It is necessary to develop an automatic assistant diagnosis method based on medical image analysis techniques.",0,0
484,"Predicting hypoglycemia in critically Ill patients using machine learning and electronic health records. Hypoglycemia is a common occurrence in critically ill patients and is associated with significant mortality and morbidity. We developed a machine learning model to predict hypoglycemia by using a multicenter intensive care unit (ICU) electronic health record dataset. Machine learning algorithms were trained and tested on patient data from the publicly available eICU Collaborative Research Database. Forty-four features including patient demographics, laboratory test results, medications, and vitals sign recordings were considered. The outcome of interest was the occurrence of a hypoglycemic event (blood glucoseâ€‰<â€‰72Â mg/dL) during a patient's ICU stay. Machine learning models used data prior to the second hour of the ICU stay to predict hypoglycemic outcome. Data from 61,575 patients who underwent 82,479 admissions at 199 hospitals were considered in the study. The best-performing predictive model was the eXtreme gradient boosting model (XGBoost), which achieved an area under the received operating curve (AUROC) of 0.85, a sensitivity of 0.76, and a specificity of 0.76. The machine learning model developed has strong discrimination and calibration for the prediction of hypoglycemia in ICU patients. Prospective trials of these models are required to evaluate their clinical utility in averting hypoglycemia within critically ill patient populations.",0,0
487,Detection of urinary tract calculi on CT images reconstructed with deep learning algorithms. Deep learning Computed Tomography (CT) reconstruction (DLR) algorithms promise to improve image quality but the impact on clinical diagnostic performance remains to be demonstrated. We aimed to compare DLR to standard iterative reconstruction for detection of urolithiasis by unenhanced CT in children and young adults.,0,0
488,"Repeatability and reproducibility of deep-learning-based liver volume and Couinaud segment volume measurement tool. Volumetric and health assessment of the liver is crucial to avoid poor post-operative outcomes following liver resection surgery. No current methods allow for concurrent and accurate measurement of both Couinaud segmental volumes for future liver remnant estimation and liver health using non-invasive imaging. In this study, we demonstrate the accuracy and precision of segmental volume measurements using new medical software, Hepaticaâ„¢.",0,0
491,Open-Source Automatic Biomarker Measurement on Slit-Lamp Photography to Estimate Visual Acuity in Microbial Keratitis. To assess clinical applicability of automatic image analysis in microbial keratitis (MK) by evaluating the relationship between biomarker measurements on slit-lamp photography (SLP) and best-corrected visual acuity (BCVA).,0,0
499,A radiomics method based on MR FS-T2WI sequence for diagnosing of autosomal dominant polycystic kidney disease progression. We aimed to construct/validate a radiomics method based on MR FS-T2WI sequence for the evaluation of kidney function in patients with autosomal dominant polycystic kidney disease (ADPKD).,0,0
504,"Real-time machine learning-based intensive care unit alarm classification without prior knowledge of the underlying rhythm. This work attempts to develop a standalone heart rhythm alerting system for the intensive care unit (ICU), where life-threatening arrhythmias have to be identified/alerted more precisely and more instantaneously (i.e. with lower latency) than existing bedside monitors.",0,0
509,"Improving natural language information extraction from cancer pathology reports using transfer learning and zero-shot string similarity. We develop natural language processing (NLP) methods capable of accurately classifying tumor attributes from pathology reports given minimal labeled examples. Our hierarchical cancer to cancer transfer (HCTC) and zero-shot string similarity (ZSS) methods are designed to exploit shared information between cancers and auxiliary class features, respectively, to boost performance using enriched annotations which give both location-based information and document level labels for each pathology report.",0,0
524,Machine Learning Prediction of Liver Allograft Utilization From Deceased Organ Donors Using the National Donor Management Goals Registry. Early prediction of whether a liver allograft will be utilized for transplantation may allow better resource deployment during donor management and improve organ allocation. The national donor management goals (DMG) registry contains critical care data collected during donor management. We developed a machine learning model to predict transplantation of a liver graft based on data from the DMG registry.,0,0
525,"Malaria detection through digital microscopic imaging using Deep Greedy Network with transfer learning. <b>Purpose:</b> In conventional diagnosis, the visual inspection of the malaria parasite <i>Plasmodium falciparum</i> in infected red blood cells under a microscope, is done manually by pathologists, which is both laborious and error-prone. Recent studies on automating this process have been conducted using artificial intelligence and feature selection of positional and morphological features from blood smear cell images using convolutional neural network (CNN). However, most deep CNN models do not perform well as per the expectation on small datasets. <b>Approach:</b> In this context, we propose a comprehensive computer-aided diagnosis scheme for automating the detection of malaria parasites in thin blood smear images using deep CNN, where transfer learning is used for optimizing the feature selection process. As an extra layer of security, layer embeddings are extracted from the intermediate convolutional layers using the feature matrix to cross-check the selection of features in the intermediate layers. The proposal includes the utilization of the ResNet 152 model integrated with the Deep Greedy Network for training, which produces an enhanced quality of prediction. <b>Results:</b> The performance of the proposed hybrid model has been evaluated concerning the evaluation metrics such as accuracy, precision, recall, specificity, and F1-score, which has been further compared with the pre-existing deep learning algorithms. <b>Conclusions:</b> The comparative analysis of the results reported based on the accuracy metrics demonstrates promising outcomes concerning the other models. Lastly, the embedding extraction from the intermediate hidden layers and their visual analysis also provides an opportunity for manual verification of the performance of the trained model.",0,0
527,"Machine Learning Models for Predicting In-Hospital Mortality in Acute Aortic Dissection Patients. <b>Background:</b> Acute aortic dissection is a potentially fatal cardiovascular disorder associated with high mortality. However, current predictive models show a limited ability to efficiently and flexibly detect this mortality risk, and have been unable to discover a relationship between the mortality rate and certain variables. Thus, this study takes an artificial intelligence approach, whereby clinical data-driven machine learning was utilized to predict the in-hospital mortality of acute aortic dissection. <b>Methods:</b> Patients diagnosed with acute aortic dissection between January 2015 to December 2018 were voluntarily enrolled from the Second Xiangya Hospital of Central South University in the study. The diagnosis was defined by magnetic resonance angiography or computed tomography angiography, with an onset time of the symptoms being within 14 days. The analytical variables included demographic characteristics, physical examination, symptoms, clinical condition, laboratory results, and treatment strategies. The machine learning algorithms included logistic regression, decision tree, K nearest neighbor, Gaussian naive bayes, and extreme gradient boost (XGBoost). Evaluation of the predictive performance of the models was mainly achieved using the area under the receiver operating characteristic curve. SHapley Additive exPlanation was also implemented to interpret the final prediction model. <b>Results:</b> A total of 1,344 acute aortic dissection patients were recruited, including 1,071 (79.7%) patients in the survivor group and 273 (20.3%) patients in non-survivor group. The extreme gradient boost model was found to be the most effective model with the greatest area under the receiver operating characteristic curve (0.927, 95% CI: 0.860-0.968). The three most significant aspects of the extreme gradient boost importance matrix plot were treatment, type of acute aortic dissection, and ischemia-modified albumin levels. In the SHapley Additive exPlanation summary plot, medical treatment, type A acute aortic dissection, and higher ischemia-modified albumin level were shown to increase the risk of hospital-based mortality.",0,0
533,"Deep Learning Model to Predict Serious Infection Among Children With Central Venous Lines. <b>Objective:</b> Predict the onset of presumed serious infection, defined as a positive blood culture drawn and new antibiotic course of at least 4 days (PSI<sup>*</sup>), among pediatric patients with Central Venous Lines (CVLs). <b>Design:</b> Retrospective cohort study. <b>Setting:</b> Single academic children's hospital. <b>Patients:</b> All hospital encounters from January 2013 to December 2018, excluding the ones without a CVL or with a length-of-stay shorter than 24 h. <b>Measurements and Main Results:</b> Clinical features including demographics, laboratory results, vital signs, characteristics of the CVLs and medications used were extracted retrospectively from electronic medical records. Data were aggregated across all hospitals within a single pediatric health system and used to train a deep learning model to predict the occurrence of PSI<sup>*</sup> during the next 48 h of hospitalization. The proposed model prediction was compared to prediction of PSI<sup>*</sup> by a marker of illness severity (PELOD-2). The baseline prevalence of line infections was 0.34% over all segmented 48-h time windows. Events were identified among cases using onset time. All data from admission till the onset was used for cases and among controls we used all data from admission till discharge. The benchmarks were aggregated over all 48 h time windows [N=748,380 associated with 27,137 patient encounters]. The model achieved an area under the receiver operating characteristic curve of 0.993 (95% CI = [0.990, 0.996]), the enriched positive predictive value (PPV) was 23 times greater than the base prevalence. Conversely, prediction by PELOD-2 achieved a lower PPV of 1.5% [0.9%, 2.1%] which was 5 times the baseline prevalence. <b>Conclusion:</b> A deep learning model that employs common clinical features in the electronic health record can help predict the onset of CLABSI in hospitalized children with central venous line 48 hours prior to the time of specimen collection.",0,1
535,"Multi-Task Deep Supervision on Attention R2U-Net for Brain Tumor Segmentation. Accurate automatic medical image segmentation technology plays an important role for the diagnosis and treatment of brain tumor. However, simple deep learning models are difficult to locate the tumor area and obtain accurate segmentation boundaries. In order to solve the problems above, we propose a 2D end-to-end model of attention R2U-Net with multi-task deep supervision (MTDS). MTDS can extract rich semantic information from images, obtain accurate segmentation boundaries, and prevent overfitting problems in deep learning. Furthermore, we propose the attention pre-activation residual module (APR), which is an attention mechanism based on multi-scale fusion methods. APR is suitable for a deep learning model to help the network locate the tumor area accurately. Finally, we evaluate our proposed model on the public BraTS 2020 validation dataset which consists of 125 cases, and got a competitive brain tumor segmentation result. Compared with the state-of-the-art brain tumor segmentation methods, our method has the characteristics of a small parameter and low computational cost.",0,0
537,Detection of Incidental Esophageal Cancers on Chest CT by Deep Learning. To develop a deep learning-based model using esophageal thickness to detect esophageal cancer from unenhanced chest CT images.,0,0
539,"Fully automated guideline-compliant diameter measurements of the thoracic aorta on ECG-gated CT angiography using deep learning. Manually performed diameter measurements on ECG-gated CT-angiography (CTA) represent the gold standard for diagnosis of thoracic aortic dilatation. However, they are time-consuming and show high inter-reader variability. Therefore, we aimed to evaluate the accuracy of measurements of a deep learning-(DL)-algorithm in comparison to those of radiologists and evaluated measurement times (MT).",1,1
546,"Obstructive Sleep Apnea Syndrome Treated Using a Positive Pressure Ventilator Based on Artificial Intelligence Processor. With the acceleration of people's life rhythm, obstructive sleep apnea syndrome appears more and more frequently. This research mainly discusses the treatment of obstructive sleep apnea syndrome with a positive pressure ventilator based on artificial intelligence processor. The information storage function of the smart positive pressure ventilator is included in the local medical terminal, presented after logging in with the user authority. It is mainly composed of data collection, data processing, and medical interface design, which embeds data request, data transmission, data analysis, and detailed tasks such as data compression and storage, and functions such as data display, image drawing, and alarm notification are realized by the medical interface. When the CPAP ventilator transmits respiratory data to the local medical terminal, it sends real-time respiratory information data packets. The data packet is collected and sent in real time in a fixed period and then received and analyzed by the local medical terminal. In the CPAP ventilator telemedicine system, the function of alarm message processing is mainly used to detect the patient's breathing status in real time, extract the alarm-related information, and generate an alarm. This function specifically includes several tasks such as alarm detection, alarm prompt, alarm storage, and remote transmission of alarm messages. The confirmed OSAS patients were pressure-titrated with a smart CPAP ventilator and then treated for 5 hours a day, followed by echocardiography after 5 months of continuous treatment. During the study, the average BMI was (28.9â€‰Â±â€‰7.2)â€‰kg/m<sup>2</sup> and the average AHI index was (53.1â€‰Â±â€‰37.8) times/h. This study may help improve the quality of life of patients with obstructive sleep apnea syndrome.",0,0
547,"Identification of the Vas Deferens in Laparoscopic Inguinal Hernia Repair Surgery Using the Convolutional Neural Network. Inguinal hernia repair is one of the most frequently conducted surgical procedures worldwide. Laparoscopic inguinal hernia repair is considered to be technically challenging. Artificial intelligence technology has made significant progress in medical imaging, but its application in laparoscopic surgery has not been widely carried out. Our aim is to detect vas deferens images in laparoscopic inguinal hernial repair using the convolutional neural network (CNN) and help surgeons to identify the vas deferens in time. We collected surgery videos from 35 patients with inguinal hernia who underwent laparoscopic hernia repair. We classified and labeled the images of the vas deferens and used the CNN to learn the image features. Totally, 2,600 images (26 patients) were labeled for training and validating the neural network and 1,200 images (6 patients) and 6 short video clips (3 patients) for testing. We adjusted the model parameters and tested the performance of the model under different confidence levels and IoU and used the chi-square to analyze the statistical difference in the video test dataset. We evaluated the model performance by calculating the true positive rate (TPR), true negative rate (TNR), accuracy (ACC), positive predictive value (PPV), and <i>F</i>1-score at different confidence levels of 0.1 to 0.9. In confidence level 0.4, the results were TPR 90.61%, TNR 98.67%, PPV 98.57%, ACC 94.61%, and <i>F</i>1 94.42%, respectively. The average precision (AP) was 92.38% at IoU 0.3. In the video test dataset, the average values of TPR and TNR were 90.11% and 95.76%, respectively, and there was no significant difference among the patients. The results suggest that the CNN can quickly and accurately identify and label vas deferens images in laparoscopic inguinal hernia repair.",0,0
556,"The Role of Medication Data to Enhance the Prediction of Alzheimer's Progression Using Machine Learning. Early detection of Alzheimer's disease (AD) progression is crucial for proper disease management. Most studies concentrate on neuroimaging data analysis of baseline visits only. They ignore the fact that AD is a chronic disease and patient's data are naturally longitudinal. In addition, there are no studies that examine the effect of dementia medicines on the behavior of the disease. In this paper, we propose a machine learning-based architecture for early progression detection of AD based on multimodal data of AD drugs and cognitive scores data. We compare the performance of five popular machine learning techniques including support vector machine, random forest, logistic regression, decision tree, and K-nearest neighbor to predict AD progression after 2.5 years. Extensive experiments are performed using an ADNI dataset of 1036 subjects. The cross-validation performance of most algorithms has been improved by fusing the drugs and cognitive scores data. The results indicate the important role of patient's taken drugs on the progression of AD disease.",0,0
558,"EEG-Based Personality Prediction Using Fast Fourier Transform and DeepLSTM Model. In this paper, a deep long short term memory (DeepLSTM) network to classify personality traits using the electroencephalogram (EEG) signals is implemented. For this research, the Myers-Briggs Type Indicator (MBTI) model for predicting personality is used. There are four groups in MBTI, and each group consists of two traits versus each other; i.e., out of these two traits, every individual will have one personality trait in them. We have collected EEG data using a single NeuroSky MindWave Mobile 2 dry electrode unit. For data collection, 40 Hindi and English video clips were included in a standard database. All clips provoke various emotions, and data collection is focused on these emotions, as the clips include targeted, inductive scenes of personality. Fifty participants engaged in this research and willingly agreed to provide brain signals. We compared the performance of our deep learning DeepLSTM model with other state-of-the-art-based machine learning classifiers such as artificial neural network (ANN), K-nearest neighbors (KNN), LibSVM, and hybrid genetic programming (HGP). The analysis shows that, for the 10-fold partitioning method, the DeepLSTM model surpasses the other state-of-the-art models and offers a maximum classification accuracy of 96.94%. The proposed DeepLSTM model was also applied to the publicly available ASCERTAIN EEG dataset and showed an improvement over the state-of-the-art methods.",0,0
566,"A Machine Learning Model to Predict the Triple Negative Breast Cancer Immune Subtype. Immune checkpoint blockade (ICB) has been approved for the treatment of triple-negative breast cancer (TNBC), since it significantly improved the progression-free survival (PFS). However, only about 10% of TNBC patients could achieve the complete response (CR) to ICB because of the low response rate and potential adverse reactions to ICB.",0,0
572,"Prediction of Cerebral Aneurysm Hemodynamics With Porous-Medium Models of Flow-Diverting Stents via Deep Learning. The interventional treatment of cerebral aneurysm requires hemodynamics to provide proper guidance. Computational fluid dynamics (CFD) is gradually used in calculating cerebral aneurysm hemodynamics before and after flow-diverting (FD) stent placement. However, the complex operation (such as the construction and placement simulation of fully resolved or porous-medium FD stent) and high computational cost of CFD hinder its application. To solve these problems, we applied aneurysm hemodynamics point cloud data sets and a deep learning network with double input and sampling channels. The flexible point cloud format can represent the geometry and flow distribution of different aneurysms before and after FD stent (represented by porous medium layer) placement with high resolution. The proposed network can directly analyze the relationship between aneurysm geometry and internal hemodynamics, to further realize the flow field prediction and avoid the complex operation of CFD. Statistical analysis shows that the prediction results of hemodynamics by our deep learning method are consistent with the CFD method (error function <13%), but the calculation time is significantly reduced 1,800 times. This study develops a novel deep learning method that can accurately predict the hemodynamics of different cerebral aneurysms before and after FD stent placement with low computational cost and simple operation processes.",0,0
576,"Multi-Order Brain Functional Connectivity Network-Based Machine Learning Method for Recognition of Delayed Neurocognitive Recovery in Older Adults Undergoing Non-cardiac Surgery. <b>Objectives:</b> Delayed neurocognitive recovery (DNR) seriously affects the post-operative recovery of elderly surgical patients, but there is still a lack of effective methods to recognize high-risk patients with DNR. This study proposed a machine learning method based on a multi-order brain functional connectivity (FC) network to recognize DNR. <b>Method:</b> Seventy-four patients who completed assessments were included in this study, in which 16/74 (21.6%) had DNR following surgery. Based on resting-state functional magnetic resonance imaging (rs-fMRI), we first constructed low-order FC networks of 90 brain regions by calculating the correlation of brain region signal changing in the time dimension. Then, we established high-order FC networks by calculating correlations among each pair of brain regions. Afterward, we built sparse representation-based machine learning model to recognize DNR on the extracted multi-order FC network features. Finally, an independent testing was conducted to validate the established recognition model. <b>Results:</b> Three hundred ninety features of FC networks were finally extracted to identify DNR. After performing the <i>independent-sample T test</i> between these features and the categories, 15 features showed statistical differences (<i>P</i> < 0.05) and 3 features had significant statistical differences (<i>P</i> < 0.01). By comparing DNR and non-DNR patients' brain region connection matrices, it is found that there are more connections among brain regions in DNR patients than in non-DNR patients. For the machine learning recognition model based on multi-feature combination, the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, and specificity of the classifier reached 95.61, 92.00, 66.67, and 100.00%, respectively. <b>Conclusion:</b> This study not only reveals the significance of preoperative rs-fMRI in recognizing post-operative DNR in elderly patients but also establishes a promising machine learning method to recognize DNR.",0,0
579,"Image Features of Magnetic Resonance Angiography under Deep Learning in Exploring the Effect of Comprehensive Rehabilitation Nursing on the Neurological Function Recovery of Patients with Acute Stroke. This study was to explore the effects of imaging characteristics of magnetic resonance angiography (MRA) based on deep learning on the comprehensive rehabilitation nursing on the neurological recovery of patients with acute stroke. In this study, 84 patients with acute stroke who were treated in hospital were selected as the research objects, and they were rolled into a control group (routine care) and an experimental group (comprehensive rehabilitation care). The dense dilated block-convolution neural network (DD-CNN) algorithm under deep learning for cerebrovascular was adopted to assess the effect of comprehensive rehabilitation care on the neurological recovery of patients with acute stroke. The results showed that the Berg scale scores, Fugl-Meyer scores, and <i>Functional Independence Measure</i> (FIM) scores of the experimental group of patients after 6 weeks and 12 weeks of comprehensive rehabilitation nursing were greatly different from those before treatment, showing statistical differences (<i>P</i> < 0.05). Compared with conventional magnetic resonance imaging (MRI) images, MRA images based on CNN algorithm, Dense Net algorithm, and DD-CNN algorithm can more clearly show the patient's cerebral artery occlusion. The average dice similarity coefficient (DSC) values of CNN algorithm, Dense Net algorithm, and DD-CNN algorithm were determined to be 84.3%, 95.7%, and 97.8%, respectively; the average sensitivity (Sen) values of the three algorithms were 76.1%, 95.4%, and 96.8%, respectively; and the average accuracy (Acc) values were 87.9%, 96.3%, and 97.9%, respectively. Thus, there were statistically obvious differences among the three algorithms in terms of average values of DSC, Sen, and Acc (<i>P</i> < 0.05). The MRA images processed by the DD-CNN algorithm showed that the degree of neurological recovery of the experimental group was observably greater than that of the control group, and the difference was statistically obvious (<i>P</i> < 0.05). In short, the image features of MRA based on the deep learning DD-CNN algorithm showed good application value in studying the effect of comprehensive rehabilitation nursing on the neurological recovery of patients with acute stroke, and it was worthy of promotion.",0,0
581,"Diagnosing COVID-19 from CT Image of Lung Segmentation & Classification with Deep Learning Based on Convolutional Neural Networks. Early-stage exposure and analysis of diseases are life-threatening causes for controlling the spread of COVID-19. Recently, Deep Learning (DL) centered approaches have projected intended for COVID-19 during the initial stage through the Computed Tomography (CT) mechanism is to simplify and aid with the analysis. However, these methodologiesundergocommencing one of the following issues: each CT scan slice treated separately and train and evaluate from the same dataset the strategies for image collections. Independent slice therapy is the identical patient involved in the preparation and set the tests at the same time, which can yield inaccurate outcomes. It also poses the issue of whether or not an individual should compare the scans of the same patient. This paper aims to establish image classifiers to determine whether a patient tested positive or negative for COVID-19 centered on lung CT scan imageries. In doing so, a Visual Geometry Group-16 (VGG-16) and a Convolutional Neural Network (CNN) 3-layer model used for marking. The images are first segmented using K-means Clustering before the classification to increase classification efficiency. Then, the VGG-16 model and the 3-layer CNN model implemented on the raw and segmented data. The impact of the segmentation of the image and two versions are explored and compared, respectively. Various tuning techniques were performed and tested to improve the VGG-16 model's performance, including increasing epochs, optimizer adjustment, and decreasing the learning rate. Moreover, pre-trained weights of the VGG-16 the model added to enhance the algorithm.",0,0
589,"Predicting Parkinson's Disease and Its Pathology via Simple Clinical Variables. Parkinson's disease (PD) is a chronic, disabling neurodegenerative disorder.",0,0
590,"Automatic Prediction of Cognitive and Functional Decline Can Significantly Decrease the Number of Subjects Required for Clinical Trials in Early Alzheimer's Disease. While both cognitive and magnetic resonance imaging (MRI) data has been used to predict progression in Alzheimer's disease, heterogeneity between patients makes it challenging to predict the rate of cognitive and functional decline for individual subjects.",0,0
591,"Identification of the Neural Circuit Underlying Episodic Memory Deficit in Amnestic Mild Cognitive Impairment via Machine Learning on Gray Matter Volume. Based on whole-brain gray matter volume (GMV), we used relevance vector regression to predict the Rey's Auditory Verbal Learning Test Delayed Recall (AVLT-DR) scores of individual amnestic mild cognitive impairment (aMCI) patient. The whole-brain GMV pattern could significantly predict the AVLT-DR scores (râ€Š=â€Š0.54, pâ€Š<â€Š0.001). The most important GMV features mainly involved default-mode (e.g., posterior cingulate gyrus, angular gyrus, and middle temporal gyrus) and limbic systems (e.g., hippocampus and parahippocampal gyrus). Therefore, our results provide evidence supporting the idea that the episodic memory deficit in aMCI patients is associated with disruption of the default-mode and limbic systems.",0,0
594,"Deep-learning model for screening sepsis using electrocardiography. Sepsis is a life-threatening organ dysfunction and a major healthcare burden worldwide. Although sepsis is a medical emergency that requires immediate management, screening for the occurrence of sepsis is difficult. Herein, we propose a deep learning-based model (DLM) for screening sepsis using electrocardiography (ECG).",0,0
597,A Robust Deep Learning Segmentation Method for Hematoma Volumetric Detection in Intracerebral Hemorrhage. Hematoma volume (HV) is a significant diagnosis for determining the clinical stage and therapeutic approach for intracerebral hemorrhage (ICH). The aim of this study is to develop a robust deep learning segmentation method for the fast and accurate HV analysis using computed tomography.,0,0
601,"Automated liver lesion detection in <sup>68</sup>Ga DOTATATE PET/CT using a deep fully convolutional neural network. Gastroenteropancreatic neuroendocrine tumors most commonly metastasize to the liver; however, high normal background <sup>68</sup>Ga-DOTATATE activity and high image noise make metastatic lesions difficult to detect. The purpose of this study is to develop a rapid, automated and highly specific method to identify <sup>68</sup>Ga-DOTATATE PET/CT hepatic lesions using a 2D U-Net convolutional neural network.",0,0
605,"Prediction of insulin treatment in women with gestational diabetes mellitus. The identification of pregnant women with Gestational Diabetes Mellitus (GDM) who will require insulin therapy, may modify their management to closer monitoring and probable early interventions. The aim of the study was to develop a predictive model for the necessity of insulin treatment in women with GDM.",0,0
609,"Estimated connectivity networks outperform observed connectivity networks when classifying people with multiple sclerosis into disability groups. Multiple Sclerosis (MS), a neurodegenerative and neuroinflammatory disease, causing lesions that disrupt the brain's anatomical and physiological connectivity networks, resulting in cognitive, visual and/or motor disabilities. Advanced imaging techniques like diffusion and functional MRI allow measurement of the brain's structural connectivity (SC) and functional connectivity (FC) networks, and can enable a better understanding of how their disruptions cause disability in people with MS (pwMS). However, advanced MRI techniques are used mainly for research purposes as they are expensive, time-consuming and require high-level expertise to acquire and process. As an alternative, the Network Modification (NeMo) Tool can be used to estimate SC and FC using lesion masks derived from pwMS and a reference set of controls' connectivity networks.",0,0
610,"A machine learning approach to identifying pregnant women's risk for persistent post-traumatic stress following childbirth. Recent literature identifies childbirth as a potentially traumatic event, following which mothers may develop symptoms of Post-Traumatic-Stress-Following-Childbirth (PTS-FC). Especially when persistent, PTS-FC may interfere with mothers' caregiving and associated infant development, underscoring the need for accurate predictive screening of risk. Drawing on recent developments in advanced statistical modeling, the aim of the current study was to identify a set of prenatal indicators and prediction rules that may accurately identify pregnant women's risk for developing symptoms of PTS-FC which persist throughout the early postpartum period.",0,0
611,Predicting prognosis in COVID-19 patients using machine learning and readily available clinical data. Prognostic tools for aiding in the treatment of hospitalized COVID-19 patients could help improve outcome by identifying patients at higher or lower risk of severe disease. The study objective was to develop models to stratify patients by risk of severe outcomes during COVID-19 hospitalization using readily available information at hospital admission.,0,0
615,Breast nodule classification with two-dimensional ultrasound using Mask-RCNN ensemble aggregation. The purpose of this study was to create a deep learning algorithm to infer the benign or malignant nature of breast nodules using two-dimensional B-mode ultrasound data initially marked as BI-RADS 3 and 4.,0,0
617,"3D DCE-MRI Radiomic Analysis for Malignant Lesion Prediction in Breast Cancer Patients. To develop and validate a radiomic model, with radiomic features extracted from breast Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) from a 1.5T scanner, for predicting the malignancy of masses with enhancement. Images were acquired using an 8-channel breast coil in the axial plane. The rationale behind this study is to show the feasibility of a radiomics-powered model that could be integrated into the clinical practice by exploiting only standard-of-care DCE-MRI with the goal of reducing the required image pre-processing (ie, normalization and quantitative imaging map generation).",0,0
621,"Automating classification of osteoarthritis according to Kellgren-Lawrence in the knee using deep learning in an unfiltered adult population. Prevalence for knee osteoarthritis is rising in both Sweden and globally due to increased age and obesity in the population. This has subsequently led to an increasing demand for knee arthroplasties. Correct diagnosis and classification of a knee osteoarthritis (OA) are therefore of a great interest in following-up and planning for either conservative or operative management. Most orthopedic surgeons rely on standard weight bearing radiographs of the knee. Improving the reliability and reproducibility of these interpretations could thus be hugely beneficial. Recently, deep learning which is a form of artificial intelligence (AI), has been showing promising results in interpreting radiographic images. In this study, we aim to evaluate how well an AI can classify the severity of knee OA, using entire image series and not excluding common visual disturbances such as an implant, cast and non-degenerative pathologies.",0,0
622,"A laminar augmented cascading flexible neural forest model for classification of cancer subtypes based on gene expression data. Correctly classifying the subtypes of cancer is of great significance for the in-depth study of cancer pathogenesis and the realization of personalized treatment for cancer patients. In recent years, classification of cancer subtypes using deep neural networks and gene expression data has gradually become a research hotspot. However, most classifiers may face overfitting and low classification accuracy when dealing with small sample size and high-dimensional biology data.",0,0
629,"Prediction of illness remission in patients with Obsessive-Compulsive Disorder with supervised machine learning. The course of OCD differs widely among OCD patients, varying from chronic symptoms to full remission. No tools for individual prediction of OCD remission are currently available. This study aimed to develop a machine learning algorithm to predict OCD remission after two years, using solely predictors easily accessible in the daily clinical routine.",0,0
641,"Prediction of post-stroke cognitive impairment using brain FDG PET: deep learning-based approach. Post-stroke cognitive impairment can affect up to one third of stroke survivors. Since cognitive function greatly contributes to patients' quality of life, an objective quantitative biomarker for early prediction of dementia after stroke is required. We developed a deep-learning (DL)-based signature using positron emission tomography (PET) to objectively evaluate cognitive decline in patients with stroke.",0,0
645,"A deep learning algorithm for white matter hyperintensity lesion detection and segmentation. White matter hyperintensity (WMHI) lesions on MR images are an important indication of various types of brain diseases that involve inflammation and blood vessel abnormalities. Automated quantification of the WMHI can be valuable for the clinical management of patients, but existing automated software is often developed for a single type of disease and may not be applicable for clinical scans with thick slices and different scanning protocols. The purpose of the study is to develop and validate an algorithm for automatic quantification of white matter hyperintensity suitable for heterogeneous MRI data with different disease types.",0,0
647,"Deep convolutional neural network-based algorithm for muscle biopsy diagnosis. Histopathologic evaluation of muscle biopsy samples is essential for classifying and diagnosing muscle diseases. However, the numbers of experienced specialists and pathologists are limited. Although new technologies such as artificial intelligence are expected to improve medical reach, their use with rare diseases, such as muscle diseases, is challenging because of the limited availability of training datasets. To address this gap, we developed an algorithm based on deep convolutional neural networks (CNNs) and collected 4041 microscopic images of 1400 hematoxylin-and-eosin-stained pathology slides stored in the National Center of Neurology and Psychiatry for training CNNs. Our trained algorithm differentiated idiopathic inflammatory myopathies (mostly treatable) from hereditary muscle diseases (mostly non-treatable) with an area under the curve (AUC) of 0.996 and achieved better sensitivity and specificity than the diagnoses done by nine physicians under limited diseases and conditions. Furthermore, it successfully and accurately classified four subtypes of the idiopathic inflammatory myopathies with an average AUC of 0.958 and classified seven subtypes of hereditary muscle disease with an average AUC of 0.936. We also established a method to validate the similarity between the predictions made by the algorithm and the seven physicians using visualization technology and clarified the validity of the predictions. These results support the reliability of the algorithm and suggest that our algorithm has the potential to be used straightforwardly in a clinical setting.",1,1
648,"Radiologists can visually predict mortality risk based on the gestalt of chest radiographs comparable to a deep learning network. Deep learning convolutional neural network (CNN) can predict mortality from chest radiographs, yet, it is unknown whether radiologists can perform the same task. Here, we investigate whether radiologists can visually assess image gestalt (defined as deviation from an unremarkable chest radiograph associated with the likelihood of 6-year mortality) of a chest radiograph to predict 6-year mortality. The assessment was validated in an independent testing dataset and compared to the performance of a CNN developed for mortality prediction. Results are reported for the testing dataset only (nâ€‰=â€‰100; age 62.5â€‰Â±â€‰5.2; male 55%, event rate 50%). The probability of 6-year mortality based on image gestalt had high accuracy (AUC: 0.68 (95% CI 0.58-0.78), similar to that of the CNN (AUC: 0.67 (95% CI 0.57-0.77); pâ€‰=â€‰0.90). Patients with high/very high image gestalt ratings were significantly more likely to die when compared to those rated as very low (pâ€‰â‰¤â€‰0.04). Assignment to risk categories was not explained by patient characteristics or traditional risk factors and imaging findings (pâ€‰â‰¥â€‰0.2). In conclusion, assessing image gestalt on chest radiographs by radiologists renders high prognostic accuracy for the probability of mortality, similar to that of a specifically trained CNN. Further studies are warranted to confirm this concept and to determine potential clinical benefits.",1,1
651,"Budget constrained machine learning for early prediction of adverse outcomes for COVID-19 patients. The combination of machine learning (ML) and electronic health records (EHR) data may be able to improve outcomes of hospitalized COVID-19 patients through improved risk stratification and patient outcome prediction. However, in resource constrained environments the clinical utility of such data-driven predictive tools may be limited by the cost or unavailability of certain laboratory tests. We leveraged EHR data to develop an ML-based tool for predicting adverse outcomes that optimizes clinical utility under a given cost structure. We further gained insights into the decision-making process of the ML models through an explainable AI tool. This cohort study was performed using deidentified EHR data from COVID-19 patients from ProMedica Health SystemÂ in northwest Ohio and southeastern Michigan. We tested the performance of various ML approaches for predicting either increasing ventilatory support or mortality. We performed post hoc analysis to obtain optimal feature sets under various budget constraints. We demonstrate that it is possible to achieve a significant reduction in cost at the expense of a small reduction in predictive performance. For example, when predicting ventilation, it is possible to achieve a 43% reduction in cost with only a 3% reduction in performance. Similarly, when predicting mortality, it is possible to achieve a 50% reduction in cost with only a 1% reduction in performance. This study presents a quick, accurate, and cost-effective method to evaluate risk of deterioration for patients with SARS-CoV-2 infection at the time of clinical evaluation.",0,0
659,"A Cascaded Deep Learning-Based Artificial Intelligence Algorithm for Automated Lesion Detection and Classification on Biparametric Prostate Magnetic Resonance Imaging. Prostate MRI improves detection of clinically significant prostate cancer; however, its diagnostic performance has wide variation. Artificial intelligence (AI) has the potential to assist radiologists in the detection and classification of prostatic lesions. Herein, we aimed to develop and test a cascaded deep learning detection and classification system trained on biparametric prostate MRI using PI-RADS for assisting radiologists during prostate MRI read out.",0,0
660,"Multi-Center Follow-up Study to Develop a Classification System Which Differentiates Mucinous Cystic Neoplasm of the Liver and Benign Hepatic Cyst Using Machine Learning. To date, no clinically useful classification system has been developed for reliably differentiating mucinous cystic neoplasm (MCN) from a benign hepatic cyst (BHC) in the liver. The objective was toÂ use machine learning and a multi-center study design to develop and assess the performance of a novel classification system for predicting whether a hepatic cystic lesion represents MCN or BHC.",0,0
665,"Do you have COVID-19? An artificial intelligence-based screening tool for COVID-19 using acoustic parameters. This study aimed to develop an artificial intelligence (AI)-based tool for screening COVID-19 patients based on the acoustic parameters of their voices. Twenty-five acoustic parameters were extracted from voice samples of 203 COVID-19 patients and 171 healthy individuals who produced a sustained vowel, i.e., /a/, as long as they could after a deep breath. The selected acoustic parameters were from different categories including fundamental frequency and its perturbation, harmonicity, vocal tract function, airflow sufficiency, and periodicity. After the feature extraction, different machine learning methods were tested. A leave-one-subject-out validation scheme was used to tune the hyper-parameters and record the test set results. Then the models were compared based on their accuracy, precision, recall, and F1-score. Based on accuracy (89.71%), recall (91.63%), and F1-score (90.62%), the best model was the feedforward neural network (FFNN). Its precision function (89.63%) was a bit lower than the logistic regression (90.17%). Based on these results and confusion matrices, the FFNN model was employed in the software. This screening tool could be practically used at home and public places to ensure the health of each individual's respiratory system. If there are any related abnormalities in the test taker's voice, the tool recommends that they seek a medical consultant.",0,0
666,"Multiple abnormality classification in wireless capsule endoscopy images based on EfficientNet using attention mechanism. The wireless capsule endoscopy (WCE) procedure produces tens of thousands of images of the digestive tract, for which the use of the manual reading process is full of challenges. Convolutional neural networks are used to automatically detect lesions in WCE images. However, studies on clinical multilesion detection are scarce, and it is difficult to effectively balance the sensitivity to multiple lesions. A strategy for detecting multiple lesions is proposed, wherein common vascular and inflammatory lesions can be automatically and quickly detected on capsule endoscopic images. Based on weakly supervised learning, EfficientNet is fine-tuned to extract the endoscopic image features. Combining spatial features and channel features, the proposed attention network is then used as a classifier to obtain three classifications. The accuracy and speed of the model were compared with those of the ResNet121 and InceptionNetV4 models. It was tested on a public WCE image dataset obtained from 4143 subjects. On the computer-assisted diagnosis for capsule endoscopy database, the method gives a sensitivity of 96.67% for vascular lesions and 93.33% for inflammatory lesions. The precision for vascular lesions was 92.80%, and that for inflammatory lesions was 95.73%. The accuracy was 96.11%, which is 1.11% higher than that of the latest InceptionNetV4 network. Prediction for an image only requires 14Â ms, which balances the accuracy and speed comparatively better. This strategy can be used as an auxiliary diagnostic method for specialists for the rapid reading of clinical capsule endoscopes.",0,0
668,"Classification of motor imagery using multisource jointÂ transfer learning. As an important way for human-computer interaction, the motor imagery brain-computer interface (MI-BCI) can decode personal motor intention directly by analyzing electroencephalogram (EEG) signals. However, a large amount of labeled data has to be collected for each new subject since EEG patterns vary between individuals. The long calibration phase severely limits the further development of MI-BCI. To tackle this problem, multi-source jointÂ domain adaption (MJDA) and multi-source jointÂ Riemannian adaption (MJRA) algorithms are proposed in this paper. Both methods aim to transfer knowledge from other subjects to the current subject who has only a small amount of labeled data. First, the common spatial pattern with Euclidean alignment is used to select source subjects who have similar spatial patterns to the target subject. Second, the covariance matrices of EEG trials are aligned in Riemannian space by removing subject-specific baselines. These two steps are shared by MJDA and MJRA. In the last step, MJDA attempts to minimize the feature distribution mismatch in the Riemannian tangent space, while MJRA attempts to find an adaptive Riemannian classifier. Finally, the proposed methods are validated on two datasets: BCI Competition IV 2a and online event-related desynchronization (ERD)-BCI. The experimental results demonstrate that both MJDA and MJRA outperform the state-of-the-art approaches. The MJDA provides a new idea for the offline analysis of MI-BCI, while MJRA could make a big difference to the online calibration of MI-BCI.",0,0
675,"Using Machine Learning to Capture Quality Metrics from Natural Language: A Case Study of Diabetic Eye Exams. â€ƒThe prevalence of value-based payment models has led to an increased use of the electronic health record to capture quality measures, necessitating additional documentation requirements for providers.",0,0
678,"Automatic measurement of axial vertebral rotation in 3D vertebral models. Axial Vertebral Rotation (AVR) is a significant indicator of adolescent idiopathic scoliosis (AIS). A host of methods are provided to measure AVR on coronal plane radiographs or 3D vertebral model. This paper provides a method of automatic AVR measurement in 3D vertebral model that is based on point cloud segmentation neural network and the tip of the spinous process searching algorithm. An improved PointNet using multi-input and attention mechanism named Multi-Input PointNet is proposed, which can segment the upper and lower endplates of the vertebral model accurately to determine the transverse plane of vertebral model. An algorithm is developed to search the tip of the spinous process according to the special structure of vertebrae. AVR angle is measured automatically using the midline of vertebral model and projection of y-axis on the transverse plane of vertebral model based on points obtained above. We compare automatic measurement results with manual measurement results on different vertebral models. The experiment shows that automatic results can achieve accuracy of manual measurement results and the correlation coefficient of them is 0.986, proving our automatic AVR measurement method performs well.",1,1
679,Quantification of tumor response of cystic vestibular schwannoma to Gamma Knife radiosurgery by using artificial intelligence. Gamma Knife radiosurgery (GKRS) is a common treatment modality for vestibular schwannoma (VS). The ability to predict treatment response is important in patient counseling and decision-making. The authors developed an algorithm that can automatically segment and differentiate cystic and solid tumor components of VS. They also investigated associations between the quantified radiological features of each component and tumor response after GKRS.,0,0
681,"3D shearlet-based descriptors combined with deep features for the classification of Alzheimer's disease based on MRI data. Alzheimer's disease (AD) is a neurodegenerative disease that afflicts millions of people worldwide. Early detection of AD is critical, as drug trials show a promising advantage to those patients with early diagnoses. In this study, magnetic resonance imaging (MRI) datasets from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and The Open Access Series of Imaging Studies are used. Our method for performing the classification of AD is to combine a set of shearlet-based descriptors with deep features. A major challenge in classifying such MRI datasets is the high dimensionality of feature vectors because of the large number of slices of each MRI sample. Given the volumetric nature of the MRI data, we propose using the 3D shearlet transform (3D-ST), but we obtain the average of all directionalities, which reduces the dimensionality. On the other hand, we propose to leverage the capabilities of convolutional neural networks (CNN) to learn feature maps from stacked MRI slices, which generate a very compact feature vector for each MRI sample. The 3D-ST and CNN feature vectors are combined for the classification of AD. After the concatenation of the feature vectors, they are used to train a classifier. Alternatively, a custom CNN model is utilized, in which the descriptors are further processed end to end to obtain the classification model. Our experimental results show that the fusion of shearlet-based descriptors and deep features improves classification performance, especially on the ADNI dataset.",0,0
685,Improved predictive performance of prostate biopsy collaborative group risk calculator when based on automated machine learning. The Prostate Biopsy Collaborative Group risk calculator (PBCG RC) has a moderate discriminatory capability. This study aimed to create automated machine learning (AutoML) PBCG RC for predicting the probability of any-grade and high-grade prostate cancer (PCa).,0,0
687,"Binge drinking in early adulthood: A machine learning approach. Binge drinking among young adults (18-25) has been recognized as a public health concern. Considerable variation among drinking behaviors have been found among this group. Several statistical methods are available to identify theoretically and empirically meaningful correlates of binge drinking. The present study evaluated three methods for identifying correlates of binge drinking, comparing logistic regression to two machine learning methods-classification tress and random forests. While each model identified similar correlates of binge drinking-such as propensity for engaging in risky behaviors, marijuana dependence, cocaine dependence, identifying as non-Hispanic white, and higher education-the AUC analysis showed that the random forest analysis more accurately classified positive cases of binge drinking. Random forests modelling of psychosocial data is a feasible approach for identifying correlates of binge drinking behaviors among young adults. Clinical implications are discussed related to screening for binge drinking in behavioral health organizations.",0,0
688,"Deep learning takes the pain out of back breaking work - Automatic vertebral segmentation and attenuation measurement for osteoporosis. Osteoporosis is an underdiagnosed and undertreated disease worldwide. Recent studies have highlighted the use of simple vertebral trabecular attenuation values for opportunistic osteoporosis screening. Meanwhile, machine learning has been used to accurately segment large parts of the human skeleton.",0,0
689,"Precise anatomical localization and classification of rib fractures on CT using a convolutional neural network. To develop a convolutional neural network (CNN) model for the detection, precise anatomical localization (right 1-12th and left 1-12th) and classification (fresh, healing and old fractures) of rib fractures automatically, and to compare the performance with the experienced radiologists.",1,1
690,"Auto-weighted centralised multi-task learning via integrating functional and structural connectivity for subjective cognitive decline diagnosis. Early diagnosis and intervention of mild cognitive impairment (MCI) and its early stage (i.e., subjective cognitive decline (SCD)) is able to delay or reverse the disease progression. However, discrimination between SCD, MCI and healthy subjects accurately remains challenging. This paper proposes an auto-weighted centralised multi-task (AWCMT) learning framework for differential diagnosis of SCD and MCI. AWCMT is based on structural and functional connectivity information inferred from magnetic resonance imaging (MRI). To be specific, we devise a novel multi-task learning algorithm to combine neuroimaging functional and structural connective information. We construct a functional brain network through a sparse and low-rank machine learning method, and also a structural brain network via fibre bundle tracking. Those two networks are constructed separately and independently. Multi-task learning is then used to identify features integration of functional and structural connectivity. Hence, we can learn each task's significance automatically in a balanced way. By combining the functional and structural information, the most informative features of SCD and MCI are obtained for diagnosis. The extensive experiments on the public and self-collected datasets demonstrate that the proposed algorithm obtains better performance in classifying SCD, MCI and healthy people than traditional algorithms. The newly proposed method has good interpretability as it is able to discover the most disease-related brain regions and their connectivity. The results agree well with current clinical findings and provide new insights into early AD detection based on the multi-modal neuroimaging technique.",0,0
699,A novel semi auto-segmentation method for accurate dose and NTCP evaluation in adaptive head and neck radiotherapy. Accurate segmentation of organs-at-risk (OARs) is crucial but tedious and time-consuming in adaptive radiotherapy (ART). The purpose of this work was to automate head and neck OAR-segmentation on repeat CT (rCT) by an optimal combination of human and auto-segmentation for accurate prediction of Normal Tissue Complication Probability (NTCP).,0,0
705,"Environmental chemical exposure dynamics and machine learning-based prediction of diabetes mellitus. With dramatically increasing prevalence, diabetes mellitus has imposed a tremendous toll on individual well-being. Humans are exposed to various environmental chemicals, which have been postulated as underappreciated but potentially modifiable diabetes risk factors.",0,0
712,"High value correlates of caregiver reported counseling service need and utilization for adolescents at-risk for childhood maltreatment and neglect. Adolescents with a history of child maltreatment experience increased risk for psychopathology that sets them on a trajectory towards a range of difficulties in adulthood. Various factors influence caregivers' decisions to seek mental health services (MHS) that could improve developmental outcomes. The present study applied a machine learning algorithm, elastic net, to a sample of 878 adolescent-caregiver dyads from the Longitudinal Studies of Child Abuse and Neglect. Analyses simultaneously examined a large number of factors to determine their ability to discriminate between caregivers who perceived a need for MHS and those who did not, as well as caregivers who utilized MHS and those who did not. Results highlight family demographics, chronic parental stressors, youth psychopathology, and exposure to recent adversities as good classifiers of caregiver perceived need for (77.6%; sensitivity = .77; specificity = .78) and utilization of (71%; sensitivity = .71; specificity = .71) adolescent MHS. Elastic net identified adolescent clinical externalizing and internalizing problems, and parental stress related to child(ren)'s behavior as high value classifiers of both outcomes. Youth living with non-kin caregivers were also significantly more likely to utilize MHS. Findings highlight the importance of assessing clinical need, stress related to child(ren)'s behavior, and caregiver kinship in understanding the likelihood that at-risk families will seek adolescent MHS.",0,0
713,Prediction of Incident Atrial Fibrillation in Chronic Kidney Disease: The Chronic Renal Insufficiency Cohort Study. Atrial fibrillation (AF) is common in CKD and associated with poor kidney and cardiovascular outcomes. Prediction models developed using novel methods may be useful to identify patients with CKD at highest risk of incident AF. We compared a previously published prediction model with models developed using machine learning methods in a CKD population.,1,1
722,"A machine learning risk model based on preoperative computed tomography scan to predict postoperative outcomes after pancreatoduodenectomy. Clinically relevant postoperative pancreatic fistula (CR-POPF) is a life-threatening complication following pancreaticoduodenectomy (PD). Individualized preoperative risk assessment could improve clinical management and prevent or mitigate adverse outcomes. The aim of this study is to develop a machine learning risk model to predict occurrence of CR-POPF after PD from preoperative computed tomography (CT) scans. A total of 100 preoperative high-quality CT scans of consecutive patients who underwent pancreaticoduodenectomy in our institution between 2011 and 2019 were analyzed. Radiomic and morphological features extracted from CT scans related to pancreatic anatomy and patient characteristics were included as variables. These data were then assessed by a machine learning classifier to assess the risk of developing CR-POPF. Among the 100 patients evaluated, 20 had CR-POPF. The predictive model based on logistic regression demonstrated specificity of 0.824 (0.133) and sensitivity of 0.571 (0.337), with an AUC of 0.807 (0.155), PPV of 0.468 (0.310) and NPV of 0.890 (0.084). The performance of the model minimally decreased utilizing a random forest approach, with specificity of 0.914 (0.106), sensitivity of 0.424 (0.346), AUC of 0.749 (0.209), PPV of 0.502 (0.414) and NPV of 0.869 (0.076). Interestingly, using the same data, the model was also able to predict postoperative overall complications and a postoperative length of stay over the median with AUCs of 0.690 (0.209) and 0.709 (0.160), respectively. These findings suggest that preoperative CT scans evaluated by machine learning may provide a novel set of information to help clinicians choose a tailored therapeutic pathway in patients candidated to pancreatoduodenectomy.",0,0
726,Use of Deep Learning to Predict Acute Kidney Injury After Intravenous Contrast Media Administration: Prediction Model Development Study. Precise prediction of contrast media-induced acute kidney injury (CIAKI) is an important issue because of its relationship with poor outcomes.,0,0
728,"Machine Learning to Identify Psychomotor Behaviors of Delirium for Patients in Long-Term Care Facility. This study aimed to develop accurate and explainable machine learning models for three psychomotor behaviors of delirium for hospitalized adult patients. A prospective pilot study was conducted with 33 participants admitted to a long-term care facility between August 10 and 25, 2020. During the pilot study, we collected 560 cases that included 33 clinical variables and the survey items from the short confusion assessment method (S-CAM), and developed a mobile-based application. Multiple machine learning algorithms, including four rule-mining algorithms (C4.5, CBA, MCAR, and LEM2) and four other statistical learning algorithms (LR, ANNs, SVMs with three kernel functions, and random forest), were validated by paired Wilcoxon signed-rank tests on both macro-averaged F1 and weighted average F1-measures during the 10-times stratified 2-fold cross-validation. The LEM2 algorithm achieved the best prediction performance (macro-averaged F1-measure of 49.35%; weighted average F1-measure of 96.55%), correctly identifying adult patients at delirium risk. In the pairwise comparison between predictive powers observed from independent models, the LEM2 model showed a medium or large effect size between 0.4925 and 0.8766 when compared with LR, ANN, SVM with RBF, and MCAR models. We have confirmed that acute consciousness in S-CAM assessment is closely associated with different predictors for screening three psychomotor behaviors of delirium: 1) education level, dementia type or its level, sleep disorder, dehydration, and infection in mixed-type delirium; 2) gender, education level, dementia type, dehydration, bedsores, and foley catheter in hyperactive delirium; and 3) pain, sleep disorder, and haloperidol use in hypoactive delirium.",0,0
732,"Predicting embryo viability based on self-supervised alignment of time-lapse videos. With self-supervised learning, both labeled and unlabeled data can be used for representation learning and model pretraining. This is particularly relevant when automating the selection of a patient's fertilized eggs (embryos) during a fertility treatment, in which only the embryos that were transferred to the female uterus may have labels of pregnancy. In this paper, we apply a self-supervised video alignment method known as temporal cycle-consistency (TCC) on 38;176 time-lapse videos of developing embryos, of which 14;550 were labeled. We show how TCC can be used to extract temporal similarities between embryo videos and use these for predicting pregnancy likelihood. Our temporal similarity method outperforms the time alignment measurement (TAM) with an area under the receiver operating characteristic (AUC) of 0.64 vs. 0.56. Compared to existing embryo evaluation models, it places in between a pure temporal and a spatio-temporal model that both require manual annotations. Furthermore, we use TCC for transfer learning in a semi-supervised fashion and show significant performance improvements compared to standard supervised learning, when only a small subset of the dataset is labeled. Specifically, two variants of transfer learning both achieve an AUC of 0.66 compared to 0.63 for supervised learning when 16% of the dataset is labeled.",0,0
743,"Unique serum immune phenotypes stratify Oklahoma Native American rheumatic disease patients. Native American (NA) populations have higher rates of rheumatic disease and present with overlapping disease symptoms and nontraditional serological features, thus presenting an urgent need for better biomarkers in NA diagnostics. This study utilized a machine-learning approach to identify immune signatures that more effectively stratify NA rheumatic disease patients.",0,0
745,"Computer-aided automatic measurement of leg length on full leg radiographs. To develop and evaluate a deep learning (DL)-based system for measuring leg length on full leg radiographs of diverse patients, including those with orthopedic hardware implanted for surgical treatment.",0,0
752,"Role of standard and soft tissue chest radiography images in deep-learning-based early diagnosis of COVID-19. <b>Purpose:</b> We propose a deep learning method for the automatic diagnosis of COVID-19 at patient presentation on chest radiography (CXR) images and investigates the role of standard and soft tissue CXR in this task. <b>Approach:</b> The dataset consisted of the first CXR exams of 9860 patients acquired within 2 days after their initial reverse transcription polymerase chain reaction tests for the SARS-CoV-2 virus, 1523 (15.5%) of whom tested positive and 8337 (84.5%) of whom tested negative for COVID-19. A sequential transfer learning strategy was employed to fine-tune a convolutional neural network in phases on increasingly specific and complex tasks. The COVID-19 positive/negative classification was performed on standard images, soft tissue images, and both combined via feature fusion. A U-Net variant was used to segment and crop the lung region from each image prior to performing classification. Classification performances were evaluated and compared on a held-out test set of 1972 patients using the area under the receiver operating characteristic curve (AUC) and the DeLong test. <b>Results:</b> Using full standard, cropped standard, cropped, soft tissue, and both types of cropped CXR yielded AUC values of 0.74 [0.70, 0.77], 0.76 [0.73, 0.79], 0.73 [0.70, 0.76], and 0.78 [0.74, 0.81], respectively. Using soft tissue images significantly underperformed standard images, and using both types of CXR failed to significantly outperform using standard images alone. <b>Conclusions:</b> The proposed method was able to automatically diagnose COVID-19 at patient presentation with promising performance, and the inclusion of soft tissue images did not result in a significant performance improvement.",0,0
755,"Discrimination Between Invasive and <i>In Situ</i> Melanomas Using Clinical Close-Up Images and a <i>De Novo</i> Convolutional Neural Network. <b>Background:</b> Melanomas are often easy to recognize clinically but determining whether a melanoma is <i>in situ</i> (MIS) or invasive is often more challenging even with the aid of dermoscopy. Recently, convolutional neural networks (CNNs) have made significant and rapid advances within dermatology image analysis. The aims of this investigation were to create a <i>de novo</i> CNN for differentiating between MIS and invasive melanomas based on clinical close-up images and to compare its performance on a test set to seven dermatologists. <b>Methods:</b> A retrospective study including clinical images of MIS and invasive melanomas obtained from our department during a five-year time period (2016-2020) was conducted. Overall, 1,551 images [819 MIS (52.8%) and 732 invasive melanomas (47.2%)] were available. The images were randomized into three groups: training set (<i>n</i> = 1,051), validation set (<i>n</i> = 200), and test set (<i>n</i> = 300). A <i>de novo</i> CNN model with seven convolutional layers and a single dense layer was developed. <b>Results:</b> The area under the curve was 0.72 for the CNN (95% CI 0.66-0.78) and 0.81 for dermatologists (95% CI 0.76-0.86) (<i>P</i> < 0.001). The CNN correctly classified 208 out of 300 lesions (69.3%) whereas the corresponding number for dermatologists was 216 (72.0%). When comparing the CNN performance to each individual reader, three dermatologists significantly outperformed the CNN. <b>Conclusions:</b> For this classification problem, the CNN was outperformed by the dermatologist. However, since the algorithm was only trained and validated on 1,251 images, future refinement and development could make it useful for dermatologists in a real-world setting.",1,1
757,Analysis of EPID Transmission Fluence Maps Using Machine Learning Models and CNN for Identifying Position Errors in the Treatment of GO Patients. To find a suitable method for analyzing electronic portal imaging device (EPID) transmission fluence maps for the identification of position errors in the <i>in vivo</i> dose monitoring of patients with Graves' ophthalmopathy (GO).,0,0
764,"Deep Learning-Based Three-Dimensional Oral Conical Beam Computed Tomography for Diagnosis. In order to deeply study oral three-dimensional cone beam computed tomography (CBCT), the diagnosis of oral and facial surgical diseases based on deep learning was studied. The utility model related to a deep learning-based classification algorithm for oral neck and facial surgery diseases (deep diagnosis of oral and maxillofacial diseases, referred to as DDOM) is brought out; in this method, the DDOM algorithm proposed for patient classification, lesion segmentation, and tooth segmentation, respectively, can effectively process the three-dimensional oral CBCT data of patients and carry out patient-level classification. The segmentation results show that the proposed segmentation method can effectively segment the independent teeth in CBCT images, and the vertical magnification error of tooth CBCT images is clear. The average magnification rate was 7.4%. By correcting the equation of <i>R</i> value and CBCT image vertical magnification rate, the magnification error of tooth image length could be reduced from 7.4. According to the CBCT image length of teeth, the distance <i>R</i> from tooth center to FOV center, and the vertical magnification of CBCT image, the data closer to the real tooth size can be obtained, in which the magnification error is reduced to 1.0%. Therefore, it is proved that the 3D oral cone beam electronic computer based on deep learning can effectively assist doctors in three aspects: patient diagnosis, lesion localization, and surgical planning.",0,0
765,"Deep Learning-Based Image Segmentation of Cone-Beam Computed Tomography Images for Oral Lesion Detection. This paper aimed to study the adoption of deep learning (DL) algorithm of oral lesions for segmentation of cone-beam computed tomography (CBCT) images. 90 patients with oral lesions were taken as research subjects, and they were grouped into blank, control, and experimental groups, whose images were treated by the manual segmentation method, threshold segmentation algorithm, and full convolutional neural network (FCNN) DL algorithm, respectively. Then, effects of different methods on oral lesion CBCT image recognition and segmentation were analyzed. The results showed that there was no substantial difference in the number of patients with different types of oral lesions among three groups (<i>P</i> > 0.05). The accuracy of lesion segmentation in the experimental group was as high as 98.3%, while those of the blank group and control group were 78.4% and 62.1%, respectively. The accuracy of segmentation of CBCT images in the blank group and control group was considerably inferior to the experimental group (<i>P</i> < 0.05). The segmentation effect on the lesion and the lesion model in the experimental group and control group was evidently superior to the blank group (<i>P</i> < 0.05). In short, the image segmentation accuracy of the FCNN DL method was better than the traditional manual segmentation and threshold segmentation algorithms. Applying the DL segmentation algorithm to CBCT images of oral lesions can accurately identify and segment the lesions.",0,0
766,"Construction and validation of nomograms for non-metastatic Ewing sarcoma: A prognostic factor analysis based on the SEER database. Ewing sarcoma is the second most common osseous disease in children and adolescents. It presents with a poor prognosis due to the high degree of malignancy and distant metastasis. In order to predict the disease prognosis and investigate a suitable therapeutic strategy for Ewing sarcoma, the present study aimed to describe the clinical characteristics, and to construct and validate nomograms for patients with non-metastatic Ewing sarcoma. A total of 627 cases of non-metastatic Ewing sarcoma were retrospectively collected from the Surveillance, Epidemiology, and End Results database between 2005 and 2014. Survival analysis and a machine learning model were used to identify independent prognostic variables and establish nomograms to estimate overall survival (OS) and cause-specific survival (CSS). The nomograms were bootstrap internally validated and externally validated using non-metastatic Ewing sarcoma cases from the First Affiliated Hospital of Zhengzhou University. The accuracy was also assessed by comparing with current American Joint Committee on Cancer (AJCC) staging systems. The total series consisted of 627 patients with non-metastatic Ewing sarcoma with a mean age of 20.14 years. Age, tumor extension, sex, International Classification of Diseases for Oncology, 3rd Edition histology, surgery and chemotherapy were identified as independent risk factors for OS and CSS. The aforementioned outcomes were incorporated to construct the nomograms, and the concordance indices (C-indices) for internal validation of OS and CSS prediction were 0.791 and 0.813, which were higher than those for AJCC sixth edition (OS, 0.531; CSS, 0.534) and seventh edition (OS, 0.547; CSS, 0.561), while the C-indices for external validation of OS and CSS prediction were 0.834 and 0.825, respectively. In conclusion, age, sex, tumor extension and surgery were independent prognostic factors for both OS and CSS. In addition, with regard to OS, the Ewing sarcoma subtype was a poor factor and chemotherapy was a favorable one. Nomograms based on reduced Cox models attained a satisfactory accuracy in predicting the survival of patients with non-metastatic Ewing sarcoma and could assist clinicians in evaluating survival more accurately.",0,1
767,"An Approach for Thoracic Syndrome Classification with Convolutional Neural Networks. There have been remarkable changes in our lives and the way we perceive the world with advances in computing technology. Healthcare sector is evolving with the intervention of the latest computer-driven technology and has made a remarkable change in the diagnosis and treatment of various diseases. Due to many governing factors including air pollution, there is a rapid rise in chest-related diseases and the number of such patients is rising at an alarming rate. In this research work, we have employed machine learning approach for the detecting various chest-related problems using convolutional neural networks (CNN) on an open dataset of chest X-rays. The method has an edge over the traditional approaches for image segmentation including thresholding, <i>k</i>-means clustering, and edge detection. The CNN cannot scan and process the whole image at an instant; it needs to recursively scan small pixel spots until it has scanned the whole image. Spatial transformation layers and VGG19 have been used for the purpose of feature extraction, and ReLU activation function has been employed due to its inherent low complexity and high computation efficiency; finally, stochastic gradient descent has been used as an optimizer. The main advantage of the current method is that it retains the essential features of the image for prediction along with incorporating a considerable dimensional reduction. The model delivered substantial improvement over existing research in terms of precision, <i>f</i>-score, and accuracy of prediction. This model if used precisely can be very effective for healthcare practitioners in determining the thoracic or pneumonic symptoms in the patient at an early stage thus guiding the practitioner to start the treatment immediately leading to fast improvement in the health status of the patient.",0,0
773,"Low Back Pain Exacerbation Is Predictable Through Motif Identification in Center of Pressure Time Series Recorded During Dynamic Sitting. <b>Background:</b> Low back pain (LBP) is a common health problem - sitting on a chair for a prolonged time is considered a significant risk factor. Furthermore, the level of LBP may vary at different times of the day. However, the role of the time-sequence property of sitting behavior in relation to LBP has not been considered. During the dynamic sitting, small changes, such as slight or big sways, have been identified. Therefore, it is possible to identify the motif consisting of such changes, which may be associated with the incidence, exacerbation, or improvement of LBP. <b>Method:</b> Office chairs installed with pressure sensors were provided to a total of 22 office workers (age = 43.4 Â± 8.3 years) in Japan. Pressure sensors data were collected during working days and hours (from morning to evening). The participants were asked to answer subjective levels of pain including LBP. Center of pressure (COP) was calculated from the load level, the changes in COP were analyzed by applying the Toeplitz inverse covariance-based clustering (TICC) analysis, COP changes were categorized into several states. Based on the states, common motifs were identified as a recurring sitting behavior pattern combination of different states by motif-aware state assignment (MASA). Finally, the identified motif was tested as a feature to infer the changing levels of LBP within a day. Changes in the levels of LBP from morning to evening were categorized as exacerbated, did not change, or improved based on the survey questions. Here, we present a novel approach based on social spider algorithm (SSA) and probabilistic neural network (PNN) for the prediction of LBP. The specificity and sensitivity of the LBP inference were compared among ten different models, including SSA-PNN. <b>Result:</b> There exists a common motif, consisting of stable sitting and slight sway. When LBP level improved toward the evening, the frequency of motif appearance was higher than when LBP was exacerbated (<i>p</i> < 0.05) or the level did not change. The performance of the SSA-PNN optimization was better than that of the other algorithms. Accuracy, precision, recall, and F1-score were 59.20, 72.46, 40.94, and 63.24%, respectively. <b>Conclusion:</b> A lower frequency of a common motif of the COP dynamic changes characterized by stable sitting and slight sway was found to be associated with the exacerbation of LBP in the evening. LBP exacerbation is predictable by AI-based analysis of COP changes during the sitting behavior of the office workers.",0,0
774,"Using Artificial Intelligence for Automatic Segmentation of CT Lung Images in Acute Respiratory Distress Syndrome. Knowledge of gas volume, tissue mass and recruitability measured by the quantitative CT scan analysis (CT-qa) is important when setting the mechanical ventilation in acute respiratory distress syndrome (ARDS). Yet, the manual segmentation of the lung requires a considerable workload. Our goal was to provide an automatic, clinically applicable and reliable lung segmentation procedure. Therefore, a convolutional neural network (CNN) was used to train an artificial intelligence (AI) algorithm on 15 healthy subjects (1,302 slices), 100 ARDS patients (12,279 slices), and 20 COVID-19 (1,817 slices). Eighty percent of this populations was used for training, 20% for testing. The AI and manual segmentation at slice level were compared by intersection over union (IoU). The CT-qa variables were compared by regression and Bland Altman analysis. The AI-segmentation of a single patient required 5-10 s vs. 1-2 h of the manual. At slice level, the algorithm showed on the test set an IOU across all CT slices of 91.3 Â± 10.0, 85.2 Â± 13.9, and 84.7 Â± 14.0%, and across all lung volumes of 96.3 Â± 0.6, 88.9 Â± 3.1, and 86.3 Â± 6.5% for normal lungs, ARDS and COVID-19, respectively, with a U-shape in the performance: better in the lung middle region, worse at the apex and base. At patient level, on the test set, the total lung volume measured by AI and manual segmentation had a <i>R</i> <sup>2</sup> of 0.99 and a bias -9.8 ml [CI: +56.0/-75.7 ml]. The recruitability measured with manual and AI-segmentation, as change in non-aerated tissue fraction had a bias of +0.3% [CI: +6.2/-5.5%] and -0.5% [CI: +2.3/-3.3%] expressed as change in well-aerated tissue fraction. The AI-powered lung segmentation provided fast and clinically reliable results. It is able to segment the lungs of seriously ill ARDS patients fully automatically.",0,0
775,"Outer Retinal Layer Thickness Changes in White Matter Hyperintensity and Parkinson's Disease. <b>Purpose:</b> To investigate the thickness changes of outer retinal layers in subjects with white matter hyperintensities (WMH) and Parkinson's Disease (PD). <b>Methods:</b> 56 eyes from 31 patients with WMH, 11 eyes from 6 PD patients, and 58 eyes from 32 healthy controls (HC) were enrolled in this study. A macular-centered scan was conducted on each participant using a spectral-domain optical coherence tomography (SD-OCT) device. After speckle noise reduction, a state-of-the-art deep learning method (i.e., a context encoder network) was employed to segment the outer retinal layers from OCT <i>B</i>-scans. Thickness quantification of the outer retinal layers was conducted on the basis of the segmentation results. <b>Results:</b> WMH patients had significantly thinner Henle fiber layers, outer nuclear layers (HFL+ONL) and photoreceptor outer segments (OS) than HC (<i>p</i> = 0.031, and <i>p</i> = 0.005), while PD patients showed a significant increase of mean thickness in the interdigitation zone and the retinal pigment epithelium/Bruch complex (IZ+RPE) (19.619 Â± 4.626) compared to HC (17.434 Â± 1.664). There were no significant differences in the thickness of the outer plexiform layer (OPL), the myoid and ellipsoid zone (MEZ), and the IZ+RPE layer between WMH and HC subjects. Similarly, there were also no obvious differences in the thickness of the OPL, HFL+ONL, MEZ and the OS layer between PD and HC subjects. <b>Conclusion:</b> Thickness changes in HFL+ONL, OS, and IZ+RPE layers may correlate with brain-related diseases such as WMH and PD. Further longitudinal study is needed to confirm HFL+ONL/OS/IZ+RPE layer thickness as potential biomarkers for detecting certain brain-related diseases.",0,0
776,"Multimodal MR Images-Based Diagnosis of Early Adolescent Attention-Deficit/Hyperactivity Disorder Using Multiple Kernel Learning. Attention-deficit/hyperactivity disorder (ADHD) is one of the most common brain diseases among children. The current criteria of ADHD diagnosis mainly depend on behavior analysis, which is subjective and inconsistent, especially for children. The development of neuroimaging technologies, such as magnetic resonance imaging (MRI), drives the discovery of brain abnormalities in structure and function by analyzing multimodal neuroimages for computer-aided diagnosis of brain diseases. This paper proposes a multimodal machine learning framework that combines the Boruta based feature selection and Multiple Kernel Learning (MKL) to integrate the multimodal features of structural and functional MRIs and Diffusion Tensor Images (DTI) for the diagnosis of early adolescent ADHD. The rich and complementary information of the macrostructural features, microstructural properties, and functional connectivities are integrated at the kernel level, followed by a support vector machine classifier for discriminating ADHD from healthy children. Our experiments were conducted on the comorbidity-free ADHD subjects and covariable-matched healthy children aged 9-10 chosen from the Adolescent Brain and Cognitive Development (ABCD) study. This paper is the first work to combine structural and functional MRIs with DTI for early adolescents of the ABCD study. The results indicate that the kernel-level fusion of multimodal features achieves 0.698 of AUC (area under the receiver operating characteristic curves) and 64.3% of classification accuracy for ADHD diagnosis, showing a significant improvement over the early feature fusion and unimodal features. The abnormal functional connectivity predictors, involving default mode network, attention network, auditory network, and sensorimotor mouth network, thalamus, and cerebellum, as well as the anatomical regions in basal ganglia, are found to encode the most discriminative information, which collaborates with macrostructure and diffusion alterations to boost the performances of disorder diagnosis.",0,0
785,"Prediction of hospitalization using artificial intelligence for urgent patients in the emergency department. Timely assessment to accurately prioritize patients is crucial for emergency department (ED) management. Urgent (i.e., level-3, on a 5-level emergency severity index system) patients have become a challenge since under-triage and over-triage often occur. This study was aimed to develop a computational model by artificial intelligence (AI) methodologies to accurately predict urgent patient outcomes using data that are readily available in most ED triage systems. We retrospectively collected data from the ED of a tertiary teaching hospital between January 1, 2015 and December 31, 2019. Eleven variables were used for data analysis and prediction model building, including 1 response, 2 demographic, and 8 clinical variables. A model to predict hospital admission was developed using neural networks and machine learning methodologies. A total of 282,971 samples of urgent (level-3) visits were included in the analysis. Our model achieved a validation area under the curve (AUC) of 0.8004 (95% CI 0.7963-0.8045). The optimal cutoff value identified by Youden's index for determining hospital admission was 0.5517. Using this cutoff value, the sensitivity was 0.6721 (95% CI 0.6624-0.6818), and the specificity was 0.7814 (95% CI 0.7777-0.7851), with a positive predictive value of 0.3660 (95% CI 0.3586-0.3733) and a negative predictive value of 0.9270 (95% CI 0.9244-0.9295). Subgroup analysis revealed that this model performed better in the nontraumatic adult subgroup and achieved a validation AUC of 0.8166 (95% CI 0.8199-0.8212). Our AI model accurately assessed the need for hospitalization for urgent patients, which constituted nearly 70% of ED visits. This model demonstrates the potential for streamlining ED operations using a very limited number of variables that are readily available in most ED triage systems. Subgroup analysis is an important topic for future investigation.",0,0
787,"New segmentation and feature extraction algorithm for classification of white blood cells in peripheral smear images. This article addresses a new method for the classification of white blood cells (WBCs) using image processing techniques and machine learning methods. The proposed method consists of three steps: detecting the nucleus and cytoplasm, extracting features, and classification. At first, a new algorithm is designed to segment the nucleus. For the cytoplasm to be detected, only a part of it located inside the convex hull of the nucleus is involved in the process. This attitude helps us overcome the difficulties of segmenting the cytoplasm. In the second phase, three shapes and four novel color features are devised and extracted. Finally, by using an SVM model, the WBCs are classified. The segmentation algorithm can detect the nucleus with a dice similarity coefficient of 0.9675. The proposed method can categorize WBCs in Raabin-WBC, LISC, and BCCD datasets with accuracies of 94.65%, 92.21%, and 94.20%, respectively. Besides, we show that the proposed method possesses more generalization power than pre-trained CNN models. It is worth mentioning that the hyperparameters of the classifier are fixed only with the Raabin-WBC dataset, and these parameters are not readjusted for LISC and BCCD datasets.",0,0
788,"Cardiac involvement in hospitalized patients with COVID-19 and its incremental value in outcomes prediction. Recent reports linked acute COVID-19 infection in hospitalized patients to cardiac abnormalities. Studies have not evaluated presence of abnormal cardiac structure and function before scanning in setting of COVD-19 infection. We sought to examine cardiac abnormalities in consecutive group of patients with acute COVID-19 infection according to the presence or absence of cardiac disease based on review of health records and cardiovascular imaging studies. We looked at independent contribution of imaging findings to clinical outcomes. After excluding patients with previous left ventricular (LV) systolic dysfunction (global and/or segmental), 724 patients were included. Machine learning identified predictors of in-hospital mortality and in-hospital mortalityâ€‰+â€‰ECMO. In patients without previous cardiovascular disease, LV EFâ€‰<â€‰50% occurred in 3.4%, abnormal LVÂ global longitudinal strain (<â€‰16%) in 24%, and diastolic dysfunction in 20%. Right ventricular systolic dysfunction (RV free wall strainâ€‰<â€‰20%) was noted in 18%. Moderate and large pericardial effusion were uncommon with an incidence of 0.4% for each category. Forty patients received ECMO support, and 79 died (10.9%). A stepwise increase in AUC was observed with addition of vital signs and laboratory measurements to baseline clinical characteristics, and a further significant increase (AUC 0.91) was observed when echocardiographic measurements were added. The performance of an optimized prediction model was similar to the model including baseline characteristicsâ€‰+â€‰vital signs and laboratory resultsâ€‰+â€‰echocardiographic measurements.",0,0
796,Cervical Myelopathy Screening with Machine Learning Algorithm Focusing on Finger Motion Using Non-Contact Sensor. Cross-sectional study.,0,0
802,"A Geno-Clinical Decision Model for the Diagnosis of Myelodysplastic Syndromes. The differential diagnosis of myeloid malignancies is challenging and subject to inter-observer variability. We used clinical and next-generation sequencing (NGS) data to develop a machine learning model for the diagnosis of myeloid malignancies independent of bone marrow biopsy data based on a three institution, international cohort of patients. The model achieves high performance, with model interpretations indicating that it relies on factors similar to those used by clinicians. Additionally, we describe associations between NGS findings and clinically important phenotypes, and introduce the use of machine learning algorithms to elucidate clinico-genomic relationships.",0,0
803,"Predicting next-day discharge via electronic health record access logs. Hospital capacity management depends on accurate real-time estimates of hospital-wide discharges. Estimation by a clinician requires an excessively large amount of effort and, even when attempted, accuracy in forecasting next-day patient-level discharge is poor. This study aims to support next-day discharge predictions with machine learning by incorporating electronic health record (EHR) audit log data, a resource that captures EHR users' granular interactions with patients' records by communicating various semantics and has been neglected in outcome predictions.",0,0
805,Using administrative data to predict cessation risk and identify novel predictors among new entrants to opioid agonist treatment. Longer retention in opioid agonist treatment (OAT) is associated with improved treatment outcomes but 12-month retention rates are often low. Innovative approaches are needed to strengthen retention in OAT. We develop and compare traditional and deep learning-extensions of Cox regression to examine the potential for predicting time in OAT at individuals' first episode entry.,0,0
807,MTU-COVNet: A hybrid methodology for diagnosing the COVID-19 pneumonia with optimized features from multi-net. The aim of this study was to establish and evaluate a fully automatic deep learning system for the diagnosis of COVID-19 using thoracic computed tomography (CT).,0,0
808,"Paroxysmal atrial fibrillation prediction based on morphological variant P-wave analysis with wideband ECG and deep learning. Atrial fibrillation (AF) is one of the most frequent asymptomatic arrhythmias associated with significant morbidity and mortality. Identifying the susceptibility to AF based on routine or continuous ECG recording is of considerable interest. Despite several P-wave characteristics and skin sympathetic nerve activity (SKNA) linked to AF onset, neither factor has offered accurate predictability. We propose a deep learning enabled method for AF risk prediction.",0,0
810,"Systemic cytokines, chemokines and growth factors reveal specific and shared immunological characteristics in infectious cardiomyopathies. Heart disease is a major cause of death worldwide. Chronic Chagas cardiomyopathy (CCC) caused by infection with Trypanosoma cruzi leading to high mortality in adults, and rheumatic heart disease (RHD), resulting from infection by Streptococcus pyogenes affecting mainly children and young adults, are amongst the deadliest heart diseases in low-middle income countries. Despite distinct etiology, the pathology associated with both diseases is a consequence of inflammation. Here we compare systemic immune profile in patients with these cardiopathies, to identify particular and common characteristics in these infectious heart diseases. We evaluated the expression of 27 soluble factors, employing single and multivariate analysis combined with machine-learning approaches. We observed that, while RHD and CCC display higher levels of circulating mediators than healthy individuals, CCC is associated with stronger immune activation as compared to RHD. Despite distinct etiologies, univariate analysis showed that expression of TNF, IL-17, IFN-gamma, IL-4, CCL4, CCL3, CXCL8, CCL11, CCL2, PDGF-BB were similar between CCC and RHD, consistent with their inflammatory nature. Network analysis revealed common inflammatory pathways between CCC and RHD, while highlighting the broader reach of the inflammatory response in CCC. The final multivariate model showed a 100% discrimination power for the combination of the cytokines IL-12p70, IL-1Ra, IL-4, and IL-7 between CCC and RHD groups. Thus, while clear immunological distinctions were identified between CCC and RHD, similarities indicate shared inflammatory pathways in these infectious heart diseases. These results contribute to understanding the pathogenesis of CCC and RHD and may impact the design of immune-based therapies for these and other inflammatory cardiopathies that may also share immunological characteristics.",0,0
813,"Novel Computer-Aided Diagnosis Software for the Prevention of Retained Surgical Items. Retained surgical items are serious human errors. Surgical sponges account for 70% of retained surgical material. To prevent retained surgical sponges, it is important to establish a system that can identify errors and avoid the occurrence of adverse events. To date, no computer-aided diagnosis (CAD) software specialized for detecting retained surgical sponges has been reported. We developed a software program that enables easy and effective computer-aided diagnosis of retained surgical sponges with high sensitivity and specificity using the technique of deep learning, a subfield of artificial intelligence (AI).",0,0
817,Prediction of response after cardiac resynchronization therapy with machine learning. Nearly one third of patients receiving cardiac resynchronization therapy (CRT) suffer non-response. We intend to develop predictive models using machine learning (ML) approaches and easily attainable features before CRT implantation.,0,0
821,Evaluation of an Automated Approach for Facial Midline Detection and Asymmetry Assessment: A Preliminary Study. To examine the level of agreement between the conventional method and a machine learning approach to facial midline determination and asymmetry assessment.,0,0
824,"Feature selection to classify lameness using a smartphone-based inertial measurement unit. Gait can be severely affected by pain, muscle weakness, and aging resulting in lameness. Despite the high incidence of lameness, there are no studies on the features that are useful for classifying lameness patterns. Therefore, we aimed to identify features of high importance for classifying population differences in lameness patterns using an inertial measurement unit mounted above the sacral region.",0,0
827,"Integrating additional factors into the TNM staging for cutaneous melanoma by machine learning. Integrating additional factors into the TNM staging system is needed for more accurate risk classification and survival prediction for patients with cutaneous melanoma. In the present study, we introduce machine learning as a novel tool that incorporates additional prognostic factors to improve the current TNM staging system.",0,0
829,"Machine learning implicates the IL-18 signaling axis in severe asthma. Asthma is a common disease with profoundly variable natural history and patient morbidity. Heterogeneity has long been appreciated and much work has focused on identifying subgroups of patients with similar pathobiological underpinnings. Previous studies of the Severe Asthma Research Program (SARP) cohort linked gene expression changes to specific clinical and physiologic characteristics. While invaluable for hypothesis generation, these data include extensive candidate gene lists that complicate target identification and validation. In this analysis, we performed unsupervised clustering of the SARP cohort using bronchial epithelial cell gene expression data, identifying a transcriptional signature for participants suffering exacerbation prone asthma with impaired lung function. Clinically, participants in this asthma cluster exhibited a mixed inflammatory process and bore transcriptional hallmarks of nuclear factor kappa B (NF-ÎºB) and activator protein 1 (AP-1) activation despite high corticosteroid exposure. Using supervised machine learning, we found a set of 31 genes that classified patients with high accuracy and could reconstitute clinical and transcriptional hallmarks of our patient clustering in an external cohort. Of these genes, IL18R1 (IL-18 Receptor 1) negatively associated with lung function and was highly expressed in the most severe patient cluster. We validated IL18R1 protein expression in lung tissue and identified downstream NF-ÎºB and AP-1 activity, supporting IL-18 signaling in severe asthma pathogenesis and highlighting this approach for gene/pathway discovery.",0,0
830,"Diabetes detection from whole-body magnetic resonance imaging using deep learning. HypothesisObesity is one of the main drivers of type 2 diabetes (T2D), but not uniformly associated with the disease. The location of fat accumulation is critical for metabolic health. Specific patterns of body fat distribution such as visceral fat, are closely related to insulin resistance. There might be further, hitherto unknown features of body fat distribution which could additionally contribute to the disease.MethodsWe used machine learning with dense convolutional neural networks (DCNN) to detect diabetes related variables from 2,371 T1-weighted whole-body magnetic resonance imaging (MRI) datasets. MRI was performed in participants undergoing metabolic screening with oral glucose tolerance tests. Models were trained for sex, age, BMI, insulin sensitivity, HbA1c and prediabetes or incident diabetes. The results were compared to conventional models.ResultsThe Area Under the Receiver Operator Characteristic curve was 87% for the T2D discrimination and 68% for prediabetes, both superior to conventional models. Mean absolute regression errors were comparable to conventional models. Heatmaps showed that lower visceral abdominal regions were critical in diabetes classification. Subphenotyping revealed a group with high future diabetes and microalbuminuria risk.InterpretationOur results show that diabetes is detectable from whole-body MRI without additional data. Our technique of heatmap visualization unravels plausible anatomical regions and highlights the leading role of fat accumulation in the lower abdomen in diabetes pathogenesis.",0,0
831,"Deep Learning Based Centerline-Aggregated Aortic Hemodynamics: An Efficient Alternative to Numerical Modelling of Hemodynamics. Image-based patient-specific modelling of hemodynamics are gaining increased popularity as a diagnosis and outcome prediction solution for a variety of cardiovascular diseases. While their potential to improve diagnostic capabilities and thereby clinical outcome is widely recognized, these methods require considerable computational resources since they are mostly based on conventional numerical methods such as computational fluid dynamics (CFD). As an alternative to the numerical methods, we propose a machine learning (ML) based approach to calculate patient-specific hemodynamic parameters. Compared to CFD based methods, our approach holds the benefit of being able to calculate a patient-specific hemodynamic outcome instantly with little need for computational power. In this proof-of-concept study, we present a deep artificial neural network (ANN) capable of computing hemodynamics for patients with aortic coarctation in a centerline aggregated (i.e. locally averaged) form. Considering the complex relation between vessels shape and hemodynamics on the one hand and the limited availability of suitable clinical data on the other, a sufficient accuracy of the ANN may however not be achieved with available data only. Another key aspect of this study is therefore the successful augmentation of available clinical data. Using a statistical shape model, additional training data was generated which substantially increased the ANNs accuracy, showcasing the ability of ML based methods to perform in-silico modelling tasks previously requiring resource intensive CFD simulations.",0,0
833,"THALIS: Human-Machine Analysis of Longitudinal Symptoms in Cancer Therapy. Although cancer patients survive years after oncologic therapy, they are plagued with long-lasting or permanent residual symptoms, whose severity, rate of development, and resolution after treatment vary largely between survivors. The analysis and interpretation of symptoms is complicated by their partial co-occurrence, variability across populations and across time, and, in the case of cancers that use radiotherapy, by further symptom dependency on the tumor location and prescribed treatment. We describe THALIS, an environment for visual analysis and knowledge discovery from cancer therapy symptom data, developed in close collaboration with oncology experts. Our approach leverages unsupervised machine learning methodology over cohorts of patients, and, in conjunction with custom visual encodings and interactions, provides context for new patients based on patients with similar diagnostic features and symptom evolution. We evaluate this approach on data collected from a cohort of head and neck cancer patients. Feedback from our clinician collaborators indicates that THALIS supports knowledge discovery beyond the limits of machines or humans alone, and that it serves as a valuable tool in both the clinic and symptom research.",0,0
836,Two-Stage Approaches to Accounting for Patient Heterogeneity in Machine Learning Risk Prediction Models in Oncology. Machine learning models developed from electronic health records data have been increasingly used to predict risk of mortality for general oncology patients. But these models may have suboptimal performance because of patient heterogeneity. The objective of this work is to develop a new modeling approach to predicting short-term mortality that accounts for heterogeneity across multiple subgroups in the presence of a large number of electronic health record predictors.,0,0
838,Automated detection of severe diabetic retinopathy using deep learning method. The purpose of this study is to develop and validate the intelligent diagnosis of severe DR with lesion recognition based on color fundus photography.,0,0
839,"A Hybrid Human-Machine Learning Approach for Screening Prostate Biopsies Can Improve Clinical Efficiency Without Compromising Diagnostic Accuracy. Prostate cancer is a common malignancy, and accurate diagnosis typically requires histologic review of multiple prostate core biopsies per patient. As pathology volumes and complexity increase, new tools to improve the efficiency of everyday practice are keenly needed. Deep learning has shown promise in pathology diagnostics, but most studies silo the efforts of pathologists from the application of deep learning algorithms. Very few hybrid pathologist-deep learning approaches have been explored, and these typically require complete review of histologic slides by both the pathologist and the deep learning system.",0,0
842,"Uncovering Clinical Risk Factors and Predicting Severe COVID-19 Cases Using UK Biobank Data: Machine Learning Approach. COVID-19 is a major public health concern. Given the extent of the pandemic, it is urgent to identify risk factors associated with disease severity. More accurate prediction of those at risk of developing severe infections is of high clinical importance.",0,0
843,"Short-Term Event Prediction in the Operating Room (STEP-OP) of Five-Minute Intraoperative Hypotension Using Hybrid Deep Learning: Retrospective Observational Study and Model Development. Intraoperative hypotension has an adverse impact on postoperative outcomes. However, it is difficult to predict and treat intraoperative hypotension in advance according to individual clinical parameters.",0,0
844,"A Machine Learning Sepsis Prediction Algorithm for Intended Intensive Care Unit Use (NAVOY Sepsis): Proof-of-Concept Study. Despite decades of research, sepsis remains a leading cause of mortality and morbidity in intensive care units worldwide. The key to effective management and patient outcome is early detection, for which no prospectively validated machine learning prediction algorithm is currently available for clinical use in Europe.",0,0
848,"Determining Top Fully Connected Layer's Hidden Neuron Count for Transfer Learning, Using Knowledge Distillation: a Case Study on Chest X-Ray Classification of Pneumonia and COVID-19. Deep convolutional neural network (CNN)-assisted classification of images is one of the most discussed topics in recent years. Continuously innovation of neural network architectures is making it more correct and efficient every day. But training a neural network from scratch is very time-consuming and requires a lot of sophisticated computational equipment and power. So, using some pre-trained neural network as feature extractor for any image classification task or ""transfer learning"" is a very popular approach that saves time and computational power for practical use of CNNs. In this paper, an efficient way of building full model from any pre-trained model with high accuracy and low memory is proposed using knowledge distillation. Using the distilled knowledge of the last layer of pre-trained networks passes through fully connected layers with different hidden layers, followed by Softmax layer. The accuracies of student networks are mildly lesser than the whole models, but accuracy of student models clearly indicates the accuracy of the real network. In this way, the best number of hidden layers for dense layer for that pre-trained network with best accuracy and no-overfitting can be found with less time. Here, VGG16 and VGG19 (pre-trained upon ""ImageNet"" dataset) is tested upon chest X-rays (pneumonia and COVID-19). For finding the best total number of hidden layers, it saves nearly 44Â min for VGG19 and 36Â min and 37Â s for VGG16 feature extractor.",0,0
853,"Blood cytokines differentiate bipolar disorder and major depressive disorder during a major depressive episode: Initial discovery and independent sample replication. Bipolar disorder (BD) diagnosis currently relies on assessment of clinical symptoms, mainly retrospective and subject to memory bias. BD is often misdiagnosed as Major Depressive Disorder (MDD) resulting in ineffective treatment and worsened clinical outcome. The primary purpose of this study was to identify blood biomarkers that discriminate MDD from BD patients when in a depressed state. We have used clinical data and serum samples from two independent naturalistic cohorts of patients with a Major Depressive Episode (MDE) who fulfilled the criteria of either BD or MDD at inclusion. The discovery and replication cohorts consisted of 462 and 133 patients respectively. Patients were clinically assessed using standard diagnostic interviews, and clinical variables including current treatments were recorded. Blood was collected and serum assessed for levels of 31 cytokines using a sensitive multiplex assay. A penalized logistic regression model combined with nonparametric bootstrap was subsequently used to identify cytokines associated with BD. Interleukin (IL)-6, IL-10, IL-15, IL-27 and C-X-C ligand chemokine (CXCL)-10 were positively associated with BD in the discovery cohort. Of the five cytokines identified as discriminant features in the discovery cohort, IL-10, IL-15 and IL-27 were also positively associated with BD in the replication cohort therefore providing an external validation to our finding. Should our results be validated in a prospective cohort, they could provide new insights into the pathophysiological mechanisms of mood disorders.",0,0
854,"Explainable Machine Learning on AmsterdamUMCdb for ICU Discharge Decision Support: Uniting Intensivists and Data Scientists. Unexpected ICU readmission is associated with longer length of stay and increased mortality. To prevent ICU readmission and death after ICU discharge, our team of intensivists and data scientists aimed to use AmsterdamUMCdb to develop an explainable machine learning-based real-time bedside decision support tool.",0,0
856,"Data-Driven Prediction of Fatigue in Parkinson's Disease Patients. <b>Introduction:</b> Numerous non-motor symptoms are associated with Parkinson's disease (PD) including fatigue. The challenge in the clinic is to detect relevant non-motor symptoms while keeping patient-burden of questionnaires low and to take potential subgroups such as sex differences into account. The Fatigue Severity Scale (FSS) effectively detects clinically significant fatigue in PD patients. Machine learning techniques can determine which FSS items best predict clinically significant fatigue yet the choice of technique is crucial as it determines the stability of results. <b>Methods:</b> 182 records of PD patients were analyzed with two machine learning algorithms: random forest (RF) and Boruta. RF and Boruta calculated feature importance scores, which measured how much impact an FSS item had in predicting clinically significant fatigue. Items with the highest feature importance scores were the best predictors. Principal components analysis (PCA) grouped highly related FSS items together. <b>Results:</b> RF, Boruta and PCA demonstrated that items 8 (""Fatigue is among my three most disabling symptoms"") and 9 (""Fatigue interferes with my work, family or social life"") were the most important predictors. Item 5 (""Fatigue causes frequent problems for me"") was an important predictor for females, and item 6 (""My fatigue prevents sustained physical functioning"") was important for males. Feature importance scores' standard deviations were large for RF (14-66%) but small for Boruta (0-5%). <b>Conclusion:</b> The clinically most informative questions may be how disabling fatigue is compared to other symptoms and interference with work, family and friends. There may be some sex-related differences with frequency of fatigue-related complaints in females and endurance-related complaints in males yielding significant information. Boruta but not RF yielded stable results and might be a better tool to determine the most relevant components of abbreviated questionnaires. Further research in this area would be beneficial in order to replicate these findings with other machine learning algorithms, and using a more representative sample of PD patients.",0,0
857,"Deep learning-based segmentation of the placenta and uterus on MR images. <b>Purpose:</b> Magnetic resonance imaging has been recently used to examine the abnormalities of the placenta during pregnancy. Segmentation of the placenta and uterine cavity allows quantitative measures and further analyses of the organs. The objective of this study is to develop a segmentation method with minimal user interaction. <b>Approach:</b> We developed a fully convolutional neural network (CNN) for simultaneous segmentation of the uterine cavity and placenta in three dimensions (3D) while a minimal operator interaction was incorporated for training and testing of the network. The user interaction guided the network to localize the placenta more accurately. In the experiments, we trained two CNNs, one using 70 normal training cases and the other using 129 training cases including normal cases as well as cases with suspected placenta accreta spectrum (PAS). We evaluated the performance of the segmentation algorithms on two test sets: one with 20 normal cases and the other with 50 images from both normal women and women with suspected PAS. <b>Results:</b> For the normal test data, the average Dice similarity coefficient (DSC) was 92% and 82% for the uterine cavity and placenta, respectively. For the combination of normal and abnormal cases, the DSC was 88% and 83% for the uterine cavity and placenta, respectively. The 3D segmentation algorithm estimated the volume of the normal and abnormal uterine cavity and placenta with average volume estimation errors of 4% and 9%, respectively. <b>Conclusions:</b> The deep learning-based segmentation method provides a useful tool for volume estimation and analysis of the placenta and uterus cavity in human placental imaging.",0,0
858,"Machine Learning Models for Survival and Neurological Outcome Prediction of Out-of-Hospital Cardiac Arrest Patients. Out-of-hospital cardiac arrest (OHCA) is a major health problem worldwide, and neurologic injury remains the leading cause of morbidity and mortality among survivors of OHCA. The purpose of this study was to investigate whether a machine learning algorithm could detect complex dependencies between clinical variables in emergency departments in OHCA survivors and perform reliable predictions of favorable neurologic outcomes.",0,0
859,"Modified GAN Augmentation Algorithms for the MRI-Classification of Myocardial Scar Tissue in Ischemic Cardiomyopathy. Contrast-enhanced cardiac magnetic resonance imaging (MRI) is routinely used to determine myocardial scar burden and make therapeutic decisions for coronary revascularization. Currently, there are no optimized deep-learning algorithms for the automated classification of scarred vs. normal myocardium. We report a modified Generative Adversarial Network (GAN) augmentation method to improve the binary classification of myocardial scar using both pre-clinical and clinical approaches. For the initial training of the MobileNetV2 platform, we used the images generated from a high-field (9.4T) cardiac MRI of a mouse model of acute myocardial infarction (MI). Once the system showed 100% accuracy for the classification of acute MI in mice, we tested the translational significance of this approach in 91 patients with an ischemic myocardial scar, and 31 control subjects without evidence of myocardial scarring. To obtain a comparable augmentation dataset, we rotated scar images 8-times and control images 72-times, generating a total of 6,684 scar images and 7,451 control images. In humans, the use of Progressive Growing GAN (PGGAN)-based augmentation showed 93% classification accuracy, which is far superior to conventional automated modules. The use of other attention modules in our CNN further improved the classification accuracy by up to 5%. These data are of high translational significance and warrant larger multicenter studies in the future to validate the clinical implications.",0,0
861,"<sup>18</sup>F-FDG PET/CT Radiomics for Preoperative Prediction of Lymph Node Metastases and Nodal Staging in Gastric Cancer. The accurate assessment of lymph node metastases (LNMs) and the preoperative nodal (N) stage are critical for the precise treatment of patients with gastric cancer (GC). The diagnostic performance, however, of current imaging procedures used for this assessment is sub-optimal. Our aim was to investigate the value of preoperative <sup>18</sup>F-FDG PET/CT radiomic features to predict LNMs and the N stage.",0,0
868,"Predicting outcome of daycare cognitive behavioural therapy in a naturalistic sample of patients with PTSD: a machine learning approach. Identifying predictors for treatment outcome in patients with posttraumatic stress disorder (PTSD) is important in order to provide an effective treatment, but robust and replicated treatment outcome predictors are not available up to now.",0,0
872,"Identification of Prognostic Biomarker Candidates Associated With Melanoma Using High-Dimensional Genomic Data. Survival of patients with metastatic melanoma varies widely. Melanoma is a highly proliferative, chemo-resistant disease. With the recent availability of immunotherapies such as checkpoint inhibitors, durable response rates have improved but are often still limited to 2-3 years. Response rates to treatment range from 30 to 45% with combination therapy however no improvement in overall survival is frequently observed. Of the available therapies, many have targeted the BRAFV600E mutation that results in abnormal MAPK pathway activation which is important for regulating cell proliferation. Immune checkpoint inhibitors such as anti-PD-1 and anti-PD-L1 offer better success but response rates are still low. Identifying biomarkers to better target those who will respond and identify the right combination of treatment is the best approach. In this study, we utilize data from the Cancer Cell Line Encyclopedia (CCLE), including 62 samples, to examine features of gene expression (19K+) and copy number (20K+) in the melanoma cell lines. We perform a clustering analysis on the feature set to assess genetically similarity among the cell lines. We then discover which specific genes and combinations thereof maximize cluster density. We design a feature selection approach for high-dimensional datasets that integrates multiple disparate machine learning techniques into one cohesive pipeline. Our approach provides a small subset of genes that can accurately distinguish between the clusters of melanoma cell lines across multiple types of classifiers. In particular, we find only the 15 highest ranked genes among the original 19 K are necessary to achieve perfect or near-perfect test split classification performance. Of these 15 genes, some are known to be linked to melanoma or other cancer progressions, while others have not previously been linked to melanoma and are of interest for further examination.",0,0
876,"Multiple Sclerosis Recognition by Biorthogonal Wavelet Features and Fitness-Scaled Adaptive Genetic Algorithm. <b>Aim:</b> Multiple sclerosis (MS) is a disease, which can affect the brain and/or spinal cord, leading to a wide range of potential symptoms. This method aims to propose a novel MS recognition method. <b>Methods:</b> First, the bior4.4 wavelet is used to extract multiscale coefficients. Second, three types of biorthogonal wavelet features are proposed and calculated. Third, fitness-scaled adaptive genetic algorithm (FAGA)-a combination of standard genetic algorithm, adaptive mechanism, and power-rank fitness scaling-is harnessed as the optimization algorithm. Fourth, multiple-way data augmentation is utilized on the training set under the setting of 10 runs of 10-fold cross-validation. Our method is abbreviated as BWF-FAGA. <b>Results:</b> Our method achieves a sensitivity of 98.00 Â± 0.95%, a specificity of 97.78 Â± 0.95%, and an accuracy of 97.89 Â± 0.94%. The area under the curve of our method is 0.9876. <b>Conclusion:</b> The results show that the proposed BWF-FAGA method is better than 10 state-of-the-art MS recognition methods, including eight artificial intelligence-based methods, and two deep learning-based methods.",0,0
877,"Reconfiguration of Dynamic Functional Connectivity States in Patients With Lifelong Premature Ejaculation. <b>Purpose:</b> Neuroimaging has demonstrated altered static functional connectivity in patients with premature ejaculation (PE), while studies examining dynamic changes in spontaneous brain activity in PE patients are still lacking. We aimed to explore the reconfiguration of dynamic functional connectivity (DFC) states in lifelong PE (LPE) patients and to distinguish LPE patients from normal controls (NCs) using a machine learning method based on DFC state features. <b>Methods:</b> Thirty-six LPE patients and 23 NCs were recruited. Resting-state functional magnetic resonance imaging (fMRI) data, the clinical rating scores on the Chinese Index of PE (CIPE), and intravaginal ejaculatory latency time (IELT) were collected from each participant. DFC was calculated by the sliding window approach. Finally, the Lagrangian support vector machine (LSVM) classifier was applied to distinguish LPE patients from NCs using the DFC parameters. Two DFC state metrics (reoccurrence times and transition frequencies) were introduced and we assessed the correlations between DFC state metrics and clinical variables, and the accuracy, sensitivity, and specificity of the LSVM classifier. <b>Results:</b> By k-means clustering, four distinct DFC states were identified. The LPE patients showed an increase in the reoccurrence times for state 3 (<i>p</i> < 0.05, Bonferroni corrected) but a decrease for state 1 (<i>p</i> < 0.05, Bonferroni corrected) compared to the NCs. Moreover, the LPE patients had significantly less frequent transitions between state 1 and state 4 (<i>p</i> < 0.05, uncorrected) while more frequent transitions between state 3 and state 4 (<i>p</i> < 0.05, uncorrected) than the NCs. The reoccurrence times and transition frequencies showed significant associations with the CIPE scores and IELTs. The accuracy, sensitivity, and specificity of the LSVM classifier were 90.35, 87.59, and 85.59%, respectively. <b>Conclusion:</b> LPE patients were more inclined to be in DFC states reinforced intra-network and inter-network connection. These features correlated with clinical syndromes and can classify the LPE patients from NCs. Our results of reconfiguration of DFC states may provide novel insights for the understanding of central etiology underlying LPE, indicate neuroimaging biomarkers for the evaluation of clinical severity of LPE.",0,0
878,"Unsupervised Machine Learning-Based Analysis of Clinical Features, Bone Mineral Density Features and Medical Care Costs of Rotator Cuff Tears. We aim to present unsupervised machine learning-based analysis of clinical features, bone mineral density (BMD) features, and medical care costs of Rotator cuff tears (RCT).",0,0
879,"Applications of Machine Learning to Predict Cisplatin Resistance in Lung Cancer. Lung cancer, mainly lung adenocarcinoma, lung squamous cell carcinoma and small cell lung cancer, has the highest incidence and cancer-related mortality worldwide. Platinum-based chemotherapy plays an important role in the treatment of various lung cancer subtypes, but not all patients benefit from this treatment regimen; thus, it is worth identifying lung cancer patients who are resistant or sensitive to platinum-based therapy.",0,0
880,"Radiomics for predicting perineural invasion status in rectal cancer. Perineural invasion (PNI), as a key pathological feature of tumor spread, has emerged as an independent prognostic factor in patients with rectal cancer (RC). The preoperative stratification of RC patients according to PNI status is beneficial for individualized treatment and improved prognosis. However, the preoperative evaluation of PNI status is still challenging.",0,0
885,"Artificial intelligence-based detection of epimacular membrane from color fundus photographs. Epiretinal membrane (ERM) is a common ophthalmological disorder of high prevalence. Its symptoms include metamorphopsia, blurred vision, and decreased visual acuity. Early diagnosis and timely treatment of ERM is crucial to preventing vision loss. Although optical coherence tomography (OCT) is regarded as a de facto standard for ERM diagnosis due to its intuitiveness and high sensitivity, ophthalmoscopic examination or fundus photographs still have the advantages of price and accessibility. Artificial intelligence (AI) has been widely applied in the health care industry for its robust and significant performance in detecting various diseases. In this study, we validated the use of a previously trained deep neural network based-AI model in ERM detection based on color fundus photographs. An independent test set of fundus photographs was labeled by a group of ophthalmologists according to their corresponding OCT images as the gold standard. Then the test set was interpreted by other ophthalmologists and AI model without knowing their OCT results. Compared with manual diagnosis based on fundus photographs alone, the AI model had comparable accuracy (AI model 77.08% vs. integrated manual diagnosis 75.69%, Ï‡<sup>2</sup>â€‰=â€‰0.038, Pâ€‰=â€‰0.845, McNemar's test), higher sensitivity (75.90% vs. 63.86%, Ï‡<sup>2</sup>â€‰=â€‰4.500, Pâ€‰=â€‰0.034, McNemar's test), under the cost of lower but reasonable specificity (78.69% vs. 91.80%, Ï‡<sup>2</sup>â€‰=â€‰6.125, Pâ€‰=â€‰0.013, McNemar's test). Thus our AI model can serve as a possible alternative for manual diagnosis in ERM screening.",1,1
887,"Web-based and machine learning approaches for identification of patient-reported outcomes in inflammatory bowel disease. Messages from an Internet forum are raw material that emerges in a natural setting (i.e., non-induced by a research situation).",0,0
891,"Machine learning techniques demonstrating individual movement patterns of the vertebral column: the fingerprint of spinal motion. Surface topography systems enable the capture of spinal dynamic movement; however, it is unclear whether vertebral dynamics are unique enough to identify individuals. Therefore, in this study, we investigated whether the identification of individuals is possible based on dynamic spinal data. Three different data representations were compared (automated extracted features using contrastive loss and triplet loss functions, as well as simple descriptive statistics). High accuracies indicated the possible existence of a personal spinal 'fingerprint', therefore enabling subject recognition. The present work forms the basis for an objective comparison of subjects and the transfer of the method to clinical use cases.",0,0
892,Prediction of Stroke Infarct Growth Rates by Baseline Perfusion Imaging. Computed tomography perfusion imaging allows estimation of tissue status in patients with acute ischemic stroke. We aimed to improve prediction of the final infarct and individual infarct growth rates using a deep learning approach.,0,0
893,"Dynamic stochastic deep learning approaches for predicting geometric changes in head and neck cancer. Modern radiotherapy stands to benefit from the ability to efficiently adapt plans during treatment in response to setup and geometric variations such as those caused by internal organ deformation or tumor shrinkage. A promising strategy is to develop a framework, which given an initial state defined by patient-attributes, can predict future states based on patterns from a well-defined patient population. Here, we investigate the feasibility of predicting patient anatomical changes, defined as a joint state of volume and daily setup changes, across a fractionated treatment schedule using two approaches. The first is based on a new framework employing quantum mechanics in combination with deep recurrent neural networks, denoted QRNN. The second approach is developed based on a classical framework, which models patient changes as a Markov process, denoted MRNN. We evaluated the performance of these two approaches on a dataset of 125 head and neck cancer patients, which was supplemented by synthetic data generated using a generative adversarial network. Model performance was evaluated using area under the receiver operating characteristic curve (AUC) scores. The MRNN framework had slightly better performance, with MRNN(QRNN) validation AUC scores of 0.742 Â± 0.021 (0.675 Â± 0.036), 0.709 Â± 0.026 (0.656 Â± 0.021), 0.724 Â± 0.036 (0.652 Â± 0.044), and 0.698 Â± 0.016 (0.605 Â± 0.035) for system state vector sizes of 4, 6, 8, and 10, respectively. Of these, the results from the two higher order states had statistically significant differences (p<0.05). A similar trend was observed when the models were applied to an external testing dataset of 20 patients, yielding MRNN(QRNN) AUC scores of 0.707 (0.623), 0.687 (0.608), 0.723 (0.669), and 0.697 (0.609) for states vectors sizes of 4, 6, 8, and 10, respectively. These results suggest that both models have potential value in predicting patient changes during the course of adaptive radiotherapy.",0,0
894,"Dissected aorta segmentation using convolutional neural networks. Aortic dissection is a severe cardiovascular pathology in which an injury of theÂ intimal layerÂ of theÂ aortaÂ allows blood flowing into the aortic wall,Â forcing the wall layers apart. Such situation presents a high mortality rate and requires an in-depth understanding of the 3-D morphology of the dissected aorta to plan the right treatment. An accurate automatic segmentation algorithm is therefore needed.",0,0
898,"Acute graft-versus-host disease following orthotopic liver transplantation: Predicting this rare complication using machine learning. Acute graft-versus-host disease (GVHD) is a rare complication following orthotopic liver transplantation (OLT) that carries high mortality. We hypothesized that machine learning algorithms to predict rare events would identify patients at high risk for developing GVHD. To develop a predictive model, we retrospectively evaluated the clinical features of 1,938 donor-recipient pairs at the time they underwent OLT at our center; 19 (1.0%) of these recipients developed GVHD. This population was divided into training (70%) and test (30%) sets. Seven machine learning classification algorithms were built based on the training dataset to identify patients at high risk for GVHD. Algorithms C5.0, heterogeneous ensemble, and (Generalized Gradient Boosting Machine) GGBM predicted that 21-28% of test dataset recipients were high risk for developing GVHD with an area under the receiver operating characteristic curve (AUC) of 0.83-0.86. The 7 algorithms were then evaluated in a validation dataset of 75 more recent donor-recipient pairs who underwent OLT at our center; 2 of these recipients developed GVHD. Algorithms logistic regression, heterogeneous ensemble, and GGBM predicted that 9-11% of validation recipients were high risk for developing GVHD with an AUC of 0.93-0.96 and included the 2 that developed GVHD. In conclusion, we present a practical model that can identify patients at high risk for GVHD and may warrant additional monitoring with peripheral blood chimerism testing.",0,0
900,"A deep learning based approach identifies regions more relevant than resting-state networks to the prediction of general intelligence from resting-state fMRI. Prediction of cognitive ability latent factors such as general intelligence from neuroimaging has elucidated questions pertaining to their neural origins. However, predicting general intelligence from functional connectivity limit hypotheses to that specific domain, being agnostic to time-distributed features and dynamics. We used an ensemble of recurrent neural networks to circumvent this limitation, bypassing feature extraction, to predict general intelligence from resting-state functional magnetic resonance imaging regional signals of a large sample (nÂ =Â 873) of Human Connectome Project adult subjects. Ablating common resting-state networks (RSNs) and measuring degradation in performance, we show that model reliance can be mostly explained by network size. Using our approach based on the temporal variance of saliencies, that is, gradients of outputs with regards to inputs, we identify a candidate set of networks that more reliably affect performance in the prediction of general intelligence than similarly sized RSNs. Our approach allows us to further test the effect of local alterations on data and the expected changes in derived metrics such as functional connectivity and instantaneous innovations.",0,0
909,"COVID-view: Diagnosis of COVID-19 using Chest CT. Significant work has been done towards deep learning (DL) models for automatic lung and lesion segmentation and classification of COVID-19 on chest CT data. However, comprehensive visualization systems focused on supporting the dual visual+DL diagnosis of COVID-19 are non-existent. We present COVID-view, a visualization application specially tailored for radiologists to diagnose COVID-19 from chest CT data. The system incorporates a complete pipeline of automatic lungs segmentation, localization/isolation of lung abnormalities, followed by visualization, visual and DL analysis, and measurement/quantification tools. Our system combines the traditional 2D workflow of radiologists with newer 2D and 3D visualization techniques with DL support for a more comprehensive diagnosis. COVID-view incorporates a novel DL model for classifying the patients into positive/negative COVID-19 cases, which acts as a reading aid for the radiologist using COVID-view and provides the attention heatmap as an explainable DL for the model output. We designed and evaluated COVID-view through suggestions, close feedback and conducting case studies of real-world patient data by expert radiologists who have substantial experience diagnosing chest CT scans for COVID-19, pulmonary embolism, and other forms of lung infections. We present requirements and task analysis for the diagnosis of COVID-19 that motivate our design choices and results in a practical system which is capable of handling real-world patient cases.",0,0
936,Use of machine learning to predict the risk of early morning intraocular pressure peaks in glaucoma patients and suspects. To use machine learning to predict the risk of intraocular pressure peaks at 6 a.m. in primary open-angle glaucoma patients and suspects.,0,0
946,Machine learning-based risk prediction of malignant arrhythmia in hospitalized patients with heart failure. Predicting the risk of malignant arrhythmias (MA) in hospitalized patients with heart failure (HF) is challenging. Machine learning (ML) can handle a large volume of complex data more effectively than traditional statistical methods. This study explored the feasibility of ML methods for predicting the risk of MA in hospitalized HF patients.,0,0
948,Convolutional neural network optimizes the application of diffusion kurtosis imaging in Parkinson's disease. The literature regarding the use of diffusion-tensor imaging-derived metrics in the evaluation of Parkinson's disease (PD) is controversial. This study attempted to assess the feasibility of a deep-learning-based method for detecting alterations in diffusion kurtosis measurements associated with PD.,0,0
950,"Pathological neural networks and artificial neural networks in ALS: diagnostic classification based on pathognomonic neuroimaging features. The description of group-level, genotype- and phenotype-associated imaging traits is academically important, but the practical demands of clinical neurology centre on the accurate classification of individual patients into clinically relevant diagnostic, prognostic and phenotypic categories. Similarly, pharmaceutical trials require the precision stratification of participants based on quantitative measures. A single-centre study was conducted with a uniform imaging protocol to test the accuracy of an artificial neural network classification scheme on a cohort of 378 participants composed of patients with ALS, healthy subjects and disease controls. A comprehensive panel of cerebral volumetric measures, cortical indices and white matter integrity values were systematically retrieved from each participant and fed into a multilayer perceptron model. Data were partitioned into training and testing and receiver-operating characteristic curves were generated for the three study-groups. Area under the curve values were 0.930 for patients with ALS, 0.958 for disease controls, and 0.931 for healthy controls relying on all input imaging variables. The ranking of variables by classification importance revealed that white matter metrics were far more relevant than grey matter indices to classify single subjects. The model was further tested in a subset of patients scanned within 6Â weeks of their diagnosis and an AUC of 0.915 was achieved. Our study indicates that individual subjects may be accurately categorised into diagnostic groups in an observer-independent classification framework based on multiparametric, spatially registered radiology data. The development and validation of viable computational models to interpret single imaging datasets are urgently required for a variety of clinical and clinical trial applications.",0,0
953,"Stratified neural networks in a time-to-event setting. Deep neural networks are frequently employed to predict survival conditional on omics-type biomarkers, e.g., by employing the partial likelihood of Cox proportional hazards model as loss function. Due to the generally limited number of observations in clinical studies, combining different data sets has been proposed to improve learning of network parameters. However, if baseline hazards differ between the studies, the assumptions of Cox proportional hazards model are violated. Based on high dimensional transcriptome profiles from different tumor entities, we demonstrate how using a stratified partial likelihood as loss function allows for accounting for the different baseline hazards in a deep learning framework. Additionally, we compare the partial likelihood with the ranking loss, which is frequently employed as loss function in machine learning approaches due to its seemingly simplicity. Using RNA-seq data from the Cancer Genome Atlas (TCGA) we show that use of stratified loss functions leads to an overall better discriminatory power and lower prediction error compared to their non-stratified counterparts. We investigate which genes are identified to have the greatest marginal impact on prediction of survival when using different loss functions. We find that while similar genes are identified, in particular known prognostic genes receive higher importance from stratified loss functions. Taken together, pooling data from different sources for improved parameter learning of deep neural networks benefits largely from employing stratified loss functions that consider potentially varying baseline hazards. For easy application, we provide PyTorch code for stratified loss functions and an explanatory Jupyter notebook in a GitHub repository.",0,0
955,"Cohort-Specific Optimization of Models Predicting Preclinical Alzheimer's Disease, to Enhance Screening Performance in the Middle of Preclinical Alzheimer's Disease Clinical Studies. Models that can predict brain amyloid beta (AÎ²) status more accurately have been desired to identify participants for clinical trials of preclinical Alzheimer's disease (AD). However, potential heterogeneity between different cohorts and the limited cohort size have been the reasons preventing the development of reliable models applicable to the Asian population, including Japan.",0,0
957,"Point-of-care microchip electrophoresis for integrated anemia and hemoglobin variant testing. Anemia affects over 25% of the world's population with the heaviest burden borne by women and children. Genetic hemoglobin (Hb) variants, such as sickle cell disease, are among the major causes of anemia. Anemia and Hb variant are pathologically interrelated and have an overlapping geographical distribution. We present the first point-of-care (POC) platform to perform both anemia detection and Hb variant identification, using a single paper-based electrophoresis test. Feasibility of this new integrated diagnostic approach is demonstrated <i>via</i> testing individuals with anemia and/or sickle cell disease. Hemoglobin level determination is performed by an artificial neural network (ANN) based machine learning algorithm, which achieves a mean absolute error of 0.55 g dL<sup>-1</sup> and a bias of -0.10 g dL<sup>-1</sup> against the gold standard (95% limits of agreement: 1.5 g dL<sup>-1</sup>) from Bland-Altman analysis on the test set. Resultant anemia detection is achieved with 100% sensitivity and 92.3% specificity. With the same tests, subjects with sickle cell disease were identified with 100% sensitivity and specificity. Overall, the presented platform enabled, for the first time, integrated anemia detection and hemoglobin variant identification using a single point-of-care test.",0,0
962,"Robustness and Generalizability of Deep Learning Synthetic Computed Tomography for Positron Emission Tomography/Magnetic Resonance Imaging-Based Radiation Therapy Planning of Patients With Head and Neck Cancer. Radiotherapy planning based only on positron emission tomography/magnetic resonance imaging (PET/MRI) lacks computed tomography (CT) information required for dose calculations. In this study, a previously developed deep learning model for creating synthetic CT (sCT) from MRI in patients with head and neck cancer was evaluated in 2 scenarios: (1) using an independent external dataset, and (2) using a local dataset after an update of the model related to scanner software-induced changes to the input MRI.",0,0
969,"An attempt to construct the individual model of daily facial skin temperature using variational autoencoder. Facial skin temperature (FST) has also gained prominence as an indicator for detecting anomalies such as fever due to the COVID-19. When FST is used for engineering applications, it is enough to be able to recognize normal. We are also focusing on research to detect some anomaly in FST. In a previous study, it was confirmed that abnormal and normal conditions could be separated based on FST by using a variational autoencoder (VAE), a deep generative model. However, the simulations so far have been a far cry from reality. In this study, normal FST with a diurnal variation component was defined as a normal state, and a model of normal FST in daily life was individually reconstructed using VAE. Using the constructed model, the anomaly detection performance was evaluated by applying the Hotelling theory. As a result, the area under the curve (AUC) value in ROC analysis was confirmed to be 0.89 to 1.00 in two subjects.",0,0
972,"Assessment of the influence of features on a classification problem: an application to COVID-19 patients. This paper deals with an important subject in classification problems addressed by machine learning techniques: the evaluation of the influence of each of the features on the classification of individuals. Specifically, a measure of that influence is introduced using the Shapley value of cooperative games. In addition, an axiomatic characterisation of the proposed measure is provided based on properties of efficiency and balanced contributions. Furthermore, some experiments have been designed in order to validate the appropriate performance of such measure. Finally, the methodology introduced is applied to a sample of COVID-19 patients to study the influence of certain demographic or risk factors on various events of interest related to the evolution of the disease.",0,0
974,"Classification of COVID-19 in X-ray images with Genetic Fine-tuning. New and more transmissible SARS-COV-2 variants aggravated the SARS-COV-2 emergence. Lung X-ray images stand out as an alternative to support case screening. The latest computer-aided diagnosis systems have been using Deep Learning (DL) to detect pulmonary diseases. In this context, our work investigates different types of pneumonia detection, including COVID-19, based on X-ray image processing and DL techniques. Our methodology comprehends a pre-processing step including data-augmentation, contrast enhancement, and resizing method to overcome the challenge of heterogeneous and few samples of public datasets. Additionally, we propose a new Genetic Fine-Tuning method to automatically define an optimal set of hyper-parameters of ResNet50 and VGG16 architectures. Our results are encouraging; we achieve an accuracy of 97% considering three classes: COVID-19, other pneumonia, and healthy. Thus, our methodology could assist in classifying COVID-19 pneumonia, which could reduce costs by making the process faster and more efficient.",0,0
975,"Deep learning-based virtual cytokeratin staining of gastric carcinomas to measure tumor-stroma ratio. The tumor-stroma ratio (TSR) determined by pathologists is subject to intra- and inter-observer variability. We aimed to develop a computational quantification method of TSR using deep learning-based virtual cytokeratin staining algorithms. Patients with 373 advanced (stage III [nâ€‰=â€‰171] and IV [nâ€‰=â€‰202]) gastric cancers were analyzed for TSR. Moderate agreement was observed, with a kappa value of 0.623, between deep learning metrics (dTSR) and visual measurement by pathologists (vTSR) and the area under the curve of receiver operating characteristic of 0.907. Moreover, dTSR was significantly associated with the overall survival of the patients (Pâ€‰=â€‰0.0024). In conclusion, we developed a virtual cytokeratin staining and deep learning-based TSR measurement, which may aid in the diagnosis of TSR in gastric cancer.",1,0
976,"Cutoff criteria for the placebo response: a cluster and machine learning analysis of placebo analgesia. Computations of placebo effects are essential in randomized controlled trials (RCTs) for separating the specific effects of treatments from unspecific effects associated with the therapeutic intervention. Thus, the identification of placebo responders is important for testing the efficacy of treatments and drugs. The present study uses data from an experimental study on placebo analgesia to suggest a statistical procedure to separate placebo responders from nonresponders and suggests cutoff values for when responses to placebo treatment are large enough to be separated from reported symptom changes in a no-treatment condition. Unsupervised cluster analysis was used to classify responders and nonresponders, and logistic regression implemented in machine learning was used to obtain cutoff values for placebo analgesic responses. The results showed that placebo responders can be statistically separated from nonresponders by cluster analysis and machine learning classification, and this procedure is potentially useful in other fields for the identification of responders to a treatment.",0,0
986,"Development of Prediction Models for Unplanned Hospital Readmission within 30 Days Based on Common Data Model: A Feasibility Study. â€ƒUnplanned hospital readmission after discharge reflects low satisfaction and reliability in care and the possibility of potential medical accidents, and is thus indicative of the quality of patient care and the appropriateness of discharge plans.",0,0
990,"Detection of pancreatic cancer by convolutional-neural-network-assisted spontaneous Raman spectroscopy with critical feature visualization. Pancreatic cancer is the deadliest cancer type with a five-year survival rate of less than 9%. Detection of tumor margins plays an essential role in the success of surgical resection. However, histopathological assessment is time-consuming, expensive, and labor-intensive. We constructed a lab-designed, hand-held Raman spectroscopic system that could enable intraoperative tissue diagnosis using convolutional neural network (CNN) models to efficiently distinguish between cancerous and normal pancreatic tissue. To our best knowledge, this is the first reported effort to diagnose pancreatic cancer by CNN-aided spontaneous Raman scattering with a lab-developed system designed for intraoperative applications. Classification based on the original one-dimensional (1D) Raman, two-dimensional (2D) Raman images, and the first principal component (PC1) from the principal component analysis on the 2D image, could all achieve high performance: the testing sensitivity, specificity, and accuracy were over 95%, and the area under the curve approached 0.99. Although CNN models often show great success in classification, it has always been challenging to visualize the CNN features in these models, which has never been achieved in the Raman spectroscopy application in cancer diagnosis. By studying individual Raman regions and by extracting and visualizing CNN features from max-pooling layers, we identified critical Raman peaks that could aid in the classification of cancerous and noncancerous tissues. 2D Raman PC1 yielded more critical peaks for pancreatic cancer identification than that of 1D Raman, as the Raman intensity was amplified by 2D Raman PC1. To our best knowledge, the feature visualization was achieved for the first time in the field of CNN-aided spontaneous Raman spectroscopy for cancer diagnosis. Based on these CNN feature peaks and their frequency at specific wavenumbers, pancreatic cancerous tissue was found to contain more biochemical components related to the protein contents (particularly collagen), whereas normal pancreatic tissue was found to contain more lipids and nucleic acid (particularly deoxyribonucleic acid/ribonucleic acid). Overall, the CNN model in combination with Raman spectroscopy could serve as a useful tool for the extraction of key features that can help differentiate pancreatic cancer from a normal pancreas.",0,0
992,"Identification of Sex and Age from Macular Optical Coherence Tomography and Feature Analysis Using Deep Learning. To develop deep learning models for identification of sex and age from macular optical coherence tomography (OCT), and to analyze the features for differentiation of sex and age.",0,0
993,Machine Learning to Predict Outcomes and Cost by Phase of Care after Coronary Artery Bypass Grafting. Machine learning may enhance prediction of outcomes after coronary artery bypass grafting (CABG). We sought to develop and validate a dynamic machine learning model to predict CABG outcomes at clinically relevant pre- and postoperative timepoints.,0,0
996,"Stem-cell based, machine learning approach for optimizing natural killer cell-based personalized immunotherapy for high-grade ovarian cancer. Advanced high-grade serous ovarian cancer continues to be a therapeutic challenge for those affected using the current therapeutic interventions. There is an increasing interest in personalized cancer immunotherapy using activated natural killer (NK) cells. NK cells account for approximately 15% of circulating white blood cells. They are also an important element of the tumor microenvironment (TME) and the body's immune response to cancers. In the present study, DeepNEU-C2Rx, a machine learning platform, was first used to create validated artificially induced pluripotent stem cell simulations. These simulations were then used to generate wild-type artificially induced NK cells (aiNK-WT) and TME simulations. Once validated, the aiNK-WT simulations were exposed to artificially induced high-grade serous ovarian cancer represented by aiOVCAR3. Cytolytic activity of aiNK was evaluated in presence and absence of aiOVCAR3 and data were compared with the literature for validation. The TME simulations suggested 26 factors that could be evaluated based on their ability to enhance aiNK-WT cytolytic activity in the presence of aiOVCAR3. The addition of programmed cell death-1 inhibitor leads to significant reinvigoration of aiNK cytolytic activity. The combination of programmed cell death-1 and glycogen synthase kinase 3 inhibitors showed further improvement. Further addition of ascitic fluid factor inhibitors leads to optimal aiNK activation. Our data showed that NK cell simulations could be used not only to pinpoint novel immunotherapeutic targets to reinvigorate the activity of NK cells against cancers, but also to predict the outcome of targeting tumors with specific genetic expression and mutation profiles.",0,0
1000,"Learning from Deep Stereoscopic Attention for Simulator Sickness Prediction. Simulator sickness induced by 360 stereoscopic video contents is a prolonged challenging issue in Virtual Reality (VR) system. Current machine learning models for simulator sickness prediction ignore the underlying interdependencies and correlations across multiple visual features which may lead to simulator sickness. We propose a model for sickness prediction by automatic learning and adaptive integrating multi-level mappings from stereoscopic video features to simulator sickness scores. Firstly, saliency, optical flow and disparity features are extracted from videos to reflect the factors causing simulator sickness, including human attention area, motion velocity and depth information. Then, these features are embedded and fed into a 3-dimensional convolutional neural network (3D CNN) to extract the underlying multi-level knowledge which includes low-level and higher-order visual concepts, and global image descriptor. Finally, an attentional mechanism is exploited to adaptively fuse multi-level information with attentional weights for sickness score estimation. The proposed model is trained by an end-to-end approach and validated over a public dataset. Comparison results with state-of-the-art models and ablation studies demonstrated improved performance in terms of Root Mean Square Error (RMSE) and Pearson Linear Correlation Coefficient.",0,0
1001,"SMU-Net: Saliency-guided Morphology-aware U-Net for Breast Lesion Segmentation in Ultrasound Image. Deep learning methods, especially convolutional neural networks, have been successfully applied to lesion segmentation in breast ultrasound (BUS) images. However, pattern complexity and intensity similarity between the surrounding tissues (i.e., background) and lesion regions (i.e., foreground) bring challenges for lesion segmentation. Considering that such rich texture information is contained in background, very few methods have tried to explore and exploit background-salient representations for assisting foreground segmentation. Additionally, other characteristics of BUS images, i.e., 1) low-contrast appearance and blurry boundary, and 2) significant shape and position variation of lesions, also increase the difficulty in accurate lesion segmentation. In this paper, we present a saliency-guided morphology-aware U-Net (SMU-Net) for lesion segmentation in BUS images. The SMU-Net is composed of a main network with an additional middle stream and an auxiliary network. Specifically, we first propose generation of saliency maps which incorporate both low-level and high-level image structures, for foreground and background. These saliency maps are then employed to guide the main network and auxiliary network for respectively learning foreground-salient and background-salient representations. Furthermore, we devise an additional middle stream which basically consists of background-assisted fusion, shape-aware, edge-aware and position-aware units. This stream receives the coarse-to-fine representations from the main network and auxiliary network for efficiently fusing the foreground-salient and background-salient features and enhancing the ability of learning morphological information for network. Extensive experiments on five datasets demonstrate higher performance and superior robustness to the scale of dataset than several state-of-the-art deep learning approaches in breast lesion segmentation in ultrasound image.",0,0
1004,"Design a novel BCI for neurorehabilitation using concurrent LFP and EEG features: a case study. Brain-computer interfaces (BCI) that enables people with severe motor disabilities to use their brain signals for direct control of objects have attracted increased interest in rehabilitation. To date, no study has investigated feasibility of the BCI framework incorporating both intracortical and scalp signals. <i>Methods</i>: Concurrent local field potential (LFP) from the hand-knob area and scalp EEG were recorded in a paraplegic patient undergoing a spike-based close-loop neurorehabilitation training. Based upon multimodal spatio-spectral feature extraction and Naive Bayes classification, we developed, for the first time, a novel LFP-EEG-BCI for motor intention decoding. A transfer learning (TL) approach was employed to further improve the feasibility. The performance of the proposed LFP-EEG-BCI for four-class upper-limb motor intention decoding was assessed. <i>Results</i>: Using a decision fusion strategy, we showed that the LFP-EEG-BCI significantly (p <0.05) outperformed single modal BCI (LFP-BCI and EEG-BCI) in terms of decoding accuracy with the best performance achieved using regularized common spatial pattern features. Interrogation of feature characteristics revealed discriminative spatial and spectral patterns, which may lead to new insights for better understanding of brain dynamics during different motor imagery tasks and promote development of efficient decoding algorithms. Moreover, we showed that similar classification performance could be obtained with few training trials, therefore highlighting the efficacy of TL. <i>Conclusion</i>: The present findings demonstrated the superiority of the novel LFP-EEG-BCI in motor intention decoding. <i>Significance</i>: This work introduced a novel LFP-EEG-BCI that may lead to new directions for developing practical neurorehabilitation systems with high detection accuracy and multi-paradigm feasibility in clinical applications.",0,0
1005,Predictive radiomics signature for treatment response to nivolumab in patients with advanced renal cell carcinoma. The anti-PD-1 immune checkpoint inhibitor nivolumab is currently approved for the treatment of patients with metastatic renal cell carcinoma (mRCC); approximately 25% of patients respond. We hypothesized that we could identify a biomarker of response using radiomics to train a machine learning classifier to predict nivolumab response outcomes.,0,0
1009,"Identifying individuals with Alzheimer's disease-like brains based on structural imaging in the Human Connectome Project Aging cohort. Given the difficulty in factoring out typical age effects from subtle Alzheimer's disease (AD) effects on brain structure, identification of very early, as well as younger preclinical ""at-risk"" individuals has unique challenges. We examined whether age-correction procedures could be used to better identify individuals at very early potential risk from adults who did not have any existing cognitive diagnosis. First, we obtained cross-sectional age effects for each structural feature using data from a selected portion of the Human Connectome Project Aging (HCP-A) cohort. After age detrending, we weighted AD structural deterioration with patterns quantified from data of the Alzheimer's Disease Neuroimaging Initiative. Support vector machine was then used to classify individuals with brains that most resembled atrophy in AD across the entire HCP-A sample. Additionally, we iteratively adjusted the pipeline by removing individuals classified as AD-like from the HCP-A cohort to minimize atypical brain structural contributions to the age detrending. The classifier had a mean cross-validation accuracy of 94.0% for AD recognition. It also could identify mild cognitive impairment with more severe AD-specific biomarkers and worse cognition. In an independent HCP-A cohort, 8.8% were identified as AD-like, and they trended toward worse cognition. An ""AD risk"" score derived from the machine learning models also significantly correlated with cognition. This work provides a proof of concept for the potential to use structural brain imaging to identify asymptomatic individuals at young ages who show structural brain patterns similar to AD and are potentially at risk for a future clinical disorder.",0,0
1014,AI-Based Quantitative CT Analysis of Temporal Changes According to Disease Severity in COVID-19 Pneumonia. To quantitatively evaluate computed tomography (CT) parameters of coronavirus disease 2019 (COVID-19) pneumonia an artificial intelligence (AI)-based software in different clinical severity groups during the disease course.,0,0
1018,"Artificial Intelligence Algorithm Improves Radiologist Performance in Skeletal Age Assessment: A Prospective Multicenter Randomized Controlled Trial. Background Previous studies suggest that use of artificial intelligence (AI) algorithms as diagnostic aids may improve the quality of skeletal age assessment, though these studies lack evidence from clinical practice. Purpose To compare the accuracy and interpretation time of skeletal age assessment on hand radiograph examinations with and without the use of an AI algorithm as a diagnostic aid. Materials and Methods In this prospective randomized controlled trial, the accuracy of skeletal age assessment on hand radiograph examinations was performed with (<i>n</i> = 792) and without (<i>n</i> = 739) the AI algorithm as a diagnostic aid. For examinations with the AI algorithm, the radiologist was shown the AI interpretation as part of their routine clinical work and was permitted to accept or modify it. Hand radiographs were interpreted by 93 radiologists from six centers. The primary efficacy outcome was the mean absolute difference between the skeletal age dictated into the radiologists' signed report and the average interpretation of a panel of four radiologists not using a diagnostic aid. The secondary outcome was the interpretation time. A linear mixed-effects regression model with random center- and radiologist-level effects was used to compare the two experimental groups. Results Overall mean absolute difference was lower when radiologists used the AI algorithm compared with when they did not (5.36 months vs 5.95 months; <i>P</i> = .04). The proportions at which the absolute difference exceeded 12 months (9.3% vs 13.0%, <i>P</i> = .02) and 24 months (0.5% vs 1.8%, <i>P</i> = .02) were lower with the AI algorithm than without it. Median radiologist interpretation time was lower with the AI algorithm than without it (102 seconds vs 142 seconds, <i>P</i> = .001). Conclusion Use of an artificial intelligence algorithm improved skeletal age assessment accuracy and reduced interpretation times for radiologists, although differences were observed between centers. Clinical trial registration no. NCT03530098 Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Rubin in this issue.",1,1
1020,"Individualized Prediction of Prodromal Symptom Remission for Youth at Clinical High Risk for Psychosis. The clinical high-risk period before a first episode of psychosis (CHR-P) has been widely studied with the goal of understanding the development of psychosis; however, less attention has been paid to the 75%-80% of CHR-P individuals who do not transition to psychosis. It is an open question whether multivariable models could be developed to predict remission outcomes at the same level of performance and generalizability as those that predict conversion to psychosis. Participants were drawn from the North American Prodrome Longitudinal Study (NAPLS3). An empirically derived set of clinical and demographic predictor variables were selected with elastic net regularization and were included in a gradient boosting machine algorithm to predict prodromal symptom remission. The predictive model was tested in a comparably sized independent sample (NAPLS2). The classification algorithm developed in NAPLS3 achieved an area under the curve of 0.66 (0.60-0.72) with a sensitivity of 0.68 and specificity of 0.53 when tested in an independent external sample (NAPLS2). Overall, future remitters had lower baseline prodromal symptoms than nonremitters. This study is the first to use a data-driven machine-learning approach to assess clinical and demographic predictors of symptomatic remission in individuals who do not convert to psychosis. The predictive power of the models in this study suggest that remission represents a unique clinical phenomenon. Further study is warranted to best understand factors contributing to resilience and recovery from the CHR-P state.",0,0
1021,Deep Learning for Discrimination Between Fungal Keratitis and Bacterial Keratitis: DeepKeratitis. Microbial keratitis is an urgent condition in ophthalmology that requires prompt treatment. This study aimed to apply deep learning algorithms for rapidly discriminating between fungal keratitis (FK) and bacterial keratitis (BK).,0,0
1026,"Development of a semi-automated method for tumour budding assessment in colorectal cancer and comparison with manual methods. Tumour budding is an established prognostic feature in multiple cancers but is not routinely assessed in pathology practice. Efforts to standardise and automate assessment have shifted from haematoxylin and eosin (H&E)-stained images towards cytokeratin immunohistochemistry. In this study, we compare manual H&E and cytokeratin assessment methods with a semi-automated approach built within QuPath open-source software.",1,1
1027,"Detection of Baseline Emotion in Brow Lift Patients Using Artificial Intelligence. The widespread popularity of browlifts and blepharoplasties speaks directly to the importance that patients place on the periorbital region of the face. In literature, most esthetic outcomes are based on instinctive analysis of the esthetic surgeon, rather than on patient assessments, public opinions, or other objective means. We employed an artificial intelligence system to objectively measure the impact of brow lifts and associated rejuvenation procedures on the appearance of emotion while the patient is in repose.",0,0
1028,"A simple and robust methylation test for risk stratification of patients with juvenile myelomonocytic leukemia. Juvenile myelomonocytic leukemia (JMML) is a rare myelodysplastic/myeloproliferative neoplasm that develops during infancy and early childhood. The array-based international consensus definition of DNA methylation has recently classified patients with JMML into the following three groups: high methylation (HM), intermediate methylation (IM), and low methylation (LM). To develop a simple and robust methylation clinical test, 137 patients with JMML have been analyzed using the Digital Restriction Enzyme Analysis of Methylation (DREAM), which is a next-generation sequencing based methylation analysis. Unsupervised consensus clustering of the discovery cohort (n=99) using the DREAM data has identified HM and LM subgroups (HM_DREAM, n=35; LM_DREAM; n=64). Of the 98 cases that could be compared with the international consensus classification, 90 cases of HM (n=30) and LM (n=60) had 100% concordance with the DREAM clustering results. For the remaining eight cases classified as the IM group, four cases were classified into the HM_DREAM group and four cases into the LM_DREAM group. A machine-learning classifier has been successfully constructed using a Support Vector Machine (SVM), which divided the validation cohort (n=38) into HM (HM_SVM; n=18) and LM (LM_SVM; n=20) groups. Patients with the HM_SVM profile had a significantly poorer 5-year overall survival rate than those with the LM_SVM profile. In conclusion, a robust methylation test has been developed using the DREAM analysis for patients with JMML. This simple and straightforward test can be easily incorporated in diagnosis to generate a methylation classification for patients so that they can receive risk-adapted treatment in the context of future clinical trials.",0,0
1030,"A deep learning based approach for automatic detection of COVID-19 cases using chest X-ray images. In this global pandemic situation of coronavirus disease (COVID-19), it is of foremost priority to look up efficient and faster diagnosis methods for reducing the transmission rate of the virus severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Recent research has indicated that radio-logical images carry essential information about the COVID-19 virus. Therefore, artificial intelligence (AI) assisted automated detection of lung infections may serve as a potential diagnostic tool. It can be augmented with conventional medical tests for tackling COVID-19. In this paper, we propose a new method for detecting COVID-19 and pneumonia using chest X-ray images. The proposed method can be described as a three-step process. The first step includes the segmentation of the raw X-ray images using the conditional generative adversarial network (C-GAN) for obtaining the lung images. In the second step, we feed the segmented lung images into a novel pipeline combining key points extraction methods and trained deep neural networks (DNN) for extraction of discriminatory features. Several machine learning (ML) models are employed to classify COVID-19, pneumonia, and normal lung images in the final step. A comparative analysis of the classification performance is carried out among the different proposed architectures combining DNNs, key point extraction methods, and ML models. We have achieved the highest testing classification accuracy of 96.6% using the VGG-19 model associated with the binary robust invariant scalable key-points (BRISK) algorithm. The proposed method can be efficiently used for screening of COVID-19 infected patients.",0,0
1036,"A practical artificial intelligence system to diagnose COVID-19 using computed tomography: A multinational external validation study. Computed tomography has gained an important role in the early diagnosis of COVID-19 pneumonia. However, the ever-increasing number of patients has overwhelmed radiology departments and has caused a reduction in quality of services. Artificial intelligence (AI) systems are the remedy to the current situation. However, the lack of application in real-world conditions has limited their consideration in clinical settings. This study validated a clinical AI system, COVIDiag, to aid radiologists in accurate and rapid evaluation of COVID-19 cases. 50 COVID-19 and 50 non-COVID-19 pneumonia cases were included from each of five centers: Argentina, Turkey, Iran, Netherlands, and Italy. The Dutch database included only 50 COVID-19 cases. The performance parameters namely sensitivity, specificity, accuracy, and area under the ROC curve (AUC) were computed for each database using COVIDiag model. The most common pattern of involvement among COVID-19 cases in all databases were bilateral involvement of upper and lower lobes with ground-glass opacities. The best sensitivity of 92.0% was recorded for the Italian database. The system achieved an AUC of 0.983, 0.914, 0.910, and 0.882 for Argentina, Turkey, Iran, and Italy, respectively. The model obtained a sensitivity of 86.0% for the Dutch database. COVIDiag model could diagnose COVID-19 pneumonia in all of cohorts with AUC of 0.921 (sensitivity, specificity, and accuracy of 88.8%, 87.0%, and 88.0%, respectively). Our study confirmed the accuracy of our proposed AI model (COVIDiag) in the diagnosis of COVID-19 cases. Furthermore, the system demonstrated consistent optimal diagnostic performance on multinational databases, which is critical to determine the generalizability and objectivity of the proposed COVIDiag model. Our results are significant as they provide real-world evidence regarding the applicability of AI systems in clinical medicine.",0,0
1037,"Identifying individuals with recent COVID-19 through voice classification using deep learning. Recently deep learning has attained a breakthrough in model accuracy for the classification of images due mainly to convolutional neural networks. In the present study, we attempted to investigate the presence of subclinical voice feature alteration in COVID-19 patients after the recent resolution of disease using deep learning. The study was a prospective study of 76 post COVID-19 patients and 40 healthy individuals. The diagnoses of post COVID-19 patients were based on more than the eighth week after onset of symptoms. Voice samples of an 'ah' sound, coughing sound and a polysyllabic sentence were collected and preprocessed to log-mel spectrogram. Transfer learning using the VGG19 pre-trained convolutional neural network was performed with all voice samples. The performance of the model using the polysyllabic sentence yielded the highest classification performance of all models. The coughing sound produced the lowest classification performance while the ability of the monosyllabic 'ah' sound to predict the recent COVID-19 fell between the other two vocalizations. The model using the polysyllabic sentence achieved 85% accuracy, 89% sensitivity, and 77% specificity. In conclusion, deep learning is able to detect the subtle change in voice features of COVID-19 patients after recent resolution of the disease.",0,0
1040,"Artificial intelligence-based image analysis can predict outcome in high-grade serous carcinoma via histology alone. High-grade extrauterine serous carcinoma (HGSC) is an aggressive tumor with high rates of recurrence, frequent chemotherapy resistance, and overall 5-year survival of less than 50%. Beyond determining and confirming the diagnosis itself, pathologist review of histologic slides provides no prognostic or predictive information, which is in sharp contrast to almost all other carcinoma types. Deep-learning based image analysis has recently been able to predict outcome and/or identify morphology-based representations of underlying molecular alterations in other tumor types, such as colorectal carcinoma, lung carcinoma, breast carcinoma, and melanoma. Using a carefully stratified HGSC patient cohort consisting of women (nâ€‰=â€‰30) with similar presentations who experienced very different treatment responses (platinum free intervals of eitherâ€‰â‰¤â€‰6Â months orâ€‰â‰¥â€‰18Â months), we used whole slide images (WSI, nâ€‰=â€‰205) to train a convolutional neural network. The neural network was trained, in three steps, to identify morphologic regions (digital biomarkers) that are highly associating with one or the other treatment response group. We tested the classifier using a separate 22 slide test set, and 18/22 slides were correctly classified. We show that a neural network based approach can discriminate extremes in patient response to primary platinum-based chemotherapy with high sensitivity (73%) and specificity (91%). These proof-of-concept results are novel, because for the first time, prospective prognostic information is identified specifically within HGSC tumor morphology.",0,0
1044,"External validation of a novel signature of illness in continuous cardiorespiratory monitoring to detect early respiratory deterioration of ICU patients. The goal of predictive analytics monitoring is the early detection of patients at high risk of subacute potentially catastrophic illnesses. An excellent example of a targeted illness is respiratory failure leading to urgent unplanned intubation, where early detection might lead to interventions that improve patient outcomes. Previously, we identified signatures of this illness in the continuous cardiorespiratory monitoring data of intensive care unit (ICU) patients and devised algorithms to identify patients at rising risk. Here, we externally validated three logistic regression models to estimate the risk of emergency intubation developed in Medical and Surgical ICUs at the University of Virginia.",0,0
1046,"Deep learning and capsule endoscopy: automatic identification and differentiation of small bowel lesions with distinct haemorrhagic potential using a convolutional neural network. Capsule endoscopy (CE) is pivotal for evaluation of small bowel disease. Obscure gastrointestinal bleeding most often originates from the small bowel. CE frequently identifies a wide range of lesions with different bleeding potentials in these patients. However, reading CE examinations is a time-consuming task. Convolutional neural networks (CNNs) are highly efficient artificial intelligence tools for image analysis. This study aims to develop a CNN-based model for identification and differentiation of multiple small bowel lesions with distinct haemorrhagic potential using CE images.",0,0
1047,"Influence of social determinants of health and county vaccination rates on machine learning models to predict COVID-19 case growth in Tennessee. The SARS-CoV-2 (COVID-19) pandemic has exposed health disparities throughout the USA, particularly among racial and ethnic minorities. As a result, there is a need for data-driven approaches to pinpoint the unique constellation of clinical and social determinants of health (SDOH) risk factors that give rise to poor patient outcomes following infection in US communities.",0,0
1049,"Efficacy of a deep leaning model created with the transfer learning method in detecting sialoliths of the submandibular gland on panoramic radiography. This study aimed to compare the performance of 3 deep learning models, including a model constructed with the transfer learning method, in detecting submandibular gland sialoliths on panoramic radiographs.",0,0
1053,"Robust inflammatory breast cancer gene signature using nonparametric random forest analysis. Inflammatory breast cancer (IBC) is a rare, aggressive cancer found in all the molecular breast cancer subtypes. Despite extensive previous efforts to screen for transcriptional differences between IBC and non-IBC patients, a robust IBC-specific molecular signature has been elusive. We report a novel IBC-specific gene signature (59 genes; G59) that achieves 100% accuracy in discovery and validation samples (45/45 correct classification) and remarkably only misclassified one sample (60/61 correct classification) in an independent dataset. G59 is independent of ER/HER2 status, molecular subtypes and is specific to untreated IBC samples, with most of the genes being enriched for plasma membrane cellular component proteins, interleukin (IL), and chemokine signaling pathways. Our finding suggests the existence of an IBC-specific molecular signature, paving the way for the identification and validation of targetable genomic drivers of IBC.",0,0
1070,"Artificial Intelligence-Assisted Throat Sensor Using Ionic Polymer-Metal Composite (IPMC) Material. Throat sensing has received increasing demands in recent years, especially for oropharyngeal treatment applications. The conventional videofluoroscopy (VFS) approach is limited by either exposing the patient to radiation or incurring expensive costs on sophisticated equipment as well as well-trained speech-language pathologists. Here, we propose a smart and non-invasive throat sensor that can be fabricated using an ionic polymer-metal composite (IPMC) material. Through the cation's movement inside the IPMC material, the sensor can detect muscle movement at the throat using a self-generated signal. We have further improved the output responses of the sensor by coating it with a corrosive-resistant gold material. A support vector machine algorithm is used to train the sensor in recognizing the pattern of the throat movements, with a high accuracy of 95%. Our proposed throat sensor has revealed its potential to be used as a promising solution for smart healthcare devices, which can benefit many practical applications such as human-machine interactions, sports training, and rehabilitation.",0,0
1071,"Assessment of the Impact of Alcohol Consumption Patterns on Heart Rate Variability by Machine Learning in Healthy Young Adults. <i>Background and Objectives:</i> Autonomic nervous system (ANS) dysfunction is present in early stages of alcohol abuse and increases the likelihood of cardiovascular events. Given the nonlinear pattern of dynamic interaction between sympathetic nervous system (SNS) and para sympathetic nervous system (PNS) and the complex relationship with lifestyle factors, machine learning (ML) algorithms are best suited for analyzing alcohol impact over heart rate variability (HRV), because they allow the analysis of complex interactions between multiple variables. This study aimed to characterize autonomic nervous system dysfunction by analysis of HRV correlated with cardiovascular risk factors in young individuals by using machine learning. <i>Materials and Methods:</i> Total of 142 young adults (28.4 Â± 4.34 years) agreed to participate in the study. Alcohol intake and drinking patterns were assessed by the AUDIT (Alcohol Use Disorders Identification Test) questionnaire and the YAI (Yearly Alcohol Intake) index. A short 5-min HRV evaluation was performed. Post-hoc analysis and machine learning algorithms were used to assess the impact of alcohol intake on HRV. <i>Results:</i> Binge drinkers presented slight modification in the frequency domain. Heavy drinkers had significantly lower time-domain values: standard deviation of RR intervals (SDNN) and root mean square of the successive differences (RMSSD), compared to casual and binge drinkers. High frequency (HF) values were significantly lower in heavy drinkers (<i>p</i> = 0.002). The higher low-to-high frequency ratio (LF/HF) that we found in heavy drinkers was interpreted as parasympathetic inhibition. Gradient boosting machine learner regression showed that age and alcohol consumption had the biggest scaled impact on the analyzed HRV parameters, followed by smoking, anxiety, depression, and body mass index. Gender and physical activity had the lowest impact on HRV. <i>Conclusions:</i> In healthy young adults, high alcohol intake has a negative impact on HRV in both time and frequency-domains. In parameters like HRV, where a multitude of risk factors can influence measurements, artificial intelligence algorithms seem to be a viable alternative for correct assessment.",0,0
1072,"Subtyping Hyperchloremia among Hospitalized Patients by Machine Learning Consensus Clustering. <i>Background and Objectives</i>: Despite the association between hyperchloremia and adverse outcomes, mortality risks among patients with hyperchloremia have not consistently been observed among all studies with different patient populations with hyperchloremia. The objective of this study was to characterize hyperchloremic patients at hospital admission into clusters using an unsupervised machine learning approach and to evaluate the mortality risk among these distinct clusters. <i>Materials and Methods</i>: We performed consensus cluster analysis based on demographic information, principal diagnoses, comorbidities, and laboratory data among 11,394 hospitalized adult patients with admission serum chloride of >108 mEq/L. We calculated the standardized mean difference of each variable to identify each cluster's key features. We assessed the association of each hyperchloremia cluster with hospital and one-year mortality. <i>Results</i>: There were three distinct clusters of patients with admission hyperchloremia: 3237 (28%), 4059 (36%), and 4098 (36%) patients in clusters 1 through 3, respectively. Cluster 1 was characterized by higher serum chloride but lower serum sodium, bicarbonate, hemoglobin, and albumin. Cluster 2 was characterized by younger age, lower comorbidity score, lower serum chloride, and higher estimated glomerular filtration (eGFR), hemoglobin, and albumin. Cluster 3 was characterized by older age, higher comorbidity score, higher serum sodium, potassium, and lower eGFR. Compared with cluster 2, odds ratios for hospital mortality were 3.60 (95% CI 2.33-5.56) for cluster 1, and 4.83 (95% CI 3.21-7.28) for cluster 3, whereas hazard ratios for one-year mortality were 4.49 (95% CI 3.53-5.70) for cluster 1 and 6.96 (95% CI 5.56-8.72) for cluster 3. <i>Conclusions</i>: Our cluster analysis identified three clinically distinct phenotypes with differing mortality risks in hospitalized patients with admission hyperchloremia.",0,0
1075,"Classification and Automated Interpretation of Spinal Posture Data Using a Pathology-Independent Classifier and Explainable Artificial Intelligence (XAI). Clinical classification models are mostly pathology-dependent and, thus, are only able to detect pathologies they have been trained for. Research is needed regarding pathology-independent classifiers and their interpretation. Hence, our aim is to develop a pathology-independent classifier that provides prediction probabilities and explanations of the classification decisions. Spinal posture data of healthy subjects and various pathologies (back pain, spinal fusion, osteoarthritis), as well as synthetic data, were used for modeling. A one-class support vector machine was used as a pathology-independent classifier. The outputs were transformed into a probability distribution according to Platt's method. Interpretation was performed using the explainable artificial intelligence tool Local Interpretable Model-Agnostic Explanations. The results were compared with those obtained by commonly used binary classification approaches. The best classification results were obtained for subjects with a spinal fusion. Subjects with back pain were especially challenging to distinguish from the healthy reference group. The proposed method proved useful for the interpretation of the predictions. No clear inferiority of the proposed approach compared to commonly used binary classifiers was demonstrated. The application of dynamic spinal data seems important for future works. The proposed approach could be useful to provide an objective orientation and to individually adapt and monitor therapy measures pre- and post-operatively.",0,0
1080,"Estimation of Continuous Blood Pressure from PPG via a Federated Learning Approach. Ischemic heart disease is the highest cause of mortality globally each year. This puts a massive strain not only on the lives of those affected, but also on the public healthcare systems. To understand the dynamics of the healthy and unhealthy heart, doctors commonly use an electrocardiogram (ECG) and blood pressure (BP) readings. These methods are often quite invasive, particularly when continuous arterial blood pressure (ABP) readings are taken, and not to mention very costly. Using machine learning methods, we develop a framework capable of inferring ABP from a single optical photoplethysmogram (PPG) sensor alone. We train our framework across distributed models and data sources to mimic a large-scale distributed collaborative learning experiment that could be implemented across low-cost wearables. Our time-series-to-time-series generative adversarial network (T2TGAN) is capable of high-quality continuous ABP generation from a PPG signal with a mean error of 2.95 mmHg and a standard deviation of 19.33 mmHg when estimating mean arterial pressure on a previously unseen, noisy, independent dataset. To our knowledge, this framework is the first example of a GAN capable of continuous ABP generation from an input PPG signal that also uses a federated learning methodology.",0,0
1086,"The Role of Surface Electromyography in Data Fusion with Inertial Sensors to Enhance Locomotion Recognition and Prediction. Locomotion recognition and prediction is essential for real-time human-machine interactive control. The integration of electromyography (EMG) with mechanical sensors could improve the performance of locomotion recognition. However, the potential of EMG in motion prediction is rarely discussed. This paper firstly investigated the effect of surface EMG on the prediction of locomotion while integrated with inertial data. We collected EMG signals of lower limb muscle groups and linear acceleration data of lower limb segments from ten healthy participants in seven locomotion activities. Classification models were built based on four machine learning methods-support vector machine (SVM), k-nearest neighbor (KNN), artificial neural network (ANN), and linear discriminant analysis (LDA)-where a major vote strategy and a content constraint rule were utilized for improving the online performance of the classification decision. We compared four classifiers and further investigated the effect of data fusion on the online locomotion classification. The results showed that the SVM model with a sliding window size of 80 ms achieved the best recognition performance. The fusion of EMG signals does not only improve the recognition accuracy of steady-state locomotion activity from 90% (using acceleration data only) to 98% (using data fusion) but also enables the prediction of the next steady locomotion (âˆ¼370 ms). The study demonstrates that the employment of EMG in locomotion recognition could enhance online prediction performance.",0,0
1092,"Detection of Error-Related Potentials in Stroke Patients from EEG Using an Artificial Neural Network. Error-related potentials (ErrPs) have been proposed as a means for improving brain-computer interface (BCI) performance by either correcting an incorrect action performed by the BCI or label data for continuous adaptation of the BCI to improve the performance. The latter approach could be relevant within stroke rehabilitation where BCI calibration time could be minimized by using a generalized classifier that is continuously being individualized throughout the rehabilitation session. This may be achieved if data are correctly labelled. Therefore, the aims of this study were: (1) classify single-trial ErrPs produced by individuals with stroke, (2) investigate test-retest reliability, and (3) compare different classifier calibration schemes with different classification methods (artificial neural network, ANN, and linear discriminant analysis, LDA) with waveform features as input for meaningful physiological interpretability. Twenty-five individuals with stroke operated a sham BCI on two separate days where they attempted to perform a movement after which they received feedback (error/correct) while continuous EEG was recorded. The EEG was divided into epochs: ErrPs and NonErrPs. The epochs were classified with a multi-layer perceptron ANN based on temporal features or the entire epoch. Additionally, the features were classified with shrinkage LDA. The features were waveforms of the ErrPs and NonErrPs from the sensorimotor cortex to improve the explainability and interpretation of the output of the classifiers. Three calibration schemes were tested: within-day, between-day, and across-participant. Using within-day calibration, 90% of the data were correctly classified with the entire epoch as input to the ANN; it decreased to 86% and 69% when using temporal features as input to ANN and LDA, respectively. There was poor test-retest reliability between the two days, and the other calibration schemes led to accuracies in the range of 63-72% with LDA performing the best. There was no association between the individuals' impairment level and classification accuracies. The results show that ErrPs can be classified in individuals with stroke, but that user- and session-specific calibration is needed for optimal ErrP decoding with this approach. The use of ErrP/NonErrP waveform features makes it possible to have a physiological meaningful interpretation of the output of the classifiers. The results may have implications for labelling data continuously in BCIs for stroke rehabilitation and thus potentially improve the BCI performance.",0,0
1096,"Hyperglycemia Identification Using ECG in Deep Learning Era. A growing number of smart wearable biosensors are operating in the medical IoT environment and those that capture physiological signals have received special attention. Electrocardiogram (ECG) is one of the physiological signals used in the cardiovascular and medical fields that has encouraged researchers to discover new non-invasive methods to diagnose hyperglycemia as a personal variable. Over the years, researchers have proposed different techniques to detect hyperglycemia using ECG. In this paper, we propose a novel deep learning architecture that can identify hyperglycemia using heartbeats from ECG signals. In addition, we introduce a new fiducial feature extraction technique that improves the performance of the deep learning classifier. We evaluate the proposed method with ECG data from 1119 different subjects to assess the efficiency of hyperglycemia detection of the proposed work. The result indicates that the proposed algorithm is effective in detecting hyperglycemia with a 94.53% area under the curve (AUC), 87.57% sensitivity, and 85.04% specificity. That performance represents an relative improvement of 53% versus the best model found in the literature. The high sensitivity and specificity achieved by the 10-layer deep neural network proposed in this work provide an excellent indication that ECG possesses intrinsic information that can indicate the level of blood glucose concentration.",0,0
1097,"Non-Invasive Hemodynamics Monitoring System Based on Electrocardiography via Deep Convolutional Autoencoder. This study evaluates cardiovascular and cerebral hemodynamics systems by only using non-invasive electrocardiography (ECG) signals. The Massachusetts General Hospital/Marquette Foundation (MGH/MF) and Cerebral Hemodynamic Autoregulatory Information System Database (CHARIS DB) from the PhysioNet database are used for cardiovascular and cerebral hemodynamics, respectively. For cardiovascular hemodynamics, the ECG is used for generating the arterial blood pressure (ABP), central venous pressure (CVP), and pulmonary arterial pressure (PAP). Meanwhile, for cerebral hemodynamics, the ECG is utilized for the intracranial pressure (ICP) generator. A deep convolutional autoencoder system is applied for this study. The cross-validation method with Pearson's linear correlation (R), root mean squared error (RMSE), and mean absolute error (MAE) are measured for the evaluations. Initially, the ECG is used to generate the cardiovascular waveform. For the ABP system-the systolic blood pressure (SBP) and diastolic blood pressures (DBP)-the R evaluations are 0.894 Â± 0.004 and 0.881 Â± 0.005, respectively. The MAE evaluations for SBP and DBP are, respectively, 6.645 Â± 0.353 mmHg and 3.210 Â± 0.104 mmHg. Furthermore, for the PAP system-the systolic and diastolic pressures-the R evaluations are 0.864 Â± 0.003 mmHg and 0.817 Â± 0.006 mmHg, respectively. The MAE evaluations for systolic and diastolic pressures are, respectively, 3.847 Â± 0.136 mmHg and 2.964 Â± 0.181 mmHg. Meanwhile, the mean CVP evaluations are 0.916 Â± 0.001, 2.220 Â± 0.039 mmHg, and 1.329 Â± 0.036 mmHg, respectively, for R, RMSE, and MAE. For the mean ICP evaluation in cerebral hemodynamics, the R and MAE evaluations are 0.914 Â± 0.003 and 2.404 Â± 0.043 mmHg, respectively. This study, as a proof of concept, concludes that the non-invasive cardiovascular and cerebral hemodynamics systems can be potentially investigated by only using the ECG signal.",0,0
1103,"AI-Assisted In-House Power Monitoring for the Detection of Cognitive Impairment in Older Adults. In-home monitoring systems have been used to detect cognitive decline in older adults by allowing continuous monitoring of routine activities. In this study, we investigated whether unobtrusive in-house power monitoring technologies could be used to predict cognitive impairment. A total of 94 older adults aged â‰¥65 years were enrolled in this study. Generalized linear mixed models with subject-specific random intercepts were used to evaluate differences in the usage time of home appliances between people with and without cognitive impairment. Three independent power monitoring parameters representing activity behavior were found to be associated with cognitive impairment. Representative values of mean differences between those with cognitive impairment relative to those without were -13.5 min for induction heating in the spring, -1.80 min for microwave oven in the winter, and -0.82 h for air conditioner in the winter. We developed two prediction models for cognitive impairment, one with power monitoring data and the other without, and found that the former had better predictive ability (accuracy, 0.82; sensitivity, 0.48; specificity, 0.96) compared to the latter (accuracy, 0.76; sensitivity, 0.30; specificity, 0.95). In summary, in-house power monitoring technologies can be used to detect cognitive impairment.",0,0
1104,"Improved Self-Organizing Map-Based Unsupervised Learning Algorithm for Sitting Posture Recognition System. As the intensity of work increases, many of us sit for long hours while working in the office. It is not easy to sit properly at work all the time and sitting for a long time with wrong postures may cause a series of health problems as time goes by. In addition, monitoring the sitting posture of patients with spinal disease would be beneficial for their recovery. Accordingly, this paper designs and implements a sitting posture recognition system from a flexible array pressure sensor, which is used to acquire pressure distribution map of sitting hips in a real-time manner. Moreover, an improved self-organizing map-based classification algorithm for six kinds of sitting posture recognition is proposed to identify whether the current sitting posture is appropriate. The extensive experimental results verify that the performance of ISOM-based sitting posture recognition algorithm (ISOM-SPR) in short outperforms that of four kinds of traditional algorithms including decision tree-based (DT), K-means-based (KM), back propagation neural network-based (BP), self-organizing map-based (SOM) sitting posture recognition algorithms. Finally, it is proven that the proposed system based on ISOM-SPR algorithm has good robustness and high accuracy.",0,0
1108,"Detection of Health-Related Events and Behaviours from Wearable Sensor Lifestyle Data Using Symbolic Intelligence: A Proof-of-Concept Application in the Care of Multiple Sclerosis. In this paper, we demonstrate the potential of a knowledge-driven framework to improve the efficiency and effectiveness of care through remote and intelligent assessment. More specifically, we present a rule-based approach to detect health related problems from wearable lifestyle sensor data that add clinical value to take informed decisions on follow-up and intervention. We use OWL 2 ontologies as the underlying knowledge representation formalism for modelling contextual information and high-level concepts and relations among them. The conceptual model of our framework is defined on top of existing modelling standards, such as SOSA and WADM, promoting the creation of interoperable knowledge graphs. On top of the symbolic knowledge graphs, we define a rule-based framework for infusing expert knowledge in the form of SHACL constraints and rules to recognise patterns, anomalies and situations of interest based on the predefined and stored rules and conditions. A dashboard visualizes both sensor data and detected events to facilitate clinical supervision and decision making. Preliminary results on the performance and scalability are presented, while a focus group of clinicians involved in an exploratory research study revealed their preferences and perspectives to shape future clinical research using the framework.",0,0
1111,"Detection of Mild Cognitive Impairment with MEG Functional Connectivity Using Wavelet-Based Neuromarkers. Studies on developing effective neuromarkers based on magnetoencephalographic (MEG) signals have been drawing increasing attention in the neuroscience community. This study explores the idea of using source-based magnitude-squared spectral coherence as a spatial indicator for effective regions of interest (ROIs) localization, subsequently discriminating the participants with mild cognitive impairment (MCI) from a group of age-matched healthy control (HC) elderly participants. We found that the cortical regions could be divided into two distinctive groups based on their coherence indices. Compared to HC, some ROIs showed increased connectivity (hyper-connected ROIs) for MCI participants, whereas the remaining ROIs demonstrated reduced connectivity (hypo-connected ROIs). Based on these findings, a series of wavelet-based source-level neuromarkers for MCI detection are proposed and explored, with respect to the two distinctive ROI groups. It was found that the neuromarkers extracted from the hyper-connected ROIs performed significantly better for MCI detection than those from the hypo-connected ROIs. The neuromarkers were classified using support vector machine (SVM) and k-NN classifiers and evaluated through Monte Carlo cross-validation. An average recognition rate of 93.83% was obtained using source-reconstructed signals from the hyper-connected ROI group. To better conform to clinical practice settings, a leave-one-out cross-validation (LOOCV) approach was also employed to ensure that the data for testing was from a participant that the classifier has never seen. Using LOOCV, we found the best average classification accuracy was reduced to 83.80% using the same set of neuromarkers obtained from the ROI group with functional hyper-connections. This performance surpassed the results reported using wavelet-based features by approximately 15%. Overall, our work suggests that (1) certain ROIs are particularly effective for MCI detection, especially when multi-resolution wavelet biomarkers are employed for such diagnosis; (2) there exists a significant performance difference in system evaluation between research-based experimental design and clinically accepted evaluation standards.",0,0
1115,"A Spatiotemporal Deep Learning Approach for Automatic Pathological Gait Classification. Human motion analysis provides useful information for the diagnosis and recovery assessment of people suffering from pathologies, such as those affecting the way of walking, i.e., gait. With recent developments in deep learning, state-of-the-art performance can now be achieved using a single 2D-RGB-camera-based gait analysis system, offering an objective assessment of gait-related pathologies. Such systems provide a valuable complement/alternative to the current standard practice of subjective assessment. Most 2D-RGB-camera-based gait analysis approaches rely on compact gait representations, such as the gait energy image, which summarize the characteristics of a walking sequence into one single image. However, such compact representations do not fully capture the temporal information and dependencies between successive gait movements. This limitation is addressed by proposing a spatiotemporal deep learning approach that uses a selection of key frames to represent a gait cycle. Convolutional and recurrent deep neural networks were combined, processing each gait cycle as a collection of silhouette key frames, allowing the system to learn temporal patterns among the spatial features extracted at individual time instants. Trained with gait sequences from the GAIT-IT dataset, the proposed system is able to improve gait pathology classification accuracy, outperforming state-of-the-art solutions and achieving improved generalization on cross-dataset tests.",0,0
1118,"A Novel Hybrid Approach Based on Deep CNN Features to Detect Knee Osteoarthritis. In the recent era, various diseases have severely affected the lifestyle of individuals, especially adults. Among these, bone diseases, including Knee Osteoarthritis (KOA), have a great impact on quality of life. KOA is a knee joint problem mainly produced due to decreased Articular Cartilage between femur and tibia bones, producing severe joint pain, effusion, joint movement constraints and gait anomalies. To address these issues, this study presents a novel KOA detection at early stages using deep learning-based feature extraction and classification. Firstly, the input X-ray images are preprocessed, and then the Region of Interest (ROI) is extracted through segmentation. Secondly, features are extracted from preprocessed X-ray images containing knee joint space width using hybrid feature descriptors such as Convolutional Neural Network (CNN) through Local Binary Patterns (LBP) and CNN using Histogram of oriented gradient (HOG). Low-level features are computed by HOG, while texture features are computed employing the LBP descriptor. Lastly, multi-class classifiers, that is, Support Vector Machine (SVM), Random Forest (RF), and K-Nearest Neighbour (KNN), are used for the classification of KOA according to the Kellgren-Lawrence (KL) system. The Kellgren-Lawrence system consists of Grade I, Grade II, Grade III, and Grade IV. Experimental evaluation is performed on various combinations of the proposed framework. The experimental results show that the HOG features descriptor provides approximately 97% accuracy for the early detection and classification of KOA for all four grades of KL.",0,0
1131,"Action Recognition of Lower Limbs Based on Surface Electromyography Weighted Feature Method. To improve the recognition rate of lower limb actions based on surface electromyography (sEMG), an effective weighted feature method is proposed, and an improved genetic algorithm support vector machine (IGA-SVM) is designed in this paper. First, for the problem of high feature redundancy and low discrimination in the surface electromyography feature extraction process, the weighted feature method is proposed based on the correlation between muscles and actions. Second, to solve the problem of the genetic algorithm selection operator easily falling into a local optimum solution, the improved genetic algorithm-support vector machine is designed by championship with sorting method. Finally, the proposed method is used to recognize six types of lower limb actions designed, and the average recognition rate reaches 94.75%. Experimental results indicate that the proposed method has definite potentiality in lower limb action recognition.",0,0
1156,"Automatic Sleep-Arousal Detection with Single-Lead EEG Using Stacking Ensemble Learning. Poor-quality sleep substantially diminishes the overall quality of life. It has been shown that sleep arousal serves as a good indicator for scoring sleep quality. However, patients are conventionally asked to perform overnight polysomnography tests to collect their physiological data, which are used for the manual judging of sleep arousals. Even worse, not only is this process time-consuming and cumbersome, the judgment of sleep-arousal events is subjective and differs widely from expert to expert. Therefore, this work focuses on designing an automatic sleep-arousal detector that necessitates only a single-lead electroencephalogram signal. Based on the stacking ensemble learning framework, the automatic sleep-arousal detector adopts a meta-classifier that stacks four sub-models: one-dimensional convolutional neural networks, recurrent neural networks, merged convolutional and recurrent networks, and random forest classifiers. This meta-classifier exploits both advantages from deep learning networks and conventional machine learning algorithms to enhance its performance. The embedded information for discriminating the sleep-arousals is extracted from waveform sequences, spectrum characteristics, and expert-defined statistics in single-lead EEG signals. Its effectiveness is evaluated using an open-accessed database, which comprises polysomnograms of 994 individuals, provided by PhysioNet. The improvement of the stacking ensemble learning over a single sub-model was up to 9.29%, 7.79%, 11.03%, 8.61% and 9.04%, respectively, in terms of specificity, sensitivity, precision, accuracy, and area under the receiver operating characteristic curve.",0,0
1158,"Artificial Intelligence-Enabled ECG Algorithm Based on Improved Residual Network for Wearable ECG. Heart disease is the leading cause of death for men and women globally. The residual network (ResNet) evolution of electrocardiogram (ECG) technology has contributed to our understanding of cardiac physiology. We propose an artificial intelligence-enabled ECG algorithm based on an improved ResNet for a wearable ECG. The system hardware consists of a wearable ECG with conductive fabric electrodes, a wireless ECG acquisition module, a mobile terminal App, and a cloud diagnostic platform. The algorithm adopted in this study is based on an improved ResNet for the rapid classification of different types of arrhythmia. First, we visualize ECG data and convert one-dimensional ECG signals into two-dimensional images using Gramian angular fields. Then, we improve the ResNet-50 network model, add multistage shortcut branches to the network, and optimize the residual block. The ReLu activation function is replaced by a scaled exponential linear units (SELUs) activation function to improve the expression ability of the model. Finally, the images are input into the improved ResNet network for classification. The average recognition rate of this classification algorithm against seven types of arrhythmia signals (atrial fibrillation, atrial premature beat, ventricular premature beat, normal beat, ventricular tachycardia, atrial tachycardia, and sinus bradycardia) is 98.3%.",0,0
1160,"Towards Intraoperative Quantification of Atrial Fibrosis Using Light-Scattering Spectroscopy and Convolutional Neural Networks. Light-scattering spectroscopy (LSS) is an established optical approach for characterization of biological tissues. Here, we investigated the capabilities of LSS and convolutional neural networks (CNNs) to quantitatively characterize the composition and arrangement of cardiac tissues. We assembled tissue constructs from fixed myocardium and the aortic wall with a thickness similar to that of the atrial free wall. The aortic sections represented fibrotic tissue. Depth, volume fraction, and arrangement of these fibrotic insets were varied. We gathered spectra with wavelengths from 500-1100 nm from the constructs at multiple locations relative to a light source. We used single and combinations of two spectra for training of CNNs. With independently measured spectra, we assessed the accuracy of the CNNs for the classification of tissue constructs from single spectra and combined spectra. Combined spectra, including the spectra from fibers distal from the illumination fiber, typically yielded the highest accuracy. The maximal classification accuracy of the depth detection, volume fraction, and permutated arrangements was (mean Â± standard deviation (stddev)) 88.97 Â± 2.49%, 76.33 Â± 1.51%, and 84.25 Â± 1.88%, respectively. Our studies demonstrate the reliability of quantitative characterization of tissue composition and arrangements using a combination of LSS and CNNs. The potential clinical applications of the developed approach include intraoperative quantification and mapping of atrial fibrosis, as well as the assessment of ablation lesions.",0,0
1163,"Assessment of Non-Invasive Blood Pressure Prediction from PPG and rPPG Signals Using Deep Learning. Exploiting photoplethysmography signals (PPG) for non-invasive blood pressure (BP) measurement is interesting for various reasons. First, PPG can easily be measured using fingerclip sensors. Second, camera based approaches allow to derive remote PPG (rPPG) signals similar to PPG and therefore provide the opportunity for non-invasive measurements of BP. Various methods relying on machine learning techniques have recently been published. Performances are often reported as the mean average error (MAE) on the data which is problematic. This work aims to analyze the PPG- and rPPG based BP prediction error with respect to the underlying data distribution. First, we train established neural network (NN) architectures and derive an appropriate parameterization of input segments drawn from continuous PPG signals. Second, we use this parameterization to train NNs with a larger PPG dataset and carry out a systematic evaluation of the predicted blood pressure. The analysis revealed a strong systematic increase of the prediction error towards less frequent BP values across NN architectures. Moreover, we tested different train/test set split configurations which underpin the importance of a careful subject-aware dataset assignment to prevent overly optimistic results. Third, we use transfer learning to train the NNs for rPPG based BP prediction. The resulting performances are similar to the PPG-only case. Finally, we apply different personalization techniques and retrain our NNs with subject-specific data for both the PPG-only and rPPG case. Whilst the particular technique is less important, personalization reduces the prediction errors significantly.",0,0
1166,"Tooth and Bone Parameters in the Assessment of the Chronological Age of Children and Adolescents Using Neural Modelling Methods. The analog methods used in the clinical assessment of the patient's chronological age are subjective and characterized by low accuracy. When using those methods, there is a noticeable discrepancy between the chronological age and the age estimated based on relevant scientific studies. Innovations in the field of information technology are increasingly used in medicine, with particular emphasis on artificial intelligence methods. The paper presents research aimed at developing a new, effective methodology for the assessment of the chronological age using modern IT methods. In this paper, a study was conducted to determine the features of pantomographic images that support the determination of metric age, and neural models were produced to support the process of identifying the age of children and adolescents. The whole conducted work was a new methodology of metric age assessment. The result of the conducted study is a set of 21 original indicators necessary for the assessment of the chronological age with the use of computer image analysis and neural modelling, as well as three non-linear models of radial basis function networks (RBF), whose accuracy ranges from 96 to 99%. The result of the research are three neural models that determine the chronological age.",0,0
1171,"Colorectal Polyp Image Detection and Classification through Grayscale Images and Deep Learning. Colonoscopy screening and colonoscopic polypectomy can decrease the incidence and mortality rate of colorectal cancer (CRC). The adenoma detection rate and accuracy of diagnosis of colorectal polyp which vary in different experienced endoscopists have impact on the colonoscopy protection effect of CRC. The work proposed a colorectal polyp image detection and classification system through grayscale images and deep learning. The system collected the data of CVC-Clinic and 1000 colorectal polyp images of Linkou Chang Gung Medical Hospital. The red-green-blue (RGB) images were transformed to 0 to 255 grayscale images. Polyp detection and classification were performed by convolutional neural network (CNN) model. Data for polyp detection was divided into five groups and tested by 5-fold validation. The accuracy of polyp detection was 95.1% for grayscale images which is higher than 94.1% for RGB and narrow-band images. The diagnostic accuracy, precision and recall rates were 82.8%, 82.5% and 95.2% for narrow-band images, respectively. The experimental results show that grayscale images achieve an equivalent or even higher accuracy of polyp detection than RGB images for lightweight computation. It is also found that the accuracy of polyp detection and classification is dramatically decrease when the size of polyp images small than 1600 pixels. It is recommended that clinicians could adjust the distance between the lens and polyps appropriately to enhance the system performance when conducting computer-assisted colorectal polyp analysis.",0,0
1188,"Personalised Medicine for Colorectal Cancer Using Mechanism-Based Machine Learning Models. Gaining insight into the mechanisms of signal transduction networks (STNs) by using critical features from patient-specific mathematical models can improve patient stratification and help to identify potential drug targets. To achieve this, these models should focus on the critical STNs for each cancer, include prognostic genes and proteins, and correctly predict patient-specific differences in STN activity. Focussing on colorectal cancer and the WNT STN, we used mechanism-based machine learning models to identify genes and proteins with significant associations to event-free patient survival and predictive power for explaining patient-specific differences of STN activity. First, we identified the WNT pathway as the most significant pathway associated with event-free survival. Second, we built linear-regression models that incorporated both genes and proteins from established mechanistic models in the literature and novel genes with significant associations to event-free patient survival. Data from The Cancer Genome Atlas and Clinical Proteomic Tumour Analysis Consortium were used, and patient-specific STN activity scores were computed using PROGENy. Three linear regression models were built, based on; (1) the gene-set of a state-of-the-art mechanistic model in the literature, (2) novel genes identified, and (3) novel proteins identified. The novel genes and proteins were genes and proteins of the extant WNT pathway whose expression was significantly associated with event-free survival. The results show that the predictive power of a model that incorporated novel event-free associated genes is better compared to a model focussing on the genes of a current state-of-the-art mechanistic model. Several significant genes that should be integrated into future mechanistic models of the WNT pathway are DVL3, FZD5, RAC1, ROCK2, GSK3B, CTB2, CBT1, and PRKCA. Thus, the study demonstrates that using mechanistic information in combination with machine learning can identify novel features (genes and proteins) that are important for explaining the STN heterogeneity between patients and their association to clinical outcomes.",0,0
1191,"Feature Explanations in Recurrent Neural Networks for Predicting Risk of Mortality in Intensive Care Patients. Critical care staff are presented with a large amount of data, which made it difficult to systematically evaluate. Early detection of patients whose condition is deteriorating could reduce mortality, improve treatment outcomes, and allow a better use of healthcare resources. In this study, we propose a data-driven framework for predicting the risk of mortality that combines high-accuracy recurrent neural networks with interpretable explanations. Our model processes time-series of vital signs and laboratory observations to predict the probability of a patient's mortality in the intensive care unit (ICU). We investigated our approach on three public critical care databases: Multiparameter Intelligent Monitoring in Intensive Care III (MIMIC-III), MIMIC-IV, and eICU. Our models achieved an area under the receiver operating characteristic curve (AUC) of 0.87-0.91. Our approach was not only able to provide the predicted mortality risk but also to recognize and explain the historical contributions of the associated factors to the prediction. The explanations provided by our model were consistent with the literature. Patients may benefit from early intervention if their clinical observations in the ICU are continuously monitored in real time.",0,0
1192,"Deep-Learning-Based Smartphone Application for Self-Diagnosis of Scleral Jaundice in Patients with Hepatobiliary and Pancreatic Diseases. Outpatient detection of total bilirubin levels should be performed regularly to monitor the recurrence of jaundice in hepatobiliary and pancreatic disease patients. However, frequent hospital visits for blood testing are burdensome for patients with poor medical conditions. This study validates a novel deep-learning-based smartphone application for the self-diagnosis of scleral jaundice in such patients. The system predicts total serum bilirubin levels using the deep-learning-based regression analysis of scleral photos taken by the smartphone's built-in camera. Enrolled patients were randomly assigned to either the training cohort (<i>n</i> = 90, 1034 photos) or the validation cohort (<i>n</i> = 40, 426 photos). The intraclass correlation coefficient value for predicted serum total bilirubin (PSB) derived from the images repeatedly taken at the same time for the same patient showed good reliability (0.86). A strong correlation between measured serum total bilirubin (MSB) and PSB was observed in the subgroup with MSB levels â‰¥1.5 mg/dL (Spearman rho = 0.70, <i>p</i> < 0.001). The receiver operating characteristic curve for PSB showed that the area under the curve was 0.93, demonstrating good test performance as a predictor of hyperbilirubinemia (<i>p</i> < 0.001). Using a cut-off PSB â‰¥1.5, the prediction sensitivity of hyperbilirubinemia was 80.0%, with a specificity of 92.6%. Hence, the tool is effective for patient monitoring.",0,0
1195,"MRI Deep Learning-Based Solution for Alzheimer's Disease Prediction. Alzheimer's is a degenerative dementing disorder that starts with a mild memory impairment and progresses to a total loss of mental and physical faculties. The sooner the diagnosis is made, the better for the patient, as preventive actions and treatment can be started. Although tests such as the Mini-Mental State Tests Examination are usually used for early identification, diagnosis relies on magnetic resonance imaging (MRI) brain analysis.",0,0
1199,"Molecular Classification Models for Triple Negative Breast Cancer Subtype Using Machine Learning. Triple negative breast cancer (TNBC) lacks well-defined molecular targets and is highly heterogenous, making treatment challenging. Using gene expression analysis, TNBC has been classified into four different subtypes: basal-like immune-activated (BLIA), basal-like immune-suppressed (BLIS), mesenchymal (MES), and luminal androgen receptor (LAR). However, there is currently no standardized method for classifying TNBC subtypes. We attempted to define a gene signature for each subtype, and to develop a classification method based on machine learning (ML) for TNBC subtyping. In these experiments, gene expression microarray data for TNBC patients were downloaded from the Gene Expression Omnibus database. Differentially expressed genes unique to 198 known TNBC cases were identified and selected as a training gene set to train in seven different classification models. We produced a training set consisting of 719 DEGs selected from uniquely expressed genes of all four subtypes. The highest average accuracy of classification of the BLIA, BLIS, MES, and LAR subtypes was achieved by the SVM algorithm (accuracy 95-98.8%; AUC 0.99-1.00). For model validation, we used 334 samples of unknown TNBC subtypes, of which 97 (29.04%), 73 (21.86%), 39 (11.68%) and 59 (17.66%) were predicted to be BLIA, BLIS, MES, and LAR, respectively. However, 66 TNBC samples (19.76%) could not be assigned to any subtype. These samples contained only three upregulated genes (<i>EN1</i>, <i>PROM1</i>, and <i>CCL2</i>). Each TNBC subtype had a unique gene expression pattern, which was confirmed by identification of DEGs and pathway analysis. These results indicated that our training gene set was suitable for development of classification models, and that the SVM algorithm could classify TNBC into four unique subtypes. Accurate and consistent classification of the TNBC subtypes is essential for personalized treatment and prognosis of TNBC.",0,0
1200,"Filtration-Histogram Based Magnetic Resonance Texture Analysis (MRTA) for the Distinction of Primary Central Nervous System Lymphoma and Glioblastoma. Primary central nervous system lymphoma (PCNSL) has variable imaging appearances, which overlap with those of glioblastoma (GBM), thereby necessitating invasive tissue diagnosis. We aimed to investigate whether a rapid filtration histogram analysis of clinical MRI data supports the distinction of PCNSL from GBM. Ninety tumours (PCNSL <i>n</i> = 48, GBM <i>n</i> = 42) were analysed using pre-treatment MRI sequences (T<sub>1</sub>-weighted contrast-enhanced (T<sub>1</sub>CE), T<sub>2</sub>-weighted (T<sub>2</sub>), and apparent diffusion coefficient maps (ADC)). The segmentations were completed with proprietary texture analysis software (TexRAD version 3.3). Filtered (five filter sizes SSF = 2-6 mm) and unfiltered (SSF = 0) histogram parameters were compared using Mann-Whitney U non-parametric testing, with receiver operating characteristic (ROC) derived area under the curve (AUC) analysis for significant results. Across all (<i>n</i> = 90) tumours, the optimal algorithm performance was achieved using an unfiltered ADC mean and the mean of positive pixels (MPP), with a sensitivity of 83.8%, specificity of 8.9%, and AUC of 0.88. For subgroup analysis with >1/3 necrosis masses, ADC permitted the identification of PCNSL with a sensitivity of 96.9% and specificity of 100%. For T<sub>1</sub>CE-derived regions, the distinction was less accurate, with a sensitivity of 71.4%, specificity of 77.1%, and AUC of 0.779. A role may exist for cross-sectional texture analysis without complex machine learning models to differentiate PCNSL from GBM. ADC appears the most suitable sequence, especially for necrotic lesion distinction.",0,0
1201,"Clinical Evaluation of Pathognomonic Salivary Protease Fingerprinting for Oral Disease Diagnosis. Dental decay (Caries) and periodontal disease are globally prevalent diseases with significant clinical need for improved diagnosis. As mediators of dental disease-specific extracellular matrix degradation, proteases are promising analytes. We hypothesized that dysregulation of active proteases can be functionally linked to oral disease status and may be used for diagnosis. To address this, we examined a total of 52 patients with varying oral disease states, including healthy controls. Whole mouth saliva samples and caries biopsies were collected and subjected to analysis. Overall proteolytic and substrate specific activities were assessed using five multiplexed, fluorogenic peptides. Peptide cleavage was further described by inhibitors targeting matrix metalloproteases (MMPs) and cysteine, serine, calpain proteases (CSC). Proteolytic fingerprints, supported by supervised machine-learning analysis, were delineated by total proteolytic activity (PepE) and substrate preference combined with inhibition profiles. Caries and peridontitis showed increased enzymatic activities of MMPs with common (PepA) and divergent substrate cleavage patterns (PepE), suggesting different MMP contribution in particular disease states. Overall, sensitivity and specificity values of 84.6% and 90.0%, respectively, were attained. Thus, a combined analysis of protease derived individual and arrayed substrate cleavage rates in conjunction with inhibitor profiles may represent a sensitive and specific tool for oral disease detection.",0,0
1202,"Prediction of Hemorrhagic Transformation after Ischemic Stroke Using Machine Learning. Hemorrhagic transformation (HT) is one of the leading causes of a poor prognostic marker after acute ischemic stroke (AIS). We compared the performances of the several machine learning (ML) algorithms to predict HT after AIS using only structured data. A total of 2028 patients with AIS, who were admitted within seven days of symptoms onset, were included in this analysis. HT was defined based on the criteria of the European Co-operative Acute Stroke Study-II trial. The whole dataset was randomly divided into a training and a test dataset with a 7:3 ratio. Binary logistic regression, support vector machine, extreme gradient boosting, and artificial neural network (ANN) algorithms were used to assess the performance of predicting the HT occurrence after AIS. Five-fold cross validation and a grid search technique were used to optimize the hyperparameters of each ML model, which had its performance measured by the area under the receiver operating characteristic (AUROC) curve. Among the included AIS patients, the mean age and number of male subjects were 69.6 years and 1183 (58.3%), respectively. HT was observed in 318 subjects (15.7%). There were no significant differences in corresponding variables between the training and test dataset. Among all the ML algorithms, the ANN algorithm showed the best performance in terms of predicting the occurrence of HT in our dataset (0.844). Feature scaling including standardization and normalization, and the resampling strategy showed no additional improvement of the ANN's performance. The ANN-based prediction of HT after AIS showed better performance than the conventional ML algorithms. Deep learning may be used to predict important outcomes for structured data-based prediction.",0,0
1211,"Diagnosis of Subclinical Keratoconus Based on Machine Learning Techniques. (1) Background: Keratoconus is a non-inflammatory corneal disease characterized by gradual thinning of the stroma, resulting in irreversible visual quality and quantity decline. Early detection of keratoconus and subsequent prevention of possible risks are crucial factors in its progression. Random forest is a machine learning technique for classification based on the construction of thousands of decision trees. The aim of this study was to use the random forest technique in the classification and prediction of subclinical keratoconus, considering the metrics proposed by Pentacam and Corvis. (2) Methods: The design was a retrospective cross-sectional study. A total of 81 eyes of 81 patients were enrolled: sixty-one eyes with healthy corneas and twenty patients with subclinical keratoconus (SCKC): This initial stage includes patients with the following conditions: (1) minor topographic signs of keratoconus and suspicious topographic findings (mild asymmetric bow tie, with or without deviation; (2) average K (mean corneal curvature) < 46, 5 D; (3) minimum corneal thickness (ECM) > 490 Î¼m; (4) no slit lamp found; and (5) contralateral clinical keratoconus of the eye. Pentacam topographic and Corvis biomechanical variables were collected. Decision tree and random forest were used as machine learning techniques for classifications. Random forest performed a ranking of the most critical variables in classification. (3) Results: The essential variable was SP A1 (stiffness parameter A1), followed by A2 time, posterior coma 0Â°, A2 velocity and peak distance. The model efficiently predicted all patients with subclinical keratoconus (Sp = 93%) and was also a good model for classifying healthy cases (Sen = 86%). The overall accuracy rate of the model was 89%. (4) Conclusions: The random forest model was a good model for classifying subclinical keratoconus. The SP A1 variable was the most critical determinant in classifying and identifying subclinical keratoconus, followed by A2 time.",0,0
1212,"Intravesical Prostatic Protrusion and Prognosis of Non-Muscle Invasive Bladder Cancer: Analysis of Long-Term Data over 5 Years with Machine-Learning Algorithms. We aim to investigate the significance of intravesical prostate protrusion (IPP) on the prognosis of non-muscle invasive bladder cancer (NMIBC) after the transurethral resection of bladder tumors (TURBT). For newly diagnosed NMIBC, we retrospectively analyzed the association between prognosis and IPP for at least a 5-year follow-up. A degree of IPP over 5 mm in a preoperative CT scan was classified as severe. The primary endpoint was recurrence-free survival, and the secondary endpoint was progression-free survival. The machine learning (ML) algorithm of a support vector machine was used for predictive model development. Of a total of 122 patients, ultimately, severe IPP was observed in 33 patients (27.0%). IPP correlated positively with age, BPH, recurrence, and prognosis. Severe IPP was significantly higher in the recurrence group and reduced in the recurrence-free survival group (<i>p</i> = 0.038, <i>p</i> = 0.032). Severe IPP independently increased the risk of intravesical recurrence by 2.6 times. The addition of IPP to the known oncological risk factors in the prediction model using the ML algorithm improved the predictability of cancer recurrence by approximately 6%, to 0.803. IPP was analyzed as a potential independent risk factor for NMIBC recurrence and progression after TURBT. This anatomical feature of the prostate could affect the recurrence of bladder tumors.",0,0
1214,"Machine-Learning Points at Endoscopic, Quality of Life, and Olfactory Parameters as Outcome Criteria for Endoscopic Paranasal Sinus Surgery in Chronic Rhinosinusitis. Chronic rhinosinusitis (CRS) is often treated by functional endoscopic paranasal sinus surgery, which improves endoscopic parameters and quality of life, while olfactory function was suggested as a further criterion of treatment success. In a prospective cohort study, 37 parameters from four categories were recorded from 60 men and 98 women before and four months after endoscopic sinus surgery, including endoscopic measures of nasal anatomy/pathology, assessments of olfactory function, quality of life, and socio-demographic or concomitant conditions. Parameters containing relevant information about changes associated with surgery were examined using unsupervised and supervised methods, including machine-learning techniques for feature selection. The analyzed cohort included 52 men and 38 women. Changes in the endoscopic Lildholdt score allowed separation of baseline from postoperative data with a cross-validated accuracy of 85%. Further relevant information included primary nasal symptoms from SNOT-20 assessments, and self-assessments of olfactory function. Overall improvement in these relevant parameters was observed in 95% of patients. A ranked list of criteria was developed as a proposal to assess the outcome of functional endoscopic sinus surgery in CRS patients with nasal polyposis. Three different facets were captured, including the Lildholdt score as an endoscopic measure and, in addition, disease-specific quality of life and subjectively perceived olfactory function.",0,0
1216,"Machine Learning Prediction of Length of Stay in Adult Spinal Deformity Patients Undergoing Posterior Spine Fusion Surgery. (1) Background: Length of stay (LOS) is a commonly reported metric used to assess surgical success, patient outcomes, and economic impact. The focus of this study is to use a variety of machine learning algorithms to reliably predict whether a patient undergoing posterior spinal fusion surgery treatment for Adult Spine Deformity (ASD) will experience a prolonged LOS. (2) Methods: Patients undergoing treatment for ASD with posterior spinal fusion surgery were selected from the American College of Surgeon's NSQIP dataset. Prolonged LOS was defined as a LOS greater than or equal to 9 days. Data was analyzed with the Logistic Regression, Decision Tree, Random Forest, XGBoost, and Gradient Boosting functions in Python with the Sci-Kit learn package. Prediction accuracy and area under the curve (AUC) were calculated. (3) Results: 1281 posterior patients were analyzed. The five algorithms had prediction accuracies between 68% and 83% for posterior cases (AUC: 0.566-0.821). Multivariable regression indicated that increased Work Relative Value Units (RVU), elevated American Society of Anesthesiologists (ASA) class, and longer operating times were linked to longer LOS. (4) Conclusions: Machine learning algorithms can predict if patients will experience an increased LOS following ASD surgery. Therefore, medical resources can be more appropriately allocated towards patients who are at risk of prolonged LOS.",0,0
1217,"Identifying Lung Cancer Cell Markers with Machine Learning Methods and Single-Cell RNA-Seq Data. Non-small cell lung cancer is a major lethal subtype of epithelial lung cancer, with high morbidity and mortality. The single-cell sequencing technique plays a key role in exploring the pathogenesis of non-small cell lung cancer. We proposed a computational method for distinguishing cell subtypes from the different pathological regions of non-small cell lung cancer on the basis of transcriptomic profiles, including a group of qualitative classification criteria (biomarkers) and various rules. The random forest classifier reached a Matthew's correlation coefficient (MCC) of 0.922 by using 720 features, and the decision tree reached an MCC of 0.786 by using 1880 features. The obtained biomarkers and rules were analyzed in the end of this study.",0,0
1218,"Predicting Emotional Valence of People Living with the Human Immunodeficiency Virus Using Daily Voice Clips: A Preliminary Study. To detect depression in people living with the human immunodeficiency virus (PLHIV), this preliminary study developed an artificial intelligence (AI) model aimed at discriminating the emotional valence of PLHIV. Sixteen PLHIV recruited from the Taoyuan General Hospital, Ministry of Health and Welfare, participated in this study from 2019 to 2020. A self-developed mobile application (app) was installed on sixteen participants' mobile phones and recorded their daily voice clips and emotional valence values. After data preprocessing of the collected voice clips was conducted, an open-source software, openSMILE, was applied to extract 384 voice features. These features were then tested with statistical methods to screen critical modeling features. Several decision-tree models were built based on various data combinations to test the effectiveness of feature selection methods. The developed model performed very well for individuals who reported an adequate amount of data with widely distributed valence values. The effectiveness of feature selection methods, limitations of collected data, and future research were discussed.",0,0
1219,"The Feasibility of Using Machine Learning to Classify Calls to South African Emergency Dispatch Centres According to Prehospital Diagnosis, by Utilising Caller Descriptions of the Incident. This paper presents the application of machine learning for classifying time-critical conditions namely sepsis, myocardial infarction and cardiac arrest, based off transcriptions of emergency calls from emergency services dispatch centers in South Africa. In this study we present results from the application of four multi-class classification algorithms: Support Vector Machine (SVM), Logistic Regression, Random Forest and K-Nearest Neighbor (kNN). The application of machine learning for classifying time-critical diseases may allow for earlier identification, adequate telephonic triage, and quicker response times of the appropriate cadre of emergency care personnel. The data set consisted of an original data set of 93 examples which was further expanded through the use of data augmentation. Two feature extraction techniques were investigated namely; TF-IDF and handcrafted features. The results were further improved using hyper-parameter tuning and feature selection. In our work, within the limitations of a limited data set, classification results yielded an accuracy of up to 100% when training with 10-fold cross validation, and 95% accuracy when predicted on unseen data. The results are encouraging and show that automated diagnosis based on emergency dispatch centre transcriptions is feasible. When implemented in real time, this can have multiple utilities, e.g. enabling the call-takers to take the right action with the right priority.",0,0
1220,"Detection of COVID-19 Patients from CT Scan and Chest X-ray Data Using Modified <i>MobileNetV2</i> and <i>LIME</i>. The COVID-19 global pandemic caused by the widespread transmission of the novel coronavirus (SARS-CoV-2) has become one of modern history's most challenging issues from a healthcare perspective. At its dawn, still without a vaccine, contagion containment strategies remained most effective in preventing the disease's spread. Patient isolation has been primarily driven by the results of polymerase chain reaction (PCR) testing, but its initial reach was challenged by low availability and high cost, especially in developing countries. As a means of taking advantage of a preexisting infrastructure for respiratory disease diagnosis, researchers have proposed COVID-19 patient screening based on the results of Chest Computerized Tomography (CT) and Chest Radiographs (X-ray). When paired with artificial-intelligence- and deep-learning-based approaches for analysis, early studies have achieved a comparatively high accuracy in diagnosing the disease. Considering the opportunity to further explore these methods, we implement six different Deep Convolutional Neural Networks (Deep CNN) models-VGG16, MobileNetV2, InceptionResNetV2, ResNet50, ResNet101, and VGG19-and use a mixed dataset of CT and X-ray images to classify COVID-19 patients. Preliminary results showed that a modified MobileNetV2 model performs best with an accuracy of 95 Â± 1.12% (AUC = 0.816). Notably, a high performance was also observed for the VGG16 model, outperforming several previously proposed models with an accuracy of 98.5 Â± 1.19% on the X-ray dataset. Our findings are supported by recent works in the academic literature, which also uphold the higher performance of MobileNetV2 when X-ray, CT, and their mixed datasets are considered. Lastly, we further explain the process of feature extraction using Local Interpretable Model-Agnostic Explanations (LIME), which contributes to a better understanding of what features in CT/X-ray images characterize the onset of COVID-19.",0,0
1228,"The Importance of Close Follow-Up in Patients with Early-Grade Diabetic Retinopathy: A Taiwan Population-Based Study Grading via Deep Learning Model. (1) Background: Diabetic retinopathy (DR) can cause blindness. Current guidelines on diabetic eye care recommend more frequent eye examinations for more severe DR to prevent deterioration. However, close follow-up and early intervention at earlier stages are important for the prevention of disease progression of other diabetes mellitus (DM) complications. The study was designed to investigate the association between different stages of DR in type 2 DM patients and the progression of DR; (2) Methods: A total of 2623 type 2 DM patients were included in this study. In these patients, a total of 14,409 fundus color photographs was obtained. The primary outcome was the progression of DR; (3) Results: The progression of DR was highly associated with the initial grade of DR (<i>p</i> < 0.001). Severe nonproliferative diabetic retinopathy (NPDR) was the most likely to progress to proliferative diabetic retinopathy (PDR), followed by moderate NPDR, mild NPDR, and no retinopathy. However, progression to the next stage of DR showed a different trend. We used no retinopathy as a reference. Mild NPDR showed the highest risk for progression to the next stage [hazard ratio (HR): 2.00 (95% conference interval (CI): 1.72-2.32)] relative to higher initial grades [HR (moderate NPDR): 1.82 (95% CI: 1.58-2.09) and HR (severe NPDR): 0.87 (95% CI: 0.69-1.09)]. The same trend was observed in the multivariate analysis, in which mild NPDR presented the highest risk for progression to the next stage (adjusted HR (mild NPDR): 1.95 (95% CI: 1.68-2.27), adjusted HR (moderate NPDR): 1.73 (95% CI: 1.50-1.99), and adjusted HR (severe NPDR): 0.82 (95% CI: 0.65-1.03)); (4) Conclusions: Type 2 diabetic patients with earlier-grade DR appeared to exhibit more rapid development to the next grade in our study. As these findings show, more frequent fundus color photography follow-up in earlier-grade DR patients is important to slow DR progression and awaken self-perception.",0,0
1236,"A Deep Learning Based Approach for Patient Pulmonary CT Image Screening to Predict Coronavirus (SARS-CoV-2) Infection. The novel coronavirus (nCoV-2019) is responsible for the acute respiratory disease in humans known as COVID-19. This infection was found in the Wuhan and Hubei provinces of China in the month of December 2019, after which it spread all over the world. By March, 2020, this epidemic had spread to about 117 countries and its different variants continue to disturb human life all over the world, causing great damage to the economy. Through this paper, we have attempted to identify and predict the novel coronavirus from influenza-A viral cases and healthy patients without infection through applying deep learning technology over patient pulmonary computed tomography (CT) images, as well as by the model that has been evaluated. The CT image data used under this method has been collected from various radiopedia data from online sources with a total of 548 CT images, of which 232 are from 12 patients infected with COVID-19, 186 from 17 patients with influenza A virus, and 130 are from 15 healthy candidates without infection. From the results of examination of the reference data determined from the point of view of CT imaging cases in general, the accuracy of the proposed model is 79.39%. Thus, this deep learning model will help in establishing early screening of COVID-19 patients and thus prove to be an analytically robust method for clinical experts.",0,0
1237,"Object or Background: An Interpretable Deep Learning Model for COVID-19 Detection from CT-Scan Images. The new strains of the pandemic COVID-19 are still looming. It is important to develop multiple approaches for timely and accurate detection of COVID-19 and its variants. Deep learning techniques are well proved for their efficiency in providing solutions to many social and economic problems. However, the transparency of the reasoning process of a deep learning model related to a high stake decision is a necessity. In this work, we propose an interpretable deep learning model Ps-ProtoPNet to detect COVID-19 from the medical images. Ps-ProtoPNet classifies the images by recognizing the objects rather than their background in the images. We demonstrate our model on the dataset of the chest CT-scan images. The highest accuracy that our model achieves is 99.29%.",0,0
1238,"The TVGH-NYCU Thal-Classifier: Development of a Machine-Learning Classifier for Differentiating Thalassemia and Non-Thalassemia Patients. Thalassemia and iron deficiency are the most common etiologies for microcytic anemia and there are indices discriminating both from common laboratory simple automatic counters. In this study a new classifier for discriminating thalassemia and non-thalassemia microcytic anemia was generated via combination of exciting indices with machine-learning techniques. A total of 350 Taiwanese adult patients whose anemia diagnosis, complete blood cell counts, and hemoglobin gene profiles were retrospectively reviewed. Thirteen prior established indices were applied to current cohort and the sensitivity, specificity, positive and negative predictive values were calculated. A support vector machine (SVM) with Monte-Carlo cross-validation procedure was adopted to generate the classifier. The performance of our classifier was compared with original indices by calculating the average classification error rate and area under the curve (AUC) for the sampled datasets. The performance of this SVM model showed average AUC of 0.76 and average error rate of 0.26, which surpassed all other indices. In conclusion, we developed a convenient tool for primary-care physicians when deferential diagnosis contains thalassemia for the Taiwanese adult population. This approach needs to be validated in other studies or bigger database.",0,0
1241,"Comparison of Different Machine Learning Classifiers for Glaucoma Diagnosis Based on Spectralis OCT. Early detection is important in glaucoma management. By using optical coherence tomography (OCT), the subtle structural changes caused by glaucoma can be detected. Though OCT provided abundant parameters for comprehensive information, clinicians may be confused once the results conflict. Machine learning classifiers (MLCs) are good tools for considering numerous parameters and generating reliable diagnoses in glaucoma practice. Here we aim to compare different MLCs based on Spectralis OCT parameters, including circumpapillary retinal nerve fiber layer (cRNFL) thickness, Bruch's membrane opening-minimum rim width (BMO-MRW), Early Treatment Diabetes Retinopathy Study (ETDRS) macular thickness, and posterior pole asymmetry analysis (PPAA), in discriminating normal from glaucomatous eyes. Five MLCs were proposed, namely conditional inference trees (CIT), logistic model tree (LMT), C5.0 decision tree, random forest (RF), and extreme gradient boosting (XGBoost). Logistic regression (LGR) was used as a benchmark for comparison. RF was shown to be the best model. Ganglion cell layer measurements were the most important predictors in early glaucoma detection and cRNFL measurements were more important as the glaucoma severity increased. The global, temporal, inferior, superotemporal, and inferotemporal sites were relatively influential locations among all parameters. Clinicians should cautiously integrate the Spectralis OCT results into the entire clinical picture when diagnosing glaucoma.",0,0
1242,"Diagnosis of Diabetes Mellitus Using Gradient Boosting Machine (LightGBM). Diabetes mellitus (DM) is a severe chronic disease that affects human health and has a high prevalence worldwide. Research has shown that half of the diabetic people throughout the world are unaware that they have DM and its complications are increasing, which presents new research challenges and opportunities. In this paper, we propose a preemptive diagnosis method for diabetes mellitus (DM) to assist or complement the early recognition of the disease in countries with low medical expert densities. Diabetes data are collected from the Zewditu Memorial Hospital (ZMHDD) in Addis Ababa, Ethiopia. Light Gradient Boosting Machine (LightGBM) is one of the most recent successful research findings for the gradient boosting framework that uses tree-based learning algorithms. It has low computational complexity and, therefore, is suited for applications in limited capacity regions such as Ethiopia. Thus, in this study, we apply the principle of LightGBM to develop an accurate model for the diagnosis of diabetes. The experimental results show that the prepared diabetes dataset is informative to predict the condition of diabetes mellitus. With accuracy, AUC, sensitivity, and specificity of 98.1%, 98.1%, 99.9%, and 96.3%, respectively, the LightGBM model outperformed KNN, SVM, NB, Bagging, RF, and XGBoost in the case of the ZMHDD dataset.",0,0
1243,"CSGBBNet: An Explainable Deep Learning Framework for COVID-19 Detection. The COVID-19 virus has swept the world and brought great impact to various fields, gaining wide attention from all walks of life since the end of 2019. At present, although the global epidemic situation is leveling off and vaccine doses have been administered in a large amount, confirmed cases are still emerging around the world. To make up for the missed diagnosis caused by the uncertainty of nucleic acid polymerase chain reaction (PCR) test, utilizing lung CT examination as a combined detection method to improve the diagnostic rate becomes a necessity. Our research considered the time-consuming and labor-intensive characteristics of the traditional CT analyzing process, and developed an efficient deep learning framework named CSGBBNet to solve the binary classification task of COVID-19 images based on a COVID-Seg model for image preprocessing and a GBBNet for classification. The five runs with random seed on the test set showed our novel framework can rapidly analyze CT scan images and give out effective results for assisting COVID-19 detection, with the mean accuracy of 98.49 Â± 1.23%, the sensitivity of 99.00 Â± 2.00%, the specificity of 97.95 Â± 2.51%, the precision of 98.10 Â± 2.61%, and the F1 score of 98.51 Â± 1.22%. Moreover, our model CSGBBNet performs better when compared with seven previous state-of-the-art methods. In this research, the aim is to link together biomedical research and artificial intelligence and provide some insights into the field of COVID-19 detection.",0,0
1244,"The Reproducibility of Deep Learning-Based Segmentation of the Prostate Gland and Zones on T2-Weighted MR Images. Volume of interest segmentation is an essential step in computer-aided detection and diagnosis (CAD) systems. Deep learning (DL)-based methods provide good performance for prostate segmentation, but little is known about the reproducibility of these methods. In this work, an in-house collected dataset from 244 patients was used to investigate the intra-patient reproducibility of 14 shape features for DL-based segmentation methods of the whole prostate gland (WP), peripheral zone (PZ), and the remaining prostate zones (non-PZ) on T2-weighted (T2W) magnetic resonance (MR) images compared to manual segmentations. The DL-based segmentation was performed using three different convolutional neural networks (CNNs): V-Net, nnU-Net-2D, and nnU-Net-3D. The two-way random, single score intra-class correlation coefficient (ICC) was used to measure the inter-scan reproducibility of each feature for each CNN and the manual segmentation. We found that the reproducibility of the investigated methods is comparable to manual for all CNNs (14/14 features), except for V-Net in PZ (7/14 features). The ICC score for segmentation volume was found to be 0.888, 0.607, 0.819, and 0.903 in PZ; 0.988, 0.967, 0.986, and 0.983 in non-PZ; 0.982, 0.975, 0.973, and 0.984 in WP for manual, V-Net, nnU-Net-2D, and nnU-Net-3D, respectively. The results of this work show the feasibility of embedding DL-based segmentation in CAD systems, based on multiple T2W MR scans of the prostate, which is an important step towards the clinical implementation.",1,1
1245,"Radiomics and Machine Learning Can Differentiate Transient Osteoporosis from Avascular Necrosis of the Hip. Differentiation between transient osteoporosis (TOH) and avascular necrosis (AVN) of the hip is a longstanding challenge in musculoskeletal radiology. The purpose of this study was to utilize MRI-based radiomics and machine learning (ML) for accurate differentiation between the two entities. A total of 109 hips with TOH and 104 hips with AVN were retrospectively included. Femoral heads and necks with segmented radiomics features were extracted. Three ML classifiers (XGboost, CatBoost and SVM) using 38 relevant radiomics features were trained on 70% and validated on 30% of the dataset. ML performance was compared to two musculoskeletal radiologists, a general radiologist and two radiology residents. XGboost achieved the best performance with an area under the curve (AUC) of 93.7% (95% CI from 87.7 to 99.8%) among ML models. MSK radiologists achieved an AUC of 90.6% (95% CI from 86.7% to 94.5%) and 88.3% (95% CI from 84% to 92.7%), respectively, similar to residents. The general radiologist achieved an AUC of 84.5% (95% CI from 80% to 89%), significantly lower than of XGboost (<i>p</i> = 0.017). In conclusion, radiomics-based ML achieved a performance similar to MSK radiologists and significantly higher compared to general radiologists in differentiating between TOH and AVN.",1,1
1246,"Potential of Rule-Based Methods and Deep Learning Architectures for ECG Diagnostics. The main objective of this study is to propose relatively simple techniques for the automatic diagnosis of electrocardiogram (ECG) signals based on a classical rule-based method and a convolutional deep learning architecture. The validation task was performed in the framework of the PhysioNet/Computing in Cardiology Challenge 2020, where seven databases consisting of 66,361 recordings with 12-lead ECGs were considered for training, validation and test sets. A total of 24 different diagnostic classes are considered in the entire training set. The rule-based method uses morphological and time-frequency ECG descriptors that are defined for each diagnostic label. These rules are extracted from the knowledge base of a cardiologist or from a textbook, with no direct learning procedure in the first phase, whereas a refinement was tested in the second phase. The deep learning method considers both raw ECG and median beat signals. These data are processed via continuous wavelet transform analysis, obtaining a time-frequency domain representation, with the generation of specific images (ECG scalograms). These images are then used for the training of a convolutional neural network based on GoogLeNet topology for ECG diagnostic classification. Cross-validation evaluation was performed for testing purposes. A total of 217 teams submitted 1395 algorithms during the Challenge. The diagnostic accuracy of our algorithm produced a challenge validation score of 0.325 (CPU time = 35 min) for the rule-based method, and a 0.426 (CPU time = 1664 min) for the deep learning method, which resulted in our team attaining 12th place in the competition.",0,0
1247,"A Personalized Medical Decision Support System Based on Explainable Machine Learning Algorithms and ECC Features: Data from the Real World. Artificial intelligence can help physicians improve the accuracy of breast cancer diagnosis. However, the effectiveness of AI applications is limited by doctors' adoption of the results recommended by the personalized medical decision support system. Our primary purpose is to study the impact of external case characteristics (ECC) on the effectiveness of the personalized medical decision support system for breast cancer assisted diagnosis (PMDSS-BCAD) in making accurate recommendations. Therefore, we designed a novel comprehensive framework for case-based reasoning (CBR) that takes the impact of external features of cases into account, made use of the naive Bayes and k-nearest neighbor (KNN) algorithms (CBR-ECC), and developed a PMDSS-BCAD system by using the CBR-ECC model and external features as system components. Under the new case-based reasoning framework, the accuracy of the combined model of naive Bayes and KNN with an optimal K value of 2 is 99.40%. Moreover, in a real hospital scenario, users rated the PMDSS-BCAD system, which takes into account the external characteristics of the case, better than the original personalized system. These results suggest that PMDSS-BCD can not only provide doctors with more personalized and accurate results for auxiliary diagnosis, but also improve doctors' trust in the results, so as to encourage doctors to adopt the results recommended by the personalized system.",0,0
1248,"Convolutional Neural Networks for Classifying Laterality of Vestibular Schwannomas on Single MRI Slices-A Feasibility Study. <b>Introduction</b>: Many proposed algorithms for tumor detection rely on 2.5/3D convolutional neural networks (CNNs) and the input of segmentations for training. The purpose of this study is therefore to assess the performance of tumor detection on single MRI slices containing vestibular schwannomas (VS) as a computationally inexpensive alternative that does not require the creation of segmentations. <b>Methods</b>: A total of 2992 T1-weighted contrast-enhanced axial slices containing VS from the MRIs of 633 patients were labeled according to tumor location, of which 2538 slices from 539 patients were used for training a CNN (ResNet-34) to classify them according to the side of the tumor as a surrogate for detection and 454 slices from 94 patients were used for internal validation. The model was then externally validated on contrast-enhanced and non-contrast-enhanced slices from a different institution. Categorical accuracy was noted, and the results of the predictions for the validation set are provided with confusion matrices. <b>Results</b>: The model achieved an accuracy of 0.928 (95% CI: 0.869-0.987) on contrast-enhanced slices and 0.795 (95% CI: 0.702-0.888) on non-contrast-enhanced slices from the external validation cohorts. The implementation of Gradient-weighted Class Activation Mapping (Grad-CAM) revealed that the focus of the model was not limited to the contrast-enhancing tumor but to a larger area of the cerebellum and the cerebellopontine angle. <b>Conclusions</b>: Single-slice predictions might constitute a computationally inexpensive alternative to training 2.5/3D-CNNs for certain detection tasks in medical imaging even without the use of segmentations. Head-to-head comparisons between 2D and more sophisticated architectures could help to determine the difference in accuracy, especially for more difficult tasks.",0,0
1249,"Deep Learning for Caries Detection and Classification. Deep learning methods have achieved impressive diagnostic performance in the field of radiology. The current study aimed to use deep learning methods to detect caries lesions, classify different radiographic extensions on panoramic films, and compare the classification results with those of expert dentists.",1,1
1250,"Artificial Intelligence Model to Detect Real Contact Relationship between Mandibular Third Molars and Inferior Alveolar Nerve Based on Panoramic Radiographs. This study aimed to develop a novel detection model for automatically assessing the real contact relationship between mandibular third molars (MM3s) and the inferior alveolar nerve (IAN) based on panoramic radiographs processed with deep learning networks, minimizing pseudo-contact interference and reducing the frequency of cone beam computed tomography (CBCT) use. A deep-learning network approach based on YOLOv4, named as MM3-IANnet, was applied to oral panoramic radiographs for the first time. The relationship between MM3s and the IAN in CBCT was considered the real contact relationship. Accuracy metrics were calculated to evaluate and compare the performance of the MM3-IANnet, dentists and a cooperative approach with dentists and the MM3-IANnet. Our results showed that in comparison with detection by dentists (AP = 76.45%) or the MM3-IANnet (AP = 83.02%), the cooperative dentist-MM3-IANnet approach yielded the highest average precision (AP = 88.06%). In conclusion, the MM3-IANnet detection model is an encouraging artificial intelligence approach that might assist dentists in detecting the real contact relationship between MM3s and IANs based on panoramic radiographs.",1,1
1251,"Machine Learning-Based Definition of Symptom Clusters and Selection of Antidepressants for Depressive Syndrome. The current polythetic and operational criteria for major depression inevitably contribute to the heterogeneity of depressive syndromes. The heterogeneity of depressive syndrome has been criticized using the concept of language game in Wittgensteinian philosophy. Moreover, ""a symptom- or endophenotype-based approach, rather than a diagnosis-based approach, has been proposed"" as the ""next-generation treatment for mental disorders"" by Thomas Insel. Understanding the heterogeneity renders promise for personalized medicine to treat cases of depressive syndrome, in terms of both defining symptom clusters and selecting antidepressants. Machine learning algorithms have emerged as a tool for personalized medicine by handling clinical big data that can be used as predictors for subtype classification and treatment outcome prediction. The large clinical cohort data from the Sequenced Treatment Alternatives to Relieve Depression (STAR*D), Combining Medications to Enhance Depression Outcome (CO-MED), and the German Research Network on Depression (GRND) have recently began to be acknowledged as useful sources for machine learning-based depression research with regard to cost effectiveness and generalizability. In addition, noninvasive biological tools such as functional and resting state magnetic resonance imaging techniques are widely combined with machine learning methods to detect intrinsic endophenotypes of depression. This review highlights recent studies that have used clinical cohort or brain imaging data and have addressed machine learning-based approaches to defining symptom clusters and selecting antidepressants. Potentially applicable suggestions to realize machine learning-based personalized medicine for depressive syndrome are also provided herein.",0,0
1252,"Automated Final Lesion Segmentation in Posterior Circulation Acute Ischemic Stroke Using Deep Learning. Final lesion volume (FLV) is a surrogate outcome measure in anterior circulation stroke (ACS). In posterior circulation stroke (PCS), this relation is plausibly understudied due to a lack of methods that automatically quantify FLV. The applicability of deep learning approaches to PCS is limited due to its lower incidence compared to ACS. We evaluated strategies to develop a convolutional neural network (CNN) for PCS lesion segmentation by using image data from both ACS and PCS patients. We included follow-up non-contrast computed tomography scans of 1018 patients with ACS and 107 patients with PCS. To assess whether an ACS lesion segmentation generalizes to PCS, a CNN was trained on ACS data (ACS-CNN). Second, to evaluate the performance of only including PCS patients, a CNN was trained on PCS data. Third, to evaluate the performance when combining the datasets, a CNN was trained on both datasets. Finally, to evaluate the performance of transfer learning, the ACS-CNN was fine-tuned using PCS patients. The transfer learning strategy outperformed the other strategies in volume agreement with an intra-class correlation of 0.88 (95% CI: 0.83-0.92) vs. 0.55 to 0.83 and a lesion detection rate of 87% vs. 41-77 for the other strategies. Hence, transfer learning improved the FLV quantification and detection rate of PCS lesions compared to the other strategies.",0,0
1253,"Using Machine Learning Algorithms to Predict Hospital Acquired Thrombocytopenia after Operation in the Intensive Care Unit: A Retrospective Cohort Study. Hospital acquired thrombocytopenia (HAT) is a common hematological complication after surgery. This research aimed to develop and compare the performance of seven machine learning (ML) algorithms for predicting patients that are at risk of HAT after surgery. We conducted a retrospective cohort study which enrolled adult patients transferred to the intensive care unit (ICU) after surgery in West China Hospital of Sichuan University from January 2016 to December 2018. All subjects were randomly divided into a derivation set (70%) and test set (30%). ten-fold cross-validation was used to estimate the hyperparameters of ML algorithms during the training process in the derivation set. After ML models were developed, the sensitivity, specificity, area under the curve (AUC), and net benefit (decision analysis curve, DCA) were calculated to evaluate the performances of ML models in the test set. A total of 10,369 patients were included and in 1354 (13.1%) HAT occurred. The AUC of all seven ML models exceeded 0.7, the two highest were Gradient Boosting (GB) (0.834, 0.814-0.853, <i>p</i> < 0.001) and Random Forest (RF) (0.828, 0.807-0.848, <i>p</i> < 0.001). There was no difference between GB and RF (0.834 vs. 0.828, <i>p</i> = 0.293); however, these two were better than the remaining five models (<i>p</i> < 0.001). The DCA revealed that all ML models had high net benefits with a threshold probability approximately less than 0.6. In conclusion, we found that ML models constructed by multiple preoperative variables can predict HAT in patients transferred to ICU after surgery, which can improve risk stratification and guide management in clinical practice.",0,0
1254,"A Low-Dose CT-Based Radiomic Model to Improve Characterization and Screening Recall Intervals of Indeterminate Prevalent Pulmonary Nodules. Lung cancer (LC) is currently one of the main causes of cancer-related deaths worldwide. Low-dose computed tomography (LDCT) of the chest has been proven effective in secondary prevention (i.e., early detection) of LC by several trials. In this work, we investigated the potential impact of radiomics on indeterminate prevalent pulmonary nodule (PN) characterization and risk stratification in subjects undergoing LDCT-based LC screening. As a proof-of-concept for radiomic analyses, the first aim of our study was to assess whether indeterminate PNs could be automatically classified by an LDCT radiomic classifier as solid or sub-solid (first-level classification), and in particular for sub-solid lesions, as non-solid versus part-solid (second-level classification). The second aim of the study was to assess whether an LCDT radiomic classifier could automatically predict PN risk of malignancy, and thus optimize LDCT recall timing in screening programs. Model performance was evaluated using the area under the receiver operating characteristic curve (AUC), accuracy, positive predictive value, negative predictive value, sensitivity, and specificity. The experimental results showed that an LDCT radiomic machine learning classifier can achieve excellent performance for characterization of screen-detected PNs (mean AUC of 0.89 Â± 0.02 and 0.80 Â± 0.18 on the blinded test dataset for the first-level and second-level classifiers, respectively), providing quantitative information to support clinical management. Our study showed that a radiomic classifier could be used to optimize LDCT recall for indeterminate PNs. According to the performance of such a classifier on the blinded test dataset, within the first 6 months, 46% of the malignant PNs and 38% of the benign ones were identified, improving early detection of LC by doubling the current detection rate of malignant nodules from 23% to 46% at a low cost of false positives. In conclusion, we showed the high potential of LDCT-based radiomics for improving the characterization and optimizing screening recall intervals of indeterminate PNs.",0,0
1255,"Automatized Detection and Categorization of Fissure Sealants from Intraoral Digital Photographs Using Artificial Intelligence. The aim of the present study was to investigate the diagnostic performance of a trained convolutional neural network (CNN) for detecting and categorizing fissure sealants from intraoral photographs using the expert standard as reference. An image set consisting of 2352 digital photographs from permanent posterior teeth (461 unsealed tooth surfaces/1891 sealed surfaces) was divided into a training set (<i>n</i> = 1881/364/1517) and a test set (<i>n</i> = 471/97/374). All the images were scored according to the following categories: unsealed molar, intact, sufficient and insufficient sealant. Expert diagnoses served as the reference standard for cyclic training and repeated evaluation of the CNN (ResNeXt-101-32x8d), which was trained by using image augmentation and transfer learning. A statistical analysis was performed, including the calculation of contingency tables and areas under the receiver operating characteristic curve (AUC). The results showed that the CNN accurately detected sealants in 98.7% of all the test images, corresponding to an AUC of 0.996. The diagnostic accuracy and AUC were 89.6% and 0.951, respectively, for intact sealant; 83.2% and 0.888, respectively, for sufficient sealant; 92.4 and 0.942, respectively, for insufficient sealant. On the basis of the documented results, it was concluded that good agreement with the reference standard could be achieved for automatized sealant detection by using artificial intelligence methods. Nevertheless, further research is necessary to improve the model performance.",0,0
1257,"Recognition Rate Advancement and Data Error Improvement of Pathology Cutting with H-DenseUNet for Hepatocellular Carcinoma Image. Due to the fact that previous studies have rarely investigated the recognition rate discrepancy and pathology data error when applied to different databases, the purpose of this study is to investigate the improvement of recognition rate via deep learning-based liver lesion segmentation with the incorporation of hospital data. The recognition model used in this study is H-DenseUNet, which is applied to the segmentation of the liver and lesions, and a mixture of 2D/3D Hybrid-DenseUNet is used to reduce the recognition time and system memory requirements. Differences in recognition results were determined by comparing the training files of the standard LiTS competition data set with the training set after mixing in an additional 30 patients. The average error value of 9.6% was obtained by comparing the data discrepancy between the actual pathology data and the pathology data after the analysis of the identified images imported from Kaohsiung Chang Gung Memorial Hospital. The average error rate of the recognition output after mixing the LiTS database with hospital data for training was 1%. In the recognition part, the Dice coefficient was 0.52 after training 50 epochs using the standard LiTS database, while the Dice coefficient was increased to 0.61 after adding 30 hospital data to the training. After importing 3D Slice and ITK-Snap software, a 3D image of the lesion and liver segmentation can be developed. It is hoped that this method could be used to stimulate more research in addition to the general public standard database in the future, as well as to study the applicability of hospital data and improve the generality of the database.",0,0
1258,"Brain Tumor Detection and Classification on MR Images by a Deep Wavelet Auto-Encoder Model. The process of diagnosing brain tumors is very complicated for many reasons, including the brain's synaptic structure, size, and shape. Machine learning techniques are employed to help doctors to detect brain tumor and support their decisions. In recent years, deep learning techniques have made a great achievement in medical image analysis. This paper proposed a deep wavelet autoencoder model named ""DWAE model"", employed to divide input data slice as a tumor (abnormal) or no tumor (normal). This article used a high pass filter to show the heterogeneity of the MRI images and their integration with the input images. A high median filter was utilized to merge slices. We improved the output slices' quality through highlight edges and smoothened input MR brain images. Then, we applied the seed growing method based on 4-connected since the thresholding cluster equal pixels with input MR data. The segmented MR image slices provide two two-layer using the proposed deep wavelet auto-encoder model. We then used 200 hidden units in the first layer and 400 hidden units in the second layer. The softmax layer testing and training are performed for the identification of the MR image normal and abnormal. The contribution of the deep wavelet auto-encoder model is in the analysis of pixel pattern of MR brain image and the ability to detect and classify the tumor with high accuracy, short time, and low loss validation. To train and test the overall performance of the proposed model, we utilized 2500 MR brain images from BRATS2012, BRATS2013, BRATS2014, BRATS2015, 2015 challenge, and ISLES, which consists of normal and abnormal images. The experiments results show that the proposed model achieved an accuracy of 99.3%, loss validation of 0.1, low FPR and FNR values. This result demonstrates that the proposed DWAE model can facilitate the automatic detection of brain tumors.",0,0
1259,"Mortality Prediction Utilizing Blood Biomarkers to Predict the Severity of COVID-19 Using Machine Learning Technique. Healthcare researchers have been working on mortality prediction for COVID-19 patients with differing levels of severity. A rapid and reliable clinical evaluation of disease intensity will assist in the allocation and prioritization of mortality mitigation resources. The novelty of the work proposed in this paper is an early prediction model of high mortality risk for both COVID-19 and non-COVID-19 patients, which provides state-of-the-art performance, in an external validation cohort from a different population. Retrospective research was performed on two separate hospital datasets from two different countries for model development and validation. In the first dataset, COVID-19 and non-COVID-19 patients were admitted to the emergency department in Boston (24 March 2020 to 30 April 2020), and in the second dataset, 375 COVID-19 patients were admitted to Tongji Hospital in China (10 January 2020 to 18 February 2020). The key parameters to predict the risk of mortality for COVID-19 and non-COVID-19 patients were identified and a nomogram-based scoring technique was developed using the top-ranked five parameters. Age, Lymphocyte count, D-dimer, CRP, and Creatinine (ALDCC), information acquired at hospital admission, were identified by the logistic regression model as the primary predictors of hospital death. For the development cohort, and internal and external validation cohorts, the area under the curves (AUCs) were 0.987, 0.999, and 0.992, respectively. All the patients are categorized into three groups using ALDCC score and death probability: Low (probability < 5%), Moderate (5% < probability < 50%), and High (probability > 50%) risk groups. The prognostic model, nomogram, and ALDCC score will be able to assist in the early identification of both COVID-19 and non-COVID-19 patients with high mortality risk, helping physicians to improve patient management.",0,0
1261,"Deep Learning-Based Prediction of Paresthesia after Third Molar Extraction: A Preliminary Study. The purpose of this study was to determine whether convolutional neural networks (CNNs) can predict paresthesia of the inferior alveolar nerve using panoramic radiographic images before extraction of the mandibular third molar. The dataset consisted of a total of 300 preoperative panoramic radiographic images of patients who had planned mandibular third molar extraction. A total of 100 images taken of patients who had paresthesia after tooth extraction were classified as Group 1, and 200 images taken of patients without paresthesia were classified as Group 2. The dataset was randomly divided into a training and validation set (n = 150 [50%]), and a test set (n = 150 [50%]). CNNs of SSD300 and ResNet-18 were used for deep learning. The average accuracy, sensitivity, specificity, and area under the curve were 0.827, 0.84, 0.82, and 0.917, respectively. This study revealed that CNNs can assist in the prediction of paresthesia of the inferior alveolar nerve after third molar extraction using panoramic radiographic images.",0,0
1263,"A Method for Detecting and Analyzing Facial Features of People with Drug Use Disorders. Drug use disorders caused by illicit drug use are significant contributors to the global burden of disease, and it is vital to conduct early detection of people with drug use disorders (PDUD). However, the primary care clinics and emergency departments lack simple and effective tools for screening PDUD. This study proposes a novel method to detect PDUD using facial images. Various experiments are designed to obtain the convolutional neural network (CNN) model by transfer learning based on a large-scale dataset (9870 images from PDUD and 19,567 images from GP (the general population)). Our results show that the model achieved 84.68%, 87.93%, and 83.01% in accuracy, sensitivity, and specificity in the dataset, respectively. To verify its effectiveness, the model is evaluated on external datasets based on real scenarios, and we found it still achieved high performance (accuracy > 83.69%, specificity > 90.10%, sensitivity > 80.00%). Our results also show differences between PDUD and GP in different facial areas. Compared with GP, the facial features of PDUD were mainly concentrated in the left cheek, right cheek, and nose areas (<i>p</i> < 0.001), which also reveals the potential relationship between mechanisms of drugs action and changes in facial tissues. This is the first study to apply the CNN model to screen PDUD in clinical practice and is also the first attempt to quantitatively analyze the facial features of PDUD. This model could be quickly integrated into the existing clinical workflow and medical care to provide capabilities.",0,0
1264,"Faster Region-Based Convolutional Neural Network in the Classification of Different Parkinsonism Patterns of the Striatum on Maximum Intensity Projection Images of [<sup>18</sup>F]FP-CIT Positron Emission Tomography. The aim of this study was to compare the performance of a deep-learning convolutional neural network (Faster R-CNN) model to detect imaging findings suggestive of idiopathic Parkinson's disease (PD) based on [<sup>18</sup>F]FP-CIT PET maximum intensity projection (MIP) images versus that of nuclear medicine (NM) physicians. The anteroposterior MIP images of the [<sup>18</sup>F]FP-CIT PET scan of 527 patients were classified as having PD (139 images) or non-PD (388 images) patterns according to the final diagnosis. Non-PD patterns were classified as overall-normal (ONL, 365 images) and vascular parkinsonism with definite defects or prominently decreased dopamine transporter binding (dVP, 23 images) patterns. Faster R-CNN was trained on 120 PD, 320 ONL, and 16 dVP pattern images and tested on the 19 PD, 45 ONL, and seven dVP patterns images. The performance of the Faster R-CNN and three NM physicians was assessed using receiver operating characteristics curve analysis. The difference in performance was assessed using Cochran's Q test, and the inter-rater reliability was calculated. Faster R-CNN showed high accuracy in differentiating PD from non-PD patterns and also from dVP patterns, with results comparable to those of NM physicians. There were no significant differences in the area under the curve and performance. The inter-rater reliability among Faster R-CNN and NM physicians showed substantial to almost perfect agreement. The deep-learning model accurately differentiated PD from non-PD patterns on MIP images of [<sup>18</sup>F]FP-CIT PET, and its performance was comparable to that of NM physicians.",1,1
1265,Classification of Cardiomyopathies from MR Cine Images Using Convolutional Neural Network with Transfer Learning. The automatic classification of various types of cardiomyopathies is desirable but has never been performed using a convolutional neural network (CNN). The purpose of this study was to evaluate currently available CNN models to classify cine magnetic resonance (cine-MR) images of cardiomyopathies.,0,0
1268,"Generating Virtual Short Tau Inversion Recovery (STIR) Images from T1- and T2-Weighted Images Using a Conditional Generative Adversarial Network in Spine Imaging. Short tau inversion recovery (STIR) sequences are frequently used in magnetic resonance imaging (MRI) of the spine. However, STIR sequences require a significant amount of scanning time. The purpose of the present study was to generate virtual STIR (vSTIR) images from non-contrast, non-fat-suppressed T1- and T2-weighted images using a conditional generative adversarial network (cGAN). The training dataset comprised 612 studies from 514 patients, and the validation dataset comprised 141 studies from 133 patients. For validation, 100 original STIR and respective vSTIR series were presented to six senior radiologists (blinded for the STIR type) in independent A/B-testing sessions. Additionally, for 141 real or vSTIR sequences, the testers were required to produce a structured report of 15 different findings. In the A/B-test, most testers could not reliably identify the real STIR (mean error of tester 1-6: 41%; 44%; 58%; 48%; 39%; 45%). In the evaluation of the structured reports, vSTIR was equivalent to real STIR in 13 of 15 categories. In the category of the number of STIR hyperintense vertebral bodies (<i>p</i> = 0.08) and in the diagnosis of bone metastases (<i>p</i> = 0.055), the vSTIR was only slightly insignificantly equivalent. By virtually generating STIR images of diagnostic quality from T1- and T2-weighted images using a cGAN, one can shorten examination times and increase throughput.",1,1
1269,"Automatic Liver Viability Scoring with Deep Learning and Hyperspectral Imaging. Hyperspectral imaging (HSI) is a non-invasive imaging modality already applied to evaluate hepatic oxygenation and to discriminate different models of hepatic ischemia. Nevertheless, the ability of HSI to detect and predict the reperfusion damage intraoperatively was not yet assessed. Hypoxia caused by hepatic artery occlusion (HAO) in the liver brings about dreadful vascular complications known as ischemia-reperfusion injury (IRI). Here, we show the evaluation of liver viability in an HAO model with an artificial intelligence-based analysis of HSI. We have combined the potential of HSI to extract quantitative optical tissue properties with a deep learning-based model using convolutional neural networks. The artificial intelligence (AI) score of liver viability showed a significant correlation with capillary lactate from the liver surface (r = -0.78, <i>p</i> = 0.0320) and Suzuki's score (r = -0.96, <i>p</i> = 0.0012). CD31 immunostaining confirmed the microvascular damage accordingly with the AI score. Our results ultimately show the potential of an HSI-AI-based analysis to predict liver viability, thereby prompting for intraoperative tool development to explore its application in a clinical setting.",0,0
1272,"Enhanced Directed Random Walk for the Identification of Breast Cancer Prognostic Markers from Multiclass Expression Data. Artificial intelligence in healthcare can potentially identify the probability of contracting a particular disease more accurately. There are five common molecular subtypes of breast cancer: luminal A, luminal B, basal, ERBB2, and normal-like. Previous investigations showed that pathway-based microarray analysis could help in the identification of prognostic markers from gene expressions. For example, directed random walk (DRW) can infer a greater reproducibility power of the pathway activity between two classes of samples with a higher classification accuracy. However, most of the existing methods (including DRW) ignored the characteristics of different cancer subtypes and considered all of the pathways to contribute equally to the analysis. Therefore, an enhanced DRW (eDRW+) is proposed to identify breast cancer prognostic markers from multiclass expression data. An improved weight strategy using one-way ANOVA (F-test) and pathway selection based on the greatest reproducibility power is proposed in eDRW+. The experimental results show that the eDRW+ exceeds other methods in terms of AUC. Besides this, the eDRW+ identifies 294 gene markers and 45 pathway markers from the breast cancer datasets with better AUC. Therefore, the prognostic markers (pathway markers and gene markers) can identify drug targets and look for cancer subtypes with clinically distinct outcomes.",0,0
1288,"ECG Signal Classification Using Deep Learning Techniques Based on the PTB-XL Dataset. The analysis and processing of ECG signals are a key approach in the diagnosis of cardiovascular diseases. The main field of work in this area is classification, which is increasingly supported by machine learning-based algorithms. In this work, a deep neural network was developed for the automatic classification of primary ECG signals. The research was carried out on the data contained in a PTB-XL database. Three neural network architectures were proposed: the first based on the convolutional network, the second on SincNet, and the third on the convolutional network, but with additional entropy-based features. The dataset was divided into training, validation, and test sets in proportions of 70%, 15%, and 15%, respectively. The studies were conducted for 2, 5, and 20 classes of disease entities. The convolutional network with entropy features obtained the best classification result. The convolutional network without entropy-based features obtained a slightly less successful result, but had the highest computational efficiency, due to the significantly lower number of neurons.",0,0
1300,"Glioblastoma Surgery Imaging-Reporting and Data System: Validation and Performance of the Automated Segmentation Task. For patients with presumed glioblastoma, essential tumor characteristics are determined from preoperative MR images to optimize the treatment strategy. This procedure is time-consuming and subjective, if performed by crude eyeballing or manually. The standardized GSI-RADS aims to provide neurosurgeons with automatic tumor segmentations to extract tumor features rapidly and objectively. In this study, we improved automatic tumor segmentation and compared the agreement with manual raters, describe the technical details of the different components of GSI-RADS, and determined their speed. Two recent neural network architectures were considered for the segmentation task: nnU-Net and AGU-Net. Two preprocessing schemes were introduced to investigate the tradeoff between performance and processing speed. A summarized description of the tumor feature extraction and standardized reporting process is included. The trained architectures for automatic segmentation and the code for computing the standardized report are distributed as open-source and as open-access software. Validation studies were performed on a dataset of 1594 gadolinium-enhanced T1-weighted MRI volumes from 13 hospitals and 293 T1-weighted MRI volumes from the BraTS challenge. The glioblastoma tumor core segmentation reached a Dice score slightly below 90%, a patientwise F1-score close to 99%, and a 95th percentile Hausdorff distance slightly below 4.0 mm on average with either architecture and the heavy preprocessing scheme. A patient MRI volume can be segmented in less than one minute, and a standardized report can be generated in up to five minutes. The proposed GSI-RADS software showed robust performance on a large collection of MRI volumes from various hospitals and generated results within a reasonable runtime.",0,0
1301,"Identifying New Potential Biomarkers in Adrenocortical Tumors Based on mRNA Expression Data Using Machine Learning. Adrenocortical carcinoma (ACC) is a rare disease, associated with poor survival. Several ""multiple-omics"" studies characterizing ACC on a molecular level identified two different clusters correlating with patient survival (C1A and C1B). We here used the publicly available transcriptome data from the TCGA-ACC dataset (<i>n</i> = 79), applying machine learning (ML) methods to classify the ACC based on expression pattern in an unbiased manner. UMAP (uniform manifold approximation and projection)-based clustering resulted in two distinct groups, ACC-UMAP1 and ACC-UMAP2, that largely overlap with clusters C1B and C1A, respectively. However, subsequent use of random-forest-based learning revealed a set of new possible marker genes showing significant differential expression in the described clusters (e.g., <i>SOAT1</i>, <i>EIF2A1</i>). For validation purposes, we used a secondary dataset based on a previous study from our group, consisting of 4 normal adrenal glands and 52 benign and 7 malignant tumor samples. The results largely confirmed those obtained for the TCGA-ACC cohort. In addition, the ENSAT dataset showed a correlation between benign adrenocortical tumors and the good prognosis ACC cluster ACC-UMAP1/C1B. In conclusion, the use of ML approaches re-identified and redefined known prognostic ACC subgroups. On the other hand, the subsequent use of random-forest-based learning identified new possible prognostic marker genes for ACC.",0,0
1302,The Impact of Tumor Edema on T2-Weighted 3T-MRI Invasive Breast Cancer Histological Characterization: A Pilot Radiomics Study. to evaluate the contribution of edema associated with histological features to the prediction of breast cancer (BC) prognosis using T2-weighted MRI radiomics.,0,0
1305,"Hyperspectral Imaging Combined with Artificial Intelligence in the Early Detection of Esophageal Cancer. This study uses hyperspectral imaging (HSI) and a deep learning diagnosis model that can identify the stage of esophageal cancer and mark the locations. This model simulates the spectrum data from the image using an algorithm developed in this study which is combined with deep learning for the classification and diagnosis of esophageal cancer using a single-shot multibox detector (SSD)-based identification system. Some 155 white-light endoscopic images and 153 narrow-band endoscopic images of esophageal cancer were used to evaluate the prediction model. The algorithm took 19 s to predict the results of 308 test images and the accuracy of the test results of the WLI and NBI esophageal cancer was 88 and 91%, respectively, when using the spectral data. Compared with RGB images, the accuracy of the WLI was 83% and the NBI was 86%. In this study, the accuracy of the WLI and NBI was increased by 5%, confirming that the prediction accuracy of the HSI detection method is significantly improved.",0,0
1306,"Deep Learning Based Automated Orthotopic Lung Tumor Segmentation in Whole-Body Mouse CT-Scans. Lung cancer is the leading cause of cancer related deaths worldwide. The development of orthotopic mouse models of lung cancer, which recapitulates the disease more realistically compared to the widely used subcutaneous tumor models, is expected to critically aid the development of novel therapies to battle lung cancer or related comorbidities such as cachexia. However, follow-up of tumor take, tumor growth and detection of therapeutic effects is difficult, time consuming and requires a vast number of animals in orthotopic models. Here, we describe a solution for the fully automatic segmentation and quantification of orthotopic lung tumor volume and mass in whole-body mouse computed tomography (CT) scans. The goal is to drastically enhance the efficiency of the research process by replacing time-consuming manual procedures with fast, automated ones. A deep learning algorithm was trained on 60 unique manually delineated lung tumors and evaluated by four-fold cross validation. Quantitative performance metrics demonstrated high accuracy and robustness of the deep learning algorithm for automated tumor volume analyses (mean dice similarity coefficient of 0.80), and superior processing time (69 times faster) compared to manual segmentation. Moreover, manual delineations of the tumor volume by three independent annotators was sensitive to bias in human interpretation while the algorithm was less vulnerable to bias. In addition, we showed that besides longitudinal quantification of tumor development, the deep learning algorithm can also be used in parallel with the previously published method for muscle mass quantification and to optimize the experimental design reducing the number of animals needed in preclinical studies. In conclusion, we implemented a method for fast and highly accurate tumor quantification with minimal operator involvement in data analysis. This deep learning algorithm provides a helpful tool for the noninvasive detection and analysis of tumor take, tumor growth and therapeutic effects in mouse orthotopic lung cancer models.",0,1
1307,"Machine Learning Incorporating Host Factors for Predicting Survival in Head and Neck Squamous Cell Carcinoma Patients. Prognostication for cancer patients is integral for patient counseling and treatment planning, yet providing accurate prediction can be challenging using existing patient-specific clinical indicators and host factors. In this work, we evaluated common machine learning models in predicting head and neck squamous cell carcinoma (HNSCC) patients' overall survival based on demographic, clinical features and host factors. We found random survival forest had best performance among the models evaluated, which achieved a C-index of 0.729 and AUROC of 0.792 in predicting two-year overall survival. In addition, we verified that host factors are independently predictive of HNSCC overall survival, which improved the C-index by a margin of 0.026 and the AUROC by 0.034. Due to the strong correlation among host factors, we showed that proper dimension reduction is an important step before their incorporation into the machine learning models, which provides a host factor score reflecting the patients' nutrition and inflammation status. The score by itself showed excellent discriminating capacity with the high-risk group having a hazard ratio of 3.76 (1.93-7.32, <i>p</i> < 0.0001) over the low-risk group. The hazard ratios were further improved to 7.41 (3.66-14.98, <i>p</i> < 0.0001) by the random survival forest model after including demographic and clinical features.",0,0
1309,"Deep-Learning Assessed Muscular Hypodensity Independently Predicts Mortality in DLBCL Patients Younger Than 60 Years. Muscle depletion (MD) assessed by computed tomography (CT) has been shown to be a predictive marker in solid tumors, but has not been assessed in non-Hodgkin's lymphomas. Despite software improvements, MD measurement remains highly time-consuming and cannot be used in clinical practice.",0,0
1315,"Artificial Intelligence-Assisted Identification of Genetic Factors Predisposing High-Risk Individuals to Asymptomatic Heart Failure. Heart failure (HF) is a global pandemic public health burden affecting one in five of the general population in their lifetime. For high-risk individuals, early detection and prediction of HF progression reduces hospitalizations, reduces mortality, improves the individual's quality of life, and reduces associated medical costs. In using an artificial intelligence (AI)-assisted genome-wide association study of a single nucleotide polymorphism (SNP) database from 117 asymptomatic high-risk individuals, we identified a SNP signature composed of 13 SNPs. These were annotated and mapped into six protein-coding genes (GAD2, APP, RASGEF1C, MACROD2, DMD, and DOCK1), a pseudogene (PGAM1P5), and various non-coding RNA genes (LINC01968, LINC00687, LOC105372209, LOC101928047, LOC105372208, and LOC105371356). The SNP signature was found to have a good performance when predicting HF progression, namely with an accuracy rate of 0.857 and an area under the curve of 0.912. Intriguingly, analysis of the protein connectivity map revealed that DMD, RASGEF1C, MACROD2, DOCK1, and PGAM1P5 appear to form a protein interaction network in the heart. This suggests that, together, they may contribute to the pathogenesis of HF. Our findings demonstrate that a combination of AI-assisted identifications of SNP signatures and clinical parameters are able to effectively identify asymptomatic high-risk subjects that are predisposed to HF.",0,0
1322,"An Automated In-Depth Feature Learning Algorithm for Breast Abnormality Prognosis and Robust Characterization from Mammography Images Using Deep Transfer Learning. Diagnosing breast cancer masses and calcification clusters have paramount significance in mammography, which aids in mitigating the disease's complexities and curing it at early stages. However, a wrong mammogram interpretation may lead to an unnecessary biopsy of the false-positive findings, which reduces the patient's survival chances. Consequently, approaches that learn to discern breast masses can reduce the number of misconceptions and incorrect diagnoses. Conventionally used classification models focus on feature extraction techniques specific to a particular problem based on domain information. Deep learning strategies are becoming promising alternatives to solve the many challenges of feature-based approaches.",0,0
1324,Identification of glaucoma from fundus images using deep learning techniques. Glaucoma is one of the preeminent causes of incurable visual disability and blindness across the world due to elevated intraocular pressure within the eyes. Accurate and timely diagnosis is essential for preventing visual disability. Manual detection of glaucoma is a challenging task that needs expertise and years of experience.,0,0
1325,Use of predictive models to identify patients who are likely to benefit from refraction at a follow-up visit after cataract surgery. To develop predictive models to identify cataract surgery patients who are more likely to benefit from refraction at a four-week postoperative exam.,0,0
1327,Deep significance clustering: a novel approach for identifying risk-stratified and predictive patient subgroups. Deep significance clustering (DICE) is a self-supervised learning framework. DICE identifies clinically similar and risk-stratified subgroups that neither unsupervised clustering algorithms nor supervised risk prediction algorithms alone are guaranteed to generate.,0,0
1334,"Cardiovascular risk and mortality prediction in patients suspected of sleep apnea: a model based on an artificial intelligence system. Cardiovascular disease (CVD) is one of the leading causes of death worldwide. There are many CVD risk estimators but very few take into account sleep features. Moreover, they are rarely tested on patients investigated for obstructive sleep apnea (OSA). However, numerous studies have demonstrated that OSA index or sleep features are associated with CVD and mortality. The aim of this study is to propose a new simple CVD and mortality risk estimator for use in routine sleep testing.",0,0
1336,"Outliers in clinical symptoms as preictal biomarkers. Previous findings have suggested that a preictal state might precede the epileptic seizure onset, which is the basis for seizure prediction attempts. Preictal states can be apprehended as outliers that differ from an interictal baseline and display clinical changes. We collected daily clinical scores from patients with epilepsy who underwent continuous video-EEG and assessed the ability of several outlier detection methods to identify preictal states. Results from 24 patients suggested that outlying clinical features were suggestive of preictal states and can be identified by statistical methods: AUC = 0.71, 95 % CI = [0.63 - 0.79]; PPV = 0.77, 95 % CI = [0.70 - 0.84]; FPR = 0.31, 95 % CI = [0.21 - 0.44]); and F1 score = 0.74, 95 % CI = [0.64 - 0.81]. Such algorithms could be straightforwardly implemented in a mobile device (e.g., tablet or smartphone), which would allow a longer data collection that could improve prediction performances. Additional clinical - and even multimodal - parameters could identify more subtle physiological modifications.",0,0
1338,"Adaptive risk prediction system with incremental and transfer learning. Currently, popular methods for prenatal risk assessment of fetal aneuploidies are based on multivariate probabilistic modelling, that are built on decades of scientific research and large-scale multi-center clinical studies. These static models that are deployed to screening labs are rarely updated or adapted to local population characteristics. In this article, we propose an adaptive risk prediction system or ARPS, which considers these changing characteristics and automatically deploys updated risk models. 8 years of real-life Down syndrome screening data was used to firstly develop a distribution shift detection method that captures significant changes in the patient population and secondly a probabilistic risk modelling system that adapts to new data when these changes are detected. Various candidate systems that utilize transfer -and incremental learning that implement different levels of plasticity were tested. Distribution shift detection using a windowed approach provides a computationally less expensive alternative to fitting models at every data block step while not sacrificing performance. This was possible when utilizing transfer learning. Deploying an ARPS to a lab requires careful consideration of the parameters regarding the distribution shift detection and model updating, as they are affected by lab throughput and the incidence of the screened rare disorder. When this is done, ARPS could be also utilized for other population screening problems. We demonstrate with a large real-life dataset that our best performing novel Incremental-Learning-Population-to-Population-Transfer-Learning design can achieve on par prediction performance without human intervention, when compared to a deployed risk screening algorithm that has been manually updated over several years.",0,1
1339,"Computer-aided diagnosis of low grade endometrial stromal sarcoma (LGESS). Low grade endometrial stromal sarcoma (LGESS) accounts for about 0.2% of all uterine cancer cases. Approximately 75% of LGESS patients are initially misdiagnosed with leiomyoma, which is a type of benign tumor, also known as fibroids. In this research, uterine tissue biopsy images of potential LGESS patients are preprocessed using segmentation and stain normalization algorithms. We then apply a variety of classic machine learning and advanced deep learning models to classify tissue images as either benign or cancerous. For the classic techniques considered, the highest classification accuracy we attain is about 0.85, while our best deep learning model achieves an accuracy of approximately 0.87. These results clearly indicate that properly trained learning algorithms can aid in the diagnosis of LGESS.",0,0
1340,"Prediction of arterial blood pressure waveforms from photoplethysmogram signals via fully convolutional neural networks. Cardiovascular disease (CVD) is one of the most serious diseases threatening human health. Arterial blood pressure (ABP) waveforms, containing vivid cardiovascular information, are of great significance for the diagnosis and the prevention of CVD. This paper proposes a deep learning model, named ABP-Net, to transform photoplethysmogram (PPG) signals into ABP waveforms that contain vital physiological information related to cardiovascular systems. In order to guarantee the quality of the predicted ABP waveforms, the structure of the network, the input signals and the loss functions are carefully designed. Specifically, a Wave-U-Net, one kind of fully convolutional neural networks (CNN), is taken as the core architecture of the ABP-Net. Besides the original PPG signals, its first derivative and second derivative signals are all utilized as the inputs of the ABP-Net. Additionally, the maximal absolute loss, accompany with the mean squared error loss is employed to ensure the match of the predicted ABP waveform with the reference one. The performance of the proposed ABP network is tested on the public MIMIC II database both in subject-dependent and subject-independent manners. Both results verify the superior performance of the proposed model over those existing methods accordingly. The mean absolute error (MAE) and the root-mean-square error (RMSE) between the predicted waveforms via the ABP-Net and the reference ones are 3.20Â mmHg and 4.38Â mmHg during the subject-dependent experiments while those are 5.57Â mmHg and 7.15Â mmHg during the subject-independent experiments. Benefiting from the predicted high-quality ABP waveforms, more ABP related physiological parameters can be better obtained, which effectively expands the application scope of PPG devices.",0,0
1345,"Deep learning from MRI-derived labels enables automatic brain tissue classification on human brain CT. Automatic methods for feature extraction, volumetry, and morphometric analysis in clinical neuroscience typically operate on images obtained with magnetic resonance (MR) imaging equipment. Although CT scans are less expensive to acquire and more widely available than MR scans, their application is currently limited to the visual assessment of brain integrity and the exclusion of co-pathologies. CT has rarely been used for tissue classification because the contrast between grey matter and white matter was considered insufficient. In this study, we propose an automatic method for segmenting grey matter (GM), white matter (WM), cerebrospinal fluid (CSF), and intracranial volume (ICV) from head CT images. A U-Net deep learning model was trained and validated on CT images with MRI-derived segmentation labels. We used data from 744 participants of the Gothenburg H70 Birth Cohort Studies for whom CT and T1-weighted MR images had been acquired on the same day. Our proposed model predicted brain tissue classes accurately from unseen CT images (Dice coefficients of 0.79, 0.82, 0.75, 0.93 and 0.98 for GM, WM, CSF, brain volume and ICV, respectively). To contextualize these results, we generated benchmarks based on established MR-based methods and intentional image degradation. Our findings demonstrate that CT-derived segmentations can be used to delineate and quantify brain tissues, opening new possibilities for the use of CT in clinical practice and research.",0,0
1347,"Exploring AdaBoost and Random Forests machine learning approaches for infrared pathology on unbalanced data sets. The use of infrared spectroscopy to augment decision-making in histopathology is a promising direction for the diagnosis of many disease types. Hyperspectral images of healthy and diseased tissue, generated by infrared spectroscopy, are used to build chemometric models that can provide objective metrics of disease state. It is important to build robust and stable models to provide confidence to the end user. The data used to develop such models can have a variety of characteristics which can pose problems to many model-building approaches. Here we have compared the performance of two machine learning algorithms - AdaBoost and Random Forests - on a variety of non-uniform data sets. Using samples of breast cancer tissue, we devised a range of training data capable of describing the problem space. Models were constructed from these training sets and their characteristics compared. In terms of separating infrared spectra of cancerous epithelium tissue from normal-associated tissue on the tissue microarray, both AdaBoost and Random Forests algorithms were shown to give excellent classification performance (over 95% accuracy) in this study. AdaBoost models were more robust when datasets with large imbalance were provided. The outcomes of this work are a measure of classification accuracy as a function of training data available, and a clear recommendation for choice of machine learning approach.",0,0
1350,"Claims-based algorithms for common chronic conditions were efficiently constructed using machine learning methods. Identification of medical conditions using claims data is generally conducted with algorithms based on subject-matter knowledge. However, these claims-based algorithms (CBAs) are highly dependent on the knowledge level and not necessarily optimized for target conditions. We investigated whether machine learning methods can supplement researchers' knowledge of target conditions in building CBAs. Retrospective cohort study using a claims database combined with annual health check-up results of employees' health insurance programs for fiscal year 2016-17 in Japan (study population for hypertension, N = 631,289; diabetes, N = 152,368; dyslipidemia, N = 614,434). We constructed CBAs with logistic regression, k-nearest neighbor, support vector machine, penalized logistic regression, tree-based model, and neural network for identifying patients with three common chronic conditions: hypertension, diabetes, and dyslipidemia. We then compared their association measures using a completely hold-out test set (25% of the study population). Among the test cohorts of 157,822, 38,092, and 153,608 enrollees for hypertension, diabetes, and dyslipidemia, 25.4%, 8.4%, and 38.7% of them had a diagnosis of the corresponding condition. The areas under the receiver operating characteristic curve (AUCs) of the logistic regression with/without subject-matter knowledge about the target condition were .923/.921 for hypertension, .957/.938 for diabetes, and .739/.747 for dyslipidemia. The logistic lasso, logistic elastic-net, and tree-based methods yielded AUCs comparable to those of the logistic regression with subject-matter knowledge: .923-.931 for hypertension; .958-.966 for diabetes; .747-.773 for dyslipidemia. We found that machine learning methods can attain AUCs comparable to the conventional knowledge-based method in building CBAs.",0,0
1354,"DiaDeL: An accurate deep learning-based model with mutational signatures for predicting metastasis stage and cancer types. Mutational signatures help identify cancer-associated genes that are being involved in tumorigenesis pathways. Hence, these pathways guide precision medicine approaches to find appropriate drugs and treatments. The pattern of mutations varies in different cancer types. Some mutations dysregulate protein function so that their accumulation is responsible for cancer development and might be associated with different cancer types. Therefore, mutations as a feature set can be used as an informative candidate to distinguish various cancer types. There are several options for demonstrating mutations. One might employ binary values to demonstrate mutation regions. Another potential method for extracting features is utilizing mutation interpreters. In this study, we investigate the trinucleotide mutational pattern of each cancer type. Moreover, we extract salient NMF-based mutational signatures across various cancer types. Then, we identify cancer-associated genes of a target cancer based on its salient signatures. We evaluate the cancer-associated genes using survival and gene expression analysis in different stages of cancer. Furthermore, we introduce DiaDeL, which is a deep learning-based binary classifier. The DiaDeL model uses mutational signatures as input features and distinct a cancer type from the others. Our proposed model outperforms six state-of-the-art methods with 0.824 and 0.88 for accuracy and AUC, respectively.",0,0
1355,"Data-driven approaches to executive function performance and structure in aging: Integrating person-centered analyses and machine learning risk prediction. <b><i>Objective:</i></b> Executive function (EF) performance and structure in nondemented aging are frequently examined with variable-centered approaches. Person-centered analytics can contribute unique information about classes of persons by simultaneously considering EF performance and structure. The risk predictors of these classes can then be determined by machine learning technology. Using data from the Victoria Longitudinal Study we examined two goals: (a) detect different underlying subgroups (or classes) of EF performance and structure and (b) test multiple risk predictors for best discrimination of these detected subgroups. <b><i>Method:</i></b> We used a classification sample (n = 778; <i>M</i><sub>age</sub> = 71.42) for the first goal and a prediction subsample (<i>n</i> = 570; <i>M</i><sub>age</sub> = 70.10) for the second goal. Eight neuropsychological measures represented three EF dimensions (inhibition, updating, shifting). Fifteen predictors represented five domains (genetic, functional, lifestyle, mobility, demographic). <b><i>Results:</i></b> First, we observed two distinct classes: (a) lower EF performance and unidimensional structure (Class 1) and (b) higher EF performance and multidimensional structure (Class 2). Second, Class 2 was predicted by younger age, more novel cognitive activity, more education, lower body mass index, lower pulse pressure, female sex, faster balance, and more physical activity. <b><i>Conclusions:</i></b> Data-driven modeling approaches tested the possibility of an EF aging class that displayed both preserved EF performance levels and sustained multidimensional structure. The two observed classes differed in both performance level (lower, higher) and structure (unidimensional, multidimensional). Machine learning prediction analyses showed that the higher performing and multidimensional class was associated with multiple brain health-related protective factors. (PsycInfo Database Record (c) 2021 APA, all rights reserved).",0,0
1358,"Identifying peripheral arterial disease in the elderly patientsÂ using machine-learning algorithms. Peripheral artery disease (PAD) is a common syndrome in elderly people. Recently, artificial intelligence (AI) algorithms, in particular machine-learning algorithms, have been increasingly used in disease diagnosis.",0,0
1360,A Deep Learning System for Automatic Assessment of Anterior Chamber Angle in Ultrasound Biomicroscopy Images. To develop and assess a deep learning system that automatically detects angle closure and quantitatively measures angle parameters from ultrasound biomicroscopy (UBM) images using a deep learning algorithm.,0,0
1366,Impact of novel deep learning image reconstruction algorithm on diagnosis of contrast-enhanced liver computed tomography imaging: Comparing to adaptive statistical iterative reconstruction algorithm. To assess clinical application of applying deep learning image reconstruction (DLIR) algorithm to contrast-enhanced portal venous phase liver computed tomography (CT) for improving image quality and lesions detection rate compared with using adaptive statistical iterative reconstruction (ASIR-V) algorithm under routine dose.,0,0
1369,"EXPRESS: Weakly Supervised Multitask Learning Models to Identify Symptom Onset Time of Intracerebral Hemorrhage with Unclear Onset. Background Approximately 1/3 of spontaneous intracerebral hemorrhage (sICH) patients did not know the onset time and were excluded from studies about time-dependent treatments for hyperacute sICH. Aims To help clinicians explore the benefit of time-dependent treatments for unclear-onset patients, we presented artificial intelligence models to identify onset time using non-contrast computed tomography (NCCT) based on weakly supervised multitask learning (WS-MTL) structure. Methods The patients with reliable symptom onset time (strong label) or repeat CT (weak label) were included and split into training set and test set (internal and external). The WS-MTL structure utilized strong and weak labels simultaneously to improve performance. The models included three binary classification models for classifying whether NCCT acquired within 6, 8 or 12 hours for different treatments measured by area under curve (AUC), and a regression model for determining the exact onset time measured by mean absolute error (MAE). The generalizability of models was also explored in comprehensive analysis. Results 4 004 patients with 10 780 NCCT scans were included. The performance of WS-MTL classification model showed high accuracy, and that of regression model was satisfactory in Ã¢Â¤ 6 hours subgroup. In comprehensive analysis, the WS-MTL showed better performance for larger hematomas and thinner scans. And the performance improved effectively as training amounts increasing and could be improved steadily through retraining. Conclusions The WS-MTL models showed good performance and generalizability. Considering the large number of unclear-onset sICH patients, it may be worth to integrate the WS-MTL model into clinical practice to identify the onset time.",0,0
1373,"Use of machine learning to transform complex standardized nursing care plan data into meaningful research variables: a palliative care exemplar. The aim of this article was to describe a novel methodology for transforming complex nursing care plan data into meaningful variables to assess the impact of nursing care. We extracted standardized care plan data for older adults from the electronic health records of 4 hospitals. We created a palliative care framework with 8 categories. A subset of the data was manually classified under the framework, which was then used to train random forest machine learning algorithms that performed automated classification. Two expert raters achieved a 78% agreement rate. Random forest classifiers trained using the expert consensus achieved accuracy (agreement with consensus) between 77% and 89%. The best classifier was utilized for the automated classification of the remaining data. Utilizing machine learning reduces the cost of transforming raw data into representative constructs that can be used in research and practice to understand the essence of nursing specialty care, such as palliative care.",0,0
1375,"Estimation of Baseline Serum Creatinine with Machine Learning. Comparing current to baseline serum creatinine is important in detecting acute kidney injury. In this study, we report a regression-based machine learning model to predict baseline serum creatinine.",0,0
1387,"Integrating 31-Gene Expression Profiling With Clinicopathologic Features to Optimize Cutaneous Melanoma Sentinel Lymph Node Metastasis Prediction. National guidelines recommend sentinel lymph node biopsy (SLNB) be offered to patients with > 10% likelihood of sentinel lymph node (SLN) positivity. On the other hand, guidelines do not recommend SLNB for patients with T1a tumors without high-risk features who have < 5% likelihood of a positive SLN. However, the decision to perform SLNB is less certain for patients with higher-risk T1 melanomas in which a positive node is expected 5%-10% of the time. We hypothesized that integrating clinicopathologic features with the 31-gene expression profile (31-GEP) score using advanced artificial intelligence techniques would provide more precise SLN risk prediction.",0,0
1391,"Routine magnetoencephalography in memory clinic patients: A machine learning approach. We report the routine application of magnetoencephalography (MEG) in a memory clinic, and its value in the discrimination of patients with Alzheimer's disease (AD) dementia from controls.",0,0
1392,"Predicting Progression Patterns of Type 2 Diabetes using Multi-sensor Measurements. Type 2 diabetes - a prevalent chronic disease worldwide - increases risk for serious health consequences including heart and kidney disease. Forecasting diabetes progression can inform disease management strategies, thereby potentially reducing the likelihood or severity of its consequences. We use continuous glucose monitoring and actigraphy data from 54 individuals with Type 2 diabetes to predict their future hemoglobin A1c, HDL cholesterol, LDL cholesterol, and triglyceride levels one year later. We use a combination of convolutional and recurrent neural networks to develop a deep neural network architecture that can learn the dynamic patterns in different sensors' data and combine those patterns with additional demographic and lab data. To further demonstrate the generalizability of our models, we also evaluate their performance using an independent public dataset of individuals with Type 1 diabetes. In addition to diabetes, our approach could be useful for other serious and chronic physical illness, where dynamic (e.g., from multiple sensors) and static (e.g., demographic) data are used for creating predictive models.",0,0
1393,"A Prediction Model for Primary Anterior Cruciate Ligament Injury Using Artificial Intelligence. Supervised machine learning models in artificial intelligence (AI) have been increasingly used to predict different types of events. However, their use in orthopaedic surgery has been limited.",0,0
1395,"Integrative Analysis of Biomarkers Through Machine Learning Identifies Stemness Features in Colorectal Cancer. <b>Background:</b> Cancer stem cells (CSCs), which are characterized by self-renewal and plasticity, are highly correlated with tumor metastasis and drug resistance. To fully understand the role of CSCs in colorectal cancer (CRC), we evaluated the stemness traits and prognostic value of stemness-related genes in CRC. <b>Methods:</b> In this study, the data from 616 CRC patients from The Cancer Genome Atlas (TCGA) were assessed and subtyped based on the mRNA expression-based stemness index (mRNAsi). The correlations of cancer stemness with the immune microenvironment, tumor mutational burden (TMB), and N6-methyladenosine (m6A) RNA methylation regulators were analyzed. Weighted gene co-expression network analysis (WGCNA) was performed to identify the crucial stemness-related genes and modules. Furthermore, a prognostic expression signature was constructed using the Lasso-penalized Cox regression analysis. The signature was validated <i>via</i> multiplex immunofluorescence staining of tissue samples in an independent cohort of 48 CRC patients. <b>Results:</b> This study suggests that high-mRNAsi scores are associated with poor overall survival in stage IV CRC patients. Moreover, the levels of TMB and m6A RNA methylation regulators were positively correlated with mRNAsi scores, and low-mRNAsi scores were characterized by increased immune activity in CRC. The analysis identified 34 key genes as candidate prognosis biomarkers. Finally, a three-gene prognostic signature (PARPBP, KNSTRN, and KIF2C) was explored together with specific clinical features to construct a nomogram, which was successfully validated in an external cohort. <b>Conclusion:</b> There is a unique correlation between CSCs and the prognosis of CRC patients, and the novel biomarkers related to cell stemness could accurately predict the clinical outcomes of these patients.",0,0
1400,"Consecutive Serial Non-Contrast CT Scan-Based Deep Learning Model Facilitates the Prediction of Tumor Invasiveness of Ground-Glass Nodules. Tumors are continuously evolving biological systems which can be monitored by medical imaging. Previous studies only focus on single timepoint images, whether the performance could be further improved by using serial noncontrast CT imaging obtained during nodule follow-up management remains unclear. In this study, we evaluated DL model for predicting tumor invasiveness of GGNs through analyzing time series CT images.",0,0
1401,"MRI-Only Radiotherapy Planning for Nasopharyngeal Carcinoma Using Deep Learning. Radical radiotherapy is the main treatment modality for early and locally advanced nasopharyngeal carcinoma (NPC). Magnetic resonance imaging (MRI) has the advantages of no ionizing radiation and high soft-tissue resolution compared to computed tomography (CT), but it does not provide electron density (ED) information for radiotherapy planning. Therefore, in this study, we developed a pseudo-CT (pCT) generation method to provide necessary ED information for MRI-only planning in NPC radiotherapy.",0,0
1402,Radiomics Models for the Preoperative Prediction of Pelvic and Sacral Tumor Types: A Single-Center Retrospective Study of 795 Cases. To assess the performance of random forest (RF)-based radiomics approaches based on 3D computed tomography (CT) and clinical features to predict the types of pelvic and sacral tumors.,0,0
1403,"Calculation of Apparent Diffusion Coefficients in Prostate Cancer Using Deep Learning Algorithms: A Pilot Study. Apparent diffusion coefficients (ADCs) obtained with diffusion-weighted imaging (DWI) are highly valuable for the detection and staging of prostate cancer and for assessing the response to treatment. However, DWI suffers from significant anatomic distortions and susceptibility artifacts, resulting in reduced accuracy and reproducibility of the ADC calculations. The current methods for improving the DWI quality are heavily dependent on software, hardware, and additional scan time. Therefore, their clinical application is limited. An accelerated ADC generation method that maintains calculation accuracy and repeatability without heavy dependence on magnetic resonance imaging scanners is of great clinical value.",0,0
1405,Prediction of Clinical Outcome for High-Intensity Focused Ultrasound Ablation of Uterine Leiomyomas Using Multiparametric MRI Radiomics-Based Machine Leaning Model. This study sought to develop a multiparametric MRI radiomics-based machine learning model for the preoperative prediction of clinical success for high-intensity-focused ultrasound (HIFU) ablation of uterine leiomyomas.,0,0
1417,"Ultrasound Image Features under Deep Learning in Breast Conservation Surgery for Breast Cancer. This study was to analyze the effect of the combined application of deep learning technology and ultrasound imaging on the effect of breast-conserving surgery for breast cancer. A deep label distribution learning (LDL) model was designed, and the semiautomatic segmentation algorithm based on the region growing and active contour technology (RA) and the segmentation model based on optimized nearest neighbors (ON) were introduced for comparison. The designed algorithm was applied to the breast-conserving surgery of breast cancer patients. According to the difference in intraoperative guidance methods, 102 female patients with early breast cancer were divided into three groups: 34 cases in W1 group (ultrasound guidance based on deep learning segmentation model), 34 cases in W2 group (ultrasound guidance), and 34 cases in W3 group (palpation guidance). The results revealed that the tumor area segmented by the LDL algorithm constructed in this study was closer to the real tumor area; the segmentation accuracy (AC), Jaccard, and true-positive (TP) values of the LDL algorithm were obviously greater than those of the RA and ON algorithms, while the false-positive (FP) value was significantly lower in contrast to the RA and ON algorithms, showing statistically observable differences (<i>P</i>â€‰<â€‰0.05); the actual resection volume of the patients in the W1 group was the closest to the ideal resection volume, which was much smaller in contrast to that of the patients in the W2 and W3 groups, showing statistical differences (<i>P</i>â€‰<â€‰0.05); the positive margins of the patients in the W1 group were statistically lower than those in the W2 and W3 groups (<i>P</i>â€‰<â€‰0.05). In addition, 1 patient in the W1 group was not satisfied with the cosmetic effect, 3 patients in the W2 group were not satisfied with the cosmetic effect, and 9 patients in the W3 group were not satisfied with the cosmetic effect. Finally, it was found that the ultrasound image based on the deep LDL model effectively improved the AC of tumor resection and negative margins, reduced the probability of normal tissue being removed, and improved the postoperative cosmetic effect of breast.",0,0
1418,"Wavelet Transform Artificial Intelligence Algorithm-Based Data Mining Technology for Norovirus Monitoring and Early Warning. Norovirus monitoring and early warning can be used for diagnosis without etiological testing, and the treatment of this disease does not require the antibiotics. It often occurs in preschool children and affects their growth and development, so the coping measures for this disease are more prevention than treatment. In this study, the clinical data of 2133 children with diarrhea were collected. Based on the artificial intelligence (AI) algorithm of wavelet transform, a related model for data mining and processing of children's intestinal ultrasound images and stool specimens was constructed. Then, the norovirus infection trend was warned based on the wavelet analysis algorithm model. The results showed that the intestinal ultrasound image processed by the wavelet transform algorithm was clearer. The positive detection rate of norovirus in children with clinical diarrhea was as high as 59%, and the children had different degrees of body damage, of which the probability of compensatory metabolic acidosis was the highest. The epidemiological analysis found that children with norovirus infection were mainly concentrated in the age group under 2 years old and over 5 years old and showed a peak of infection in December. In summary, the intelligent algorithm based on wavelet transform can realize the noise reduction of intestinal ultrasound, and it should protect children with susceptible age and susceptible seasons to reduce the clinical infection rate of norovirus.",0,0
1420,"Deep Learning-Based Image Feature with Arthroscopy-Aided Early Diagnosis and Treatment of Meniscus Injury of Knee Joint. The aim of this study is to explore the clinical effect of deep learning-based MRI-assisted arthroscopy in the early treatment of knee meniscus sports injury. Based on convolutional neural network algorithm, Adam algorithm was introduced to optimize it, and the magnetic resonance imaging (MRI) image super-resolution reconstruction model (SRCNN) was established. Peak signal-to-noise ratio (PSNR) and structural similarity (SSIM) were compared between SRCNN and other algorithms. Sixty patients with meniscus injury of knee joint were studied. Arthroscopic surgery was performed according to the patients' actual type of injury, and knee scores were evaluated for all patients. Then, postoperative scores and MRI results were analyzed. The results showed that the PSNR and SSIM values of the SRCNN algorithm were (42.19â€‰Â±â€‰4.37) dB and 0.9951, respectively, which were significantly higher than those of other algorithms (<i>P</i>â€‰<â€‰0.05). Among patients with meniscus injury, 17 cases (28.33%) were treated with meniscus suture, 39 cases (65.00%) underwent secondary resection, 3 cases (5.00%) underwent partial resection, and 1 case (1.67%) underwent full resection. After meniscus suture, secondary resection, partial resection, and total resection, the knee function scores of patients after treatment were (83.17â€‰Â±â€‰8.63), (80.06â€‰Â±â€‰7.96), (84.34â€‰Â±â€‰7.74), and (85.52â€‰Â±â€‰5.97), respectively. There was no great difference in knee function scores after different methods of treatment (<i>P</i>â€‰>â€‰0.05), and there were considerable differences compared with those before treatment (<i>P</i>â€‰<â€‰0.01). Compared with the results of arthroscopy, there was no significant difference in the grading of meniscus injury by MRI (<i>P</i>â€‰>â€‰0.05). To sum up, the SRCNN algorithm based on the deep convolutional network algorithm improved the MRI image quality and the diagnosis of knee meniscus injuries. Arthroscopic knee surgery had good results and had great clinical application and promotion value.",0,0
1422,"A two-tier feature selection method using Coalition game and Nystrom sampling for screening COVID-19 from chest X-Ray images. The world is still under the threat of different strains of the coronavirus and the pandemic situation is far from over. The method, that is widely used for the detection of COVID-19 is Reverse Transcription Polymerase chain reaction (RT-PCR), which is a time-consuming method and is prone to manual errors, and has poor precision. Although many nations across the globe have begun the mass immunization procedure, the COVID-19 vaccine will take a long time to reach everyone. The application of artificial intelligence (AI) and computer-aided diagnosis (CAD) has been used in the domain of medical imaging for a long period. It is quite evident that the use of CAD in the detection of COVID-19 is inevitable. The main objective of this paper is to use convolutional neural network (CNN) and a novel feature selection technique to analyze Chest X-Ray (CXR) images for the detection of COVID-19. We propose a novel two-tier feature selection method, which increases the accuracy of the overall classification model used for screening COVID-19 CXRs. Filter feature selection models are often more effective than wrapper methods as wrapper methods tend to be computationally more expensive and are not useful for large datasets dealing with a large number of features. However, most filter methods do not take into consideration how a group of features would work together, rather they just look at the features individually and decide on a score. We have used approximate Shapley value, a concept of Coalition game theory, to deal with this problem. Further, in the case of a large dataset, it is important to work with shorter embeddings of the features. We have used CUR decomposition and Nystrom sampling to further reduce the feature space. To check the efficacy of this two-tier feature selection method, we have applied it to the features extracted by three standard deep learning models, namely <i>VGG16</i>, <i>Xception</i> and <i>InceptionV3</i>, where the features have been extracted from the CXR images of COVID-19 datasets and we have found that the selection procedure works quite well for the features extracted by <i>Xception</i> and <i>InceptionV3</i>. The source code of this work is available at https://github.com/subhankar01/covidfs-aihc.",0,0
1423,"Detection and classification of lung diseases for pneumonia and Covid-19 using machine and deep learning techniques. Since the arrival of the novel Covid-19, several types of researches have been initiated for its accurate prediction across the world. The earlier lung disease pneumonia is closely related to Covid-19, as several patients died due to high chest congestion (pneumonic condition). It is challenging to differentiate Covid-19 and pneumonia lung diseases for medical experts. The chest X-ray imaging is the most reliable method for lung disease prediction. In this paper, we propose a novel framework for the lung disease predictions like pneumonia and Covid-19 from the chest X-ray images of patients. The framework consists of dataset acquisition, image quality enhancement, adaptive and accurate region of interest (ROI) estimation, features extraction, and disease anticipation. In dataset acquisition, we have used two publically available chest X-ray image datasets. As the image quality degraded while taking X-ray, we have applied the image quality enhancement using median filtering followed by histogram equalization. For accurate ROI extraction of chest regions, we have designed a modified region growing technique that consists of dynamic region selection based on pixel intensity values and morphological operations. For accurate detection of diseases, robust set of features plays a vital role. We have extracted visual, shape, texture, and intensity features from each ROI image followed by normalization. For normalization, we formulated a robust technique to enhance the detection and classification results. Soft computing methods such as artificial neural network (ANN), support vector machine (SVM), K-nearest neighbour (KNN), ensemble classifier, and deep learning classifier are used for classification. For accurate detection of lung disease, deep learning architecture has been proposed using recurrent neural network (RNN) with long short-term memory (LSTM). Experimental results show the robustness and efficiency of the proposed model in comparison to the existing state-of-the-art methods.",0,0
1425,"Texture Analysis in the Assessment of Rectal Cancer: Comparison of T2WI and Diffusion-Weighted Imaging. Texture analysis (TA) techniques derived from T2-weighted imaging (T2WI) and apparent diffusion coefficient (ADC) maps of rectal cancer can both achieve good diagnosis performance. This study was to compare TA from T2WI and ADC maps between different pathological T and N stages to confirm which TA analysis is better in diagnosis performance. 146 patients were enrolled in this study. Tumor TA was performed on every patient's T2WI and ADC maps, respectively; then, skewness, kurtosis, uniformity, entropy, energy, inertia, and correlation were calculated. Our results demonstrated that those significant different parameters derived from T2WI had better diagnostic performance than those from ADC maps in differentiating pT3b-4 and pN1-2 stage tumors. In particular, the energy derived from T2WI was an optimal parameter for diagnostic efficiency. High-resolution T2WI plays a key point in the local stage of rectal cancer; thus, TA derived from T2WI may be a more useful tool to aid radiologists and surgeons in selecting treatment.",0,0
1426,"Multilayer perceptron neural network model development for mechanical ventilator parameters prediction by real time system learning. In pandemic situations like COVID 19, real time monitoring of patient condition and continuous delivery of inspired oxygen can be made possible only through artificial intelligence-based system modeling. Even now manual control of mechanical ventilator parameters is continuing despite the ever-increasing number of patients in critical epidemic conditions. Here a suggestive multi-layer perceptron neural network model is developed to predict the level of inspired oxygen delivered by the mechanical ventilator along with mode and positive end expiratory pressure (PEEP) changes for reducing the effort of health care professionals.",0,0
1430,"A Smart Healthcare Recommendation System for Multidisciplinary Diabetes Patients with Data Fusion Based on Deep Ensemble Learning. The prediction of human diseases precisely is still an uphill battle task for better and timely treatment. A multidisciplinary diabetic disease is a life-threatening disease all over the world. It attacks different vital parts of the human body, like Neuropathy, Retinopathy, Nephropathy, and ultimately Heart. A smart healthcare recommendation system predicts and recommends the diabetic disease accurately using optimal machine learning models with the data fusion technique on healthcare datasets. Various machine learning models and methods have been proposed in the recent past to predict diabetes disease. Still, these systems cannot handle the massive number of multifeatures datasets on diabetes disease properly. A smart healthcare recommendation system is proposed for diabetes disease based on deep machine learning and data fusion perspectives. Using data fusion, we can eliminate the irrelevant burden of system computational capabilities and increase the proposed system's performance to predict and recommend this life-threatening disease more accurately. Finally, the ensemble machine learning model is trained for diabetes prediction. This intelligent recommendation system is evaluated based on a well-known diabetes dataset, and its performance is compared with the most recent developments from the literature. The proposed system achieved 99.6% accuracy, which is higher compared to the existing deep machine learning methods. Therefore, our proposed system is better for multidisciplinary diabetes disease prediction and recommendation. Our proposed system's improved disease diagnosis performance advocates for its employment in the automated diagnostic and recommendation systems for diabetic patients.",0,0
1433,"Construction and Drug Evaluation Based on Convolutional Neural Network System Optimized by Grey Correlation Analysis. Incidence rate of mental illness is increasing year by year with the development of city. The amount of modern medical data is huge and complex. In many cases, it is difficult to realize the rational allocation of resources, which puts forward an urgent demand for the artificial intelligence of modern medicine and brings great pressure to the development of the medical industry. The purpose of this study is to develop and construct a grey correlation analysis and related drug evaluation system of mental diseases based on deep convolution neural network. The establishment of the system can effectively improve the automation and intelligence of modern psychiatric treatment process. In this article, the grey correlation analysis of patient data is carried out, and then, the optimized deep convolution neural network is constructed. Combined with the medical knowledge base, the analysis of disease results is realized, and on this basis, the efficacy of related drugs in the treatment of mental diseases is evaluated. The results show that the advantage of the deep convolution neural network system is to effectively improve the induction rate. What's more, compared with other algorithms, this algorithm has higher accuracy and efficiency. It improves the comprehensiveness and informatization of disease screening methods, improves the accuracy of screening, reduces the consumption of doctors' human resources, and provides a theoretical basis for the digitization of the medical industry in the future.",0,0
1437,"A Modeling and Machine Learning Pipeline to Rationally Design Treatments to Restore Neuroendocrine Disorders in Heterogeneous Individuals. Heterogeneity among individual patients presents a fundamental challenge to effective treatment, since a treatment protocol working for a portion of the population often fails in others. We hypothesize that a computational pipeline integrating mathematical modeling and machine learning could be used to address this fundamental challenge and facilitate the optimization of individualized treatment protocols. We tested our hypothesis with the neuroendocrine systems controlled by the hypothalamic-pituitary-adrenal (HPA) axis. With a synergistic combination of mathematical modeling and machine learning (ML), this integrated computational pipeline could indeed efficiently reveal optimal treatment targets that significantly contribute to the effective treatment of heterogeneous individuals. What is more, the integrated pipeline also suggested quantitative information on how these key targets should be perturbed. Based on such ML revealed hints, mathematical modeling could be used to rationally design novel protocols and test their performances. We believe that this integrated computational pipeline, properly applied in combination with other computational, experimental and clinical research tools, can be used to design novel and improved treatment against a broad range of complex diseases.",0,0
1441,"Assessing the Relative Value of CT Perfusion Compared to Non-contrast CT and CT Angiography in Prognosticating Reperfusion-Eligible Acute Ischemic Stroke Patients. In the present study we sought to measure the relative statistical value of various multimodal CT protocols at identifying treatment responsiveness in patients being considered for thrombolysis. We used a prospectively collected cohort of acute ischemic stroke patients being assessed for IV-alteplase, who had CT-perfusion (CTP) and CT-angiography (CTA) before a treatment decision. Linear regression and receiver operator characteristic curve analysis were performed to measure the prognostic value of models incorporating each imaging modality. One thousand five hundred and sixty-two sub-4.5 h ischemic stroke patients were included in this study. A model including clinical variables, alteplase treatment, and NCCT ASPECTS was weak (<i>R</i> <sup>2</sup> 0.067, <i>P</i> < 0.001, AUC 0.605) at predicting 90 day mRS. A second model, including dynamic CTA variables (collateral grade, occlusion severity) showed better predictive accuracy for patient outcome (<i>R</i> <sup>2</sup> 0.381, <i>P</i> < 0.001, AUC 0.781). A third model incorporating CTP variables showed very high predictive accuracy (<i>R</i> <sup>2</sup> 0.488, <i>P</i> < 0.001, AUC 0.899). Combining all three imaging modalities variables also showed good predictive accuracy for outcome but did not improve on the CTP model (<i>R</i> <sup>2</sup> 0.439, <i>P</i> < 0.001, AUC 0.825). CT perfusion predicts patient outcomes from alteplase therapy more accurately than models incorporating NCCT and/or CT angiography. This data has implications for artificial intelligence or machine learning models.",0,0
1442,"MRI Patterns Distinguish AQP4 Antibody Positive Neuromyelitis Optica Spectrum Disorder From Multiple Sclerosis. Neuromyelitis optica spectrum disorder (NMOSD) and multiple sclerosis (MS) are inflammatory diseases of the CNS. Overlap in the clinical and MRI features of NMOSD and MS means that distinguishing these conditions can be difficult. With the aim of evaluating the diagnostic utility of MRI features in distinguishing NMOSD from MS, we have conducted a cross-sectional analysis of imaging data and developed predictive models to distinguish the two conditions. NMOSD and MS MRI lesions were identified and defined through a literature search. Aquaporin-4 (AQP4) antibody positive NMOSD cases and age- and sex-matched MS cases were collected. MRI of orbits, brain and spine were reported by at least two blinded reviewers. MRI brain or spine was available for 166/168 (99%) of cases. Longitudinally extensive (OR = 203), ""bright spotty"" (OR = 93.8), whole (axial; OR = 57.8) or gadolinium (Gd) enhancing (OR = 28.6) spinal cord lesions, bilateral (OR = 31.3) or Gd-enhancing (OR = 15.4) optic nerve lesions, and nucleus tractus solitarius (OR = 19.2), periaqueductal (OR = 16.8) or hypothalamic (OR = 7.2) brain lesions were associated with NMOSD. Ovoid (OR = 0.029), Dawson's fingers (OR = 0.031), pyramidal corpus callosum (OR = 0.058), periventricular (OR = 0.136), temporal lobe (OR = 0.137) and T1 black holes (OR = 0.154) brain lesions were associated with MS. A score-based algorithm and a decision tree determined by machine learning accurately predicted more than 85% of both diagnoses using first available imaging alone. We have confirmed NMOSD and MS specific MRI features and combined these in predictive models that can accurately identify more than 85% of cases as either AQP4 seropositive NMOSD or MS.",0,0
1448,"Using Machine Learning for Predicting the Best Outcomes With Electrical Muscle Stimulation for Tremors in Parkinson's Disease. Recent studies have identified that peripheral stimulation in Parkinson's disease (PD) is effective in tremor reduction, indicating that a peripheral feedback loop plays an important role in the tremor reset mechanism. This was an open-label, quasi-experimental, pre- and post-test design, single-blind, single-group study involving 20 tremor-dominant PD patients. The objective of this study is to explore the effect of electrical muscle stimulation (EMS) as an adjunctive treatment for resting tremor during ""on"" period and to identify the best machine learning model to predict the suitable stimulation level that will yield the longest period of tremor reduction or tremor reset time. In this study, we used a Parkinson's glove to evaluate, stimulate, and quantify the tremors of PD patients. This adjustable glove incorporates a 3-axis gyroscope to measure tremor signals and an EMS to provide an on-demand muscle stimulation to suppress tremors. Machine learning models were applied to identify the suitable pulse amplitude (stimulation level) in five classes that led to the longest tremor reset time. The study was registered at the www.clinicaltrials.gov under the name ""The Study of Rest Tremor Suppression by Using Electrical Muscle Stimulation"" (NCT02370108). Twenty tremor-dominant PD patients were recruited. After applying an average pulse amplitude of 6.25 (SD 2.84) mA and stimulation period of 440.7 (SD 560.82) seconds, the total time of tremor reduction, or tremor reset time, was 329.90 (SD 340.91) seconds. A significant reduction in tremor parameters during stimulation was demonstrated by a reduction of Unified Parkinson's Disease Rating Scale (UPDRS) scores, and objectively, with a reduction of gyroscopic data (<i>p</i> < 0.05, each). None of the subjects reported any serious adverse events. We also compared gyroscopic data with five machine learning techniques: Logistic Regression, Random Forest, Support Vector Machine (SVM), Neural Network (NN), and Long-Short-Term-Memory (LSTM). The machine learning model that gave the highest accuracy was LSTM, which obtained: accuracy = 0.865 and macro-F1 = 0.736. This study confirms the efficacy of EMS in the reduction of resting tremors in PD. LSTM was identified as the most effective model for predicting pulse amplitude that would elicit the longest tremor reset time. Our study provides further insight on the tremor reset mechanism in PD.",0,0
1449,"Cerebral Microbleed Detection <i>via</i> Convolutional Neural Network and Extreme Learning Machine. <b>Aim:</b> Cerebral microbleeds (CMBs) are small round dots distributed over the brain which contribute to stroke, dementia, and death. The early diagnosis is significant for the treatment. <b>Method:</b> In this paper, a new CMB detection approach was put forward for brain magnetic resonance images. We leveraged a sliding window to obtain training and testing samples from input brain images. Then, a 13-layer convolutional neural network (CNN) was designed and trained. Finally, we proposed to utilize an extreme learning machine (ELM) to substitute the last several layers in the CNN for detection. We carried out an experiment to decide the optimal number of layers to be substituted. The parameters in ELM were optimized by a heuristic algorithm named bat algorithm. The evaluation of our approach was based on hold-out validation, and the final predictions were generated by averaging the performance of five runs. <b>Results:</b> Through the experiments, we found replacing the last five layers with ELM can get the optimal results. <b>Conclusion:</b> We offered a comparison with state-of-the-art algorithms, and it can be revealed that our method was accurate in CMB detection.",0,0
1450,"Visual Explanation for Identification of the Brain Bases for Developmental Dyslexia on fMRI Data. <b>Problem:</b> Brain imaging studies of mental health and neurodevelopmental disorders have recently included machine learning approaches to identify patients based solely on their brain activation. The goal is to identify brain-related features that generalize from smaller samples of data to larger ones; in the case of neurodevelopmental disorders, finding these patterns can help understand differences in brain function and development that underpin early signs of risk for developmental dyslexia. The success of machine learning classification algorithms on neurofunctional data has been limited to typically homogeneous data sets of few dozens of participants. More recently, larger brain imaging data sets have allowed for deep learning techniques to classify brain states and clinical groups solely from neurofunctional features. Indeed, deep learning techniques can provide helpful tools for classification in healthcare applications, including classification of structural 3D brain images. The adoption of deep learning approaches allows for incremental improvements in classification performance of larger functional brain imaging data sets, but still lacks diagnostic insights about the underlying brain mechanisms associated with disorders; moreover, a related challenge involves providing more clinically-relevant explanations from the neural features that inform classification. <b>Methods:</b> We target this challenge by leveraging two network visualization techniques in convolutional neural network layers responsible for learning high-level features. Using such techniques, we are able to provide meaningful images for expert-backed insights into the condition being classified. We address this challenge using a dataset that includes children diagnosed with developmental dyslexia, and typical reader children. <b>Results:</b> Our results show accurate classification of developmental dyslexia (94.8%) from the brain imaging alone, while providing automatic visualizations of the features involved that match contemporary neuroscientific knowledge (brain regions involved in the reading process for the dyslexic reader group and brain regions associated with strategic control and attention processes for the typical reader group). <b>Conclusions:</b> Our visual explanations of deep learning models turn the accurate yet opaque conclusions from the models into evidence to the condition being studied.",0,0
1453,"Multimodal Prediction of Alzheimer's Disease Severity Level Based on Resting-State EEG and Structural MRI. While several biomarkers have been developed for the detection of Alzheimer's disease (AD), not many are available for the prediction of disease severity, particularly for patients in the mild stages of AD. In this paper, we explore the multimodal prediction of Mini-Mental State Examination (MMSE) scores using resting-state electroencephalography (EEG) and structural magnetic resonance imaging (MRI) scans. Analyses were carried out on a dataset comprised of EEG and MRI data collected from 89 patients diagnosed with minimal-mild AD. Three feature selection algorithms were assessed alongside four machine learning algorithms. Results showed that while MRI features alone outperformed EEG features, when both modalities were combined, improved results were achieved. The top-selected EEG features conveyed information about amplitude modulation rate-of-change, whereas top-MRI features comprised information about cortical area and white matter volume. Overall, a root mean square error between predicted MMSE values and true MMSE scores of 1.682 was achieved with a multimodal system and a random forest regression model.",0,0
1454,"Identification of Epileptic EEG Signals Through TSK Transfer Learning Fuzzy System. We propose a new model to identify epilepsy EEG signals. Some existing intelligent recognition technologies require that the training set and test set have the same distribution when recognizing EEG signals, some only consider reducing the marginal distribution distance of the data while ignoring the intra-class information of data, and some lack of interpretability. To address these deficiencies, we construct a TSK transfer learning fuzzy system (TSK-TL) based on the easy-to-interpret TSK fuzzy system the transfer learning method. The proposed model is interpretable. By using the information contained in the source domain and target domains more effectively, the requirements for data distribution are further relaxed. It realizes the identification of epilepsy EEG signals in data drift scene. The experimental results show that compared with the existing algorithms, TSK-TL has better performance in EEG recognition of epilepsy.",0,0
1455,"Longitudinal Prediction of Infant MR Images With Multi-Contrast Perceptual Adversarial Learning. The infant brain undergoes a remarkable period of neural development that is crucial for the development of cognitive and behavioral capacities (Hasegawa et al., 2018). Longitudinal magnetic resonance imaging (MRI) is able to characterize the developmental trajectories and is critical in neuroimaging studies of early brain development. However, missing data at different time points is an unavoidable occurrence in longitudinal studies owing to participant attrition and scan failure. Compared to dropping incomplete data, data imputation is considered a better solution to address such missing data in order to preserve all available samples. In this paper, we adapt generative adversarial networks (GAN) to a new application: longitudinal image prediction of structural MRI in the first year of life. In contrast to existing medical image-to-image translation applications of GANs, where inputs and outputs share a very close anatomical structure, our task is more challenging as brain size, shape and tissue contrast vary significantly between the input data and the predicted data. Several improvements over existing GAN approaches are proposed to address these challenges in our task. To enhance the realism, crispness, and accuracy of the predicted images, we incorporate both a traditional voxel-wise reconstruction loss as well as a perceptual loss term into the adversarial learning scheme. As the differing contrast changes in T1w and T2w MR images in the first year of life, we incorporate multi-contrast images leading to our proposed 3D multi-contrast perceptual adversarial network (MPGAN). Extensive evaluations are performed to assess the qualityand fidelity of the predicted images, including qualitative and quantitative assessments of the image appearance, as well as quantitative assessment on two segmentation tasks. Our experimental results show that our MPGAN is an effective solution for longitudinal MR image data imputation in the infant brain. We further apply our predicted/imputed images to two practical tasks, a regression task and a classification task, in order to highlight the enhanced task-related performance following image imputation. The results show that the model performance in both tasks is improved by including the additional imputed data, demonstrating the usability of the predicted images generated from our approach.",0,0
1458,"A Fine-tuned deep convolutional neural network for chest radiography image classification on COVID-19 cases. The outbreak of coronavirus disease 2019 (COVID-19) continues to have a catastrophic impact on the living standard of people worldwide. To fight against COVID-19, many countries are using a combination of containment and mitigation activities. Effective screening of contaminated patients is a critical step in the battle against COVID-19. During the early medical examination, it was observed that patient having abnormalities in chest radiography images shows the symptoms of COVID-19 infection. Motivated by this, in this article, we proposed a unique framework to diagnose the COVID-19 infection. Here, we removed the fully connected layers of an already proven model VGG-16 and placed a new simplified fully connected layer set that is initialized with some random weights on top of this deep convolutional neural network, which has already learned discriminative features, namely, edges, colors, geometric changes,shapes, and objects. To avoid the risk of destroying the rich features, we warm up our FC head by seizing all layers in the body of our network and then unfreeze all the layers in the network body to be fine-tuned.The suggested classification model achieved an accuracy of 97.12% with 99.2% sensitivity and 99.6% specificity for COVID-19 identification. This classification model is superior to the other classification model used to classify COVID-19 infected patients.",0,0
1460,"Automatic Detection and Tracking of Marker Seeds Implanted in Prostate Cancer Patients using a Deep Learning Algorithm. Fiducial marker seeds are often used as a surrogate to identify and track the positioning of prostate volume in the treatment of prostate cancer. Tracking the movement of prostate seeds aids in minimizing the prescription dose spillage outside the target volume to reduce normal tissue complications. In this study, You Only Look Once (YOLO) v2â„¢ (MathWorksâ„¢) convolutional neural network was employed to train ground truth datasets and develop a program in MATLAB that can visualize and detect the seeds on projection images obtained from kilovoltage (kV) X-ray volume imaging (XVI) panel (Elektaâ„¢).",0,0
1466,"Unsupervised Deep Learning based Variational Autoencoder Model for COVID-19 Diagnosis and Classification. At present times, COVID-19 has become a global illness and infected people has increased exponentially and it is difficult to control due to the non-availability of large quantity of testing kits. Artificial intelligence (AI) techniques including machine learning (ML), deep learning (DL), and computer vision (CV) approaches find useful for the recognition, analysis, and prediction of COVID-19. Several ML and DL techniques are trained to resolve the supervised learning issue. At the same time, the potential measure of the unsupervised learning technique is quite high. Therefore, unsupervised learning techniques can be designed in the existing DL models for proficient COVID-19 prediction. In this view, this paper introduces a novel unsupervised DL based variational autoencoder (UDL-VAE) model for COVID-19 detection and classification. The UDL-VAE model involved adaptive Wiener filtering (AWF) based preprocessing technique to enhance the image quality. Besides, Inception v4 with Adagrad technique is employed as a feature extractor and unsupervised VAE model is applied for the classification process. In order to verify the superior diagnostic performance of the UDL-VAE model, a set of experimentation was carried out to highlight the effective outcome of the UDL-VAE model. The obtained experimental values showcased the effectual results of the UDL-VAE model with the higher accuracy of 0.987 and 0.992 on the binary and multiple classes respectively.",0,0
1467,"Deep Transfer Learning Based Classification Model for Covid-19 using Chest CT-scans. COVID-19 is an infectious and contagious virus. As of this writing, more than 160 million people have been infected since its emergence, including more than 125,000 in Algeria. In this work, We first collected a dataset of 4,986 COVID and non-COVID images confirmed by RT-PCR tests at Tlemcen hospital in Algeria. Then we performed a transfer learning on deep learning models that got the best results on the ImageNet dataset, such as DenseNet121, DenseNet201, VGG16, VGG19, Inception Resnet-V2, and Xception, in order to conduct a comparative study. Therefore, We have proposed an explainable model based on the DenseNet201 architecture and the GradCam explanation algorithm to detect COVID-19 in chest CT images and explain the output decision. Experiments have shown promising results and proven that the introduced model can be beneficial for diagnosing and following up patients with COVID-19.",0,0
1468,"Using Machine Learning Methods to Develop a Short Tree-Based Adaptive Classification Test: Case Study With a High-Dimensional Item Pool and Imbalanced Data. This study explores advanced techniques in machine learning to develop a short tree-based adaptive classification test based on an existing lengthy instrument. A case study was carried out for an assessment of risk for juvenile delinquency. Two unique facts of this case are (a) the items in the original instrument measure a large number of distinctive constructs; (b) the target outcomes are of low prevalence, which renders imbalanced training data. Due to the high dimensionality of the items, traditional item response theory (IRT)-based adaptive testing approaches may not work well, whereas decision trees, which are developed in the machine learning discipline, present as a promising alternative solution for adaptive tests. A cross-validation study was carried out to compare eight tree-based adaptive test constructions with five benchmark methods using data from a sample of 3,975 subjects. The findings reveal that the best-performing tree-based adaptive tests yielded better classification accuracy than the benchmark method IRT scoring with optimal cutpoints, and yielded comparable or better classification accuracy than the best benchmark method, random forest with balanced sampling. The competitive classification accuracy of the tree-based adaptive tests also come with an over 30-fold reduction in the length of the instrument, only administering between 3 to 6 items to any individual. This study suggests that tree-based adaptive tests have an enormous potential when used to shorten instruments that measure a large variety of constructs.",0,0
1469,"Weakly Supervised Segmentation of COVID19 Infection with Scribble Annotation on CT Images. Segmentation of infections from CT scans is important for accurate diagnosis and follow-up in tackling the COVID-19. Although the convolutional neural network has great potential to automate the segmentation task, most existing deep learning-based infection segmentation methods require fully annotated ground-truth labels for training, which is time-consuming and labor-intensive. This paper proposed a novel weakly supervised segmentation method for COVID-19 infections in CT slices, which only requires scribble supervision and is enhanced with the uncertainty-aware self-ensembling and transformation-consistent techniques. Specifically, to deal with the difficulty caused by the shortage of supervision, an uncertainty-aware mean teacher is incorporated into the scribble-based segmentation method, encouraging the segmentation predictions to be consistent under different perturbations for an input image. This mean teacher model can guide the student model to be trained using information in images without requiring manual annotations. On the other hand, considering the output of the mean teacher contains both correct and unreliable predictions, equally treating each prediction in the teacher model may degrade the performance of the student network. To alleviate this problem, the pixel level uncertainty measure on the predictions of the teacher model is calculated, and then the student model is only guided by reliable predictions from the teacher model. To further regularize the network, a transformation-consistent strategy is also incorporated, which requires the prediction to follow the same transformation if a transform is performed on an input image of the network. The proposed method has been evaluated on two public datasets and one local dataset. The experimental results demonstrate that the proposed method is more effective than other weakly supervised methods and achieves similar performance as those fully supervised.",0,0
1474,"A deep neural network with subdomain adaptation for motor imagery brain-computer interface. The nonstationarity problem of EEG is very serious, especially for spontaneous signals, which leads to the poor effect of machine learning related to spontaneous signals, especially in related tasks across time, which correspondingly limits the practical use of brain-computer interface (BCI).",0,0
1476,"Deep learning for differential diagnosis of malignant hepatic tumors based on multi-phase contrast-enhanced CT and clinical data. Liver cancer remains the leading cause of cancer death globally, and the treatment strategies are distinct for each type of malignant hepatic tumors. However, the differential diagnosis before surgery is challenging and subjective. This study aims to build an automatic diagnostic model for differentiating malignant hepatic tumors based on patients' multimodal medical data including multi-phase contrast-enhanced computed tomography and clinical features.",0,0
1479,"Artificial intelligence-based measurements of PET/CT imaging biomarkers are associated with disease-specific survival of high-risk prostate cancer patients. Artificial intelligence (AI) offers new opportunities for objective quantitative measurements of imaging biomarkers from positron-emission tomography/computed tomography (PET/CT). Clinical image reporting relies predominantly on observer-dependent visual assessment and easily accessible measures like SUV<sub>max</sub>, representing lesion uptake in a relatively small amount of tissue. Our hypothesis is that measurements of total volume and lesion uptake of the entire tumour would better reflect the disease`s activity with prognostic significance, compared with conventional measurements.",0,0
1481,"Liver-to-Spleen Volume Ratio Automatically Measured on CT Predicts Decompensation in Patients with B Viral Compensated Cirrhosis. Although the liver-to-spleen volume ratio (LSVR) based on CT reflects portal hypertension, its prognostic role in cirrhotic patients has not been proven. We evaluated the utility of LSVR, automatically measured from CT images using a deep learning algorithm, as a predictor of hepatic decompensation and transplantation-free survival in patients with hepatitis B viral (HBV)-compensated cirrhosis.",0,0
1485,Do plaque-related factors affect the diagnostic performance of an artificial intelligence coronary-assisted diagnosis system? Comparison with invasive coronary angiography. The aim of this study was to investigate the effects of plaque-related factors on the diagnostic performance of an artificial intelligence coronary-assisted diagnosis system (AI-CADS).,0,0
1493,"Per-COVID-19: A Benchmark Dataset for COVID-19 Percentage Estimation from CT-Scans. COVID-19 infection recognition is a very important step in the fight against the COVID-19 pandemic. In fact, many methods have been used to recognize COVID-19 infection including Reverse Transcription Polymerase Chain Reaction (RT-PCR), X-ray scan, and Computed Tomography scan (CT- scan). In addition to the recognition of the COVID-19 infection, CT scans can provide more important information about the evolution of this disease and its severity. With the extensive number of COVID-19 infections, estimating the COVID-19 percentage can help the intensive care to free up the resuscitation beds for the critical cases and follow other protocol for less severity cases. In this paper, we introduce COVID-19 percentage estimation dataset from CT-scans, where the labeling process was accomplished by two expert radiologists. Moreover, we evaluate the performance of three Convolutional Neural Network (CNN) architectures: ResneXt-50, Densenet-161, and Inception-v3. For the three CNN architectures, we use two loss functions: MSE and Dynamic Huber. In addition, two pretrained scenarios are investigated (ImageNet pretrained models and pretrained models using X-ray data). The evaluated approaches achieved promising results on the estimation of COVID-19 infection. Inception-v3 using Dynamic Huber loss function and pretrained models using X-ray data achieved the best performance for slice-level results: 0.9365, 5.10, and 9.25 for Pearson Correlation coefficient (PC), Mean Absolute Error (MAE), and Root Mean Square Error (RMSE), respectively. On the other hand, the same approach achieved 0.9603, 4.01, and 6.79 for PCsubj, MAEsubj, and RMSEsubj, respectively, for subject-level results. These results prove that using CNN architectures can provide accurate and fast solution to estimate the COVID-19 infection percentage for monitoring the evolution of the patient state.",0,0
1500,"Study on Data Partition for Delimitation of Masses in Mammography. Mammography is the primary medical imaging method used for routine screening and early detection of breast cancer in women. However, the process of manually inspecting, detecting, and delimiting the tumoral massess in 2D images is a very time-consuming task, subject to human errors due to fatigue. Therefore, integrated computer-aided detection systems have been proposed, based on modern computer vision and machine learning methods. In the present work, mammogram images from the publicly available Inbreast dataset are first converted to pseudo-color and then used to train and test a Mask R-CNN deep neural network. The most common approach is to start with a dataset and split the images into train and test set randomly. However, since there are often two or more images of the same case in the dataset, the way the dataset is split may have an impact on the results. Our experiments show that random partition of the data can produce unreliable training, so the dataset must be split using case-wise partition for more stable results. In experimental results, the method achieves an average true positive rate of 0.936 with 0.063 standard deviation using random partition and 0.908 with 0.002 standard deviation using case-wise partition, showing that case-wise partition must be used for more reliable results.",0,0
1503,"Deep learning features from diffusion tensor imaging improve glioma stratification and identify risk groups with distinct molecular pathway activities. To develop and validate a deep learning signature (DLS) from diffusion tensor imaging (DTI) for predicting overall survival in patients with infiltrative gliomas, and to investigate the biological pathways underlying the developed DLS.",0,0
1504,"Automatic segmentation of organs at risk and tumors in CT images of lung cancer from partially labelled datasets with a semi-supervised conditional nnU-Net. Accurately and reliably defining organs at risk (OARs) and tumors are the cornerstone of radiation therapy (RT) treatment planning for lung cancer. Almost all segmentation networks based on deep learning techniques rely on fully annotated data with strong supervision. However, existing public imaging datasets encountered in the RT domain frequently include singly labelled tumors or partially labelled organs because annotating full OARs and tumors in CT images is both rigorous and tedious. To utilize labelled data from different sources, we proposed a dual-path semi-supervised conditional nnU-Net for OARs and tumor segmentation that is trained on a union of partially labelled datasets.",0,0
1516,A Deep Learning Approach to Segment and Classify C-Shaped Canal Morphologies in Mandibular Second Molars Utilizing Cone-Beam Computed Tomography. The identification of C-shaped root-canal anatomy on radiographic images affects clinical decision-making and treatment. Aims of this study were to develop a Deep Learning (DL) model to classify C-shaped canal anatomy in mandibular second molars from Cone Beam CT (CBCT) volumes and to compare the performance of three different architectures.,0,0
1517,"A multisystem-compatible deep learning-based algorithm for detection and characterization of angiectasias in small-bowel capsule endoscopy. A proof-of-concept study. Current artificial intelligence (AI)-based solutions for capsule endoscopy (CE) interpretation are proprietary. We aimed to evaluate an AI solution trained on a specific CE system (PillcamÂ®, Medtronic) for the detection of angiectasias on images captured by a different proprietary system (MiroCamÂ®, Intromedic).",0,0
1518,Which criteria is a better predictor of ICU admission in trauma patients? An artificial neural network approach. One of the most critical concerns in the intensive care unit (ICU) section is identifying the best criteria for entering patients to this part. This study aimed to predict the best compatible criteria for entering trauma patients in the ICU section.,0,0
1519,Magnetic Resonance Radiomics and Machine-learning Models: An Approach for Evaluating Tumor-stroma Ratio in Patients with Pancreatic Ductal Adenocarcinoma. To develop and validate a magnetic resonance imaging (MRI)-based machine learning classifier for evaluating the tumor-stroma ratio (TSR) in patients with pancreatic ductal adenocarcinoma (PDAC).,0,0
1524,Development and validation of a novel predictive model and web calculator for evaluating transfusion risk after spinal fusion for spinal tuberculosis: a retrospective cohort study. The incidence and adverse events of postoperative blood transfusion in spinal tuberculosis (TB) have attracted increasing attention. Our purpose was to develop a prediction model to evaluate blood transfusion risk after spinal fusion (SF) for spinal TB.,0,0
1530,"The Importance of Age in the Prediction of Mortality by a Frailty Index: A Machine Learning Approach in the Irish Longitudinal Study on Ageing. The quantification of biological age in humans is an important scientific endeavor in the face of ageing populations. The frailty index (FI) methodology is based on the accumulation of health deficits and captures variations in health status within individuals of the same age. The aims of this study were to assess whether the addition of age to an FI improves its mortality prediction and whether the associations of the individual FI items differ in strength. We utilized data from The Irish Longitudinal Study on Ageing to conduct, by sex, machine learning analyses of the ability of a 32-item FI to predict 8-year mortality in 8174 wave 1 participants aged 50 or more years. By wave 5, 559 men and 492 women had died. In the absence of age, the FI was an acceptable predictor of mortality with AUCs of 0.7. When age was included, AUCs improved to 0.8 in men and 0.9 in women. After age, deficits related to physical function and self-rated health tended to have higher importance scores. Not all FI variables seemed equally relevant to predict mortality, and age was by far the most relevant feature. Chronological age should remain an important consideration when interpreting the prognostic significance of an FI.",0,0
1531,"Multiscale Entropy Analysis of Heart Rate Variability in Neonatal Patients with and without Seizures. The complex physiological dynamics of neonatal seizures make their detection challenging. A timely diagnosis and treatment, especially in intensive care units, are essential for a better prognosis and the mitigation of possible adverse effects on the newborn's neurodevelopment. In the literature, several electroencephalographic (EEG) studies have been proposed for a parametric characterization of seizures or their detection by artificial intelligence techniques. At the same time, other sources than EEG, such as electrocardiography, have been investigated to evaluate the possible impact of neonatal seizures on the cardio-regulatory system. Heart rate variability (HRV) analysis is attracting great interest as a valuable tool in newborns applications, especially where EEG technologies are not easily available. This study investigated whether multiscale HRV entropy indexes could detect abnormal heart rate dynamics in newborns with seizures, especially during ictal events. Furthermore, entropy measures were analyzed to discriminate between newborns with seizures and seizure-free ones. A cohort of 52 patients (33 with seizures) from the Helsinki University Hospital public dataset has been evaluated. Multiscale sample and fuzzy entropy showed significant differences between the two groups (<i>p</i>-value < 0.05, Bonferroni multiple-comparison post hoc correction). Moreover, interictal activity showed significant differences between seizure and seizure-free patients (Mann-Whitney Test: <i>p</i>-value < 0.05). Therefore, our findings suggest that HRV multiscale entropy analysis could be a valuable pre-screening tool for the timely detection of seizure events in newborns.",0,0
1532,Machine Learning Prediction Models for Mitral Valve Repairability and Mitral Regurgitation Recurrence in Patients Undergoing Surgical Mitral Valve Repair. Mitral valve regurgitation (MR) is the most common valvular heart disease and current variables associated with MR recurrence are still controversial. We aim to develop a machine learning-based prognostic model to predict causes of mitral valve (MV) repair failure and MR recurrence.,0,0
1534,"Design of a Wearable Eye-Movement Detection System Based on Electrooculography Signals and Its Experimental Validation. In the assistive research area, human-computer interface (HCI) technology is used to help people with disabilities by conveying their intentions and thoughts to the outside world. Many HCI systems based on eye movement have been proposed to assist people with disabilities. However, due to the complexity of the necessary algorithms and the difficulty of hardware implementation, there are few general-purpose designs that consider practicality and stability in real life. Therefore, to solve these limitations and problems, an HCI system based on electrooculography (EOG) is proposed in this study. The proposed classification algorithm provides eye-state detection, including the fixation, saccade, and blinking states. Moreover, this algorithm can distinguish among ten kinds of saccade movements (i.e., up, down, left, right, farther left, farther right, up-left, down-left, up-right, and down-right). In addition, we developed an HCI system based on an eye-movement classification algorithm. This system provides an eye-dialing interface that can be used to improve the lives of people with disabilities. The results illustrate the good performance of the proposed classification algorithm. Moreover, the EOG-based system, which can detect ten different eye-movement features, can be utilized in real-life applications.",0,0
1536,"Arteriovenous Fistula Flow Dysfunction Surveillance: Early Detection Using Pulse Radar Sensor and Machine Learning Classification. Vascular Access (VA) is often referred to as the ""Achilles heel"" for a Hemodialysis (HD)-dependent patient. Both the patent and sufficient VA provide adequacy for performing dialysis and reducing dialysis-related complications, while on the contrary, insufficient VA is the main reason for recurrent hospitalizations, high morbidity, and high mortality in HD patients. A non-invasive Vascular Wall Motion (VWM) monitoring system, made up of a pulse radar sensor and Support Vector Machine (SVM) classification algorithm, has been developed to detect access flow dysfunction in Arteriovenous Fistula (AVF). The harmonic ratios derived from the Fast Fourier Transform (FFT) spectrum-based signal processing technique were employed as the input features for the SVM classifier. The result of a pilot clinical trial showed that a more accurate prediction of AVF flow dysfunction could be achieved by the VWM monitor as compared with the Ultrasound Dilution (UD) flow monitor. Receiver Operating Characteristic (ROC) curve analysis showed that the SVM classification algorithm achieved a detection specificity of 100% at detection thresholds in the range from 500 to 750 mL/min and a maximum sensitivity of 95.2% at a detection threshold of 750 mL/min.",0,0
1538,Artificial Intelligence (AI) approach to identifying factors that determine systolic blood pressure in type 2 diabetes (study from the LOOK AHEAD cohort). Artificial Intelligence (AI) methods have recently become critical for research in diabetes in the era of big-data science.,0,0
1543,"Automatic multi-plaque tracking and segmentation in ultrasonic videos. Carotid plaque tracking and segmentation in ultrasound videos is the premise for subsequent plaque property evaluation and treatment plan development. However, the task is quite challenging, as it needs to address the problems of poor image quality, plaque shape variations among frames, the existence of multiple plaques, etc. To overcome these challenges, we propose a new automatic multi-plaque tracking and segmentation (AMPTS) framework. AMPTS consists of three modules. The first module is a multi-object detector, in which a Dual Attention U-Net is proposed to detect multiple plaques and vessels simultaneously. The second module is a set of single-object trackers that can utilize the previous tracking results efficiently and achieve stable tracking of the current target by using channel attention and a ranking strategy. To make the first module and the second module work together, a parallel tracking module based on a simplified 'tracking-by-detection' mechanism is proposed to solve the challenge of tracking object variation. Extensive experiments are conducted to compare the proposed method with several state-of-the-art deep learning based methods. The experimental results demonstrate that the proposed method has high accuracy and generalizability with a Dice similarity coefficient of 0.83 which is 0.16, 0.06 and 0.27 greater than MAST (Lai etÂ al., 2020), Track R-CNN (Voigtlaender etÂ al., 2019) and VSD (Yang etÂ al., 2019) respectively and has made significant improvements on seven other indicators. In the additional Testing set 2, our method achieved a Dice similarity coefficient of 0.80, an accuracy of 0.79, a precision of 0.91, a Recall 0.70, a F1 score of 0.79, an AP@0.5 of 0.92, an AP@0.7 of 0.74, and an expected average overlap of 0.79. Numerous ablation studies suggest the effectiveness of each proposed component and the great potential for multiple carotid plaques tracking and segmentation in clinical practice.",0,0
1544,"DNA methylation-based classification of small B-cell lymphomas: a proof-of-principle study. While most small B-cell lymphomas (SBCLs) can be diagnosed using routine methods, challenges exist. For example, marginal zone lymphomas (MZLs) can be difficult to rule-in, in large part because there is no widely-available, sensitive, and specific biomarker for the marginal zone cell-of-origin. In this study, we hypothesize that DNA methylation array profiling can assist with the classification of SBCLs, including MZLs. Extramedullary SBCLs, including challenging cases, were reviewed internally for pathology consensus and profiled. By combining the resulting array dataset with datasets from other groups, a set of 26 informative probes was selected, and used to train machine learning models to classify four common SBCLs: chronic lymphocytic leukemia/small lymphocytic lymphoma, follicular lymphoma, mantle cell lymphoma, and MZL. Applying a prediction probability cutoff to separate classifiable from unclassifiable cases, we found that the trained model was able to classify 95% of independent test cases (264/279). The concordance between model predictions and pathology diagnoses was 99.6% (262/263) among classifiable test cases. One validation reference test case was re-classified based on model prediction. The model was also used to predict the diagnoses of two challenging SBCLs. Although the differential examined and data on difficult cases are limited, our results support accurate methylation-based classification of SBCLs. Further, high specificities of predictions suggest that methylation signatures can be used to rule-in MZLs.",0,0
1552,"Weakly supervised annotation-free cancer detection and prediction of genotype in routine histopathology. Deep Learning is a powerful tool in computational pathology: it can be used for tumor detection and for predicting genetic alterations based on histopathology images alone. Conventionally, tumor detection and prediction of genetic alterations are two separate workflows. Newer methods have combined them, but require complex, manually engineered computational pipelines, restricting reproducibility and robustness. To address these issues, we present a new method for simultaneous tumor detection and prediction of genetic alterations: The 'Slide-Level Assessment Model' (SLAM) uses a single off-the-shelf neural network to predict molecular alterations directly from routine pathology slides without any manual annotations, improving upon previous methods by automatically excluding normal and non-informative tissue regions. SLAM requires only standard programming libraries and is conceptually simpler than previous approaches. We have extensively validated SLAM for clinically relevant tasks using two large multicentric cohorts of colorectal cancer patients, DACHS from Germany and YCR-BCIP from the United Kingdom. We show that SLAM yields reliable slide-level classification of tumor presence with an area under the receiver operating curve (AUROC) of 0.980 (confidence interval 0.975, 0.984; Nâ€‰=â€‰2297 tumor and Nâ€‰=â€‰1281 normal slides). In addition, SLAM can detect microsatellite instability (MSI) / mismatch repair deficiency (dMMR) or microsatellite stability (MSS) /mismatch repair proficiency (pMMR) with an AUROC of 0.909 (0.888, 0.929; Nâ€‰=â€‰2039 patients) and BRAF mutational status with an AUROC of 0.821 (0.786, 0.852; Nâ€‰=â€‰2075 patients). The improvement with respect to previous methods was validated in a large external testing cohort in which MSI/dMMR status was detected with an AUROC of 0.900 (0.864, 0.931; Nâ€‰=â€‰805 patients). In addition, SLAM provides human-interpretable visualization maps, enabling the analysis of multiplexed network predictions by human experts. In summary, SLAM is a new simple and powerful method for computational pathology which could be applied to multiple disease contexts. This article is protected by copyright. All rights reserved.",0,0
1560,"Artificial intelligence system reduces false-positive findings in the interpretation of breast ultrasound exams. Though consistently shown to detect mammographically occult cancers, breast ultrasound has been noted to have high false-positive rates. In this work, we present an AI system that achieves radiologist-level accuracy in identifying breast cancer in ultrasound images. Developed on 288,767 exams, consisting of 5,442,907 B-mode and Color Doppler images, the AI achieves an area under the receiver operating characteristic curve (AUROC) of 0.976 on a test set consisting of 44,755 exams. In a retrospective reader study, the AI achieves a higher AUROC than the average of ten board-certified breast radiologists (AUROC: 0.962 AI, 0.924â€‰Â±â€‰0.02 radiologists). With the help of the AI, radiologists decrease their false positive rates by 37.3% and reduce requested biopsies by 27.8%, while maintaining the same level of sensitivity. This highlights the potential of AI in improving the accuracy, consistency, and efficiency of breast ultrasound diagnosis.",1,1
1561,"Robust whole slide image analysis for cervical cancer screening using deep learning. Computer-assisted diagnosis is key for scaling up cervical cancer screening. However, current recognition algorithms perform poorly on whole slide image (WSI) analysis, fail to generalize for diverse staining and imaging, and show sub-optimal clinical-level verification. Here, we develop a progressive lesion cell recognition method combining low- and high-resolution WSIs to recommend lesion cells and a recurrent neural network-based WSI classification model to evaluate the lesion degree of WSIs. We train and validate our WSI analysis system on 3,545 patient-wise WSIs with 79,911 annotations from multiple hospitals and several imaging instruments. On multi-center independent test sets of 1,170 patient-wise WSIs, we achieve 93.5% Specificity and 95.1% Sensitivity for classifying slides, comparing favourably to the average performance of three independent cytopathologists, and obtain 88.5% true positive rate for highlighting the top 10 lesion cells on 447 positive slides. After deployment, our system recognizes a one giga-pixel WSI in about 1.5â€‰min.",1,1
1564,CheXED: Comparison of a Deep Learning Model to a Clinical Decision Support System for Pneumonia in the Emergency Department. Patients with pneumonia often present to the emergency department (ED) and require prompt diagnosis and treatment. Clinical decision support systems for the diagnosis and management of pneumonia are commonly utilized in EDs to improve patient care. The purpose of this study is to investigate whether a deep learning model for detecting radiographic pneumonia and pleural effusions can improve functionality of a clinical decision support system (CDSS) for pneumonia management (ePNa) operating in 20 EDs.,0,0
1572,"Deep Learning-Based CT Radiomics for Feature Representation and Analysis of Aging Characteristics of Asian Bony Orbit. This paper puts forward a new method for automatic segmentation of bony orbit as well as automatic extraction and classification of aging features of segmented orbit contour based on depth learning, with which the aging mode of bony orbit contour is preliminarily validated.",0,0
1573,"Radiomic modeling to predict risk of vertebral compression fracture after stereotactic body radiation therapy for spinal metastases. In the treatment of spinal metastases with stereotactic body radiation therapy (SBRT), vertebral compression fracture (VCF) is a common and potentially morbid complication. Better methods to identify patients at high risk of radiation-induced VCF are needed to evaluate prophylactic measures. Radiomic features from pretreatment imaging may be employed to more accurately predict VCF. The objective of this study was to develop and evaluate a machine learning model based on clinical characteristics and radiomic features from pretreatment imaging to predict the risk of VCF after SBRT for spinal metastases.",0,0
1579,"Artificial intelligence for quality control of oscillometry measures. The forced oscillation technique (FOT) allows non-invasive lung function testing during quiet breathing even without expert guidance. However, it still relies on an operator for excluding breaths with artefacts such as swallowing, glottis closure and coughing. This manual selection is operator-dependent and time-consuming. We evaluated supervised machine learning methods to exclude breaths with artefacts from data analysis automatically.",0,0
1580,Feasibility assessment of infectious keratitis depicted on slit-lamp and smartphone photographs using deep learning. This study aims to investigate how infectious keratitis depicted on slit-lamp and smartphone photographs can be reliably assessed using deep learning.,0,0
1584,"Disease type detection in lung and colon cancer images using the complement approach of inefficient sets. Lung and colon cancers are deadly diseases that can develop simultaneously in organs and adversely affect human life in some special cases. Although the frequency of simultaneous occurrence of these two types of cancer is unlikely, there is a high probability of metastasis between the two organs if not diagnosed early. Traditionally, specialists have to go through a lengthy and complicated process to examine histopathological images and diagnose cancer cases; yet, it is now possible to achieve this process faster with the available technological possibilities. In this study, artificial intelligence-supported model and optimization methods were used to realize the classification of lung and colon cancers' histopathological images. The used dataset has five classes of histopathological images consisting of two colon cancer classes and three lung cancer classes. In the proposed approach, the image classes were trained from scratch with the DarkNet-19 model, which is one of the deep learning models. In the feature set extracted from the DarkNet-19 model, selection of the inefficient features was performed by using Equilibrium and Manta Ray Foraging optimization algorithms. Then, the set containing the inefficient features was distinguished from the rest of the set features, creating an efficient feature set (complementary rule insets). The efficient features obtained by the two used optimization algorithms were combined and classified with the Support Vector Machine (SVM) method. The overall accuracy rate obtained in the classification process was 99.69%. Based on the outcomes of this study, it has been observed that using the complementary method together with some optimization methods improved the classification performance of the dataset.",0,0
1591,"eARDS: A multi-center validation of an interpretable machine learning algorithm of early onset Acute Respiratory Distress Syndrome (ARDS) among critically ill adults with COVID-19. We present an interpretable machine learning algorithm called 'eARDS' for predicting ARDS in an ICU population comprising COVID-19 patients, up to 12-hours before satisfying the Berlin clinical criteria. The analysis was conducted on data collected from the Intensive care units (ICU) at Emory Healthcare, Atlanta, GA and University of Tennessee Health Science Center, Memphis, TN and the CernerÂ® Health Facts Deidentified Database, a multi-site COVID-19 EMR database. The participants in the analysis consisted of adults over 18 years of age. Clinical data from 35,804 patients who developed ARDS and controls were used to generate predictive models that identify risk for ARDS onset up to 12-hours before satisfying the Berlin criteria. We identified salient features from the electronic medical record that predicted respiratory failure among this population. The machine learning algorithm which provided the best performance exhibited AUROC of 0.89 (95% CI = 0.88-0.90), sensitivity of 0.77 (95% CI = 0.75-0.78), specificity 0.85 (95% CI = 085-0.86). Validation performance across two separate health systems (comprising 899 COVID-19 patients) exhibited AUROC of 0.82 (0.81-0.83) and 0.89 (0.87, 0.90). Important features for prediction of ARDS included minimum oxygen saturation (SpO2), standard deviation of the systolic blood pressure (SBP), O2 flow, and maximum respiratory rate over an observational window of 16-hours. Analyzing the performance of the model across various cohorts indicates that the model performed best among a younger age group (18-40) (AUROC = 0.93 [0.92-0.94]), compared to an older age group (80+) (AUROC = 0.81 [0.81-0.82]). The model performance was comparable on both male and female groups, but performed significantly better on the severe ARDS group compared to the mild and moderate groups. The eARDS system demonstrated robust performance for predicting COVID19 patients who developed ARDS at least 12-hours before the Berlin clinical criteria, across two independent health systems.",0,0
1611,"Automated Measurements of Body Composition in Abdominal CT Scans Using Artificial Intelligence Can Predict Mortality in Patients With Cirrhosis. Body composition measures derived from already available electronic medical records (computed tomography [CT] scans) can have significant value, but automation of measurements is needed for clinical implementation. We sought to use artificial intelligence to develop an automated method to measure body composition and test the algorithm on a clinical cohort to predict mortality. We constructed a deep learning algorithm using Google's DeepLabv3+ on a cohort of de-identified CT scans (nÂ =Â 12,067). To test for the accuracy and clinical usefulness of the algorithm, we used a unique cohort of prospectively followed patients with cirrhosis (nÂ =Â 238) who had CT scans performed. To assess model performance, we used the confusion matrix and calculated the mean accuracy of 0.977Â Â±Â 0.02 (0.975Â Â±Â 0.018 for the training and test sets, respectively). To assess for spatial overlap, we measured the mean intersection over union and mean boundary contour scores and found excellent overlap between the manual and automated methods with mean scores of 0.954Â Â±Â 0.030, 0.987Â Â±Â 0.009, and 0.948Â Â±Â 0.039 (0.983Â Â±Â 0.013 for the training and test set, respectively). Using these automated measurements, we found that body composition features were predictive of mortality in patients with cirrhosis. On multivariate analysis, the addition of body composition measures significantly improved prediction of mortality for patients with cirrhosis over Model for End-Stage Liver Disease alone (PÂ <Â 0.001). Conclusion: The measurement of body composition can be automated using artificial intelligence and add significant value for incidental CTs performed for other clinical indications. This is proof of concept that this methodology could allow for wider implementation into the clinical arena.",0,0
1616,"Construction of a Risk Prediction Model for Hospital-Acquired Pulmonary Embolism in Hospitalized Patients. The purpose of this study is to establish a novel pulmonary embolism (PE) risk prediction model based on machine learning (ML) methods and to evaluate the predictive performance of the model and the contribution of variables to the predictive performance. We conducted a retrospective study at the Shanghai Tenth People's Hospital and collected the clinical data of in-patients that received pulmonary computed tomography imaging between January 1, 2014 and December 31, 2018. We trained several ML models, including logistic regression (LR), support vector machine (SVM), random forest (RF), and gradient boosting decision tree (GBDT), compared the models with representative baseline algorithms, and investigated their predictability and feature interpretation. A total of 3619 patients were included in the study. We discovered that the GBDT model demonstrated the best prediction with an area under the curve value of 0.799, whereas those of the RF, LR, and SVM models were 0.791, 0.716, and 0.743, respectively. The sensibilities of the GBDT, LR, RF, and SVM models were 63.9%, 68.1%, 71.5%, and 75%, respectively; the specificities were 81.1%, 66.1, 72.7%, and 65.1%, respectively; and the accuracies were 77.8%, 66.5%, 72.5%, and 67%, respectively. We discovered that the maximum D-dimer level contributed the most to the outcome prediction, followed by the extreme growth rate of the plasma fibrinogen level, in-hospital duration, and extreme growth rate of the D-dimer level. The study demonstrates the superiority of the GBDT model in predicting the risk of PE in hospitalized patients. However, in order to be applied in clinical practice and provide support for clinical decision-making, the predictive performance of the model needs to be prospectively verified.",0,0
1617,"Imaging sub-diffuse optical properties of cancerous and normal skin tissue using machine learning-aided spatial frequency domain imaging. Sub-diffuse optical properties may serve as useful cancer biomarkers, and wide-field heatmaps of these properties could aid physicians in identifying cancerous tissue. Sub-diffuse spatial frequency domain imaging (sd-SFDI) can reveal such wide-field maps, but the current time cost of experimentally validated methods for rendering these heatmaps precludes this technology from potential real-time applications.",0,0
1619,Performance of a 3D convolutional neural network in the detection of hypoperfusion at CT pulmonary angiography in patients with chronic pulmonary embolism: a feasibility study. Chronic pulmonary embolism (CPE) is a life-threatening disease easily misdiagnosed on computed tomography. We investigated a three-dimensional convolutional neural network (CNN) algorithm for detecting hypoperfusion in CPE from computed tomography pulmonary angiography (CTPA).,0,0
1624,"Prediction of Mental Health in Medical Workers During COVID-19 Based on Machine Learning. Mental health prediction is one of the most essential parts of reducing the probability of serious mental illness. Meanwhile, mental health prediction can provide a theoretical basis for public health department to work out psychological intervention plans for medical workers. The purpose of this paper is to predict mental health of medical workers based on machine learning by 32 factors. We collected the 32 factors of 5,108 Chinese medical workers through questionnaire survey, and the results of Self-reporting Inventory was applied to characterize mental health. In this study, we propose a novel prediction model based on optimization algorithm and neural network, which can select and rank the most important factors that affect mental health of medical workers. Besides, we use stepwise logistic regression, binary bat algorithm, hybrid improved dragonfly algorithm and the proposed prediction model to predict mental health of medical workers. The results show that the prediction accuracy of the proposed model is 92.55%, which is better than the existing algorithms. This method can be used to predict mental health of global medical worker. In addition, the method proposed in this paper can also play a role in the appropriate work plan for medical worker.",0,0
1626,Preoperative Prediction of Microvascular Invasion in Patients With Hepatocellular Carcinoma Based on Radiomics Nomogram Using Contrast-Enhanced Ultrasound. This study aimed to develop a radiomics nomogram based on contrast-enhanced ultrasound (CEUS) for preoperatively assessing microvascular invasion (MVI) in hepatocellular carcinoma (HCC) patients.,0,0
1635,"Quantifying Voice Characteristics for Detecting Autism. The presence of prosodic anomalies in autistic is recognized by experienced clinicians but their quantitative analysis is a cumbersome task beyond the scope of typical pen and pencil assessment. This paper proposes an automatic approach allowing to tease apart various aspects of prosodic abnormalities and to translate them into fine-grained, automated, and quantifiable measurements. Using a harmonic model (HM) of voiced signal, we isolated the harmonic content of speech and computed a set of quantities related to harmonic content. Employing these measures, along with standard speech measures such as loudness, we successfully trained machine learning models for distinguishing individuals with autism from those with typical development (TD). We evaluated our models empirically on a task of detecting autism on a sample of 118 youth (90 diagnosed with autism and 28 controls; mean age: 10.9 years) and demonstrated that these models perform significantly better than a chance model. Voice and speech analyses could be incorporated as novel outcome measures for treatment research and used for early detection of autism in preverbal infants or toddlers at risk of autism.",0,0
1638,"Operational Determination of Subjective Cognitive Decline, Mild Cognitive Impairment, and Dementia Using Sum of Boxes of the Clinical Dementia Rating Scale. <b>Objectives:</b> The Clinical Dementia Rating (CDR) Scale is the gold standard for the staging of dementia due to Alzheimer's disease (AD). However, the application of CDR for the staging of subjective cognitive decline (SCD) and mild cognitive impairment (MCI) in AD remains controversial. This study aimed to use the sum of boxes of the CDR (CDR-SB) plus an SCD single questionnaire to operationally determine the different stages of cognitive impairment (CI) due to AD and non-AD. <b>Methods:</b> This was a two-phase study, and we retrospectively analyzed the Show Chwan Dementia registry database using the data selected from 2015 to 2020. Individuals with normal cognition (NC), SCD, MCI, and mild dementia (MD) due to AD or non-AD with a CDR < 2 were included in the analysis. <b>Results:</b> A total of 6,946 individuals were studied, including 875, 1,009, 1,585, and 3,447 with NC, SCD, MCI, and MD, respectively. The cutoff scores of CDR-SB for NC/SCD, SCD/MCI, and MCI/dementia were 0/0.5, 0.5/1.0, and 2.5/3.0, respectively. The receiver operating characteristic (ROC) analysis showed that the area under the curve (AUC) values of the test groups were 0.85, 0.90, and 0.92 for discriminating NC from SCD, SCD from MCI, and MCI from dementia, respectively. Compared with the Cognitive Abilities Screening Instrument or the Montreal Cognitive Assessment, the use of CDR-SB is less influenced by age and education. <b>Conclusion:</b> Our study showed that the operational determination of SCD, MCI, and dementia using the CDR-SB is practical and can be applied in clinical settings and research on CI or dementia.",0,0
1641,"The Vital Role of Central Executive Network in Brain Age: Evidence From Machine Learning and Transcriptional Signatures. Recent studies combining neuroimaging with machine learning methods successfully infer an individual's brain age, and its discrepancy with the chronological age is used to identify age-related diseases. However, which brain networks play decisive roles in brain age prediction and the underlying biological basis of brain age remain unknown. To answer these questions, we estimated an individual's brain age in the Southwest University Adult Lifespan Dataset (<i>N</i> = 492) from the gray matter volumes (GMV) derived from T1-weighted MRI scans by means of Gaussian process regression. Computational lesion analysis was performed to determine the importance of each brain network in brain age prediction. Then, we identified brain age-related genes by using prior brain-wide gene expression data, followed by gene enrichment analysis using Metascape. As a result, the prediction model successfully inferred an individual's brain age and the computational lesion prediction results identified the central executive network as a vital network in brain age prediction (Steiger's <i>Z</i> = 2.114, <i>p</i> = 0.035). In addition, the brain age-related genes were enriched in Gene Ontology (GO) processes/Kyoto Encyclopedia of Genes and Genomes (KEGG) pathways grouped into numbers of clusters, such as regulation of iron transmembrane transport, synaptic signaling, synapse organization, retrograde endocannabinoid signaling (e.g., dopaminergic synapse), behavior (e.g., memory and associative learning), neurotransmitter secretion, and dendrite development. In all, these results reveal that the GMV of the central executive network played a vital role in predicting brain age and bridged the gap between transcriptome and neuroimaging promoting an integrative understanding of the pathophysiology of brain age.",0,0
1642,Predicting Motor Outcome of Subthalamic Nucleus Deep Brain Stimulation for Parkinson's Disease Using Quantitative Susceptibility Mapping and Radiomics: A Pilot Study. Emerging evidence indicates that iron distribution is heterogeneous within the substantia nigra (SN) and it may reflect patient-specific trait of Parkinson's Disease (PD). We assume it could account for variability in motor outcome of subthalamic nucleus deep brain stimulation (STN-DBS) in PD.,0,0
1643,"Deep Learning-Based Assessment of Brain Connectivity Related to Obstructive Sleep Apnea and Daytime Sleepiness. Obstructive sleep apnea (OSA) is associated with altered pairwise connections between brain regions, which might explain cognitive impairment and daytime sleepiness. By adopting a deep learning method, we investigated brain connectivity related to the severity of OSA and daytime sleepiness.",0,0
1646,"Genetic mutation and biological pathway prediction based on whole slide images in breast carcinoma using deep learning. Breast carcinoma is the most common cancer among women worldwide that consists of a heterogeneous group of subtype diseases. The whole-slide images (WSIs) can capture the cell-level heterogeneity, and are routinely used for cancer diagnosis by pathologists. However, key driver genetic mutations related to targeted therapies are identified by genomic analysis like high-throughput molecular profiling. In this study, we develop a deep-learning model to predict the genetic mutations and biological pathway activities directly from WSIs. Our study offers unique insights into WSI visual interactions between mutation and its related pathway, enabling a head-to-head comparison to reinforce our major findings. Using the histopathology images from the Genomic Data Commons Database, our model can predict the point mutations of six important genes (AUC 0.68-0.85) and copy number alteration of another six genes (AUC 0.69-0.79). Additionally, the trained models can predict the activities of three out of ten canonical pathways (AUC 0.65-0.79). Next, we visualized the weight maps of tumor tiles in WSI to understand the decision-making process of deep-learning models via a self-attention mechanism. We further validated our models on liver and lung cancers that are related to metastatic breast cancer. Our results provide insights into the association between pathological image features, molecular outcomes, and targeted therapies for breast cancer patients.",0,0
1648,"Using machine learning for predicting intensive care unit resource use during the COVID-19 pandemic in Denmark. The COVID-19 pandemic has put massive strains on hospitals, and tools to guide hospital planners in resource allocation during the ebbs and flows of the pandemic are urgently needed. We investigate whether machine learning (ML) can be used for predictions of intensive care requirements a fixed number of days into the future. Retrospective design where health Records from 42,526 SARS-CoV-2 positive patients in Denmark was extracted. Random Forest (RF) models were trained to predict risk of ICU admission and use of mechanical ventilation after n days (nâ€‰=â€‰1, 2, â€¦, 15). An extended analysis was provided for nâ€‰=â€‰5 and nâ€‰=â€‰10. Models predicted n-day risk of ICU admission with an area under the receiver operator characteristic curve (ROC-AUC) between 0.981 and 0.995, and n-day risk of use of ventilation with an ROC-AUC between 0.982 and 0.997. The corresponding n-day forecasting models predicted the needed ICU capacity with a coefficient of determination (R<sup>2</sup>) between 0.334 and 0.989 and use of ventilation with an R<sup>2</sup> between 0.446 and 0.973. The forecasting models performed worst, when forecasting many days into the future (for large n). For nâ€‰=â€‰5, ICU capacity was predicted with ROC-AUC 0.990 and R<sup>2</sup> 0.928, and use of ventilator was predicted with ROC-AUC 0.994 and R<sup>2</sup> 0.854. Random Forest-based modelling can be used for accurate n-day forecasting predictions of ICU resource requirements, when n is not too large.",0,0
1650,"Predicting medication adherence using ensemble learning and deep learning models with large scale healthcare data. Clinical studies from WHO have demonstrated that only 50-70% of patients adhere properly to prescribed drug therapy. Such adherence failure can impact therapeutic efficacy for the patients in question and compromises data quality around the population-level efficacy of the drug for the indications targeted. In this study, we applied various ensemble learning and deep learning models to predict medication adherence among patients. Our contribution to this endeavour involves targeting the problem of adherence prediction for a particularly challenging class of patients who self-administer injectable medication at home. Our prediction pipeline, based on event history, comprises a connected sharps bin which aims to help patients better manage their condition and improve outcomes. In other words, the efficiency of interventions can be significantly improved by prioritizing the patients who are most likely to be non-adherent. The collected data comprising a rich event feature set may be exploited for the purposes of predicting the status of the next adherence state for individual patients. This paper reports on how this concept can be realized through an investigation using a wide range of ensemble learning and deep learning models on a real-world dataset collected from such a system. The dataset investigated comprises 342,174 historic injection disposal records collected over the course of more than 5 years. A comprehensive comparison of different models is given in this paper. Moreover, we demonstrate that the selected best performer, long short-term memory (LSTM), generalizes well by deploying it in a true future testing dataset. The proposed end-to-end pipeline is capable of predicting patient failure in adhering to their therapeutic regimen with 77.35 % accuracy (Specificity: 78.28 %, Sensitivity: 76.42%, Precision: 77.87%,F1 score: 0.7714, ROC AUC: 0.8390).",0,0
1652,"Prediction of blood supply in vestibular schwannomas using radiomics machine learning classifiers. This study attempts to explore the radiomics-based features of multi-parametric magnetic resonance imaging (MRI) and construct a machine-learning model to predict the blood supply in vestibular schwannoma preoperatively. By retrospectively collecting the preoperative MRI data of patients with vestibular schwannoma, patients were divided into poor and rich blood supply groups according to the intraoperative recording. Patients were divided into training and test cohorts (2:1), randomly. Stable features were retained by intra-group correlation coefficients (ICCs). Four feature selection methods and four classification methods were evaluated to construct favorable radiomics classifiers. The mean area under the curve (AUC) obtained in the test set for different combinations of feature selecting methods and classifiers was calculated separately to compare the performance of the models. Obtain and compare the best combination results with the performance of differentiation through visual observation in clinical diagnosis. 191 patients were included in this study. 3918 stable features were extracted from each patient. Least absolute shrinkage and selection operator (LASSO) and logistic regression model was selected as the optimal combinations after comparing the AUC calculated by models, which predicted the blood supply of vestibular schwannoma by K-Fold cross-validation method with a mean AUCâ€‰=â€‰0.88 and F1-scoreâ€‰=â€‰0.83. Radiomics machine-learning classifiers can accurately predict the blood supply of vestibular schwannoma by preoperative MRI data.",0,0
1654,"Risk prediction of clinical adverse outcomes with machine learning in a cohort of critically ill patients with atrial fibrillation. Critically ill patients affected by atrial fibrillation are at high risk of adverse events: however, the actual risk stratification models for haemorrhagic and thrombotic events are not validated in a critical care setting. With this paper we aimed to identify, adopting topological data analysis, the risk factors for therapeutic failure (in-hospital death or intensive care unit transfer), the in-hospital occurrence of stroke/TIA and major bleeding in a cohort of critically ill patients with pre-existing atrial fibrillation admitted to a stepdown unit; to engineer newer prediction models based on machine learning in the same cohort. We selected all medical patients admitted for critical illness and a history of pre-existing atrial fibrillation in the timeframe 01/01/2002-03/08/2007. All data regarding patients' medical history, comorbidities, drugs adopted, vital parameters and outcomes (therapeutic failure, stroke/TIA and major bleeding) were acquired from electronic medical records. Risk factors for each outcome were analyzed adopting topological data analysis. Machine learning was used to generate three different predictive models. We were able to identify specific risk factors and to engineer dedicated clinical prediction models for therapeutic failure (AUC: 0.974, 95%CI: 0.934-0.975), stroke/TIA (AUC: 0.931, 95%CI: 0.896-0.940; Brier score: 0.13) and major bleeding (AUC: 0.930:0.911-0.939; Brier score: 0.09) in critically-ill patients, which were able to predict accurately their respective clinical outcomes. Topological data analysis and machine learning techniques represent a concrete viewpoint for the physician to predict the risk at the patients' level, aiding the selection of the best therapeutic strategy in critically ill patients affected by pre-existing atrial fibrillation.",0,0
1655,"Combining multi-site magnetic resonance imaging with machine learning predicts survival in pediatric brain tumors. Brain tumors represent the highest cause of mortality in the pediatric oncological population. Diagnosis is commonly performed with magnetic resonance imaging. Survival biomarkers are challenging to identify due to the relatively low numbers of individual tumor types. 69 children with biopsy-confirmed brain tumors were recruited into this study. All participants had perfusion and diffusion weighted imaging performed at diagnosis. Imaging data were processed using conventional methods, and a Bayesian survival analysis performed. Unsupervised and supervised machine learning were performed with the survival features, to determine novel sub-groups related to survival. Sub-group analysis was undertaken to understand differences in imaging features. Survival analysis showed that a combination of diffusion and perfusion imaging were able to determine two novel sub-groups of brain tumors with different survival characteristics (pâ€‰<â€‰0.01), which were subsequently classified with high accuracy (98%) by a neural network. Analysis of high-grade tumors showed a marked difference in survival (pâ€‰=â€‰0.029) between the two clusters with high risk and low risk imaging features. This study has developed a novel model of survival for pediatric brain tumors. Tumor perfusion plays a key role in determining survival and should be considered as a high priority for future imaging protocols.",0,0
1664,Machine Learning Identifies Clinical Parameters to Predict Mortality in Patients Undergoing Transcatheter MitralÂ Valve Repair. The aim of this study was to develop a machine learning (ML)-based risk stratification tool for 1-year mortality in transcatheter mitral valve repair (TMVR) patients incorporating metabolic and hemodynamic parameters.,0,0
1666,"Extended classifier system with continuous real-coded variables for feature extraction of instantaneous pulse-rate variability and respiration of individuals with gaming disorder. Individuals with gaming disorder (GD) exhibit autonomic nervous system responses that indicate dysfunctional emotion regulation. Pulse rate variability (PRV) is a valuable biomarker for investigating the autonomic function of patients with mental disorders. Because individuals with GD dynamically regulate emotions during gaming, the PRV response relating to GD is not well understood. To investigate the dynamic PRV responses of individuals with GD, this study proposed the indexes of instantaneous PRV (iPRV) and instantaneous respiratory frequency (IF<sub>resp</sub>) of arterial blood pressure signals using empirical mode decomposition and normalized direct-quadrature algorithms. iPRV consists of low-frequency (LF), high-frequency (HF), and very high-frequency (VHF) bands. Moreover, a novel method of extended classifier system with continuous real-coded variables (XCSR) was used to detect GD and extract GD-related iPRV features using iPRV and IF<sub>resp</sub> as input data.",0,0
1667,"A 2D-3D hybrid convolutional neural network for lung lobe auto-segmentation on standard slice thickness computed tomography of patients receiving radiotherapy. Accurate segmentation of lung lobe on routine computed tomography (CT) images of locally advanced stage lung cancer patients undergoing radiotherapy can help radiation oncologists to implement lobar-level treatment planning, dose assessment and efficacy prediction. We aim to establish a novel 2D-3D hybrid convolutional neural network (CNN) to provide reliable lung lobe auto-segmentation results in the clinical setting.",0,0
1669,"Machine learning-based scoring models to predict hematopoietic stem cell mobilization in allogeneic donors. Mobilized peripheral blood has become the primary source of hematopoietic stem cells for both autologous and allogeneic stem cell transplantation. Granulocyte Colony-Stimulating Factor (G-CSF) is currently the standard agent used in the allogeneic setting. Despite the high mobilization efficacy in most donors, G-CSF requires 4-5 days of daily administration, and a small percentage of the donors fail to mobilize an optimal number of stem cells necessary for a safe allogeneic stem cell transplant. In this study, we retrospectively reviewed 1361 related allogeneic donors who underwent stem cell mobilization at Washington University. We compared the standard mobilization agent G-CSF with five alternative mobilization regimens, including GM-CSF, G-CSF+GM-CSF, GM-CSF + Plerixafor, Plerixafor and BL-8040. Cytokine-based mobilization strategies (G-CSF or in combination with GM-CSF) induce higher CD34 cell yield after 4-5 consecutive days of treatment, while CXCR4 antagonists (plerixafor and BL-8040) induce significantly less but rapid mobilization on the same day. Next, using a large dataset containing the demographic and baseline laboratory data from G-CSF-mobilized donors, we established machine learning (ML)-based scoring models that can be used to predict patients who may have less than optimal stem cell yields after a single leukapheresis session. To our knowledge, this is the first prediction model at the early donor screening stage, which may help identify allogeneic stem cell donors who may benefit from alternative approaches to enhance stem cell yields thus insuring safe and effective stem cell transplantation.",0,0
1671,Detection of ataxia in low disability MS patients by hybrid convolutional neural networks based on images of plantar pressure distribution. This study aimed to detect ataxia in patients with multiple sclerosis (PwMS) with a deep learning-based approach based on images showing plantar pressure distribution of the patients. The secondary aim of the study was to investigate an alternative and objective method in the early diagnosis of ataxia in these patients.,0,0
1673,"Deep learning analysis and age prediction from shoeprints. Human gaits are the patterns of limb movements which involve both the upper and lower body parts. These patterns in terms of step rate, gait speed, stance widening, stride, and bipedal forces are influenced by different factors including environmental (such as social, cultural, and behavioral traits) and physical changes (such as age and health status). These factors are reflected on the imprinted shoeprints generated with body forces, which in turn can be used to predict age, a problem not systematically addressed using any computational approach. We collected 100,000 shoeprints of subjects ranging from 7 to 80 years old and used the data to develop a deep learning end-to-end model ShoeNet to analyze age-related patterns and predict age. The model integrates various convolutional neural network models together using a skip mechanism to extract age-related features, especially in pressure and abrasion regions from pair-wise shoeprints. The results show that 40.23% of the subjects had prediction errors within 5-years of age and the prediction accuracy for gender/sex classification reached 86.07%. Interestingly, the age-related features mostly reside in the asymmetric differences between left and right shoeprints. The analysis also reveals interesting age-related and gender-related patterns in the pressure distributions on shoeprints; in particular, the pressure forces spread from the middle of the toe toward outside regions over age with gender-specific variations of forces on heel regions. Such statistics provide insight into new methods for forensic investigations, medical studies of gait pattern disorders, biometrics, and sport studies.",0,0
1674,"Using synthetic data generation to train a cardiac motion tag tracking neural network. A CNN based method for cardiac MRI tag tracking was developed and validated. A synthetic data simulator was created to generate large amounts of training data using natural images, a Bloch equation simulation, a broad range of tissue properties, and programmed ground-truth motion. The method was validated using both an analytical deforming cardiac phantom and in vivo data with manually tracked reference motion paths. In the analytical phantom, error was investigated relative to SNR, and accurate results were seen for SNR>10 (displacement error <0.3Â mm). Excellent agreement was seen in vivo for tag locations (mean displacement difference = -0.02Â pixels, 95% CI [-0.73, 0.69]) and calculated cardiac circumferential strain (mean difference = 0.006, 95% CI [-0.012, 0.024]). Automated tag tracking with a CNN trained on synthetic data is both accurate and precise.",0,0
1676,"Lightweight deep neural networks for cholelithiasis and cholecystitis detection by point-of-care ultrasound. Emergency physicians (EPs) frequently deal with abdominal pain, including that is caused by either gallstones or acute cholecystitis. Easy access and low cost justify point-of-care ultrasound (POCUS) use as a first-line test to detect these diseases; yet, the detection performance of POCUS by EPs is unreliable, causing misdiagnoses with serious impacts. This study aimed to develop a machine learning system to detect and localize gallstones and to detect acute cholecystitis by ultrasound (US) still images taken by physicians or technicians for preliminary diagnoses.",0,0
1677,"Using machine learning methods to predict hepatic encephalopathy in cirrhotic patients with unbalanced data. Hepatic encephalopathy (HE) is among the most common complications of cirrhosis. Data for cirrhosis with HE is typically unbalanced. Traditional statistical methods and machine learning algorithms thus cannot identify a few classes. In this paper, we use machine learning algorithms to construct a risk prediction model for liver cirrhosis complicated by HE to improve the efficiency of its prediction.",0,0
1680,"Multi-Class brain normality and abnormality diagnosis using modified Faster R-CNN. The detection and analysis of brain disorders through medical imaging techniques are extremely important to get treatment on time and sustain a healthy lifestyle. Disorders cause permanent brain damage and alleviate the lifespan. Moreover, the classification of large volumes of medical image data manually by medicine experts is tiring, time-consuming, and prone to errors. This study aims to diagnose brain normality and abnormalities using a novel ResNet50 modified Faster Regions with Convolutional Neural Network(R-CNN) model. The classification task is performed into multiple classes which are hemorrhage, hydrocephalus, and normal. The proposed model both determines the borders of the normal/abnormal parts and classifies them with the highest accuracy.",0,0
1683,"Predicting fracture outcomes from clinical registry data using artificial intelligence supplemented models for evidence-informed treatment (PRAISE) study protocol. Distal radius (wrist) fractures are the second most common fracture admitted to hospital. The anatomical pattern of these types of injuries is diverse, with variation in clinical management, guidelines for management remain inconclusive, and the uptake of findings from clinical trials into routine practice limited. Robust predictive modelling, which considers both the characteristics of the fracture and patient, provides the best opportunity to reduce variation in care and improve patient outcomes. This type of data is housed in unstructured data sources with no particular format or schema. The ""Predicting fracture outcomes from clinical Registry data using Artificial Intelligence (AI) Supplemented models for Evidence-informed treatment (PRAISE)"" study aims to use AI methods on unstructured data to describe the fracture characteristics and test if using this information improves identification of key fracture characteristics and prediction of patient-reported outcome measures and clinical outcomes following wrist fractures compared to prediction models based on standard registry data.",0,0
1693,Intelligent quantitative assessment of skeletal maturation based on multi-stage model: a retrospective cone-beam CT study of cervical vertebrae. To develop new logistic regression estimative models of the cervical vertebral maturation index (CVMI) based on cone-beam CT (CBCT)-derived parameters for intelligent evaluating skeletal maturation.,0,0
1695,"A novel, simple, and accurate pulse oximetry indicator for screening adult obstructive sleep apnea. The objective of the study was to develop a multiparametric oximetry indicator (IMp-SpO2) to diagnose obstructive sleep apnea in adults.",0,0
1698,"Clinical decision support for severe trauma patients : Machine Learning based definition of a bundle of care for Hemorrhagic Shock and Traumatic Brain Injury. Deviation from guidelines is frequent in emergency situations and this may lead to increased mortality. Probably because of time constraints, 55% is the greatest reported guidelines compliance rate in severe trauma patients. This study aimed to identify among all available recommendations a reasonable bundle of items that should be followed to optimize the outcome of hemorrhagic shocks (HS) and severe traumatic brain injuries (TBI).",0,0
1699,"The Derivation of an ICD-10-based Trauma-related Mortality Model Utilizing Machine Learning. Existing mortality prediction models have attempted to quantify injury burden following trauma-related admissions with the most notable being the Injury Severity Score (ISS). Although easy to calculate, it requires additional administrative coding. International Classification of Diseases (ICD)-based models such as the Trauma Mortality Prediction Model (TMPM-ICD10) circumvent these limitations, but they utilize linear modeling which may not adequately capture the intricate relationships of injuries on mortality. Using ICD-10 coding and machine learning algorithms, the present study utilized the National Trauma Data Bank (NTDB) to develop mortality prediction models whose performance was compared to logistic regression, ISS and TMPM-ICD10.",0,0
1702,"A random forest model based on core genome allelic profiles of MRSA for penicillin plus potassium clavulanate susceptibility prediction. Treatment failure of methicillin-resistant <i>Staphylococcus aureus</i> (MRSA) infections remains problematic in clinical practice because therapeutic options are limited. Penicillin plus potassium clavulanate combination (PENC) was shown to have potential for treating some MRSA infections. We investigated the susceptibility of MRSA isolates and constructed a drug susceptibility prediction model for the phenotype of the PENC. We determined the minimum inhibitory concentration of PENC for MRSA (<i>n</i>=284) in a teaching hospital (SRRSH-MRSA). PENC susceptibility genotypes were analysed using a published genotyping scheme based on the <i>mecA</i> sequence. <i>mecA</i> expression in MRSA isolates was analysed by qPCR. We established a random forest model for predicting PENC-susceptible phenotypes using core genome allelic profiles from cgMLST analysis. We identified S2-R isolates with susceptible <i>mecA</i> genotypes but PENC-resistant phenotypes; these isolates expressed <i>mecA</i> at higher levels than did S2 MRSA (2.61 vs 0.98, <i>P</i><0.05), indicating the limitation of using a single factor for predicting drug susceptibility. Using the data of selected UK-sourced MRSA (<i>n</i>=74) and MRSA collected in a previous national survey (NA-MRSA, <i>n</i>=471) as a training set, we built a model with accuracies of 0.94 and 0.93 for SRRSH-MRSA and UK-sourced MRSA (<i>n</i>=287, NAM-MRSA) validation sets. The AUROC of this model for SRRSH-MRSA and NAM-MRSA was 0.96 and 0.97. Although the source of the training set data affects the scope of application of the prediction model, our data demonstrated the power of the machine learning approach in predicting susceptibility from cgMLST results.",0,0
1708,"Extrinsic parameter's adjustment and potential implications in Plasmodium falciparum malaria diagnosis. Malaria is a major public health concern, affecting over 3.2 billion people in 91 countries. The advent of digital microscopy and Machine learning with the aim of automating Plasmodium falciparum diagnosis extensively depends on the extracted image features. The color of the cells, plasma, and stained artifacts influence the topological, geometrical, and statistical parameters being used to extract image features. During microscopic image acquisition, custom adjustments to the condenser and color temperature controls often have an influence on the extracted statistical features. But, our human visual system sub-consciously adjusts the color and retains the originality in a different lighting environment. Despite the use of appropriate image preprocessing, findings from the literature indicate that statistical feature variations exist, allowing the risk of P. falciparum misinterpretation. In order to eliminate this pervasive variation, the current work focuses on preprocessing the extracted statistical features rather than the prepossessing of the source image. It begins with the augmentation of series images for a microscopic field by inducing illumination variations during the microscopic image acquisition stage. A set of such image series is analyzed using a Nonlinear Regression Model to generalize the relationship between microscopic images acquired with variable ambient brightness and a specific feature. The projection point of the centroid feature onto the brightness parameter is identified in the model and it is denoted as the optimum brightness factor (OBF). Using the model, the feature correction factor (CF) is calculated from the rate of change of feature values over the interval OBF, and the brightness of the test image is processed. The present work has investigated OBF for selected image textural features, namely Contrast, Homogeneity, Entropy, Energy, and Correlation individually from its co-occurrence matrices. For performance analysis, the best state-of-the-art method uses selected texture as a subset feature to evaluate the effectiveness of P. falciparum malaria classification. Then, the impact of proposed feature processing is evaluated on 274 blood smear images with and without Feature Correction (FC). As a result, the ""p"" value is less than .05, which leads to the result that it is highly significant and the classification accuracy and F-score of P. falciparum malaria are increased.",0,0
1709,"Fully Automated Placental Volume Quantification From 3DUS for Prediction of Small-for-Gestational-Age Infants. Early placental volume (PV) has been associated with small-for-gestational-age infants born under the 10th/5th centiles (SGA10/SGA5). Manual or semiautomated PV quantification from 3D ultrasound (3DUS) is time intensive, limiting its incorporation into clinical care. We devised a novel convolutional neural network (CNN) pipeline for fully automated placenta segmentation from 3DUS images, exploring the association between the calculated PV and SGA.",0,0
1717,Developing a machine learning model to identify delirium risk in geriatric internal medicine inpatients. To develop a machine learning model that predicts delirium risk in geriatric internal medicine inpatients.,0,0
1718,"A deep-learning model for identifying fresh vertebral compression fractures on digital radiography. To develop a deep-learning (DL) model for identifying fresh VCFs from digital radiography (DR), with magnetic resonance imaging (MRI) as the reference standard.",0,0
1721,"Phe2vec: Automated disease phenotyping based on unsupervised embeddings from electronic health records. Robust phenotyping of patients from electronic health records (EHRs) at scale is a challenge in clinical informatics. Here, we introduce Phe2vec, an automated framework for disease phenotyping from EHRs based on unsupervised learning and assess its effectiveness against standard rule-based algorithms from Phenotype KnowledgeBase (PheKB). Phe2vec is based on pre-computing embeddings of medical concepts and patients' clinical history. Disease phenotypes are then derived from a seed concept and its neighbors in the embedding space. Patients are linked to a disease if their embedded representation is close to the disease phenotype. Comparing Phe2vec and PheKB cohorts head-to-head using chart review, Phe2vec performed on par or better in nine out of ten diseases. Differently from other approaches, it can scale to any condition and was validated against widely adopted expert-based standards. Phe2vec aims to optimize clinical informatics research by augmenting current frameworks to characterize patients by condition and derive reliable disease cohorts.",0,0
1732,"Deep Learning-Based CT Imaging in Diagnosing Myeloma and Its Prognosis Evaluation. Imaging examination plays an important role in the early diagnosis of myeloma. The study focused on the segmentation effects of deep learning-based models on CT images for myeloma, and the influence of different chemotherapy treatments on the prognosis of patients. Specifically, 186 patients with suspected myeloma were the research subjects. The U-Net model was adjusted to segment the CT images, and then, the Faster region convolutional neural network (RCNN) model was used to label the lesions. Patients were divided into bortezomib group (group 1, <i>n</i>â€‰=â€‰128) and non-bortezomib group (group 2, <i>n</i>â€‰=â€‰58). The biochemical indexes, blood routine indexes, and skeletal muscle of the two groups were compared before and after chemotherapy. The results showed that the improved U-Net model demonstrated good segmentation results, the Faster RCNN model can realize the labeling of the lesion area in the CT image, and the classification accuracy rate was as high as 99%. Compared with group 1, group 2 showed enlarged psoas major and erector spinae muscle after treatment and decreased bone marrow plasma cells content, blood M protein, urine 24â€‰h light chain, pBNP, <i>ÃŸ</i>-2 microglobulin (<i>Î²</i>2MG), ALP, and white blood cell (WBC) levels (<i>P</i> < 0.05). In conclusion, deep learning is suggested in the segmentation and classification of CT images for myeloma, which can lift the detection accuracy. Two different chemotherapy regimens both improve the prognosis of patients, but the effects of non-bortezomib chemotherapy are better.",0,0
1733,"High-Efficiency Classification of White Blood Cells Based on Object Detection. White blood cells (WBCs) play a significant role in the human immune system, and the content of various subtypes of WBCs is usually maintained within a certain range in the human body, while deviant levels are important warning signs for diseases. Hence, the detection and classification of WBCs is an essential diagnostic technique. However, traditional WBC classification technologies based on image processing usually need to segment the collected target cell images from the background. This preprocessing operation not only increases the workload but also heavily affects the classification quality and efficiency. Therefore, we proposed one high-efficiency object detection technology that combines the segmentation and recognition of targets into one step to realize the detection and classification of WBCs in an image at the same time. Two state-of-the-art object detection models, Faster RCNN and Yolov4, were employed and comparatively studied to classify neutrophils, eosinophils, monocytes, and lymphocytes on a balanced and enhanced Blood Cell Count Dataset (BCCD). Our experimental results showed that the Faster RCNN and Yolov4 based deep transfer learning models achieved classification accuracy rates of 96.25% and 95.75%, respectively. For the one-stage model, Yolov4, while ensuring more than 95% accuracy, its detection speed could reach 60 FPS, which showed better performance compared with the two-stage model, Faster RCNN. The high-efficiency object detection network that does not require cell presegmentation can remove the difficulty of image preprocessing and greatly improve the efficiency of the entire classification task, which provides a potential solution for future real-time point-of-care diagnostic systems.",0,0
1734,"Evaluating Deep Neural Network Architectures with Transfer Learning for Pneumonitis Diagnosis. Pneumonitis is an infectious disease that causes the inflammation of the air sac. It can be life-threatening to the very young and elderly. Detection of pneumonitis from X-ray images is a significant challenge. Early detection and assistance with diagnosis can be crucial. Recent developments in the field of deep learning have significantly improved their performance in medical image analysis. The superior predictive performance of the deep learning methods makes them ideal for pneumonitis classification from chest X-ray images. However, training deep learning models can be cumbersome and resource-intensive. Reusing knowledge representations of public models trained on large-scale datasets through transfer learning can help alleviate these challenges. In this paper, we compare various image classification models based on transfer learning with well-known deep learning architectures. The Kaggle chest X-ray dataset was used to evaluate and compare our models. We apply basic data augmentation and fine-tune our feed-forward classification head on the models pretrained on the ImageNet dataset. We observed that the DenseNet201 model outperforms other models with an AUROC score of 0.966 and a recall score of 0.99. We also visualize the class activation maps from the DenseNet201 model to interpret the patterns recognized by the model for prediction.",0,0
1735,"Automatic Assessment of Mitral Regurgitation Severity Using the Mask R-CNN Algorithm with Color Doppler Echocardiography Images. Accurate assessment of mitral regurgitation (MR) severity is critical in clinical diagnosis and treatment. No single echocardiographic method has been recommended for MR quantification thus far. We sought to define the feasibility and accuracy of the mask regions with a convolutional neural network (Mask R-CNN) algorithm in the automatic qualitative evaluation of MR using color Doppler echocardiography images. The authors collected 1132 cases of MR from hospital A and 295 cases of MR from hospital B and divided them into the following four types according to the 2017 American Society of Echocardiography (ASE) guidelines: grade I (mild), grade II (moderate), grade III (moderate), and grade IV (severe). Both grade II and grade III are moderate. After image marking with the LabelMe software, a method using the Mask R-CNN algorithm based on deep learning (DL) was used to evaluate MR severity. We used the data from hospital A to build the artificial intelligence (AI) model and conduct internal verification, and we used the data from hospital B for external verification. According to severity, the accuracy of classification was 0.90, 0.89, and 0.91 for mild, moderate, and severe MR, respectively. The Macro F1 and Micro F1 coefficients were 0.91 and 0.92, respectively. According to grading, the accuracy of classification was 0.90, 0.87, 0.81, and 0.91 for grade I, grade II, grade III, and grade IV, respectively. The Macro F1 and Micro F1 coefficients were 0.89 and 0.89, respectively. Automatic assessment of MR severity is feasible with the Mask R-CNN algorithm and color Doppler electrocardiography images collected in accordance with the 2017 ASE guidelines, and the model demonstrates reasonable performance and provides reliable qualitative results for MR severity.",0,0
1741,"Multi-View Spectral Clustering Based on Multi-Smooth Representation Fusion for Cancer Subtype Prediction. It is a vital task to design an integrated machine learning model to discover cancer subtypes and understand the heterogeneity of cancer based on multiple omics data. In recent years, some multi-view clustering algorithms have been proposed and applied to the prediction of cancer subtypes. Among them, the multi-view clustering methods based on graph learning are widely concerned. These multi-view approaches usually have one or more of the following problems. Many multi-view algorithms use the original omics data matrix to construct the similarity matrix and ignore the learning of the similarity matrix. They separate the data clustering process from the graph learning process, resulting in a highly dependent clustering performance on the predefined graph. In the process of graph fusion, these methods simply take the average value of the affinity graph of multiple views to represent the result of the fusion graph, and the rich heterogeneous information is not fully utilized. To solve the above problems, in this paper, a Multi-view Spectral Clustering Based on Multi-smooth Representation Fusion (MRF-MSC) method was proposed. Firstly, MRF-MSC constructs a smooth representation for each data type, which can be viewed as a sample (patient) similarity matrix. The smooth representation can explicitly enhance the grouping effect. Secondly, MRF-MSC integrates the smooth representation of multiple omics data to form a similarity matrix containing all biological data information through graph fusion. In addition, MRF-MSC adaptively gives weight factors to the smooth regularization representation of each omics data by using the self-weighting method. Finally, MRF-MSC imposes constrained Laplacian rank on the fusion similarity matrix to get a better cluster structure. The above problems can be transformed into spectral clustering for solving, and the clustering results can be obtained. MRF-MSC unifies the above process of graph construction, graph fusion and spectral clustering under one framework, which can learn better data representation and high-quality graphs, so as to achieve better clustering effect. In the experiment, MRF-MSC obtained good experimental results on the TCGA cancer data sets.",0,0
1743,"Predicting Success of a Digital Self-Help Intervention for Alcohol and Substance Use With Machine Learning. Digital self-help interventions for reducing the use of alcohol tobacco and other drugs (ATOD) have generally shown positive but small effects in controlling substance use and improving the quality of life of participants. Nonetheless, low adherence rates remain a major drawback of these digital interventions, with mixed results in (prolonged) participation and outcome. To prevent non-adherence, we developed models to predict success in the early stages of an ATOD digital self-help intervention and explore the predictors associated with participant's goal achievement.",0,0
1744,"Natural Language Processing as an Emerging Tool to Detect Late-Life Depression. Late-life depression (LLD) is a major public health concern. Despite the availability of effective treatments for depression, barriers to screening and diagnosis still exist. The use of current standardized depression assessments can lead to underdiagnosis or misdiagnosis due to subjective symptom reporting and the distinct cognitive, psychomotor, and somatic features of LLD. To overcome these limitations, there has been a growing interest in the development of objective measures of depression using artificial intelligence (AI) technologies such as natural language processing (NLP). NLP approaches focus on the analysis of acoustic and linguistic aspects of human language derived from text and speech and can be integrated with machine learning approaches to classify depression and its severity. In this review, we will provide rationale for the use of NLP methods to study depression using speech, summarize previous research using NLP in LLD, compare findings to younger adults with depression and older adults with other clinical conditions, and discuss future directions including the use of complementary AI strategies to fully capture the spectrum of LLD.",0,0
1745,"Artificial Intelligence May Predict Early Sepsis After Liver Transplantation. <b>Background:</b> Sepsis, post-liver transplantation, is a frequent challenge that impacts patient outcomes. We aimed to develop an artificial intelligence method to predict the onset of post-operative sepsis earlier. <b>Methods:</b> This pilot study aimed to identify ""physiomarkers"" in continuous minute-by-minute physiologic data streams, such as heart rate, respiratory rate, oxygen saturation (SpO2), and blood pressure, to predict the onset of sepsis. The model was derived from a cohort of 5,748 transplant and non-transplant patients across intensive care units (ICUs) over 36 months, with 92 post-liver transplant patients who developed sepsis. <b>Results:</b> Using an alert timestamp generated with the Third International Consensus Definition of Sepsis (Sepsis-3) definition as a reference point, we studied up to 24 h of continuous physiologic data prior to the event, totaling to 8.35 million data points. One hundred fifty-five features were generated using signal processing and statistical methods. Feature selection identified 52 highly ranked features, many of which included blood pressures. An eXtreme Gradient Boost (XGB) classifier was then trained on the ranked features by 5-fold cross validation on all patients (<i>n</i> = 5,748). We identified that the average sensitivity, specificity, positive predictive value (PPV), and area under the receiver-operator curve (AUC) of the model after 100 iterations was 0.94 Â± 0.02, 0.9 Â± 0.02, 0.89 Â± 0.01, respectively, and 0.97 Â± 0.01 for predicting sepsis 12 h before meeting criteria. <b>Conclusion:</b> The data suggest that machine learning/deep learning can be applied to continuous streaming data in the transplant ICU to monitor patients and possibly predict sepsis.",0,0
1750,"Biologically informed deep neural network for prostate cancer discovery. The determination of molecular features that mediate clinically aggressive phenotypes in prostate cancer remains a major biological and clinical challenge<sup>1,2</sup>. Recent advances in interpretability of machine learning modelsÂ as applied to biomedical problems may enable discovery and prediction in clinical cancer genomics<sup>3-5</sup>. Here we developed P-NET-a biologically informed deep learning model-to stratify patients withÂ prostate cancer by treatment-resistance state and evaluate molecular drivers of treatment resistance for therapeutic targeting through complete model interpretability. We demonstrate that P-NET can predict cancer state using molecular data with a performance that is superior to other modelling approaches. Moreover, the biological interpretability within P-NET revealed established and novel molecularly altered candidates, such as MDM4 and FGFR1, which were implicated in predicting advanced disease and validated in vitro. Broadly, biologically informed fully interpretable neural networks enable preclinical discovery and clinical prediction in prostate cancer and may have general applicability across cancer types.",0,0
1752,"Machine learning and atherosclerotic cardiovascular disease risk prediction in a multi-ethnic population. The pooled cohort equations (PCE) predict atherosclerotic cardiovascular disease (ASCVD) risk in patients with characteristics within prespecified ranges and has uncertain performance among Asians or Hispanics. It is unknown if machine learning (ML) models can improve ASCVD risk prediction across broader diverse, real-world populations. We developed ML models for ASCVD risk prediction for multi-ethnic patients using an electronic health record (EHR) database from Northern California. Our cohort included patients aged 18 years or older with no prior CVD and not on statins at baseline (nâ€‰=â€‰262,923), stratified by PCE-eligible (nâ€‰=â€‰131,721) or PCE-ineligible patients based on missing or out-of-range variables. We trained ML models [logistic regression with L<sub>2</sub> penalty and L<sub>1</sub> lasso penalty, random forest, gradient boosting machine (GBM), extreme gradient boosting] and determined 5-year ASCVD risk prediction, including with and without incorporation of additional EHR variables, and in Asian and Hispanic subgroups. A total of 4309 patients had ASCVD events, with 2077 in PCE-ineligible patients. GBM performance in the full cohort, including PCE-ineligible patients (area under receiver-operating characteristic curve (AUC) 0.835, 95% confidence interval (CI): 0.825-0.846), was significantly better than that of the PCE in the PCE-eligible cohort (AUC 0.775, 95% CI: 0.755-0.794). Among patients aged 40-79, GBM performed similarly before (AUC 0.784, 95% CI: 0.759-0.808) and after (AUC 0.790, 95% CI: 0.765-0.814) incorporating additional EHR data. Overall, ML models achieved comparable or improved performance compared to the PCE while allowing risk discrimination in a larger group of patients including PCE-ineligible patients. EHR-trained ML models may help bridge important gaps in ASCVD risk prediction.",0,0
1754,"Multimodal deep learning models for the prediction of pathologic response to neoadjuvant chemotherapy in breast cancer. The achievement of the pathologic complete response (pCR) has been considered a metric for the success of neoadjuvant chemotherapy (NAC) and a powerful surrogate indicator of the risk of recurrence and long-term survival. This study aimed to develop a multimodal deep learning model that combined clinical information and pretreatment MR images for predicting pCR to NAC in patients with breast cancer. The retrospective study cohort consisted of 536 patients with invasive breast cancer who underwent pre-operative NAC. We developed a deep learning model to fuse high-dimensional MR image features and the clinical information for the pretreatment prediction of pCR to NAC in breast cancer. The proposed deep learning model trained on all datasets as clinical information, T1-weighted subtraction images, and T2-weighted images shows better performance with area under the curve (AUC) of 0.888 as compared to the model using only clinical information (AUCâ€‰=â€‰0.827, Pâ€‰<â€‰0.05). Our results demonstrate that the multimodal fusion approach using deep learning with both clinical information and MR images achieve higher prediction performance compared to the deep learning model without the fusion approach. Deep learning could integrate pretreatment MR images with clinical information to improve pCR prediction performance.",0,0
1755,"A genetic risk score using human chromosomal-scale length variation can predict schizophrenia. Studies indicate that schizophrenia has a genetic component, however it cannot be isolated to a single gene. We aimed to determine how well one could predict that a person will develop schizophrenia based on their germ line genetics. We compared 1129 people from the UK Biobank dataset who had a diagnosis of schizophrenia to an equal number of age matched people drawn from the general UK Biobank population. For each person, we constructed a profile consisting of numbers. Each number characterized the length of segments of chromosomes. We tested several machine learning algorithms to determine which was most effective in predicting schizophrenia and if any improvement in prediction occurs by breaking the chromosomes into smaller chunks. We found that the stacked ensemble, performed best with an area under the receiver operating characteristic curve (AUC) of 0.545 (95% CI 0.539-0.550). We noted an increase in the AUC by breaking the chromosomes into smaller chunks for analysis. Using SHAP values, we identified the X chromosome as the most important contributor to the predictive model. We conclude that germ line chromosomal scale length variation data could provide an effective genetic risk score for schizophrenia which performs better than chance.",0,0
1762,Use of artificial intelligence for public health surveillance: a case study to develop a machine Learning-algorithm to estimate the incidence of diabetes mellitus in France. The use of machine learning techniques is increasing in healthcare which allows to estimate and predict health outcomes from large administrative data sets more efficiently. The main objective of this study was to develop a generic machine learning (ML) algorithm to estimate the incidence of diabetes based on the number of reimbursements over the last 2â€‰years.,0,0
1763,Detection of shallow anterior chamber depth from two-dimensional anterior segment photographs using deep learning. The purpose of this study was to implement and evaluate a deep learning (DL) approach for automatically detecting shallow anterior chamber depth (ACD) from two-dimensional (2D) overview anterior segment photographs.,0,0
1764,"Non-small-cell lung cancer classification via RNA-Seq and histology imaging probability fusion. Adenocarcinoma and squamous cell carcinoma are the two most prevalent lung cancer types, and their distinction requires different screenings, such as the visual inspection of histology slides by an expert pathologist, the analysis of gene expression or computer tomography scans, among others. In recent years, there has been an increasing gathering of biological data for decision support systems in the diagnosis (e.g. histology imaging, next-generation sequencing technologies data, clinical information, etc.). Using all these sources to design integrative classification approaches may improve the final diagnosis of a patient, in the same way that doctors can use multiple types of screenings to reach a final decision on the diagnosis. In this work, we present a late fusion classification model using histology and RNA-Seq data for adenocarcinoma, squamous-cell carcinoma and healthy lung tissue.",0,0
1765,"Predicting chemotherapy response using a variational autoencoder approach. Multiple studies have shown the utility of transcriptome-wide RNA-seq profiles as features for machine learning-based prediction of response to chemotherapy in cancer. While tumor transcriptome profiles are publicly available for thousands of tumors for many cancer types, a relatively modest number of tumor profiles are clinically annotated for response to chemotherapy. The paucity of labeled examples and the high dimension of the feature data limit performance for predicting therapeutic response using fully-supervised classification methods. Recently, multiple studies have established the utility of a deep neural network approach, the variational autoencoder (VAE), for generating meaningful latent features from original data. Here, we report the first study of a semi-supervised approach using VAE-encoded tumor transcriptome features and regularized gradient boosted decision trees (XGBoost) to predict chemotherapy drug response for five cancer types: colon, pancreatic, bladder, breast, and sarcoma.",0,0
1768,Artificial Intelligence-Based Colorectal Polyp Histology Prediction by Using Narrow-Band Image-Magnifying Colonoscopy. We have been developing artificial intelligence based polyp histology prediction (AIPHP) method to classify Narrow Band Imaging (NBI) magnifying colonoscopy images to predict the hyperplastic or neoplastic histology of polyps. Our aim was to analyze the accuracy of AIPHP and narrow-band imaging international colorectal endoscopic (NICE) classification based histology predictions and also to compare the results of the two methods.,0,0
1769,"Bayesian supervised machine learning classification of neural networks with pathological perturbations. <i>Objective.</i>Extraction of temporal features of neuronal activity from electrophysiological data can be used for accurate classification of neural networks in healthy and pathologically perturbed conditions. In this study, we provide an extensive approach for the classification of human<i>in vitro</i>neural networks with and without an underlying pathology, from electrophysiological recordings obtained using a microelectrode array (MEA) platform.<i>Approach.</i>We developed a Dirichlet mixture (DM) Point Process statistical model able to extract temporal features related to neurons. We then applied a machine learning algorithm to discriminate between healthy control and pathologically perturbed<i>in vitro</i>neural networks.<i>Main Results.</i>We found a high degree of separability between the classes using DM point process features (p-value <0.001 for all the features, paired t-test), which reaches 93.10 of accuracy (92.37 of ROC AUC) with the Random Forest classifier. In particular, results show a higher latency in firing for pathologically perturbed neurons (43Â Â±Â 16 ms versus 67Â Â±Â 31 ms,Î¼IGfeature distribution).<i>Significance.</i>Our approach has been successful in extracting temporal features related to the neurons' behaviour, as well as distinguishing healthy from pathologically perturbed networks, including classification of responses to a transient induced perturbation.",0,0
1773,"Machine learning methods for automated classification of tumors with papillary thyroid carcinoma-like nuclei: A quantitative analysis. When approaching thyroid gland tumor classification, the differentiation between samples with and without ""papillary thyroid carcinoma-like"" nuclei is a daunting task with high inter-observer variability among pathologists. Thus, there is increasing interest in the use of machine learning approaches to provide pathologists real-time decision support. In this paper, we optimize and quantitatively compare two automated machine learning methods for thyroid gland tumor classification on two datasets to assist pathologists in decision-making regarding these methods and their parameters. The first method is a feature-based classification originating from common image processing and consists of cell nucleus segmentation, feature extraction, and subsequent thyroid gland tumor classification utilizing different classifiers. The second method is a deep learning-based classification which directly classifies the input images with a convolutional neural network without the need for cell nucleus segmentation. On the Tharun and Thompson dataset, the feature-based classification achieves an accuracy of 89.7% (Cohen's Kappa 0.79), compared to the deep learning-based classification of 89.1% (Cohen's Kappa 0.78). On the Nikiforov dataset, the feature-based classification achieves an accuracy of 83.5% (Cohen's Kappa 0.46) compared to the deep learning-based classification 77.4% (Cohen's Kappa 0.35). Thus, both automated thyroid tumor classification methods can reach the classification level of an expert pathologist. To our knowledge, this is the first study comparing feature-based and deep learning-based classification regarding their ability to classify samples with and without papillary thyroid carcinoma-like nuclei on two large-scale datasets.",0,0
1774,"Implementation of artificial intelligence algorithms for melanoma screening in a primary care setting. Skin cancer is currently the most common type of cancer among Caucasians. The increase in life expectancy, along with new diagnostic tools and treatments for skin cancer, has resulted in unprecedented changes in patient care and has generated a great burden on healthcare systems. Early detection of skin tumors is expected to reduce this burden. Artificial intelligence (AI) algorithms that support skin cancer diagnoses have been shown to perform at least as well as dermatologists' diagnoses. Recognizing the need for clinically and economically efficient means of diagnosing skin cancers at early stages in the primary care attention, we developed an efficient computer-aided diagnosis (CAD) system to be used by primary care physicians (PCP). Additionally, we developed a smartphone application with a protocol for data acquisition (i.e., photographs, demographic data and short clinical histories) and AI algorithms for clinical and dermoscopic image classification. For each lesion analyzed, a report is generated, showing the image of the suspected lesion and its respective Heat Map; the predicted probability of the suspected lesion being melanoma or malignant; the probable diagnosis based on that probability; and a suggestion on how the lesion should be managed. The accuracy of the dermoscopy model for melanoma was 89.3%, and for the clinical model, 84.7% with 0.91 and 0.89 sensitivity and 0.89 and 0.83 specificity, respectively. Both models achieved an area under the curve (AUC) above 0.9. Our CAD system can screen skin cancers to guide lesion management by PCPs, especially in the contexts where the access to the dermatologist can be difficult or time consuming. Its use can enable risk stratification of lesions and/or patients and dramatically improve timely access to specialist care for those requiring urgent attention.",1,1
1787,"A deep neural network approach for P300 detection-based BCI using single-channel EEG scalogram images. Brain-computer interfaces (BCIs) acquire electroencephalogram (EEG) signals and interpret them into a command that helps people with severe motor disabilities using single channel. The goal of BCI is to achieve a prototype that supports disabled people to develop the relevant function. Various studies have been implemented in the literature to achieve a superior design using multi-channel EEG signals. This paper proposed a novel framework for the automatic P300 detection-based BCI model using a single EEG electrode. In the present study, we introduced a denoising approach using the bandpass filter technique followed by the transformation of scalogram images using continuous wavelet transform. The derived images were trained and validated using a deep neural network based on the transfer learning approach. This paper presents a BCI model based on the deep network that delivers higher performance in terms of classification accuracy and bitrate for disabled subjects using a single-channel EEG signal. The proposed P300 based BCI model has the highest average information transfer rates of 13.23 to 26.48 bits/min for disabled subjects. The classification performance has shown that the deep network based on the transfer learning approach can offer comparable performance with other state-of-the-art-method.",0,0
1793,Preoperative Survival Prediction in Intrahepatic Cholangiocarcinoma Using a Ultrasound-Based Radiographic-Radiomics Signature. To construct a preoperative model for survival prediction in intrahepatic cholangiocarcinoma (ICC) patients using ultrasound (US) based radiographic-radiomics signatures.,0,0
1797,"Determinants of brain swelling in pediatric and adult cerebral malaria. Cerebral malaria (CM) affects children and adults, but brain swelling is more severe in children. To investigate features associated with brain swelling in malaria, we performed blood profiling and brain MRI in a cohort of pediatric and adult patients with CM in Rourkela, India, and compared them with an African pediatric CM cohort in Malawi. We determined that higher plasma Plasmodium falciparum histidine rich protein 2 (PfHRP2) levels and elevated var transcripts that encode for binding to endothelial protein C receptor (EPCR) were linked to CM at both sites. Machine learning models trained on the African pediatric cohort could classify brain swelling in Indian children CM cases but had weaker performance for adult classification, due to overall lower parasite var transcript levels in this age group and more severe thrombocytopenia in Rourkela adults. Subgrouping of patients with CM revealed higher parasite biomass linked to severe thrombocytopenia and higher Group A-EPCR var transcripts in mild thrombocytopenia. Overall, these findings provide evidence that higher parasite biomass and a subset of Group A-EPCR binding variants are common features in children and adult CM cases, despite age differences in brain swelling.",0,0
1799,"Use of classifiers to optimise the identification and characterisation of metastatic breast cancer in a nationwide administrative registry. The prognosis for patients with metastatic breast cancer (MBC) is substantially worse when compared with patients with earlier stage disease. Therefore, understanding the differences in epidemiology between these two patient groups is important. Studies using population-based cancer registries to identify MBC are hampered by the quality of reporting. Patients are registered once (at time of initial diagnosis); hence only data for patients with <i>de novo</i> MBC are identifiable, whereas data for patients with recurrent MBC are not. This makes accurate estimation of the epidemiology and healthcare utilisation of MBC challenging. This study aimed to investigate whether machine-learning could improve identification of MBC in national health registries.",0,0
1800,"Evaluation of a New Neural Network Classifier for Diabetic Retinopathy. Medical image segmentation is a well-studied subject within the field of image processing. The goal of this research is to create an AI retinal screening grading system that is both accurate and fast. We introduce a new segmentation network which achieves state-of-the-art results on semantic segmentation of color fundus photographs. By applying the net-work to identify anatomical markers of diabetic retinopathy (DR) and diabetic macular edema (DME), we collect sufficient information to classify patients by grades R0 and R1 or above, M0 and M1.",0,0
1801,"Integrating domain knowledge with machine learning to detect obstructive sleep apnea: Snore as a significant bio-feature. Our study's main purpose is to emphasise the significance of medical knowledge of pathophysiology before machine learning. We investigated whether combining domain knowledge with machine learning results might increase accuracy and minimise the number of bio-features used to detect obstructive sleep apnea (OSA). The present study analysed data on 36 self-reported symptoms and 24 clinical features obtained from 3,495 patients receiving polysomnography at a regional hospital and a medical centre. The area under the receiver operating characteristic (AUC) curve was used to evaluate patients with and without moderate or severe OSA using three prediction models on the basis of various estimation methods: the multiple logistic regression (MLR), support vector machine (SVM), and neural network (NN) methods. Odds ratios stratified by gender and age were also measured to account for clinicians' common sense. We discovered that adding the self-reported snoring item improved the AUC by 0.01-0.10 and helped us to rapidly achieve the optimum level. The performance of four items (gender, age, body mass index [BMI], and snoring) was comparable with that of adding two or more items (neck and waist circumference) for predicting moderate to severe OSA (Apnea-Hypopnea Index â‰¥15Â events/hr) in all three prediction models, demonstrating the medical knowledge value of pathophysiology. The four-item test sample AUCs were 0.83, 0.84, and 0.83 for MLR, SVM, and NN, respectively. Participants with regular snoring and a BMI of â‰¥25Â kg/m<sup>2</sup> had a greater chance of moderate to severe OSA according to the stratified adjusted odds ratios. Combining domain knowledge into machine learning could increase efficiency and enable primary care physicians to refer for an OSA diagnosis earlier.",0,0
1803,Effect of CT image acquisition parameters on diagnostic performance of radiomics in predicting malignancy of pulmonary nodules of different sizes. To investigate the effect of CT image acquisition parameters on the performance of radiomics in classifying benign and malignant pulmonary nodules (PNs) with respect to nodule size.,0,0
1809,"COV-VGX: An automated COVID-19 detection system using X-ray images and transfer learning. Coronavirus (COVID-19) has been one of the most dangerous and acute deadly diseases across the world recently. Researchers are trying to develop automated and feasible COVID-19 detection systems with the help of deep neural networks, machine learning techniques, etc. In this paper, a deep learning-based COVID-19 detection system called COV-VGX is proposed that contributes to detecting coronavirus disease automatically using chest X-ray images. The system introduces two types of classifiers, namely, a multiclass classifier that automatically predicts coronavirus, pneumonia, and normal classes and a binary classifier that predicts coronavirus and pneumonia classes. Using transfer learning, a deep CNN model is proposed to extract distinct and high-level features from X-ray images in collaboration with the pretrained model VGG-16. Despite the limitation of the COVID-19 dataset, the model is evaluated with sufficient COVID-19 images. Extensive experiments for multiclass classifier have achieved 98.91% accuracy, 97.31% precision, 99.50% recall, 98.39% F1-score, while 99.37% accuracy, 98.76% precision, 100% recall, 99.38% F1-score for binary classifier. The proposed system can contribute a lot in diagnosing COVID-19 effectively in the medical field.",0,0
1813,"Image Features of Magnetic Resonance Imaging under the Deep Learning Algorithm in the Diagnosis and Nursing of Malignant Tumors. In order to explore the effect of convolutional neural network (CNN) algorithm based on deep learning on magnetic resonance imaging (MRI) images of brain tumor patients and evaluate the practical value of MRI image features based on deep learning algorithm in the clinical diagnosis and nursing of malignant tumors, in this study, a brain tumor MRI image model based on the CNN algorithm was constructed, and 80 patients with brain tumors were selected as the research objects. They were divided into an experimental group (CNN algorithm) and a control group (traditional algorithm). The patients were nursed in the whole process. The macroscopic characteristics and imaging index of the MRI image and anxiety of patients in two groups were compared and analyzed. In addition, the image quality after nursing was checked. The results of the study revealed that the MRI characteristics of brain tumors based on CNN algorithm were clearer and more accurate in the fluid-attenuated inversion recovery (FLAIR), MRI T1, T1c, and T2; in terms of accuracy, sensitivity, and specificity, the mean value was 0.83, 0.84, and 0.83, which had obvious advantages compared with the traditional algorithm (<i>P</i> < 0.05). The patients in the nursing group showed lower depression scores and better MRI images in contrast to the control group (<i>P</i> < 0.05). Therefore, the deep learning algorithm can further accurately analyze the MRI image characteristics of brain tumor patients on the basis of conventional algorithms, showing high sensitivity and specificity, which improved the application value of MRI image characteristics in the diagnosis of malignant tumors. In addition, effective nursing for patients undergoing analysis and diagnosis on brain tumor MRI image characteristics can alleviate the patient's anxiety and ensure that high-quality MRI images were obtained after the examination.",0,0
1819,"Development and clinical deployment of a smartphone-based visual field deep learning system for glaucoma detection. By 2040, ~100 million people will have glaucoma. To date, there are a lack of high-efficiency glaucoma diagnostic tools based on visual fields (VFs). Herein, we develop and evaluate the performance of 'iGlaucoma', a smartphone application-based deep learning system (DLS) in detecting glaucomatous VF changes. A total of 1,614,808 data points of 10,784 VFs (5542 patients) from seven centers in China were included in this study, divided over two phases. In Phase I, 1,581,060 data points from 10,135 VFs of 5105 patients were included to train (8424 VFs), validate (598 VFs) and test (3 independent test sets-200, 406, 507 samples) the diagnostic performance of the DLS. In Phase II, using the same DLS, iGlaucoma cloud-based application further tested on 33,748 data points from 649 VFs of 437 patients from three glaucoma clinics. With reference to three experienced expert glaucomatologists, the diagnostic performance (area under curve [AUC], sensitivity and specificity) of the DLS and six ophthalmologists were evaluated in detecting glaucoma. In Phase I, the DLS outperformed all six ophthalmologists in the three test sets (AUC of 0.834-0.877, with a sensitivity of 0.831-0.922 and a specificity of 0.676-0.709). In Phase II, iGlaucoma had 0.99 accuracy in recognizing different patterns in pattern deviation probability plots region, with corresponding AUC, sensitivity and specificity of 0.966 (0.953-0.979), 0.954 (0.930-0.977), and 0.873 (0.838-0.908), respectively. The 'iGlaucoma' is a clinically effective glaucoma diagnostic tool to detect glaucoma from humphrey VFs, although the target population will need to be carefully identified with glaucoma expertise input.",1,1
1822,"Deep learning-based prediction of early cerebrovascular events after transcatheter aortic valve replacement. Cerebrovascular events (CVE) are among the most feared complications of transcatheter aortic valve replacement (TAVR). CVE appear difficult to predict due to their multifactorial origin incompletely explained by clinical predictors. We aimed to build a deep learning-based predictive tool for TAVR-related CVE. Integrated clinical and imaging characteristics from consecutive patients enrolled into a prospective TAVR registry were analysed. CVE comprised any strokes and transient ischemic attacks. Predictive variables were selected by recursive feature reduction to train an autoencoder predictive model. Area under the curve (AUC) represented the model's performance to predict 30-day CVE. Among 2279 patients included between 2007 and 2019, both clinical and imaging data were available in 1492 patients. Median age was 83Â years and STS score was 4.6%. Acute (<â€‰24Â h) and subacute (day 2-30) CVE occurred in 19 (1.3%) and 36 (2.4%) patients, respectively. The occurrence of CVE was associated with an increased risk of death (HR [95% CI] 2.62 [1.82-3.78]). The constructed predictive model uses less than 107 clinical and imaging variables and has an AUC of 0.79 (0.65-0.93). TAVR-related CVE can be predicted using a deep learning-based predictive algorithm. The model is implemented online for broad usage.",0,0
1826,"ECG-based machine-learning algorithms for heartbeat classification. Electrocardiogram (ECG) signals represent the electrical activity of the human hearts and consist of several waveforms (P, QRS, and T). The duration and shape of each waveform and the distances between different peaks are used to diagnose heart diseases. In this work, to better analyze ECG signals, a new algorithm that exploits two-event related moving-averages (TERMA) and fractional-Fourier-transform (FrFT) algorithms is proposed. The TERMA algorithm specifies certain areas of interest to locate desired peak, while the FrFT rotates ECG signals in the time-frequency plane to manifest the locations of various peaks. The proposed algorithm's performance outperforms state-of-the-art algorithms. Moreover, to automatically classify heart disease, estimated peaks, durations between different peaks, and other ECG signal features were used to train a machine-learning model. Most of the available studies uses the MIT-BIH database (only 48 patients). However, in this work, the recently reported Shaoxing People's Hospital (SPH) database, which consists of more than 10,000 patients, was used to train the proposed machine-learning model, which is more realistic for classification. The cross-database training and testing with promising results is the uniqueness of our proposed machine-learning model.",0,0
1831,"A novel transcriptomic-based classifier for senescent cancer cells. The inability to unequivocally identify senescent cancer cells is hindering the development of novel anticancer therapies using senolytic compounds. In a recent study in Cell Reports, Jochems et al. used a machine-learning approach to generate a classifier for senescent cancer cells based on transcriptional signatures.",0,0
1832,Predicting Survived Events in Nontraumatic Out-of-Hospital Cardiac Arrest: A Comparison Study on Machine Learning and Regression Models. Prediction of early outcomes of nontraumatic out-of-hospital cardiac arrest (OHCA) by emergency physicians is inaccurate.,0,0
1833,"Performance of deep convolutional neural network for classification and detection of oral potentially malignant disorders in photographic images. Oral potentially malignant disorders (OPMDs) are a group of conditions that can transform into oral cancer. The purpose of this study was to evaluate convolutional neural network (CNN) algorithms to classify and detect OPMDs in oral photographs. In this study, 600 oral photograph images were collected retrospectively and grouped into 300 images of OPMDs and 300 images of normal oral mucosa. CNN-based classification models were created using DenseNet-121 and ResNet-50. The detection models were created using Faster R-CNN and YOLOv4. The image data were randomly selected and assigned as training, validating, and testing data. The testing data were evaluated to compare the performance of the CNN models with the diagnosis results produced by oral and maxillofacial surgeons. DenseNet-121 and ResNet-50 were found to produce high efficiency in diagnosis of OPMDs, with an area under the receiver operating characteristic curve (AUC) of 95%. Faster R-CNN yielded the highest detection performance, with an AUC of 74.34%. For the CNN-based classification model, the sensitivity and specificity were 100% and 90%, respectively. For the oral and maxillofacial surgeons, these values were 91.73% and 92.27%, respectively. In conclusion, the DenseNet-121, ResNet-50 and Faster R-CNN models have potential for the classification and detection of OPMDs in oral photographs.",1,1
1835,"Modular deep neural networks for automatic quality control of retinal optical coherence tomography scans. Retinal optical coherence tomography (OCT) with intraretinal layer segmentation is increasingly used not only in ophthalmology but also for neurological diseases such as multiple sclerosis (MS). Signal quality influences segmentation results, and high-quality OCT images are needed for accurate segmentation and quantification of subtle intraretinal layer changes. Among others, OCT image quality depends on the ability to focus, patient compliance and operator skills. Current criteria for OCT quality define acceptable image quality, but depend on manual rating by experienced graders and are time consuming and subjective. In this paper, we propose and validate a standardized, grader-independent, real-time feedback system for automatic quality assessment of retinal OCT images. We defined image quality criteria for scan centering, signal quality and image completeness based on published quality criteria and typical artifacts identified by experienced graders when inspecting OCT images. We then trained modular neural networks on OCT data with manual quality grading to analyze image quality features. Quality analysis by a combination of these trained networks generates a comprehensive quality report containing quantitative results. We validated the approach against quality assessment according to the OSCAR-IB criteria by an experienced grader. Here, 100 OCT files with volume, circular and radial scans, centered on optic nerve head and macula, were analyzed and classified. A specificity of 0.96, a sensitivity of 0.97 and an accuracy of 0.97 as well as a Matthews correlation coefficient of 0.93 indicate a high rate of correct classification. Our method shows promising results in comparison to manual OCT grading and may be useful for real-time image quality analysis or analysis of large data sets, supporting standardized application of image quality criteria.",1,1
1837,"Nanoparticle surface-enhanced Raman spectroscopy as a noninvasive, label-free tool to monitor hematological malignancy. <b>Aim:</b> Monitoring minimal residual disease remains a challenge to the effective medical management of hematological malignancies; yet surface-enhanced Raman spectroscopy (SERS) has emerged as a potential clinical tool to do so. <b>Materials & methods:</b> We developed a cell-free, label-free SERS approach using gold nanoparticles (nanoSERS) to classify hematological malignancies referenced against two control cohorts: healthy and noncancer cardiovascular disease. A predictive model was built using machine-learning algorithms to incorporate disease burden scores for patients under standard treatment upon. <b>Results:</b> Linear- and quadratic-discriminant analysis distinguished three cohorts with 69.8Â and 71.4% accuracies, respectively. A predictive nanoSERS model correlated (MSEÂ =Â 1.6) with established clinical parameters. <b>Conclusion:</b> This study offers a proof-of-concept for the noninvasive monitoring of disease progression, highlighting the potential to incorporate nanoSERS into translational medicine.",0,0
1843,"Highly accurate diagnosis of lung adenocarcinoma and squamous cell carcinoma tissues by deep learning. Intraoperative detection of the marginal tissues is the last and most important step to complete the resection of adenocarcinoma and squamous cell carcinoma. However, the current intraoperative diagnosis is time-consuming and requires numerous steps including staining. In this paper, we present the use of Raman spectroscopy with deep learning to achieve accurate diagnosis with stain-free process. To make the spectrum more suitable for deep learning, we utilize an unusual way of thinking which regards Raman spectral signal as a sequence and then converts it into two-dimensional Raman spectrogram by short-time Fourier transform as input. The normal-adenocarcinoma deep learning model and normal-squamous carcinoma deep learning model both achieve more than 96% accuracy, 95% sensitivity and 98% specificity when test, which higher than the conventional principal components analysis-linear discriminant analysis method with normal-adenocarcinoma model (0.896 accuracy, 0.867 sensitivity, 0.926 specificity) and normal-squamous carcinoma model (0.821 accuracy, 0.776 sensitivity, 1.000 specificity). The high performance of deep learning models provides a reliable way for intraoperative detection of marginal tissue, and is expected to reduce the detection time and save human lives.",0,0
1847,"The application of machine learning algorithms in predicting the length of stay following femoral neck fracture. Femoral neck fracture is a frequent cause of hospitalization, and length of stay is an important marker of hospital cost and quality of care provided. As an extension of traditional statistical methods, machine learning provides the possibility of accurately predicting the length of hospital stay. The aim of this paper is to retrospectively identify predictive factors of the length of hospital stay (LOS) and predict the postoperative LOS by using machine learning algorithms.",0,0
1848,"Machine learning based early mortality prediction in the emergency department. It is a great challenge for emergency physicians to early detect the patient's deterioration and prevent unexpected death through a large amount of clinical data, which requires sufficient experience and keen insight.",0,0
1850,"Artificial intelligence approach towards assessment of condition of COVID-19 patients - Identification of predictive biomarkers associated with severity of clinical condition and disease progression. Although ML has been studied for different epidemiological and clinical issues as well as for survival prediction of COVID-19, there is a noticeable shortage of literature dealing with ML usage in prediction of disease severity changes through the course of the disease. In that way, predicting disease progression from mild towards moderate, severe and critical condition, would help not only to respond in a timely manner to prevent lethal results, but also to minimize the number of patients in hospitals where this is not necessary.",0,0
1852,"Deep Neural Network for Early Image Diagnosis of Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis. Stevens-Johnson syndrome (SJS)/toxic epidermal necrolysis (TEN) is a life-threatening cutaneous adverse drug reaction (cADR). Distinguishing SJS/TEN from nonsevere cADRs is difficult, especially in the early stages of the disease.",0,0
1854,"AI-based quantification of planned radiotherapy dose to cardiac structures and coronary arteries in breast cancer patients. To develop and evaluate an automatic deep learning method for segmentation of cardiac chambers and large arteries, and localization of the three main coronary arteries in radiotherapy planning CT. To determine the planned radiotherapy dose to cardiac structures for breast cancer therapy.",0,0
1856,"Real-time artificial intelligence for detecting focal lesions and diagnosing neoplasms of the stomach by white-light endoscopy (with videos). White-light endoscopy (WLE) is the most pivotal tool to detect gastric cancer in the early stage. However, the skill among endoscopists varies greatly. Here, we aim to develop a deep learning-based system named ENDOANGEL-LD (lesion detection) to assist in detecting all focal gastric lesions and predicting neoplasms by WLE.",0,0
1864,"Self-Supervised Graph Learning With Hyperbolic Embedding for Temporal Health Event Prediction. Electronic health records (EHRs) have been heavily used in modern healthcare systems for recording patients' admission information to health facilities. Many data-driven approaches employ temporal features in EHR for predicting specific diseases, readmission times, and diagnoses of patients. However, most existing predictive models cannot fully utilize EHR data, due to an inherent lack of labels in supervised training for some temporal events. Moreover, it is hard for the existing methods to simultaneously provide generic and personalized interpretability. To address these challenges, we propose Sherbet, a self-supervised graph learning framework with hyperbolic embeddings for temporal health event prediction. We first propose a hyperbolic embedding method with information flow to pretrain medical code representations in a hierarchical structure. We incorporate these pretrained representations into a graph neural network (GNN) to detect disease complications and design a multilevel attention method to compute the contributions of particular diseases and admissions, thus enhancing personalized interpretability. We present a new hierarchy-enhanced historical prediction proxy task in our self-supervised learning framework to fully utilize EHR data and exploit medical domain knowledge. We conduct a comprehensive set of experiments on widely used publicly available EHR datasets to verify the effectiveness of our model. Our results demonstrate the proposed model's strengths in both predictive tasks and interpretable abilities.",0,0
1866,"Interpretability-Based Multimodal Convolutional Neural Networks for Skin Lesion Diagnosis. Skin lesion diagnosis is a key step for skin cancer screening, which requires high accuracy and interpretability. Though many computer-aided methods, especially deep learning methods, have made remarkable achievements in skin lesion diagnosis, their generalization and interpretability are still a challenge. To solve this issue, we propose an interpretability-based multimodal convolutional neural network (IM-CNN), which is a multiclass classification model with skin lesion images and metadata of patients as input for skin lesion diagnosis. The structure of IM-CNN consists of three main paths to deal with metadata, features extracted from segmented skin lesion with domain knowledge, and skin lesion images, respectively. We add interpretable visual modules to provide explanations for both images and metadata. In addition to area under the ROC curve (AUC), sensitivity, and specificity, we introduce a new indicator, an AUC curve with a sensitivity larger than 80% (AUC_SEN_80) for performance evaluation. Extensive experimental studies are conducted on the popular HAM10000 dataset, and the results indicate that the proposed model has overwhelming advantages compared with popular deep learning models, such as DenseNet, ResNet, and other state-of-the-art models for melanoma diagnosis. The proposed multimodal model also achieves on average 72% and 21% improvement in terms of sensitivity and AUC_SEN_80, respectively, compared with the single-modal model. The visual explanations can also help gain trust from dermatologists and realize man-machine collaborations, effectively reducing the limitation of black-box models in supporting medical decision making.\enlargethispage-8pt.",0,0
1872,"Novel Application of Machine Learning Algorithms and Model-Agnostic Methods to Identify Factors Influencing Childhood Blood Lead Levels. Blood lead (Pb) poisoning remains a global concern, particularly for children in their early developmental years. Broken Hill is Australia's oldest operating silver-zinc-lead mine. In this study, we utilized recent advances in machine learning to assess multiple algorithms and identify the most optimal model for predicting childhood blood Pb levels (BLL) using Broken Hill children's (<5 years of age) data (<i>n</i> = 23,749) from 1991 to 2015, combined with demographic, socio-economic, and environmental influencing factors. We applied model-agnostic methods to interpret the most optimal model, investigating different environmental and human factors influencing childhood BLL. Algorithm assessment showed that stacked ensemble, a method for automatically and optimally combining multiple prediction algorithms, enhanced predictive performance by 1.1% with respect to mean absolute error (<i>p</i> < 0.01) and 2.6% for root-mean-squared error (<i>p</i> < 0.01) compared to the best performing constituent algorithm (random forest). By interpreting the model, the following information was acquired: children had higher BLL if they resided within 1.0 km to the central mine area or 1.37 km to the railroad; year of testing had the greatest interactive strength with all other factors; BLL increased faster in Aboriginal than in non-Aboriginal children at 9-10 and 12-18 months of age. This ""stacked ensemble + model-agnostic interpretation"" framework achieved both prediction accuracy and model interpretability, identifying previously unconnected variables associated with elevated childhood BLL, offering a marked advantage over previous works. Thus, this approach has a clear value and potential for application to other environmental health issues.",0,0
1878,"Non-melanoma skin cancer diagnosis: a comparison between dermoscopic and smartphone images by unified visual and sonification deep learning algorithms. Non-melanoma skin cancer (NMSC) is the most frequent keratinocyte-origin skin tumor. It is confirmed that dermoscopy of NMSC confers a diagnostic advantage as compared to visual face-to-face assessment. COVID-19 restrictions diagnostics by telemedicine photos, which are analogous to visual inspection, displaced part of in-person visits. This study evaluated by a dual convolutional neural network (CNN) performance metrics in dermoscopic (DI) versus smartphone-captured images (SI) and tested if artificial intelligence narrows the proclaimed gap in diagnostic accuracy.",0,0
1882,"Feasibility and Accuracy of Artificial Intelligence-Assisted Sponge Cytology for Community-Based Esophageal Squamous Cell Carcinoma Screening in China. Screening is the pivotal strategy to relieve the burden of esophageal squamous cell carcinoma (ESCC) in high-risk areas. The cost, invasiveness, and accessibility of esophagogastroduodenoscopy (EGD) necessitate the development of preliminary screening methods.",0,0
1883,"Automatic Classification of Thyroid Findings Using Static and Contextualized Ensemble Natural Language Processing Systems: Development Study. In the case of Korean institutions and enterprises that collect nonstandardized and nonunified formats of electronic medical examination results from multiple medical institutions, a group of experienced nurses who can understand the results and related contexts initially classified the reports manually. The classification guidelines were established by years of workers' clinical experiences and there were attempts to automate the classification work. However, there have been problems in which rule-based algorithms or human labor-intensive efforts can be time-consuming or limited owing to high potential errors. We investigated natural language processing (NLP) architectures and proposed ensemble models to create automated classifiers.",0,0
1884,"A Fully Automated Analytic System for Measuring Endolymphatic Hydrops Ratios in Patients With MÃ©niÃ¨re Disease via Magnetic Resonance Imaging: Deep Learning Model Development Study. Recently, the analysis of endolymphatic hydropses (EHs) via inner ear magnetic resonance imaging (MRI) for patients with MÃ©niÃ¨re disease has been attempted in various studies. In addition, artificial intelligence has rapidly been incorporated into the medical field. In our previous studies, an automated algorithm for EH analysis was developed by using a convolutional neural network. However, several limitations existed, and further studies were conducted to compensate for these limitations.",0,0
1885,"The Classification of Six Common Skin Diseases Based on Xiangya-Derm: Development of a Chinese Database for Artificial Intelligence. Skin and subcutaneous disease is the fourth-leading cause of the nonfatal disease burden worldwide and constitutes one of the most common burdens in primary care. However, there is a severe lack of dermatologists, particularly in rural Chinese areas. Furthermore, although artificial intelligence (AI) tools can assist in diagnosing skin disorders from images, the database for the Chinese population is limited.",0,0
1887,"Deep Learning for Adjacent Segment Disease at Preoperative MRI for Cervical Radiculopathy. Background Patients who undergo surgery for cervical radiculopathy are at risk for developing adjacent segment disease (ASD). Identifying patients who will develop ASD remains challenging for clinicians. Purpose To develop and validate a deep learning algorithm capable of predicting ASD by using only preoperative cervical MRI in patients undergoing single-level anterior cervical diskectomy and fusion (ACDF). Materials and Methods In this Health Insurance Portability and Accountability Act-compliant study, retrospective chart review was performed for 1244 patients undergoing single-level ACDF in two tertiary care centers. After application of inclusion and exclusion criteria, 344 patients were included, of whom 60% (<i>n</i> = 208) were used for training and 40% for validation (<i>n</i> = 43) and testing (<i>n</i> = 93). A deep learning-based prediction model with 48 convolutional layers was designed and trained by using preoperative T2-sagittal cervical MRI. To validate model performance, a neuroradiologist and neurosurgeon independently provided ASD predictions for the test set. Validation metrics included accuracy, areas under the curve, and F1 scores. The difference in proportion of wrongful predictions between the model and clinician was statistically tested by using the McNemar test. Results A total of 344 patients (median age, 48 years; interquartile range, 41-58 years; 182 women) were evaluated. The model predicted ASD on the 93 test images with an accuracy of 88 of 93 (95%; 95% CI: 90, 99), sensitivity of 12 of 15 (80%; 95% CI: 60, 100), and specificity of 76 of 78 (97%; 95% CI: 94, 100). The neuroradiologist and neurosurgeon provided predictions with lower accuracy (54 of 93; 58%; 95% CI: 48, 68), sensitivity (nine of 15; 60%; 95% CI: 35, 85), and specificity (45 of 78; 58%; 95% CI: 56, 77) compared with the algorithm. The McNemar test on the contingency table demonstrated that the proportion of wrongful predictions was significantly lower by the model (test statistic, 2.000; <i>P</i> < .001). Conclusion A deep learning algorithm that used only preoperative cervical T2-weighted MRI outperformed clinical experts at predicting adjacent segment disease in patients undergoing surgery for cervical radiculopathy. Â© RSNA, 2021.",1,1
1900,"Application of Pre-Trained Deep Learning Models for Clinical ECGs. Automatic electrocardiogram (ECG) analysis has been one of the very early use cases for computer assisted diagnosis (CAD). Most ECG devices provide some level of automatic ECG analysis. In the recent years, Deep Learning (DL) is increasingly used for this task, with the first models that claim to perform better than human physicians. In this manuscript, a pilot study is conducted to evaluate the added value of such a DL model to existing built-in analysis with respect to clinical relevance. 29 12-lead ECGs have been analyzed with a published DL model and results are compared to build-in analysis and clinical diagnosis. We could not reproduce the results of the test data exactly, presumably due to a different runtime environment. However, the errors were in the order of rounding errors and did not affect the final classification. The excellent performance in detection of left bundle branch block and atrial fibrillation that was reported in the publication could be reproduced. The DL method and the built-in method performed similarly good for the chosen cases regarding clinical relevance. While benefit of the DL method for research can be attested and usage in training can be envisioned, evaluation of added value in clinical practice would require a more comprehensive study with further and more complex cases.",1,1
1901,"Towards Interpretable Machine Learning in EEG Analysis. In this paper a machine learning model for automatic detection of abnormalities in electroencephalography (EEG) is dissected into parts, so that the influence of each part on the classification accuracy score can be examined. The most successful setup of several shallow artificial neural networks aggregated via voting results in accuracy of 81%. Stepwise simplification of the model shows the expected decrease in accuracy, but a naive model with thresholding of a single extracted feature (relative wavelet energy) is still able to achieve 75%, which remains strongly above the random guess baseline of 54%. These results suggest the feasibility of building a simple classification model ensuring accuracy scores close to the state-of-the-art research but remaining fully interpretable.",0,0
1902,"Multi-Disease Detection in Retinal Imaging Based on Ensembling Heterogeneous Deep Learning Models. Preventable or undiagnosed visual impairment and blindness affect billion of people worldwide. Automated multi-disease detection models offer great potential to address this problem via clinical decision support in diagnosis. In this work, we proposed an innovative multi-disease detection pipeline for retinal imaging which utilizes ensemble learning to combine the predictive capabilities of several heterogeneous deep convolutional neural network models. Our pipeline includes state-of-the-art strategies like transfer learning, class weighting, real-time image augmentation and Focal loss utilization. Furthermore, we integrated ensemble learning techniques like heterogeneous deep learning models, bagging via 5-fold cross-validation and stacked logistic regression models. Through internal and external evaluation, we were able to validate and demonstrate high accuracy and reliability of our pipeline, as well as the comparability with other state-of-the-art pipelines for retinal disease prediction.",0,0
1904,"Deep learning methods for automatic segmentation of lower leg muscles and bones from MRI scans of children with and without cerebral palsy. Cerebral palsy is a neurological condition that is known to affect muscle growth. Detailed investigations of muscle growth require segmentation of muscles from MRI scans, which is typically done manually. In this study, we evaluated the performance of 2D, 3D, and hybrid deep learning models for automatic segmentation of 11 lower leg muscles and two bones from MRI scans of children with and without cerebral palsy. All six models were trained and evaluated on manually segmented T<sub>1</sub> -weighted MRI scans of the lower legs of 20 children, six of whom had cerebral palsy. The segmentation results were assessed using the median Dice similarity coefficient (DSC), average symmetric surface distance (ASSD), and volume error (VError) of all 13 labels of every scan. The best performance was achieved by H-DenseUNet, a hybrid model (DSC 0.90, ASSD 0.5 mm, and VError 2.6 cm<sup>3</sup> ). The performance was equivalent to the inter-rater performance of manual segmentation (DSC 0.89, ASSD 0.6 mm, and VError 3.3 cm<sup>3</sup> ). Models trained with the Dice loss function outperformed models trained with the cross-entropy loss function. Near-optimal performance could be attained using only 11 scans for training. Segmentation performance was similar for scans of typically developing children (DSC 0.90, ASSD 0.5 mm, and VError 2.8 cm<sup>3</sup> ) and children with cerebral palsy (DSC 0.85, ASSD 0.6 mm, and VError 2.4 cm<sup>3</sup> ). These findings demonstrate the feasibility of fully automatic segmentation of individual muscles and bones from MRI scans of children with and without cerebral palsy.",0,0
1905,Robustness of deep learning segmentation of cardiac substructures in noncontrast computed tomography for breast cancer radiotherapy. To develop and evaluate deep learning-based autosegmentation of cardiac substructures from noncontrast planning computed tomography (CT) images in patients undergoing breast cancer radiotherapy and to investigate the algorithm sensitivity to out-of-distribution data such as CT image artifacts.,0,0
1907,"Robustifying Deep Networks for Medical Image Segmentation. The purpose of this study is to investigate the robustness of a commonly used convolutional neural network for image segmentation with respect to nearly unnoticeable adversarial perturbations, and suggest new methods to make these networks more robust to such perturbations. In this retrospective study, the accuracy of brain tumor segmentation was studied in subjects with low- and high-grade gliomas. Two representative UNets were implemented to segment four different MR series (T1-weighted, post-contrast T1-weighted, T2-weighted, and T2-weighted FLAIR) into four pixelwise labels (Gd-enhancing tumor, peritumoral edema, necrotic and non-enhancing tumor, and background). We developed attack strategies based on the fast gradient sign method (FGSM), iterative FGSM (i-FGSM), and targeted iterative FGSM (ti-FGSM) to produce effective but imperceptible attacks. Additionally, we explored the effectiveness of distillation and adversarial training via data augmentation to counteract these adversarial attacks. Robustness was measured by comparing the Dice coefficients for the attacks using Wilcoxon signed-rank tests. The experimental results show that attacks based on FGSM, i-FGSM, and ti-FGSM were effective in reducing the quality of image segmentation by up to 65% in the Dice coefficient. For attack defenses, distillation performed significantly better than adversarial training approaches. However, all defense approaches performed worse compared to unperturbed test images. Therefore, segmentation networks can be adversely affected by targeted attacks that introduce visually minor (and potentially undetectable) modifications to existing images. With an increasing interest in applying deep learning techniques to medical imaging data, it is important to quantify the ramifications of adversarial inputs (either intentional or unintentional).",0,0
1908,"Machine Learning in the Differentiation of Soft Tissue Neoplasms: Comparison of Fat-Suppressed T2WI and Apparent Diffusion Coefficient (ADC) Features-Based Models. Machine learning has been widely used in the characterization of tumors recently. This article aims to explore the feasibility of the whole tumor fat-suppressed (FS) T2WI and ADC features-based least absolute shrinkage and selection operator (LASSO)-logistic predictive models in the differentiation of soft tissue neoplasms (STN). The clinical and MR findings of 160 cases with 161 histologically proven STN were reviewed, retrospectively, 75 with diffusion-weighted imaging (DWI with b values of 50, 400, and 800Â s/mm<sup>2</sup>). They were divided into benign and malignant groups and further divided into training (70%) and validation (30%) cohorts. The MR FS T2WI and ADC features-based LASSO-logistic models were built and compared. The AUC of the FS T2WI features-based LASSO-logistic regression model for benign and malignant prediction was 0.65 and 0.75 for the training and validation cohorts. The model's sensitivity, specificity, and accuracy of the validation cohort were 55%, 96%, and 76.6%. While the AUC of the ADC features-based model was 0.932 and 0.955 for the training and validation cohorts. The model's sensitivity, specificity, and accuracy were 83.3%, 100%, and 91.7%. The performances of these models were also validated by decision curve analysis (DCA). The AUC of the whole tumor ADC features-based LASSO-logistic regression predictive model was larger than that of FS T2WI features (pâ€‰=â€‰0.017). The whole tumor fat-suppressed T2WI and ADC features-based LASSO-logistic predictive models both can serve as useful tools in the differentiation of STN. ADC features-based LASSO-logistic regression predictive model did better than that of FS T2WI features.",0,0
1909,Evaluation of ultrasonic fibrosis diagnostic system using convolutional network for ordinal regression. Diagnosis of liver fibrosis is important for establishing treatment and assessing the risk of carcinogenesis. Ultrasound imaging is an excellent diagnostic method as a screening test in terms of non-invasiveness and simplicity. The purpose of this study was to automatically diagnose liver fibrosis using ultrasound images to reduce the burden on physicians.,0,0
1912,"Immune and cellular damage biomarkers to predict COVID-19 mortality in hospitalized patients. Early prediction of COVID-19 in-hospital mortality relies usually on patients' preexisting comorbidities and is rarely reproducible in independent cohorts. We wanted to compare the role of routinely measured biomarkers of immunity, inflammation, and cellular damage with preexisting comorbidities in eight different machine-learning models to predict mortality, and evaluate their performance in an independent population. We recruited and followed-up consecutive adult patients with SARS-Cov-2 infection in two different Italian hospitals. We predicted 60-day mortality in one cohort (development dataset, nÂ =Â 299 patients, of which 80% was allocated to the development dataset and 20% to the training set) and retested the models in the second cohort (external validation dataset, nÂ =Â 402). Demographic, clinical, and laboratory features at admission, treatments and disease outcomes were significantly different between the two cohorts. Notably, significant differences were observed for %lymphocytes (pÂ <Â 0.05), international-normalized-ratio (pÂ <Â 0.01), platelets, alanine-aminotransferase, creatinine (all pÂ <Â 0.001). The primary outcome (60-day mortality) was 29.10% (nÂ =Â 87) in the development dataset, and 39.55% (nÂ =Â 159) in the external validation dataset. The performance of the 8 tested models on the external validation dataset were similar to that of the holdout test dataset, indicating that the models capture the key predictors of mortality. The shap analysis in both datasets showed that age, immune features (%lymphocytes, platelets) and LDH substantially impacted on all models' predictions, while creatinine and CRP varied among the different models. The model with the better performance was model 8 (60-day mortality AUROC 0.83Â Â±Â 0.06 in holdout test set, 0.79Â Â±Â 0.02 in external validation dataset). The features that had the greatest impact on this model's prediction were age, LDH, platelets, and %lymphocytes, more than comorbidities or inflammation markers, and these findings were highly consistent in both datasets, likely reflecting the virus effect at the very beginning of the disease.",0,0
1914,"Gastrointestinal Tract Disease Classification from Wireless Endoscopy Images Using Pretrained Deep Learning Model. Wireless capsule endoscopy is a noninvasive wireless imaging technology that becomes increasingly popular in recent years. One of the major drawbacks of this technology is that it generates a large number of photos that must be analyzed by medical personnel, which takes time. Various research groups have proposed different image processing and machine learning techniques to classify gastrointestinal tract diseases in recent years. Traditional image processing algorithms and a data augmentation technique are combined with an adjusted pretrained deep convolutional neural network to classify diseases in the gastrointestinal tract from wireless endoscopy images in this research. We take advantage of pretrained models VGG16, ResNet-18, and GoogLeNet, a convolutional neural network (CNN) model with adjusted fully connected and output layers. The proposed models are validated with a dataset consisting of 6702 images of 8 classes. The VGG16 model achieved the highest results with 96.33% accuracy, 96.37% recall, 96.5% precision, and 96.5% F1-measure. Compared to other state-of-the-art models, the VGG16 model has the highest Matthews Correlation Coefficient value of 0.95 and Cohen's kappa score of 0.96.",0,0
1921,"Non-invasive diagnostic tool for Parkinson's disease by sebum RNA profile with machine learning. Parkinson's disease (PD) is a progressive neurodegenerative disease presenting with motor and non-motor symptoms, including skin disorders (seborrheic dermatitis, bullous pemphigoid, and rosacea), skin pathological changes (decreased nerve endings and alpha-synuclein deposition), and metabolic changes of sebum. Recently, a transcriptome method using RNA in skin surface lipids (SSL-RNAs) which can be obtained non-invasively with an oil-blotting film was reported as a novel analytic method of sebum. Here we report transcriptome analyses using SSL-RNAs and the potential of these expression profiles with machine learning as diagnostic biomarkers for PD in double cohorts (PD [nâ€‰=â€‰15, 50], controls [nâ€‰=â€‰15, 50]). Differential expression analysis between the patients with PD and healthy controls identified more than 100 differentially expressed genes in the two cohorts. In each cohort, several genes related to oxidative phosphorylation were upregulated, and gene ontology analysis using differentially expressed genes revealed functional processes associated with PD. Furthermore, machine learning using the expression information obtained from the SSL-RNAs was able to efficiently discriminate patients with PD from healthy controls, with an area under the receiver operating characteristic curve of 0.806. This non-invasive gene expression profile of SSL-RNAs may contribute to early PD diagnosis based on the neurodegeneration background.",0,0
1922,"Enabling precision rehabilitation interventions using wearable sensors and machine learning to track motor recovery. The need to develop patient-specific interventions is apparent when one considers that clinical studies often report satisfactory motor gains only in a portion of participants. This observation provides the foundation for ""precision rehabilitation"". Tracking and predicting outcomes defining the recovery trajectory is key in this context. Data collected using wearable sensors provide clinicians with the opportunity to do so with little burden on clinicians and patients. The approach proposed in this paper relies on machine learning-based algorithms to derive clinical score estimates from wearable sensor data collected during functional motor tasks. Sensor-based score estimates showed strong agreement with those generated by clinicians. Score estimates of upper-limb impairment severity and movement quality were marked by a coefficient of determination of 0.86 and 0.79, respectively. The application of the proposed approach to monitoring patients' responsiveness to rehabilitation is expected to contribute to the development of patient-specific interventions, aiming to maximize motor gains.",0,0
1927,"Deep learning model to detect significant aortic regurgitation using electrocardiography: Detection model for aortic regurgitation. Aortic regurgitation (AR) is a common heart disease, with a relatively high prevalence of 4.9% in the Framingham Heart Study. Because the prevalence increases with advancing age, an upward shift in the age distribution may increase the burden of AR. To provide an effective screening method for AR, we developed a deep learning-based artificial intelligence algorithm for the diagnosis of significant AR using electrocardiography (ECG).",0,0
1932,"The feasibility of a dose painting procedure to treat prostate cancer based on mpMR images and hierarchical clustering. We aimed to assess the feasibility of a dose painting (DP) procedure, known as simultaneous integrated boost intensity modulated radiation Therapy (SIB-IMRT), for treating prostate cancer with dominant intraprostatic lesions (DILs) based on multi-parametric magnetic resonance (mpMR) images and hierarchical clustering with a machine learning technique.",0,0
1935,"Identifying homogeneous subgroups of patients and important features: a topological machine learning approach. This paper exploits recent developments in topological data analysis to present a pipeline for clustering based on Mapper, an algorithm that reduces complex data into a one-dimensional graph.",0,0
1941,"A neural network predicting the amplitude of the N2pc in individual EEG datasets. <i>Objective.</i>The N2pc is a small amplitude transient interhemispheric voltage asymmetry used in cognitive neuroscience to investigate subject's allocation of selective visuo-spatial attention. N2pc is typically estimated by averaging the sweeps of the electroencephalographic (EEG) signal but, in absence of explicit normative indications, the number of sweeps is often based on arbitrariness or personal experience. With the final aim of reducing duration and cost of experimental protocols, here we developed a new approach to reliably predict N2pc amplitude from a minimal EEG dataset.<i>Approach.</i>First, features predictive of N2pc amplitude were identified in the time-frequency domain. Then, an artificial neural network (NN) was trained to predict N2pc mean amplitude at the individual level. By resorting to simulated data, accuracy of the NN was assessed by computing the mean squared error (MSE) and the amplitude discretization error (ADE) and compared to the standard time averaging (TA) technique. The NN was then tested against two real datasets consisting of 14 and 12 subjects, respectively.<i>Main result.</i>In simulated scenarios entailing different number of sweeps (between 10 and 100), the MSE obtained with the proposed method resulted, on average, 1/5 of that obtained with the TA technique. Implementation on real EEG datasets showed that N2pc amplitude could be reliably predicted with as few as 40 EEG sweeps per cell of the experimental design.<i>Significance.</i>The developed approach allows to reduce duration and cost of experiments involving the N2pc, for instance in studies investigating attention deficits in pathological subjects.",0,0
1942,"A Machine Learning Model for Evaluating Imported Disease Screening Strategies in Immigrant Populations. Given the high prevalence of imported diseases in immigrant populations, it has postulated the need to establish screening programs that allow their early diagnosis and treatment. We present a mathematical model based on machine learning methodologies to contribute to the design of screening programs in this population. We conducted a retrospective cross-sectional screening program of imported diseases in all immigrant patients who attended the Tropical Medicine Unit between January 2009 and December 2016. We designed a mathematical model based on machine learning methodologies to establish the set of most discriminatory prognostic variables to predict the onset of the: HIV infection, malaria, chronic hepatitis B and C, schistosomiasis, and Chagas in immigrant population. We analyzed 759 patients. HIV was predicted with an accuracy of 84.9% and the number of screenings to detect the first HIV-infected person was 26, as in the case of Chagas disease (with a predictive accuracy of 92.9%). For the other diseases the averages were 12 screenings to detect the first case of chronic hepatitis B (85.4%), or schistosomiasis (86.9%), 23 for hepatitis C (85.6%) or malaria (93.3%), and eight for syphilis (79.4%) and strongyloidiasis (88.4%). The use of machine learning methodologies allowed the prediction of the expected disease burden and made it possible to pinpoint with greater precision those immigrants who are likely to benefit from screening programs, thus contributing effectively to their development and design.",0,0
1944,Can TKA outcomes be predicted with computational simulation? Generation of a patient specific planning tool. Computer simulations of knee movement allow Total Knee Arthroplasty (TKA) dynamic outcomes to be studied. This study aims to build a model predicting patient reported outcome from a simulation of post-operative TKA joint dynamics.,0,0
1947,"Real-time medical phase recognition using long-term video understanding and progress gate method. We introduce a real-time system for recognizing five phases of the trauma resuscitation process, the initial management of injured patients in the emergency department. We used depth videos as input to preserve the privacy of the patients and providers. The depth videos were recorded using a Kinect-v2 mounted on the sidewall of the room. Our dataset consisted of 183 depth videos of trauma resuscitations. The model was trained on 150 cases with more than 30 minutes each and tested on the remaining 33 cases. We introduced a reduced long-term operation (RLO) method for extracting features from long segments of video and combined it with the regular model having short-term information only. The model with RLO outperformed the regular short-term model by 5% using the accuracy score. We also introduced a progress gate (PG) method to distinguish visually similar phases using video progress. The final system achieved 91% accuracy and significantly outperformed previous systems for phase recognition in this setting.",0,0
1953,"PrimePatNet87: Prime pattern and tunable q-factor wavelet transform techniques for automated accurate EEG emotion recognition. Nowadays, many deep models have been presented to recognize emotions using electroencephalogram (EEG) signals. These deep models are computationally intensive, it takes a longer time to train the model. Also, it is difficult to achieve high classification performance using for emotion classification using machine learning techniques. To overcome these limitations, we present a hand-crafted conventional EEG emotion classification network. In this work, we have used novel prime pattern and tunable q-factor wavelet transform (TQWT) techniques to develop an automated model to classify human emotions. Our proposed cognitive model comprises feature extraction, feature selection, and classification steps. We have used TQWT on the EEG signals to obtain the sub-bands. The prime pattern and statistical feature generator are employed on the generated sub-bands and original signal to generate 798 features. 399 (half of them) out of 798 features are selected using minimum redundancy maximum relevance (mRMR) selector, and misclassification rates of each signal are evaluated using support vector machine (SVM) classifier. The proposed network generated 87 feature vectors hence, this model is named PrimePatNet87. In the last step of the feature generation, the best 20 feature vectors which are selected based on the calculated misclassification rates, are concatenated. The generated feature vector is subjected to the feature selection and the most significant 1000 features are selected using the mRMR selector. These selected features are then classified using an SVM classifier. In the last phase, iterative majority voting has been used to generate a general result. We have used three publicly available datasets, namely DEAP, DREAMER, and GAMEEMO, to develop our proposed model. Our presented PrimePatNet87 model reached over 99% classification accuracy on whole datasets with leave one subject out (LOSO) validation. Our results demonstrate that the developed prime pattern network is accurate and ready for real-world applications.",0,0
1954,"Penalty weighted glucose prediction models could lead to better clinically usage. Numerous attempts to predict glucose value from continuous glucose monitors (CGM) have been published. However, there is a lack of proper analysis and modeling of penalty for errors in different glycemic ranges. The aim of this study was to investigate the potential for developing glucose prediction models with focus on the clinical aspects.",0,0
1958,"Periprosthetic Joint Infection Prediction via Machine Learning: Comprehensible Personalized Decision Support for Diagnosis. The criteria outlined in the International Consensus Meeting (ICM) in 2018, which were prespecified and fixed, have been commonly practiced by clinicians to diagnose periprosthetic joint infection (PJI). We developed a machine learning (ML) system for PJI diagnosis and compared it with the ICM scoring system to verify the feasibility of ML.",0,0
1959,"Latent Class Analysis Reveals COVID-19-related ARDS Subgroups with Differential Responses to Corticosteroids. Rationale Two distinct subphenotypes have been identified in acute respiratory distress syndrome (ARDS), but the presence of subgroups in ARDS associated with COVID-19 is unknown. The objective of this study was to identify clinically relevant, novel subgroups in COVID-19-related ARDS, and compare them to previously described ARDS subphenotypes. Methods Eligible participants were adults with COVID-19 and ARDS at Columbia University Irving Medical Center. Latent class analysis (LCA) was used to identify subgroups with baseline clinical, respiratory, and laboratory data serving as partitioning variables. A previously-developed machine learning model was used to classify patients as the hypoinflammatory and hyperinflammatory subphenotypes. Baseline characteristics and clinical outcomes were compared between subgroups. Heterogeneity of treatment effect (HTE) for corticosteroid-use in subgroups was tested. Measurements and Main Results From 3/2-4/30/2020, 483 patients with COVID-19-related ARDS met study criteria. A two-class LCA model best fit the population (p=0.0075). Class 2 (23%) had higher pro-inflammatory markers, troponin, creatinine and lactate, lower bicarbonate and lower blood pressure than Class 1 (77%). 90-day mortality was higher in Class 2 versus Class 1 (75% vs 48%; p<0.0001). Considerable overlap was observed between these subgroups and ARDS subphenotypes. SARS-CoV-2 RT-PCR cycle threshold was associated with mortality in the hypoinflammatory but not the hyperinflammatory phenotype. HTE to corticosteroids was observed (p=0.0295), with improved mortality in the hyperinflammatory phenotype and worse mortality in the hypoinflammatory phenotype, with the caveat that corticosteroid treatment was not randomized. Conclusions We identified two COVID-19-related ARDS subgroups with differential outcomes, similar to previously described ARDS subphenotypes. SARS-CoV-2 PCR cycle threshold had differential value for predicting mortality in the subphenotypes. The subphenotypes had differential treatment responses to corticosteroids. This article is open access and distributed under the terms of the Creative Commons Attribution Non-Commercial No Derivatives License 4.0 (http://creativecommons.org/licenses/by-nc-nd/4.0/).",0,0
1965,Replicating prediction algorithms for hospitalization and corticosteroid use in patients with inflammatory bowel disease. Previous work had shown that machine learning models can predict inflammatory bowel disease (IBD)-related hospitalizations and outpatient corticosteroid use based on patient demographic and laboratory data in a cohort of United States Veterans. This study aimed to replicate this modeling framework in a nationally representative cohort.,0,0
1966,"Unifying information theory and machine learning in a model of electrode discrimination in cochlear implants. Despite the development and success of cochlear implants over several decades, wide inter-subject variability in speech perception is reported. This suggests that cochlear implant user-dependent factors limit speech perception at the individual level. Clinical studies have demonstrated the importance of the number, placement, and insertion depths of electrodes on speech recognition abilities. However, these do not account for all inter-subject variability and to what extent these factors affect speech recognition abilities has not been studied. In this paper, an information theoretic method and machine learning technique are unified in a model to investigate the extent to which key factors limit cochlear implant electrode discrimination. The framework uses a neural network classifier to predict which electrode is stimulated for a given simulated activation pattern of the auditory nerve, and mutual information is then estimated between the actual stimulated electrode and predicted ones. We also investigate how and to what extent the choices of parameters affect the performance of the model. The advantages of this framework include i) electrode discrimination ability is quantified using information theory, ii) it provides a flexible framework that may be used to investigate the key factors that limit the performance of cochlear implant users, and iii) it provides insights for future modeling studies of other types of neural prostheses.",0,0
1967,"Identification of high-risk COVID-19 patients using machine learning. The current COVID-19 public health crisis, caused by SARS-CoV-2 (severe acute respiratory syndrome coronavirus 2), has produced a devastating toll both in terms of human life loss and economic disruption. In this paper we present a machine-learning algorithm capable of identifying whether a given patient (actually infected or suspected to be infected) is more likely to survive than to die, or vice-versa. We train this algorithm with historical data, including medical history, demographic data, as well as COVID-19-related information. This is extracted from a database of confirmed and suspected COVID-19 infections in Mexico, constituting the official COVID-19 data compiled and made publicly available by the Mexican Federal Government. We demonstrate that the proposed method can detect high-risk patients with high accuracy, in each of four identified clinical stages, thus improving hospital capacity planning and timely treatment. Furthermore, we show that our method can be extended to provide optimal estimators for hypothesis-testing techniques commonly-used in biological and medical statistics. We believe that our work could be of use in the context of the current pandemic in assisting medical professionals with real-time assessments so as to determine health care priorities.",0,0
1970,"Regression and Classification of Alzheimers Disease Diagnosis using NMF-TDNet Features from 3D Brain MR Image. With the development of deep learning and medical imaging technology, many researchers use convolutional neural network(CNN) to obtain deep-level features of medical image in order to better classify Alzheimer's disease (AD) and predict clinical scores. The principal component analysis network (PCANet) is a lightweight deep-learning network that mainly uses principal component analysis (PCA) to generate multilevel filter banks for the centralized learning of samples and then performs binarization and generates blockwise histograms to obtain image features. However, the dimensions of the extracted PCANet features reaching tens of thousands or even hundreds of thousands, and the formation of the multilevel filter banks is sample data dependent, reducing the flexibility of PCANet. In this paper, based on the idea of PCANet, we propose a data-independent network called the nonnegative matrix factorization tensor decomposition network (NMF-TDNet), which improves the computational efficiency and solves the data dependence problem of PCANet. In this network, we use nonnegative matrix factorization (NMF) instead of PCA to create multilevel filter banks for sample learning, then uses the learning results to build a higher-order tensor and perform tensor decomposition (TD) to achieve data dimensionality reduction, producing the final image features. Finally, our method use these features as the input of the support vector machine (SVM) for AD classification diagnosis and clinical score prediction. The performance of our method is extensively evaluated on the ADNI-1, ADNI-2 and OASIS datasets. The experimental results show that NMF-TDNet can achieve data dimensionality reduction (the dimensionality of the extracted features numbers only a few hundred dimensions, far less than the hundreds of thousands required by PCANet) and the NMF-TDNet features as input achieved superior performance than using PCANet features as input.",0,0
1971,"A Cloud Approach for Melanoma Detection based on Deep Learning Networks. In the era of digitized images, the goal is to be able to extract information from them and create new knowledge thanks to the use of Computer Vision techniques, Machine Learning and Deep Learning. This allows their use for early diagnosis and subsequent determination of the treatment of many pathologies. In the specific case treated here, deep neural networks are used in the dermatological field to distinguish between melanoma and non-melanoma images. In this work we have underlined two essential points of melanoma detection research. The first aspect taken into consideration is how even a simple modification of the parameters in the dataset determines a change of the accuracy of the classifiers, while working on the same original dataset. The second point is the need to have a system architecture that can be more flexible in updating the training datasets for the classification of this pathology. In this context, the proposed architecture reserves the goal of developing and implementing a hybrid architecture based on Cloud, Fog and Edge Computing in order to provide a Melanoma Detection service based on clinical and/or dermoscopic images. At the same time, this architecture must be able to interface with the amount of data to be analyzed by reducing the running time of the necessary computational operations. This has been highlighted with experiments carried out on a single machine and on different distribution systems, highlighting how a distributed approach guarantees the achievement of an output in a much more acceptable time without the need to fully rely on data scientists skills.",0,0
1978,"A Machine Learning Approach for Predicting Sustained Remission in Rheumatoid Arthritis Patients on Biologic Agents. Despite several studies having identified factors associated with successful treatment outcomes in rheumatoid arthritis (RA), there is a lack of accurate predictive models for sustained remission in patients on biologic agents. To the best of our knowledge, no machine learning (ML) approaches apart from logistic regression (LR) have ever been tried on this class of problems.",0,0
1979,Artificial Neural Network as a Tool for Appraising Hematological Parameters in Sudanese Patients with Malaria. The purpose of this paper was to quantitatively assess and explore the effect of malaria infection in the hematological parameters of Sudanese population.,0,0
1982,Assessment of Artificial Intelligence Automatic Multiple Sclerosis Lesion Delineation Tool for Clinical Use. To implement and validate an existing algorithm for automatic delineation of white matter lesions on magnetic resonance imaging (MRI) in patients with multiple sclerosis (MS) on aÂ local single-center dataset.,0,0
1984,"Predictors of functional outcomes in patients with facioscapulohumeral muscular dystrophy. Facioscapulohumeral muscular dystrophy (FSHD) is one of the most prevalent muscular dystrophies characterized by considerable variability in severity, rates of progression and functional outcomes. Few studies follow FSHD cohorts long enough to understand predictors of disease progression and functional outcomes, creating gaps in our understanding which impacts clinical care and the design of clinical trials. Efforts to identify molecularly targeted therapies create a need to better understand disease characteristics with predictive value to help refine clinical trial strategies and understand trial outcomes. Here we analyzed a prospective cohort from a large, longitudinally-followed registry of patients with FSHD in the United States to determine predictors of outcomes such as need for wheelchair use. This study analyzed de-identified data from 578 individuals with confirmed FSHD type 1 enrolled in the United States National Registry for FSHD Patients and Family members. Data were collected from January 2002 to September 2019 and included an average of nine years (range 0 to 18) of follow up surveys. Data were analyzed using descriptive epidemiological techniques, and risk of wheelchair use was determined using cox proportional hazards models. Supervised machine learning analysis was completed using Random Forest modeling and included all 189 unique features collected from registry questionnaires. A separate medications-only model was created that included 359 unique medications reported by participants. Here we show that smaller allele sizes were predictive of earlier age at onset, diagnosis and likelihood of wheelchair use. Additionally, we show that women were more likely overall to progress to wheelchair use and at a faster rate as compared to men, independent of genetics. Use of machine learning models that included all reported clinical features showed that the effect of allele size on progression to wheelchair use is small compared to disease duration, which may be important to consider in trial design. Medical comorbidities and medication use add to the risk for need for wheelchair dependence, raising the possibility for better medical management impacting outcomes in FSHD. The findings in this study will require further validation in additional, larger datasets but could have implications for clinical care, and inclusion criteria for future clinical trials in FSHD.",0,0
1987,"Using different machine learning models to classify patientsÂ intoÂ mild and severe cases of COVID-19 based on multivariate blood testing. COVID-19 is a serious respiratory disease. The ever-increasing number of cases is causing heavier loads on the health service system.Â Using 38 blood test indicators on the first day of admission for the 422 patients diagnosed with COVID-19 (from January 2020 to June 2021) to construct different machine learning (ML) models to classify patients intoÂ either mild or severe cases of COVID-19.Â All models show good performance in the classification between COVID-19 patients intoÂ mild and severe disease. The area under the curve (AUC) of the random forest model is 0.89, the AUC of the naive Bayes model is 0.90, the AUC of the support vector machine model is 0.86, and the AUC of the KNN model is 0.78, the AUC of the Logistic regression model is 0.84, and the AUC of the artificial neural network model is 0.87, among which the naive Bayes model has the best performance.Â Different ML models can classify patients intoÂ mild and severe cases based on 38 blood test indicators taken on the first day of admission for patients diagnosed with COVID-19.",0,0
1988,"Highlighting psychological pain avoidance and decision-making bias as key predictors of suicide attempt in major depressive disorder-A novel investigative approach using machine learning. Predicting suicide is notoriously difficult and complex, but a serious public health issue. An innovative approach utilizing machine learning (ML) that incorporates features of psychological mechanisms and decision-making characteristics related to suicidality could create an improved model for identifying suicide risk in patients with major depressive disorder (MDD).",0,0
1990,"Combining Multimodal Behavioral Data of Gait, Speech, and Drawing for Classification of Alzheimer's Disease and Mild Cognitive Impairment. Gait, speech, and drawing behaviors have been shown to be sensitive to the diagnosis of Alzheimer's disease (AD) and mild cognitive impairment (MCI). However, previous studies focused on only analyzing individual behavioral modalities, although these studies suggested that each of these modalities may capture different profiles of cognitive impairments associated with AD.",0,0
1998,"KGDAL: Knowledge Graph Guided Double Attention LSTM for Rolling Mortality Prediction for AKI-D Patients. With the rapid accumulation of electronic health record (EHR) data, deep learning (DL) models have exhibited promising performance on patient risk prediction. Recent advances have also demonstrated the effectiveness of knowledge graphs (KG) in providing valuable prior knowledge for further improving DL model performance. However, it is still unclear how KG can be utilized to encode high-order relations among clinical concepts and how DL models can make full use of the encoded concept relations to solve real-world healthcare problems and to interpret the outcomes. We propose a novel knowledge graph guided double attention LSTM model named KGDAL for rolling mortality prediction for critically ill patients with acute kidney injury requiring dialysis (AKI-D). KGDAL constructs a KG-based two-dimension attention in both time and feature spaces. In the experiment with two large healthcare datasets, we compared KGDAL with a variety of rolling mortality prediction models and conducted an ablation study to test the effectiveness, efficacy, and contribution of different attention mechanisms. The results showed that KGDAL clearly outperformed all the compared models. Also, KGDAL-derived patient risk trajectories may assist healthcare providers to make timely decisions and actions. The source code, sample data, and manual of KGDAL are available at https://github.com/lucasliu0928/KGDAL.",0,0
2000,"Predicting outcomes of psychotherapy for depression with electronic health record data. Predictive analytics with electronic health record (EHR) data holds promise for improving outcomes of psychiatric care. This study evaluated models for predicting outcomes of psychotherapy for depression in a clinical practice setting. EHR data from two large integrated health systems (Kaiser Permanente Colorado and Washington) included 5,554 new psychotherapy episodes with a baseline Patient Health Questionnaire (PHQ-9) score â‰¥ 10 and a follow-up PHQ-9 14-180 days after treatment initiation. Baseline predictors included demographics and diagnostic, medication, and encounter history. Prediction models for two outcomes-follow-up PHQ-9 score and treatment response (â‰¥ 50% PHQ-9 reduction)-were trained in a random sample of 70% of episodes and validated in the remaining 30%. Two methods were used for modeling: generalized linear regression models with variable selection and random forests. Sensitivity analyses considered alternate predictor, outcome, and model specifications. Predictions of follow-up PHQ-9 scores poorly estimated observed outcomes (mean squared error = 31 for linear regression, 40 for random forest). Predictions of treatment response had low discrimination (AUC = 0.57 for logistic regression, 0.61 for random forest), low classification accuracy, and poor calibration. Sensitivity analyses showed similar results. We note that prediction model performance may vary for settings with different care or EHR documentation practices. In conclusion, prediction models did not accurately predict depression treatment outcomes despite using rich EHR data and advanced analytic techniques. Health systems should proceed cautiously when considering prediction models for psychiatric outcomes using baseline intake information. Transparent research should be conducted to evaluate performance of any model intended for clinical use.",0,0
2001,"Salivary Metabolites are Promising Non-Invasive Biomarkers of Hepatocellular Carcinoma and Chronic Liver Disease. Hepatocellular carcinoma (HCC) is a leading causes of cancer mortality worldwide. Improved tools are needed for detecting HCC so that treatment can begin as early as possible. Current diagnostic approaches and existing biomarkers, such as alpha-fetoprotein (AFP) lack sensitivity, resulting in too many false negative diagnoses. Machine-learning may be able to identify combinations of biomarkers that provide more robust predictions and improve sensitivity for detecting HCC. We sought to evaluate whether metabolites in patient saliva could distinguish those with HCC, cirrhosis, and those with no documented liver disease.",0,0
2002,"Advanced brain ageing in Parkinson's disease is related to disease duration and individual impairment. Machine learning can reliably predict individual age from MRI data, revealing that patients with neurodegenerative disorders show an elevated biological age. A surprising gap in the literature, however, pertains to Parkinson's disease. Here, we evaluate brain age in two cohorts of Parkinson's patients and investigated the relationship between individual brain age and clinical characteristics. We assessed 372 patients with idiopathic Parkinson's disease, newly diagnosed cases from the Parkinson's Progression Marker Initiative database and a more chronic local sample, as well as age- and sex-matched healthy controls. Following morphometric preprocessing and atlas-based compression, individual brain age was predicted using a multivariate machine learning model trained on an independent, multi-site reference sample. Across cohorts, healthy controls were well predicted with a mean error of 4.4 years. In turn, Parkinson's patients showed a significant (controlling for age, gender and site) increase in brain age of âˆ¼3 years. While this effect was already present in the newly diagnosed sample, advanced biological age was significantly related to disease duration as well as worse cognitive and motor impairment. While biological age is increased in patients with Parkinson's disease, the effect is at the lower end of what is found for other neurological and psychiatric disorders. We argue that this may reflect a heterochronicity between forebrain atrophy and small but behaviourally salient midbrain pathology. Finally, we point to the need to disentangle physiological ageing trajectories, lifestyle effects and core pathological changes.",0,0
2003,"Reliable and Interpretable Mortality Prediction With Strong Foresight in COVID-19 Patients: An International Study From China and Germany. Cohort-independent robust mortality prediction model in patients with COVID-19 infection is not yet established. To build up a reliable, interpretable mortality prediction model with strong foresight, we have performed an international, bi-institutional study from China (Wuhan cohort, collected from January to March) and Germany (WÃ¼rzburg cohort, collected from March to September). A Random Forest-based machine learning approach was applied to 1,352 patients from the Wuhan cohort, generating a mortality prediction model based on their clinical features. The results showed that five clinical features at admission, including lymphocyte (%), neutrophil count, C-reactive protein, lactate dehydrogenase, and Î±-hydroxybutyrate dehydrogenase, could be used for mortality prediction of COVID-19 patients with more than 91% accuracy and 99% AUC. Additionally, the time-series analysis revealed that the predictive model based on these clinical features is very robust over time when patients are in the hospital, indicating the strong association of these five clinical features with the progression of treatment as well. Moreover, for different preexisting diseases, this model also demonstrated high predictive power. Finally, the mortality prediction model has been applied to the independent WÃ¼rzburg cohort, resulting in high prediction accuracy (with above 90% accuracy and 85% AUC) as well, indicating the robustness of the model in different cohorts. In summary, this study has established the mortality prediction model that allowed early classification of COVID-19 patients, not only at admission but also along the treatment timeline, not only cohort-independent but also highly interpretable. This model represents a valuable tool for triaging and optimizing the resources in COVID-19 patients.",0,0
2009,"Machine learning for identification of frailty in Canadian primary care practices. Frailty is a medical syndrome, commonly affecting people aged 65 years and over and is characterized by a greater risk of adverse outcomes following illness or injury. Electronic medical records contain a large amount of longitudinal data that can be used for primary care research. Machine learning can fully utilize this wide breadth of data for the detection of diseases and syndromes. The creation of a frailty case definition using machine learning may facilitate early intervention, inform advanced screening tests, and allow for surveillance.",0,0
2018,Automated Grading of Diabetic Retinopathy with Ultra-Widefield Fluorescein Angiography and Deep Learning. The objective of this study was to establish diagnostic technology to automatically grade the severity of diabetic retinopathy (DR) according to the ischemic index and leakage index with ultra-widefield fluorescein angiography (UWFA) and the Early Treatment Diabetic Retinopathy Study (ETDRS) 7-standard field (7-SF).,0,0
2019,"Application of Genetic Algorithm-Based Support Vector Machine in Identification of Gene Expression Signatures for Psoriasis Classification: A Hybrid Model. Psoriasis is a chronic autoimmune disease impairing significantly the quality of life of the patient. The diagnosis of the disease is done via a visual inspection of the lesional skin by dermatologists. Classification of psoriasis using gene expression is an important issue for the early and effective treatment of the disease. Therefore, gene expression data and selection of suitable gene signatures are effective sources of information.",0,0
2020,"DeepStrain: A Deep Learning Workflow for the Automated Characterization of Cardiac Mechanics. Myocardial strain analysis from cinematic magnetic resonance imaging (cine-MRI) data provides a more thorough characterization of cardiac mechanics than volumetric parameters such as left-ventricular ejection fraction, but sources of variation including segmentation and motion estimation have limited its wider clinical use. We designed and validated a fast, fully-automatic deep learning (DL) workflow to generate both volumetric parameters and strain measures from cine-MRI data consisting of segmentation and motion estimation convolutional neural networks. The final motion network design, loss function, and associated hyperparameters are the result of a thorough <i>ad hoc</i> implementation that we carefully planned specific for strain quantification, tested, and compared to other potential alternatives. The optimal configuration was trained using healthy and cardiovascular disease (CVD) subjects (<i>n</i> = 150). DL-based volumetric parameters were correlated (>0.98) and without significant bias relative to parameters derived from manual segmentations in 50 healthy and CVD test subjects. Compared to landmarks manually-tracked on tagging-MRI images from 15 healthy subjects, landmark deformation using DL-based motion estimates from paired cine-MRI data resulted in an end-point-error of 2.9 Â± 1.5 mm. Measures of end-systolic global strain from these cine-MRI data showed no significant biases relative to a tagging-MRI reference method. On 10 healthy subjects, intraclass correlation coefficient for intra-scanner repeatability was good to excellent (>0.75) for all global measures and most polar map segments. In conclusion, we developed and evaluated the first end-to-end learning-based workflow for automated strain analysis from cine-MRI data to quantitatively characterize cardiac mechanics of healthy and CVD subjects.",0,0
2023,"Surveillance Strategy for Barcelona Clinic Liver Cancer B Hepatocellular Carcinoma Achieving Complete Response: An Individualized Risk-Based Machine Learning Study. <b>Background:</b> For patients with complete response (CR) of Barcelona Clinical Liver Cancer (BCLC) stage B hepatocellular carcinoma (HCC), there is no consensus regarding the monitoring strategy. Optimal surveillance strategies that can detect early progression of HCC within a limited visit after treatment have not yet been investigated. A retrospective, real-world study was conducted to investigate surveillance strategies for BCLC stage B HCC (BBHCC) patients with CR after curative treatment to support clinical decision making. <b>Methods:</b> From January 2007 to December 2019, 546 BBHCC patients with CR after radical treatment were collected at Sun Yat-sen University Cancer Center. Seventy percent of patients were subjected to the train cohort randomly; the remaining patients comprised the validation cohort to verify the proposed arrangements. The random survival forest method was applied to calculate the disease progression hazard per month, and follow-up schedules were arranged to maximize the capability of progression detection at each visit. The primary endpoint of the study was the delayed-detection months for disease progression. <b>Results:</b> The cumulative 1, 2, and 3-years risk-adjusted probabilities for the train/validation cohorts were 32.8%/33.7%, 54.0%/56.3%, and 64.0%/67.4%, respectively, with peaks around approximately the 9th month. The surveillance regime was primarily concentrated in the first year posttreatment. The delayed-detection months gradually decreased when the total follow-up times increased from 6 to 11. Compared with controls, our schedule reduced delayed detection. Typically, the benefits of our surveillance regimes were obvious when the patients were followed seven times according to our schedule. The optional schedules were 5, 7, 9, 11, 17, 23, and 30Â months. <b>Conclusion:</b> The proposed new surveillance schedule may provide a new perspective concerning follow-up for BBHCC patients with CR.",0,0
2028,"Diagnosis of Pediatric Pneumonia with Ensemble of Deep Convolutional Neural Networks in Chest X-Ray Images. Pneumonia is a fatal disease that appears in the lungs and is caused by viral or bacterial infection. Diagnosis of pneumonia in chest X-ray images can be difficult and error-prone because of its similarity with other infections in the lungs. The aim of this study is to develop a computer-aided pneumonia detection system to facilitate the diagnosis decision process. Therefore, a convolutional neural network (CNN) ensemble method was proposed for the automatic diagnosis of pneumonia which is seen in children. In this context, seven well-known CNN models (VGG-16, VGG-19, ResNet-50, Inception-V3, Xception, MobileNet, and SqueezeNet) pre-trained on the ImageNet dataset were trained with the appropriate transfer learning and fine-tuning strategies on the chest X-ray dataset. Among the seven different models, the three most successful ones were selected for the ensemble method. The final results were obtained by combining the predictions of CNN models with the ensemble method during the test. In addition, a CNN model was trained from scratch, and the results of this model were compared with the proposed ensemble method. The proposed ensemble method achieved remarkable results with an AUC of 95.21 and a sensitivity of 97.76 on the test data. Also, the proposed ensemble method achieved classification accuracy of 90.71 in chest X-ray images as normal, viral pneumonia, and bacterial pneumonia.",0,0
2034,"Comparing Machine Learning Methods to Improve Fall Risk Detection in Elderly with Osteoporosis from Balance Data. Falls are a multifactorial cause of injuries for older people. Subjects with osteoporosis are particularly vulnerable to falls. We study the performance of different computational methods to identify people with osteoporosis who experience a fall by analysing balance parameters. Balance parameters, from eyes open and closed posturographic studies, and prospective registration of falls were obtained from a sample of 126 community-dwelling older women with osteoporosis (age 74.3â€‰Â±â€‰6.3) using World Health Organization Questionnaire for the study of falls during a follow-up of 2.5 years. We analyzed model performance to determine falls of every developed model and to validate the relevance of the selected parameter sets. The principal findings of this research were (1) models built using oversampling methods with either IBk (KNN) or Random Forest classifier can be considered good options for a predictive clinical test and (2) feature selection for minority class (FSMC) method selected previously unnoticed balance parameters, which implies that intelligent computing methods can extract useful information with attributes which otherwise are disregarded by experts. Finally, the results obtained suggest that Random Forest classifier using the oversampling method to balance the data independent of the set of variables used got the best overall performance in measures of sensitivity (>0.71), specificity (>0.18), positive predictive value (PPV >0.74), and negative predictive value (NPV >0.66) independent of the set of variables used. Although the IBk classifier was built with oversampling data considering information from both eyes opened and closed, using all variables got the best performance (sensitivity >0.81, specificity >0.19, PPVâ€‰=â€‰0.97, and NPVâ€‰=â€‰0.66).",0,0
2035,"Passive Fetal Movement Signal Detection System Based on Intelligent Sensing Technology. Fetal movement (FM) is an essential physiological parameter to determine the health status of the fetus. To address the problems of harrowing FM signal extraction and the low recognition rate of traditional machine learning classifiers in FM signal detection, this paper develops a passive FM signal detection system based on intelligent sensing technology. FM signals are obtained from the abdomen of the pregnant woman by using accelerometers. The FM signals are extracted and identified according to the clinical nature of the features hidden in the amplitude and waveform of the FM signals that fluctuate in duration. The system consists of four main stages: (i) FM signal preprocessing, (ii) maternal artifact signal preidentification, (iii) FM signal identification, and (iv) FM classification. Firstly, Kalman filtering is used to reconstruct the FM signal in a continuous low-amplitude noise background. Secondly, the maternal artifact signal is identified using an amplitude threshold algorithm. Then, an innovative dictionary learning algorithm is used to construct a dictionary of FM features, and orthogonal matching pursuit and adaptive filtering algorithms are used to identify the FM signals, respectively. Finally, mask fusion classification is performed based on the multiaxis recognition results. Experiments are conducted to evaluate the performance of the proposed FM detection system using publicly available and self-built accelerated FM datasets. The classification results showed that the orthogonal matching pursuit algorithm was more effective than the adaptive filtering algorithm in identifying FM signals, with a positive prediction value of 89.74%. The proposed FM detection system has great potential and promise for wearable FM health monitoring.",0,0
2039,"Automated detection of COVID-19 cough. Easy detection of COVID-19 is a challenge. Quick biological tests do not give enough accuracy. Success in the fight against new outbreaks depends not only on the efficiency of the tests used, but also on the cost, time elapsed and the number of tests that can be done massively. Our proposal provides a solution to this challenge. The main objective is to design a freely available, quick and efficient methodology for the automatic detection of COVID-19 in raw audio files. Our proposal is based on automated extraction of time-frequency cough features and selection of the more significant ones to be used to diagnose COVID-19 using a supervised machine-learning algorithm. Random Forest has performed better than the other models analysed in this study. An accuracy close to 90% was obtained. This study demonstrates the feasibility of the automatic diagnose of COVID-19 from coughs, and its applicability to detecting new outbreaks.",0,0
2048,"Artificial Intelligence Predicts Severity of COVID-19 Based on Correlation of Exaggerated Monocyte Activation, Excessive Organ Damage and Hyperinflammatory Syndrome: A Prospective Clinical Study. Prediction of the severity of COVID-19 at its onset is important for providing adequate and timely management to reduce mortality.",0,0
2051,"Estimation of Subglottal Pressure, Vocal Fold Collision Pressure, and Intrinsic Laryngeal Muscle Activation From Neck-Surface Vibration Using a Neural Network Framework and a Voice Production Model. The ambulatory assessment of vocal function can be significantly enhanced by having access to physiologically based features that describe underlying pathophysiological mechanisms in individuals with voice disorders. This type of enhancement can improve methods for the prevention, diagnosis, and treatment of behaviorally based voice disorders. Unfortunately, the direct measurement of important vocal features such as subglottal pressure, vocal fold collision pressure, and laryngeal muscle activation is impractical in laboratory and ambulatory settings. In this study, we introduce a method to estimate these features during phonation from a neck-surface vibration signal through a framework that integrates a physiologically relevant model of voice production and machine learning tools. The signal from a neck-surface accelerometer is first processed using subglottal impedance-based inverse filtering to yield an estimate of the unsteady glottal airflow. Seven aerodynamic and acoustic features are extracted from the neck surface accelerometer and an optional microphone signal. A neural network architecture is selected to provide a mapping between the seven input features and subglottal pressure, vocal fold collision pressure, and cricothyroid and thyroarytenoid muscle activation. This non-linear mapping is trained solely with 13,000 Monte Carlo simulations of a voice production model that utilizes a symmetric triangular body-cover model of the vocal folds. The performance of the method was compared against laboratory data from synchronous recordings of oral airflow, intraoral pressure, microphone, and neck-surface vibration in 79 vocally healthy female participants uttering consecutive /pÃ¦/ syllable strings at comfortable, loud, and soft levels. The mean absolute error and root-mean-square error for estimating the mean subglottal pressure were 191 Pa (1.95 cm H<sub>2</sub>O) and 243 Pa (2.48 cm H<sub>2</sub>O), respectively, which are comparable with previous studies but with the key advantage of not requiring subject-specific training and yielding more output measures. The validation of vocal fold collision pressure and laryngeal muscle activation was performed with synthetic values as reference. These initial results provide valuable insight for further vocal fold model refinement and constitute a proof of concept that the proposed machine learning method is a feasible option for providing physiologically relevant measures for laboratory and ambulatory assessment of vocal function.",0,0
2052,"Multi-Modal Pain Intensity Assessment Based on Physiological Signals: A Deep Learning Perspective. Traditional pain assessment approaches ranging from self-reporting methods, to observational scales, rely on the ability of an individual to accurately assess and successfully report observed or experienced pain episodes. Automatic pain assessment tools are therefore more than desirable in cases where this specific ability is negatively affected by various psycho-physiological dispositions, as well as distinct physical traits such as in the case of professional athletes, who usually have a higher pain tolerance as regular individuals. Hence, several approaches have been proposed during the past decades for the implementation of an autonomous and effective pain assessment system. These approaches range from more conventional supervised and semi-supervised learning techniques applied on a set of carefully hand-designed feature representations, to deep neural networks applied on preprocessed signals. Some of the most prominent advantages of deep neural networks are the ability to automatically learn relevant features, as well as the inherent adaptability of trained deep neural networks to related inference tasks. Yet, some significant drawbacks such as requiring large amounts of data to train deep models and over-fitting remain. Both of these problems are especially relevant in pain intensity assessment, where labeled data is scarce and generalization is of utmost importance. In the following work we address these shortcomings by introducing several novel multi-modal deep learning approaches (characterized by specific supervised, as well as self-supervised learning techniques) for the assessment of pain intensity based on measurable bio-physiological data. While the proposed supervised deep learning approach is able to attain state-of-the-art inference performances, our self-supervised approach is able to significantly improve the data efficiency of the proposed architecture by automatically generating physiological data and simultaneously performing a fine-tuning of the architecture, which has been previously trained on a significantly smaller amount of data.",0,0
2058,"Automatic deep learning system for COVID-19 infection quantification in chest CT. The paper proposes an automatic deep learning system for COVID-19 infection areas segmentation in chest CT scans. CT imaging proved its ability to detect the COVID-19 disease even for asymptotic patients, which make it a trustworthy alternative for PCR. Coronavirus disease spread globally and PCR screening is the adopted diagnostic testing method for COVID-19 detection. However, PCR is criticized due its low sensitivity ratios, also, it is time-consuming and manual complicated process. The proposed framework includes different steps; it starts to prepare the region of interest by segmenting the lung organ, which then undergoes edge enhancing diffusion filtering (EED) to improve the infection areas contrast and intensity homogeneity. The proposed FCN is implemented using U-net architecture with modified residual block to include concatenation skip connection. The block improves the learning of gradient values by forwarding the infection area features through the network. The proposed system is evaluated using different measures and achieved dice overlapping score of 0.961 and 0.780 for lung and infection areas segmentation, respectively. The proposed system is trained and tested using many 2D CT slices extracted from diverse datasets from different sources, which demonstrate the system generalization and effectiveness. The use of more datasets from different sources helps to enhance the system accuracy and generalization, which can be accomplished based on the data availability in in the future.",0,0
2060,A Deep Learning Model to Predict Knee Osteoarthritis Based on Nonimage Longitudinal Medical Record. To develop deep learning model (Deep-KOA) that can predict the risk of knee osteoarthritis (KOA) within the next year by using the previous three years nonimage-based electronic medical record (EMR) data.,0,0
2066,"MFBCNNC: Momentum factor biogeography convolutional neural network for COVID-19 detection via chest X-ray images. By October 6, 2020, Coronavirus disease 2019 (COVID-19) was diagnosed worldwide, reaching 3,355,7427 people and 1,037,862 deaths. Detection of COVID-19 and pneumonia by the chest X-ray images is of great significance to control the development of the epidemic situation. The current COVID-19 and pneumonia detection system may suffer from two shortcomings: the selection of hyperparameters in the models is not appropriate, and the generalization ability of the model is poor.",0,0
2067,"Internet of things-enabled real-time health monitoring system using deep learning. Smart healthcare monitoring systems are proliferating due to the Internet of Things (IoT)-enabled portable medical devices. The IoT and deep learning in the healthcare sector prevent diseases by evolving healthcare from face-to-face consultation to telemedicine. To protect athletes' life from life-threatening severe conditions and injuries in training and competitions, real-time monitoring of physiological indicators is critical. In this research work, we present a deep learning-based IoT-enabled real-time health monitoring system. The proposed system uses wearable medical devices to measure vital signs and apply various deep learning algorithms to extract valuable information. For this purpose, we have taken Sanda athletes as our case study. The deep learning algorithms help physicians properly analyze these athletes' conditions and offer the proper medications to them, even if the doctors are away. The performance of the proposed system is extensively evaluated using a cross-validation test by considering various statistical-based performance measurement metrics. The proposed system is considered an effective tool that diagnoses dreadful diseases among the athletes, such as brain tumors, heart disease, cancer, etc. The performance results of the proposed system are evaluated in terms of precision, recall, AUC, and F1, respectively.",0,0
2070,"Software system to predict the infection in COVID-19 patients using deep learning and web of things. Since the end of 2019, computed tomography (CT) images have been used as an important substitute for the time-consuming Reverse Transcriptase polymerase chain reaction (RT-PCR) test; a new coronavirus 2019 (COVID-19) disease has been detected and has quickly spread through many countries across the world. Medical imaging such as computed tomography provides great potential due to growing skepticism toward the sensitivity of RT-PCR as a screening tool. For this purpose, automated image segmentation is highly desired for a clinical decision aid and disease monitoring. However, there is limited publicly accessible COVID-19 image knowledge, leading to the overfitting of conventional approaches. To address this issue, the present paper focuses on data augmentation techniques to create synthetic data. Further, a framework has been proposed using WoT and traditional U-Net with EfficientNet B0 to segment the COVID Radiopedia and Medseg datasets automatically. The framework achieves an <i>F</i>-score of 0.96, which is best among state-of-the-art methods. The performance of the proposed framework also computed using Sensitivity, Specificity, and Dice-coefficient, achieves 84.5%, 93.9%, and 65.0%, respectively. Finally, the proposed work is validated using three quality of service (QoS) parameters such as server latency, response time, and network latency which improves the performance by 8%, 7%, and 10%, respectively.",0,0
2071,"Smartphone-Based Artificial Intelligence-Assisted Prediction for Eyelid Measurements: Algorithm Development and Observational Validation Study. Margin reflex distance 1 (MRD1), margin reflex distance 2 (MRD2), and levator muscle function (LF) are crucial metrics for ptosis evaluation and management. However, manual measurements of MRD1, MRD2, and LF are time-consuming, subjective, and prone to human error. Smartphone-based artificial intelligence (AI) image processing is a potential solution to overcome these limitations.",0,0
2072,A Radiomic-based Machine Learning Algorithm to Reliably Differentiate Benign Renal Masses from Renal Cell Carcinoma. A substantial proportion of patients undergo treatment for renal masses where active surveillance or observation may be more appropriate.,0,0
2074,"Multi-step validation of a deep learning-based system for the quantification of bowel preparation: a prospective, observational study. Inadequate bowel preparation is associated with a decrease in adenoma detection rate (ADR). A deep learning-based bowel preparation assessment system based on the Boston bowel preparation scale (BBPS) has been previously established to calculate the automatic BBPS (e-BBPS) score (ranging 0-20). The aims of this study were to investigate whether there was a statistically inverse relationship between the e-BBPS score and the ADR, and to determine the threshold of e-BBPS score for adequate bowel preparation in colonoscopy screening.",0,0
2076,New machine learning scoring system for predicting postoperative mortality in gastroduodenal ulcer perforation: A study using a Japanese nationwide inpatient database. Conventional prediction models for estimating risk of postoperative mortality in gastroduodenal ulcer perforation have suboptimal prediction ability. We aimed to develop and validate new machine learning models and an integer-based score for predicting the postoperative mortality.,0,0
2078,Machine Learning-Derived Echocardiographic Phenotypes PredictÂ HeartÂ Failure Incidence in Asymptomatic Individuals. This study sought to identify homogenous echocardiographic phenotypes in community-based cohorts and assess their association with outcomes.,0,0
2079,"Automatic Extraction of Hiatal Dimensions in 3-D Transperineal Pelvic Ultrasound Recordings. The aims of this work were to create a robust automatic software tool for measurement of the levator hiatal area on transperineal ultrasound (TPUS) volumes and to measure the potential reduction in variability and time taken for analysis in a clinical setting. The proposed tool automatically detects the C-plane (i.e., the plane of minimal hiatal dimensions) from a 3-D TPUS volume and subsequently uses the extracted plane to automatically segment the levator hiatus, using a convolutional neural network. The automatic pipeline was tested using 73 representative TPUS volumes. Reference hiatal outlines were obtained manually by two experts and compared with the pipeline's automated outlines. The Hausdorff distance, area, a clinical quality score, C-plane angle and C-plane Euclidean distance were used to evaluate C-plane detection and quantify levator hiatus segmentation accuracy. A visual Turing test was created to compare the performance of the software with that of the expert, based on the visual assessment of C-plane and hiatal segmentation quality. The overall time taken to extract the hiatal area with both measurement methods (i.e., manual and automatic) was measured. Each metric was calculated both for computer-observer differences and for inter-and intra-observer differences. The automatic method gave results similar to those of the expert when determining the hiatal outline from a TPUS volume. Indeed, the hiatal area measured by the algorithm and by an expert were within the intra-observer variability. Similarly, the method identified the C-plane with an accuracy of 5.76 Â± 5.06Â° and 6.46 Â± 5.18 mm in comparison to the inter-observer variability of 9.39 Â± 6.21Â° and 8.48 Â± 6.62 mm. The visual Turing test suggested that the automatic method identified the C-plane position within the TPUS volume visually as well as the expert. The average time taken to identify the C-plane and segment the hiatal area manually was 2 min and 35 Â± 17 s, compared with 35 Â± 4 s for the automatic result. This study presents a method for automatically measuring the levator hiatal area using artificial intelligence-based methodologies whereby the C-plane within a TPUS volume is detected and subsequently traced for the levator hiatal outline. The proposed solution was determined to be accurate, relatively quick, robust and reliable and, importantly, to reduce time and expertise required for pelvic floor disorder assessment.",1,1
2087,"Characterizing Effortful Swallows from Healthy Community Dwelling Adults Across the Lifespan Using High-Resolution Cervical Auscultation Signals and MBSImP Scores: A Preliminary Study. There is growing enthusiasm to develop inexpensive, non-invasive, and portable methods that accurately assess swallowing and provide biofeedback during dysphagia treatment. High-resolution cervical auscultation (HRCA), which uses acoustic and vibratory signals from non-invasive sensors attached to the anterior laryngeal framework during swallowing, is a novel method for quantifying swallowing physiology via advanced signal processing and machine learning techniques. HRCA has demonstrated potential as a dysphagia screening method and diagnostic adjunct to VFSSs by determining swallowing safety, annotating swallow kinematic events, and classifying swallows between healthy participants and patients with a high degree of accuracy. However, its feasibility as a non-invasive biofeedback system has not been explored. This study investigated 1. Whether HRCA can accurately differentiate between non-effortful and effortful swallows; 2. Whether differences exist in Modified Barium Swallow Impairment Profile (MBSImP) scores (#9, #11, #14) between non-effortful and effortful swallows. We hypothesized that HRCA would accurately classify non-effortful and effortful swallows and that differences in MBSImP scores would exist between the types of swallows. We analyzed 247 thin liquid 3Â mL command swallows (71 effortful) to minimize variation from 36 healthy adults who underwent standardized VFSSs with concurrent HRCA. Results revealed differences (pâ€‰<â€‰0.05) in 9 HRCA signal features between non-effortful and effortful swallows. Using HRCA signal features as input, decision trees classified swallows with 76% accuracy, 76% sensitivity, and 77% specificity. There were no differences in MBSImP component scores between non-effortful and effortful swallows. While preliminary in nature, this study demonstrates the feasibility/promise of HRCA as a biofeedback method for dysphagia treatment.",0,0
2090,"Machine-learning-based diagnosis of drug-naive adult patients with attention-deficit hyperactivity disorder using mismatch negativity. Relatively little is investigated regarding the neurophysiology of adult attention-deficit/hyperactivity disorder (ADHD). Mismatch negativity (MMN) is an event-related potential component representing pre-attentive auditory processing, which is closely associated with cognitive status. We investigated MMN features as biomarkers to classify drug-naive adult patients with ADHD and healthy controls (HCs). Sensor-level features (amplitude and latency) and source-level features (source activation) of MMN were investigated and compared between the electroencephalograms of 34 patients with ADHD and 45 HCs using a passive auditory oddball paradigm. Correlations between MMN features and ADHD symptoms were analyzed. Finally, we applied machine learning to differentiate the two groups using sensor- and source-level features of MMN. Adult patients with ADHD showed significantly lower MMN amplitudes at the frontocentral electrodes and reduced MMN source activation in the frontal, temporal, and limbic lobes, which were closely associated with MMN generators and ADHD pathophysiology. Source activities were significantly correlated with ADHD symptoms. The best classification performance for adult ADHD patients and HCs showed an 81.01% accuracy, 82.35% sensitivity, and 80.00% specificity based on MMN source activity features. Our results suggest that abnormal MMN reflects the adult ADHD patients' pathophysiological characteristics and might serve clinically as a neuromarker of adult ADHD.",0,0
2093,"Use of artificial intelligence to predict mean time to delivery following cervical ripening with dinoprostone vaginal insert. To validate a mathematical model to predict the mean time to delivery (TTD) following cervical ripening with dinoprostone vaginal insert (DVI), and assess its impact on the risk of nocturnal deliveries.",0,0
2094,"Informing the study of suicidal thoughts and behaviors in distressed young adults: The use of a machine learning approach to identify neuroimaging, psychiatric, behavioral, and demographic correlates. Young adults are at high risk for suicide, yet there is limited ability to predict suicidal thoughts and behaviors. Machine learning approaches are better able to examine a large number of variables simultaneously to identify combinations of factors associated with suicidal thoughts and behaviors. The current study used LASSO regression to investigate extent to which a number of demographic, psychiatric, behavioral, and functional neuroimaging variables are associated with suicidal thoughts and behaviors during young adulthood. 78 treatment seeking young adults (ages 18-25) completed demographic, psychiatric, behavioral, and suicidality measures. Participants also completed an implicit emotion regulation functional neuroimaging paradigm. Report of recent suicidal thoughts and behaviors served as the dependent variable. Five variables were identified by the LASSO regression: Two were demographic variables (age and level of education), two were psychiatric variables (depression and general psychiatric distress), and one was a neuroimaging variable (left amygdala activity during sad faces). Amygdala function was significantly associated with suicidal thoughts and behaviors above and beyond the other factors. Findings inform the study of suicidal thoughts and behaviors among treatment seeking young adults, and also highlight the importance of investigating neurobiological markers.",0,0
2112,"Identifying discriminative features for diagnosis of Kashin-Beck disease among adolescents. Diagnosing Kashin-Beck disease (KBD) involves damages to multiple joints and carries variable clinical symptoms, posing great challenge to the diagnosis of KBD for clinical practitioners. However, it is still unclear which clinical features of KBD are more informative for the diagnosis of Kashin-Beck disease among adolescent.",0,0
2116,"Reducing variability of breast cancer subtype predictors by grounding deep learning models in prior knowledge. Deep learning neural networks have improved performance in many cancer informatics problems, including breast cancer subtype classification. However, many networks experience underspecificationwheremultiplecombinationsofparametersachievesimilarperformance, bothin training and validation. Additionally, certain parameter combinations may perform poorly when the test distribution differs from the training distribution. Embedding prior knowledge from the literature may address this issue by boosting predictive models that provide crucial, in-depth information about a given disease. Breast cancer research provides a wealth of such knowledge, particularly in the form of subtype biomarkers and genetic signatures. In this study, we draw on past research on breast cancer subtype biomarkers, label propagation, and neural graph machines to present a novel methodology for embedding knowledge into machine learning systems. We embed prior knowledge into the loss function in the form of inter-subject distances derived from a well-known published breast cancer signature. Our results show that this methodology reduces predictor variability on state-of-the-art deep learning architectures and increases predictor consistency leading to improved interpretation. We find that pathway enrichment analysis is more consistent after embedding knowledge. This novel method applies to a broad range of existing studies and predictive models. Our method moves the traditional synthesis of predictive models from an arbitrary assignment of weights to genes toward a more biologically meaningful approach of incorporating knowledge.",0,0
2118,"DR-MIL: deep represented multiple instance learning distinguishes COVID-19 from community-acquired pneumonia in CT images. Given that the novel coronavirus disease 2019 (COVID-19) has become a pandemic, a method to accurately distinguish COVID-19 from community-acquired pneumonia (CAP) is urgently needed. However, the spatial uncertainty and morphological diversity of COVID-19 lesions in the lungs, and subtle differences with respect to CAP, make differential diagnosis non-trivial.",0,0
2124,"OTNet: A CNN Method Based on Hierarchical Attention Maps for Grading Arteriosclerosis of Fundus Images with Small Samples. The severity of fundus arteriosclerosis can be determined and divided into four grades according to fundus images. Automatically grading of the fundus arteriosclerosis is helpful in clinical practices, so this paper proposes a convolutional neural network (CNN) method based on hierarchical attention maps to solve the automatic grading problem. First, we use the retinal vessel segmentation model to separate the important vascular region and the non-vascular background region from the fundus image and obtain two attention maps. The two maps are regarded as inputs to construct a two-stream CNN (TSNet), to focus on feature information through mutual reference between the two regions. In addition, we use convex hull attention maps in the one-stream CNN (OSNet) to learn valuable areas where the retinal vessels are concentrated. Then, we design an integrated OTNet model which is composed of TSNet that learns image feature information and OSNet that learns discriminative areas. After obtaining the representation learning parts of the two networks, we can train the classification layer to achieve better results. Our proposed TSNet reaches the AUC value of 0.796 and the ACC value of 0.592 on the testing set, and the integrated model OTNet reaches the AUC value of 0.806 and the ACC value of 0.606, which are better than the results of other comparable models. As far as we know, this is the first attempt to use deep learning to classify the severity of atherosclerosis in fundus images. The prediction results of our proposed method can be accepted by doctors, which shows that our method has a certain application value.",0,0
2126,"Should there be an ""AI"" in TEAM? Embryologists selection of high implantation potential embryos improves with the aid of an artificial intelligence algorithm. A deep learning artificial intelligence (AI) algorithm has been demonstrated to outperform embryologists in identifying euploid embryos destined to implant with an accuracy of 75.3% (1). Our aim was to evaluate the performance of highly trained embryologists in selecting top quality day 5 euploid blastocysts with and without the aid of a deep learning algorithm.",1,1
2127,Prediction of Early Symptom Remission in Two Independent Samples of First-Episode Psychosis Patients Using Machine Learning. Validated clinical prediction models of short-term remission in psychosis are lacking. Our aim was to develop a clinical prediction model aimed at predicting 4-6-week remission following a first episode of psychosis.,0,0
2131,"Biopsy bacterial signature can predict patient tissue malignancy. Considerable recent research has indicated the presence of bacteria in a variety of human tumours and matched normal tissue. Rather than focusing on further identification of bacteria within tumour samples, we reversed the hypothesis to query if establishing the bacterial profile of a tissue biopsy could reveal its histology / malignancy status. The aim of the present study was therefore to differentiate between malignant and non-malignant fresh breast biopsy specimens, collected specifically for this purpose, based on bacterial sequence data alone. Fresh tissue biopsies were obtained from breast cancer patients and subjected to 16S rRNA gene sequencing. Progressive microbiological and bioinformatic contamination control practices were imparted at all points of specimen handling and bioinformatic manipulation. Differences in breast tumour and matched normal tissues were probed using a variety of statistical and machine-learning-based strategies. Breast tumour and matched normal tissue microbiome profiles proved sufficiently different to indicate that a classification strategy using bacterial biomarkers could be effective. Leave-one-out cross-validation of the predictive model confirmed the ability to identify malignant breast tissue from its bacterial signature with 84.78% accuracy, with a corresponding area under the receiver operating characteristic curve of 0.888. This study provides proof-of-concept data, from fit-for-purpose study material, on the potential to use the bacterial signature of tissue biopsies to identify their malignancy status.",0,0
2132,"A deep learning approach for successful big-bubble formation prediction in deep anterior lamellar keratoplasty. The efficacy of deep learning in predicting successful big-bubble (SBB) formation during deep anterior lamellar keratoplasty (DALK) was evaluated. Medical records of patients undergoing DALK at the University of Cologne, Germany between March 2013 and July 2019 were retrospectively analyzed. Patients were divided into two groups: (1) SBB or (2) failed big-bubble (FBB). Preoperative images of anterior segment optical coherence tomography and corneal biometric values (corneal thickness, corneal curvature, and densitometry) were evaluated. A deep neural network model, Visual Geometry Group-16, was selected to test the validation data, evaluate the model, create a heat map image, and calculate the area under the curve (AUC). This pilot study included 46 patients overall (11 women, 35 men). SBBs were more common in keratoconus eyes (KC eyes) than in corneal opacifications of other etiologies (non KC eyes) (pâ€‰=â€‰0.006). The AUC was 0.746 (95% confidence interval [CI] 0.603-0.889). The determination success rate was 78.3% (18/23 eyes) (95% CI 56.3-92.5%) for SBB and 69.6% (16/23 eyes) (95% CI 47.1-86.8%) for FBB. This automated system demonstrates the potential of SBB prediction in DALK. Although KC eyes had a higher SBB rate, no other specific findings were found in the corneal biometric data.",0,0
2133,"An efficient context-aware screening system for Alzheimer's disease based on neuropsychology test. Alzheimer's disease (AD) and other dementias have become the fifth leading cause of death worldwide. Accurate early detection of the disease and its precursor, Mild Cognitive Impairment (MCI), is crucial to alleviate the burden on the healthcare system. While most of the existing work in the literature applied neural networks directly together with several data pre-processing techniques, we proposed in this paper a screening system that is to perform classification based on automatic processing of the transcripts of speeches from the subjects undertaking a neuropsychological test. Our system is also shown applicable to different datasets and languages, suggesting that our system holds a high potential to be deployed widely in hospitals across regions. We conducted comprehensive experiments on two different languages datasets, the Pitt dataset and the NTUHV dataset, to validate our study. The results showed that our proposed system significantly outperformed the previous works on both datasets, with the score of the area under the receiver operating characteristic curve (AUROC) of classifying AD and healthy control (HC) being as high as 0.92 on the Pitt dataset and 0.97 on the NTUHV dataset. The performance on classifying MCI and HC remained promising, with the AUROC being 0.83 on the Pitt dataset and 0.88 on the NTUHV dataset.",0,0
2135,"Moderate to severe OSA screening based on support vector machine of the Chinese population faciocervical measurements dataset: a cross-sectional study. Obstructive sleep apnoea (OSA) has received much attention as a risk factor for perioperative complications and 68.5% of OSA patients remain undiagnosed before surgery. Faciocervical characteristics may screen OSA for Asians due to smaller upper airways compared with Caucasians. Thus, our study aimed to explore a machine-learning model to screen moderate to severe OSA based on faciocervical and anthropometric measurements.",0,0
2137,"A machine learning approach to determine the prognosis of patients with Class III malocclusion. The conundrum of determining how to treat a patient with Class III malocclusion is significant, creating a burden on the patient and challenging the orthodontist. The objective of this study was to employ a statistical prediction model derived from our previous cephalometric data on 5 predominant subtypes of skeletal Class III malocclusion to test the hypothesis that Class III subtypes are associated with treatment modalities (eg, surgical vs nonsurgical) and treatment outcome.",0,0
2138,"Accurate diagnosis of lung tissues for 2D Raman spectrogram by deep learning based on short-time Fourier transform. Multivariate statistical analysis methods have an important role in spectrochemical analyses to rapidly identify and diagnose cancer and the subtype. However, utilizing these methods to analyze lager amount spectral data is challenging, and poses a major bottleneck toward achieving high accuracy. Here, a new convolutional neural networks (CNN) method based on short-time Fourier transform (STFT) to diagnose lung tissues via Raman spectra readily is proposed. The models yield that the accuracies of the new method are higher than the conventional methods (principal components analysis -linear discriminant analysis and support vector machine) for validation group (95.2% vs 85.5%, 94.4%) and test group (96.5% vs 90.4%, 93.9%) after cross-validation. The results illustrate that the new method which converts one-dimensional Raman data into two-dimensional Raman spectrograms improve the discriminatory ability of lung tissues and can achieve automatically accurate diagnosis of lung tissues.",0,0
2143,"Estimation of postpartum depression risk from electronic health records using machine learning. Postpartum depression is a widespread disorder, adversely affecting the well-being of mothers and their newborns. We aim to utilize machine learning for predicting risk of postpartum depression (PPD) using primary care electronic health records (EHR) data, and to evaluate the potential value of EHR-based prediction in improving the accuracy of PPD screening and in early identification of women at risk.",0,0
2145,LungAttn: advanced lung sound classification using attention mechanism with dual TQWT and triple STFT spectrogram. Auscultation of lung sound plays an important role in the early diagnosis of lung diseases. This work aims to develop an automated adventitious lung sound detection method to reduce the workload of physicians.,0,0
2146,"EEG-based emotion classification using LSTM under new paradigm. Deep learning has gained much popularity in solving challenging machine learning problems related to image, speech classification, etc. Research has been conducted to apply deep learning models in emotion classification based on physiological signals such as EEG. Most of the research works have based their model on the spatial aspects of the EEG. However, the emotion features in EEG are spread across the time domain during an emotional episode. Therefore, in this work, the emotion classification problem is modelled as a sequence classification problem. The power band frequency based features of every time segment of EEG sequences generated from 32-channel EEG data are used to train three different models of Long Short-Term Memory (LSTM1, LSTM2, and LSTM3). Four class (HVHA, HVLA, LVHA, and LVLA) classification experiments were performed based on the valence and arousal emotion models. The LSTM3 model with 128 memory cells achieved the highest classification accuracy of 90%, whereas LSTM1 (32 cells) and LSTM2 (64 cells) yielded classification accuracies of 85% and 89% respectively. Further, the impact of segment size on classification accuracy was also investigated in this work. Results obtained indicate that a smaller segment size leads to higher classification accuracy using LSTM models.",0,0
2148,"Towards personalized nutritional treatment for malnutrition using machine learning-based screening tools. Early identification of patients at risk of malnutrition or who are malnourished is crucial in order to start a timely and adequate nutritional therapy. Yet, despite the presence of many nutrition screening tools for use in the hospital setting, there is no consensus regarding the best tool as well as inadequate adherence to screening practices which impairs the achievement of effective nutritional therapy. In recent years, artificial intelligence and machine learning methods have been widely used, across multiple medical domains, to aid clinical decision making and to improve quality and efficiency of care. Therefore, Yin and colleagues propose a machine learning based individualized decision support system aimed to identify and grade malnutrition in cancer patients by applying unsupervised and supervised machine learning methods on nationwide cohort. This approach, demonstrate the ability of machine learning methods to create tools to recognize malnutrition. The machine learning based screening serves as a first layer in a nutritional therapy workflow and provides improved support for decision making of health professionals to fit individualized nutritional therapy in at-risk patients.",0,0
2150,"A machine learning model for early detection of diabetic foot using thermogram images. Diabetes foot ulceration (DFU) and amputation are a cause of significant morbidity. The prevention of DFU may be achieved by the identification of patients at risk of DFU and the institution of preventative measures through education and offloading. Several studies have reported that thermogram images may help to detect an increase in plantar temperature prior to DFU. However, the distribution of plantar temperature may be heterogeneous, making it difficult to quantify and utilize to predict outcomes. We have compared a machine learning-based scoring technique with feature selection and optimization techniques and learning classifiers to several state-of-the-art Convolutional Neural Networks (CNNs) on foot thermogram images and propose a robust solution to identify the diabetic foot. A comparatively shallow CNN model, MobilenetV2 achieved an F1 score of âˆ¼95% for a two-feet thermogram image-based classification and the AdaBoost Classifier used 10 features and achieved an F1 score of 97%. A comparison of the inference time for the best-performing networks confirmed that the proposed algorithm can be deployed as a smartphone application to allow the user to monitor the progression of the DFU in a home setting.",0,0
2157,"A predictive model for next cycle start date that accounts for adherence in menstrual self-tracking. The study sought to build predictive models of next menstrual cycle start date based on mobile health self-tracked cycle data. Because app users may skip tracking, disentangling physiological patterns of menstruation from tracking behaviors is necessary for the development of predictive models.",0,0
2158,Transfer Deep Learning for Dental and Maxillofacial Imaging Modality Classification: A Preliminary Study. To apply the technique of transfer deep learning on a small data set for automatic classification of X-ray modalities in dentistry.,0,0
2174,"Evaluation of the prediction of CoVID-19 recovered and unrecovered cases using symptoms and patient's meta data based on support vector machine, neural network, CHAID and QUEST Models. This paper aims to develop four prediction models for recovered and unrecovered cases using descriptive data of patients and symptoms of CoVID-19 patients. The developed prediction models aim to extract the important variables in predicting recovered cases by using the binary values for recovered cases.",0,0
2176,"Distinguishing pure histopathological growth patterns of colorectal liver metastases on CT using deep learning and radiomics: a pilot study. Histopathological growth patterns (HGPs) are independent prognosticators for colorectal liver metastases (CRLM). Currently, HGPs are determined postoperatively. In this study, we evaluated radiomics for preoperative prediction of HGPs on computed tomography (CT), and its robustness to segmentation and acquisition variations. Patients with pure HGPs [i.e. 100% desmoplastic (dHGP) or 100% replacement (rHGP)] and a CT-scan who were surgically treated at the Erasmus MC between 2003-2015 were included retrospectively. Each lesion was segmented by three clinicians and a convolutional neural network (CNN). A prediction model was created using 564 radiomics features and a combination of machine learning approaches by training on the clinician's and testing on the unseen CNN segmentations. The intra-class correlation coefficient (ICC) was used to select features robust to segmentation variations; ComBat was used to harmonize for acquisition variations. Evaluation was performed through a 100â€‰Ã—â€‰random-split cross-validation. The study included 93 CRLM in 76 patients (48% dHGP; 52% rHGP). Despite substantial differences between the segmentations of the three clinicians and the CNN, the radiomics model had a mean area under the curve of 0.69. ICC-based feature selection or ComBat yielded no improvement. Concluding, the combination of a CNN for segmentation and radiomics for classification has potential for automatically distinguishing dHGPs from rHGP, and is robust to segmentation and acquisition variations. Pending further optimization, including extension to mixed HGPs, our model may serve as a preoperative addition to postoperative HGP assessment, enabling further exploitation of HGPs as a biomarker.",0,0
2179,"A Machine Learning Algorithm to Identify Patients at Risk of Unplanned Subsequent Surgery After Intramedullary Nailing for Tibial Shaft Fractures. In the SPRINT trial, 18% of patients with a tibial shaft fracture (TSF) treated with intramedullary nailing (IMN) had one or more unplanned subsequent surgical procedures. It is clinically relevant for surgeon and patient to anticipate unplanned secondary procedures, other than operations that can be readily expected such as reconstructive procedures for soft tissue defects. Therefore, the objective of this study was to develop a machine learning (ML) prediction model using the SPRINT data that can give individual patients and their care team an estimate of their particular probability of an unplanned second surgery.",0,0
2186,"Identification of Non-Fatal Opioid Overdose Cases Using 9-1-1 Computer Assisted Dispatch and Prehospital Patient Clinical Record Variables. <b>Background</b>The current epidemic of opioid overdoses in the United States necessitates a robust public health and clinical response. We described patterns of non-fatal opioid overdoses (NFOODs) in a small western region using data from the 9-1-1 Computer Assisted Dispatch (CAD) record and electronic Patient Clinical Records (ePCR) completed by EMS responders. We determined whether CAD and ePCR variables could identify NFOOD cases in 9-1-1 data for intervention and surveillance efforts.<b>Methods</b>We conducted a retrospective analysis of one year of 9-1-1 emergency medical CAD and ePCR (including naloxone administration) data from the sole EMS provider in the response area. Cases were identified based on clinician review of the ePCR, and categorized as definitive NFOOD, probable NFOOD, or non-OOD. Sensitivity, specificity, positive and negative predictive values (PPV and NPV) of the most prevalent CAD and ePCR variables were calculated. We used a machine learning technique - Random-Forests (RF) modelling - to optimize our ability to accurately predict NFOOD cases within census blocks.<b>Results</b>Of 37,960 9-1-1 calls, clinical review identified 158 NFOOD cases (0.4%), of which 123 (77.8%) were definitive and 35 (22.2%) were probable cases. Overall, 106 (67.1%) received naloxone from the EMS responder at the scene. As a predictor of NFOOD, naloxone administration by paramedics had 67.1% sensitivity, 99.6% specificity, 44% PPV and 99.9% NPV. Using CAD variables alone achieved a sensitivity of 36.7% and specificity of 99.7%. Combining ePCR variables with CAD variables increased the diagnostic accuracy with the best RF model yielding 75.9% sensitivity, 99.9% specificity, 71.4% PPV and 99.9% NPV.<b>Conclusion</b>CAD problem type variables and naloxone administration, used alone or in combination, had sub-optimal predictive accuracy. However, a Random Forests modelling approach improved accuracy of identification, which could foster improved surveillance and intervention efforts. We identified the set of NFOODs that EMS encountered in a year and may be useful for future surveillance efforts.",0,0
2194,Machine learning to investigate superficial white matter integrity in early multiple sclerosis. This study aims todetermine the sensitivity of superficial white matter (SWM) integrity as a metric to distinguish early multiple sclerosis (MS) patients from healthy controls (HC).,0,0
2195,Artificial intelligence for detecting superficial esophageal squamous cell carcinoma under multiple endoscopic imaging modalities: A multicenter study. Diagnosis of esophageal squamous cell carcinoma (ESCC) is complicated and requires substantial expertise and experience. This study aimed to develop an artificial intelligence (AI) system for detecting superficial ESCC under multiple endoscopic imaging modalities.,0,0
2198,"Prediction of tuberous sclerosis-associated neurocognitive disorders and seizures via machine learning of structural magnetic resonance imaging. Tuberous sclerosis complex (TSC) is a genetic disorder characterized by multiorgan hamartomas, including cerebral lesions, with seizures as a common presentation. Most TSC patients will also experience neurocognitive comorbidities. Our objective was to use machine learning techniques incorporating clinical and imaging data to predict the occurrence of major neurocognitive disorders and seizures in TSC patients.",0,0
2200,Comprehensive Assessment of Fine-Grained Wound Images Using a Patch-Based CNN With Context-Preserving Attention. Chronic wounds affect 6.5 million Americans. Wound assessment via algorithmic analysis of smartphone images has emerged as a viable option for remote assessment.,0,0
2203,"Detection of hypomimia in patients with Parkinson's disease via smile videos. Parkinson's disease (PD) is a neurodegenerative disease characterized by the impairment of facial expression, known as hypomimia. Hypomimia has serious impacts on patients' ability to communicate, and it is difficult to detect at early stages of the disease. Furthermore, due to bradykinesia or other reasons, it is inconvenient for PD patients to visit the hospital. Therefore, it is appealing to develop an auxiliary diagnostic method that remotely detects hypomimia.",0,0
2204,"Development and validation of Auto-Neo-electroencephalography (EEG) to estimate brain age and predict report conclusion for electroencephalography monitoring data in neonatal intensive care units. Electroencephalography (EEG) monitoring is widely used in neonatal intensive care units (NICUs). However, conventional EEG report generation processes are time-consuming and labor-intensive. Therefore, an automatic, objective, and comprehensive pipeline for brain age estimation and EEG report conclusion prediction is urgently needed to assist clinician's decision-making.",0,0
2205,Prediction of keratoconus progression using deep learning of anterior segment optical coherence tomography maps. To predict keratoconus progression using deep learning of the color-coded maps measured with a swept-source anterior segment optical coherence tomography (As-OCT) device.,0,0
2207,"Identification of diagnostic and prognostic signatures derived from preoperative blood parameters for oral squamous cell carcinoma. We aimed to develop novel diagnostic and prognostic signatures based on preoperative inflammatory, immunological, and nutritional parameters in blood (PIINPBs) by machine learning algorithms for patients with oral squamous cell carcinoma (OSCC).",0,0
2225,"COVID-19 early detection for imbalanced or low number of data using a regularized cost-sensitive CapsNet. With the presence of novel coronavirus disease at the end of 2019, several approaches were proposed to help physicians detect the disease, such as using deep learning to recognize lung involvement based on the pattern of pneumonia. These approaches rely on analyzing the CT images and exploring the COVID-19 pathologies in the lung. Most of the successful methods are based on the deep learning technique, which is state-of-the-art. Nevertheless, the big drawback of the deep approaches is their need for many samples, which is not always possible. This work proposes a combined deep architecture that benefits both employed architectures of DenseNet and CapsNet. To more generalize the deep model, we propose a regularization term with much fewer parameters. The network convergence significantly improved, especially when the number of training data is small. We also propose a novel Cost-sensitive loss function for imbalanced data that makes our model feasible for the condition with a limited number of positive data. Our novelties make our approach more intelligent and potent in real-world situations with imbalanced data, popular in hospitals. We analyzed our approach on two publicly available datasets, HUST and COVID-CT, with different protocols. In the first protocol of HUST, we followed the original paper setup and outperformed it. With the second protocol of HUST, we show our approach superiority concerning imbalanced data. Finally, with three different validations of the COVID-CT, we provide evaluations in the presence of a low number of data along with a comparison with state-of-the-art.",0,0
2226,"Early outcome detection for COVID-19 patients. With the outbreak of COVID-19 exerting a strong pressure on hospitals and health facilities, clinical decision support systems based on predictive models can help to effectively improve the management of the pandemic. We present a method for predicting mortality for COVID-19 patients. Starting from a large number of clinical variables, we select six of them with largest predictive power, using a feature selection method based on genetic algorithms and starting from a set of COVID-19 patients from the first wave. The algorithm is designed to reduce the impact of missing values in the set of variables measured, and consider only variables that show good accuracy on validation data. The final predictive model provides accuracy larger than 85% on test data, including a new patient cohort from the second COVID-19 wave, and on patients with imputed missing values. The selected clinical variables are confirmed to be relevant by recent literature on COVID-19.",0,0
2230,"Automated bone mineral density prediction and fracture risk assessment using plain radiographs via deep learning. Dual-energy X-ray absorptiometry (DXA) is underutilized to measure bone mineral density (BMD) and evaluate fracture risk. We present an automated tool to identify fractures, predict BMD, and evaluate fracture risk using plain radiographs. The tool performance is evaluated on 5164 and 18175 patients with pelvis/lumbar spine radiographs and Hologic DXA. The model is well calibrated with minimal bias in the hip (slopeâ€‰=â€‰0.982, calibration-in-the-largeâ€‰=â€‰-0.003) and the lumbar spine BMD (slopeâ€‰=â€‰0.978, calibration-in-the-large = 0.003). The area under the precision-recall curve and accuracy are 0.89 and 91.7% for hip osteoporosis, 0.89 and 86.2% for spine osteoporosis, 0.83 and 95.0% for high 10-year major fracture risk, and 0.96 and 90.0% for high hip fracture risk. The tool classifies 5206 (84.8%) patients with 95% positive or negative predictive value for osteoporosis, compared to 3008 DXA conducted at the same study period. This automated tool may help identify high-risk patients for osteoporosis.",0,0
2234,"A Combined Radiomics and Machine Learning Approach to Overcome the Clinicoradiologic Paradox in Multiple Sclerosis. Conventional MR imaging explains only a fraction of the clinical outcome variance in multiple sclerosis. We aimed to evaluate machine learning models for disability prediction on the basis of radiomic, volumetric, and connectivity features derived from routine brain MR images.",0,0
2238,"Hybrid COVID-19 segmentation and recognition framework (HMB-HCF) using deep learning and genetic algorithms. COVID-19 (Coronavirus) went through a rapid escalation until it became a pandemic disease. The normal and manual medical infection discovery may take few days and therefore computer science engineers can share in the development of the automatic diagnosis for fast detection of that disease. The study suggests a hybrid COVID-19 framework (named HMB-HCF) based on deep learning (DL), genetic algorithm (GA), weighted sum (WS), and majority voting principles in nine phases. Its segmentation phase suggests a lung segmentation algorithm using X-Ray images (named HMB-LSAXI) for extracting lungs. Its classification phase is built from a hybrid convolutional neural network (CNN) architecture using an abstractly-designed CNN (named HMB1-COVID19) and transfer learning (TL) pre-trained models (VGG16, VGG19, ResNet50, ResNet101, Xception, DenseNet121, DenseNet169, MobileNet, and MobileNetV2). The hybrid CNN architecture is used for learning, classification, and parameters optimization while GA is used to optimize the hyperparameters. This hybrid working mechanism is combined in an overall algorithm named HMB-DLGA. The study experiments implemented the WS approach to evaluate the models' performance using the loss, accuracy, F1-score, precision, recall, and area under curve (AUC) metrics with different pre-defined ratios. A collected, combined, and unified X-Ray dataset from 8 different public datasets was used alongside the regularization, dropout, and data augmentation techniques to limit the overall overfitting. The applied experiments reported state-of-the-art metrics. VGG16 reported 100% WS metric (i.e., 0.0097, 99.78%, 0.9984, 99.89%, 99.78%, and 0.9996 for the loss, accuracy, F1, precision, recall, and AUC respectively) concerning the highest WS. It also reported a 99.92% WS metric (i.e., 0.0099, 99.84%, 0.9984, 99.84%, 99.84%, and 0.9996 for the loss, accuracy, F1, precision, recall, and AUC respectively) concerning the last reported WS result. HMB-HCF was validated on 13 different public datasets to verify its generalization. The best-achieved metrics were compared with 13 related studies. These extensive experiments' target was the applicability verification and generalization.",0,0
2242,"Neural network-based left ventricle geometry prediction from CMR images with application in biomechanics. Combining biomechanical modelling of left ventricular (LV) function and dysfunction with cardiac magnetic resonance (CMR) imaging has the potential to improve the prognosis of patient-specific cardiovascular disease risks. Biomechanical studies of LV function in three dimensions usually rely on a computerized representation of the LV geometry based on finite element discretization, which is essential for numerically simulating in vivo cardiac dynamics. Detailed knowledge of the LV geometry is also relevant for various other clinical applications, such as assessing the LV cavity volume and wall thickness. Accurately and automatically reconstructing personalized LV geometries from conventional CMR images with minimal manual intervention is still a challenging task, which is a pre-requisite for any subsequent automated biomechanical analysis. We propose a deep learning-based automatic pipeline for predicting the three-dimensional LV geometry directly from routinely-available CMR cine images, without the need to manually annotate the ventricular wall. Our framework takes advantage of a low-dimensional representation of the high-dimensional LV geometry based on principal component analysis. We analyze how the inference of myocardial passive stiffness is affected by using our automatically generated LV geometries instead of manually generated ones. These insights will inform the development of statistical emulators of LV dynamics to avoid computationally expensive biomechanical simulations. Our proposed framework enables accurate LV geometry reconstruction, outperforming previous approaches by delivering a reconstruction error 50% lower than reported in the literature. We further demonstrate that for a nonlinear cardiac mechanics model, using our reconstructed LV geometries instead of manually extracted ones only moderately affects the inference of passive myocardial stiffness described by an anisotropic hyperelastic constitutive law. The developed methodological framework has the potential to make an important step towards personalized medicine by eliminating the need for time consuming and costly manual operations. In addition, our method automatically maps the CMR scan into a low-dimensional representation of the LV geometry, which constitutes an important stepping stone towards the development of an LV geometry-heterogeneous emulator.",0,0
2243,"Deep learning methods for screening patients' S-ICD implantation eligibility. Subcutaneous Implantable Cardioverter-Defibrillators (S-ICDs) are used for prevention of sudden cardiac death triggered by ventricular arrhythmias. T Wave Over Sensing (TWOS) is an inherent risk with S-ICDs which can lead to inappropriate shocks. A major predictor of TWOS is a high T:R ratio (the ratio between the amplitudes of the T and R waves). Currently, patients' Electrocardiograms (ECGs) are screened over 10Â s to measure the T:R ratio to determine the patients' eligibility for S-ICD implantation. Due to temporal variations in the T:R ratio, 10Â s is not a long enough window to reliably determine the normal values of a patient's T:R ratio. In this paper, we develop a convolutional neural network (CNN) based model utilising phase space reconstruction matrices to predict T:R ratios from 10-second ECG segments without explicitly locating the R or T waves, thus avoiding the issue of TWOS. This tool can be used to automatically screen patients over a much longer period and provide an in-depth description of the behavior of the T:R ratio over that period. The tool can also enable much more reliable and descriptive screenings to better assess patients' eligibility for S-ICD implantation.",0,0
2246,"Practical fine-grained learning based anomaly classification for ECG image. As a widely used vital sign within cardiology, Electrocardiography (ECG) provides the basis for assessing heart function and diagnosing cardiovascular diseases. Automated anomaly detection for ECG plays an important role in improving patient diagnosis efficiency and reducing healthcare costs. Practically, due to the limits of electronics support or the medical system setting, image is a more common format for large-scale ECG storage in most clinical institutions. To guarantee an automated ECG detection model's scalability and practicality in clinical applications, taking good advantage of ECG images is crucial. However, existing time digital-based discriminative models fail to learn from images effectively for two reasons. First of all, the signals recorded on images have much lower resolution and higher noise, which makes it impractical to extract precise ECG signals following existing techniques. Meanwhile, the differences between abnormal signals are usually subtle, and they may be overwhelmed by the noises in the images as well. Towards this end, we design a novel neural framework that can be directly applied to massive ECG images determining various types of cardiology abnormalities. It classifies fine-grained ECG images based on weakly supervised strategy, in which case only image-level labeling is required. By eliminating the need for part annotations, the proposed method can result in significant savings in annotation time and cost. The effectiveness of the method is demonstrated by experimental results on two real ECG datasets.",0,0
2250,"Prediction of serosal invasion in gastric cancer: development and validation of multivariate models integrating preoperative clinicopathological features and radiographic findings based on late arterial phase CT images. To develop and validate multivariate models integrating endoscopic biopsy, tumor markers, and CT findings based on late arterial phase (LAP) to predict serosal invasion in gastric cancer (GC).",0,0
2253,"[Clinical significance of the deep learning algorithm based on contrast-enhanced CT in the differential diagnosis of gastric gastrointestinal stromal tumors with a diameter â‰¤ 5 cm]. <b>Objective:</b> Contrast-enhanced CT is an important method of preoperative diagnosis and evaluation for the malignant potential of gastric submucosal tumor (SMT). It has a high diagnostic accuracy rate in differentiating gastric gastrointestinal stromal tumor (GIST) with a diameter greater than 5 cm from gastric benign SMT. This study aimed to use deep learning algorithms to establish a diagnosis model (GISTNet) based on contrast-enhanced CT and evaluate its diagnostic value in distinguishing gastric GIST with a diameter â‰¤ 5 cm and other gastric SMT before surgery. <b>Methods:</b> A diagnostic test study was carried out. Clinicopathological data of 181 patients undergoing resection with postoperative pathological diagnosis of gastric SMT with a diameter â‰¤ 5 cm at Department of Gastrointestinal Surgery of Renji Hospital from September 2016 to April 2021 were retrospectively collected. After excluding 13 patients without preoperative CT or with poor CT imaging quality, a total of 168 patients were enrolled in this study, of whom, 107 were GIST while 61 were benign SMT (non-GIST), including 27 leiomyomas, 24 schwannomas, 6 heterotopic pancreas and 4 lipomas. Inclusion criteria were as follows: (1) gastric SMT was diagnosed by contrast-enhanced CT before surgery; (2) preoperative gastroscopic examination and biopsy showed no abnormal cells; (3) complete clinical and pathological data. Exclusion criteria were as follows: (1) patients received anti-tumor therapy before surgery; (2) without preoperative CT or with poor CT imaging quality due to any reason; (3) except GIST, other gastric malignant tumors were pathologically diagnosed after surgery. Based on the hold-out method, 148 patients were randomly selected as the training set and 20 patients as the test set of the GISTNet diagnosis model. After the GISTNet model was established, 5 indicators were used for evaluation in the test set, including sensitivity, specificity, positive predictive value, negative predictive value and the area under the receiver operating curve (AUC). Then GISTNet diagnosis model was compared with the GIST-risk scoring model based on traditional CT features. Besides, in order to compare the accuracy of the GISTNet diagnosis model and the imaging doctors in the diagnosis of gastric SMT imaging, 3 radiologists with 3, 9 and 19 years of work experience, respectively, blinded to clinical and pathological information, tested and judged the samples. The accuracy rate between the three doctors and the GISTNet model was compared. <b>Results:</b> The GISTNet model yielded an AUC of 0.900 (95% CI: 0.827-0.973) in the test set. When the threshold value was 0.345, the sensitivity specificity, positive and negative predictive values of the GISTNet diagnosis model was 100%, 67%, 75% and 100%, respectively. The accuracy rate of the GISTNet diagnosis model was better than that of the GIST-risk model and the manual readings from two radiologists with 3 years and 9 years of work experience (83% vs. 75%, 60%, 65%), and was close to the manual reading of the radiologist with 19 years of work experience (83% vs. 80%). <b>Conclusion:</b> The deep learning algorithm based on contrast-enhanced CT has favorable and reliable diagnostic accuracy in distinguishing gastric GIST with a diameter â‰¤ 5 cm and other gastric SMT before operation.",0,1
2256,"Abdominal synthetic CT reconstruction with intensity projection prior for MRI-only adaptive radiotherapy. <i>Objective</i>. Owing to the superior soft tissue contrast of MRI, MRI-guided adaptive radiotherapy (ART) is well-suited to managing interfractional changes in anatomy. An MRI-only workflow is desirable, but producing synthetic CT (sCT) data through paired data-driven deep learning (DL) for abdominal dose calculations remains a challenge due to the highly variable presence of intestinal gas. We present the preliminary dosimetric evaluation of our novel approach to sCT reconstruction that is well suited to handling intestinal gas in abdominal MRI-only ART.<i>Approach</i>. We utilize a paired data DL approach enabled by the intensity projection prior, in which well-matching training pairs are created by propagating air from MRI to corresponding CT scans. Evaluations focus on two classes: patients with (1) little involvement of intestinal gas, and (2) notable differences in intestinal gas presence between corresponding scans. Comparisons between sCT-based plans and CT-based clinical plans for both classes are made at the first treatment fraction to highlight the dosimetric impact of the variable presence of intestinal gas.<i>Main results</i>. Class 1 patients (<i>n</i>= 13) demonstrate differences in prescribed dose coverage of the PTV of 1.3 Â± 2.1% between clinical plans and sCT-based plans. Mean DVH differences in all structures for Class 1 patients are found to be statistically insignificant. In Class 2 (<i>n</i>= 20), target coverage is 13.3 Â± 11.0% higher in the clinical plans and mean DVH differences are found to be statistically significant.<i>Significance</i>. Significant deviations in calculated doses arising from the variable presence of intestinal gas in corresponding CT and MRI scans result in uncertainty in high-dose regions that may limit the effectiveness of adaptive dose escalation efforts. We have proposed a paired data-driven DL approach to sCT reconstruction for accurate dose calculations in abdominal ART enabled by the creation of a clinically unavailable training data set with well-matching representations of intestinal gas.",0,0
2259,"Learning the impact of acute and chronic diseases on forecasting neonatal encephalopathy. There is a wide range of risk factors predisposing to the onset of neonatal encephalopathy (NE), including maternal antepartum/intrapartum comorbidities or events. However, few studies have investigated the difference in the impact of acute and chronic diseases on forecasting NE, which could assist clinicians in choosing the best course of action to prevent NE or reduce its severity and complications. In this study, we aimed to engineer features based on acute and chronic diseases and assess the differences of the impact of acute and chronic diseases on NE prediction using machine learning models.",0,0
2260,"Improvement of automatic ischemic stroke lesion segmentation in CT perfusion maps using a learned deep neural network. Acute ischemic stroke is one of the leading causes of death and long-term disability worldwide. It occurs when a blood clot blocks an artery that supplies blood to the brain tissue. Segmentation of acute ischemic stroke lesions plays a vital role to improve diagnosis, outcome assessment, and treatment planning. The current standard approach of ischemic stroke lesion segmentation is simply thresholding the Computed Tomography Perfusion (CTP) maps, i.e., quantitative feature maps created by summarizing CTP time sequence scans. However, this approach is not precise enough (its Dice similarity score is only around 50%) to be used in practice. Numerous machine learning-based techniques have recently been proposed to improve the accuracy of ischemic stroke lesion segmentation. Although they have achieved remarkable results, they still need to be improved before they can be used in actual practice. This paper presents a novel deep learning-based technique, MutiRes U-Net, for the segmentation of ischemic stroke lesions in CTP maps. MultiRes U-Net is a modified version of the original U-Net that is re-designed to be robust to segment the objects in different scales and unusual appearances. Additionally, in this paper, we propose to enrich the input CTP maps by using their contra-lateral and corresponding Tmax images. We evaluated the proposed method using the ISLES challenge 2018 dataset. As compared to the state-of-the-art methods, the results show an improvement in segmentation task accuracy. The dice similarity score (DSC) was 68%, the Jaccard score was 57.13%, and the mean absolute volume error was 22.62(ml).",0,0
2265,"A segmentation tool for pulmonary nodules in lung cancer screening: Testing and clinical usage. With the future goal of defining a large dataset based on low-dose CT with labelled pulmonary lesions for lung cancer screening (LCS) research, the aim of this work is to propose and evaluate into a clinical context a tool for semi-automatic segmentation able to facilitate the process of labels collection from a LCS study (COSMOS, Continuous Observation of SMOking Subjects).",0,0
2266,"Screening ovarian cancers with Raman spectroscopy of blood plasma coupled with machine learning data processing. The mortality of ovarian cancer is closely related to its poor rate of early detection. In the search of an efficient diagnosis method, Raman spectroscopy of blood features as a promising technique allowing simple, rapid, minimally-invasive and cost-effective detection of cancers, in particular ovarian cancer. Although Raman spectroscopy has been demonstrated to be effective to detect ovarian cancers with respect to normal controls, a binary classification remains idealized with respect to the real clinical practice. This work considered a population of 95 woman patients initially suspected of an ovarian cancer and finally fixed with a cancer or a cyst. Additionally, 79 normal controls completed the ensemble of samples. Such sample collection proposed us a study case where a ternary classification should be realized with Raman spectroscopy of the collected blood samples coupled with suitable spectroscopic data treatment algorithms. In the medical as well as data points of view, the appearance of the cyst case considerably reduces the distances among the different populations and makes their distinction much more difficult, since the intermediate cyst case can share the specific features of the both cancer and normal cases. After a proper spectrum pretreatment, we first demonstrated the evidence of different behaviors among the Raman spectra of the 3 types of samples. Such difference was further visualized in a high dimensional space, where the data points of the cancer and the normal cases are separately clustered, whereas the data of the cyst case were scattered into the areas respectively occupied by the cancer and normal cases. We finally developed and tested an ensemble of models for a ternary classification with 2 consequent steps of binary classifications, based on machine learning algorithms, allowing identification with sensitivity and specificity of 81.0% and 97.3% for cancer samples, 63.6% and 91.5% for cyst samples, 100% and 90.6% for normal samples.",0,0
2267,"Improving differential diagnosis of pulmonary large cell neuroendocrine carcinoma and small cell lung cancer via a transcriptomic, biological pathway-based machine learning model. Accurately differentiating between pulmonary large cell neuroendocrine carcinomas (LCNEC) and small cell lung cancer (SCLC) is crucial to make appropriate therapeutic decisions. Here, a classifier was constructed based on transcriptome data to improve the diagnostic accuracy for LCNEC and SCLC.",0,0
2269,DEEP LEARNING COMPUTER-AIDED POLYP DETECTION REDUCES ADENOMA MISS RATE: A U.S. MULTI-CENTER RANDOMIZED TANDEM COLONOSCOPY STUDY (CADeT-CS Trial). Artificial intelligence-based computer aided polyp detection (CADe) systems are intended to address the issue of missed polyps during colonoscopy. The effect of CADe during screening and surveillance colonoscopy has not previously been studied in a United States population.,0,1
2274,"Predicting Future Mobility Limitation in Older Adults: A Machine Learning Analysis of Health ABC Study Data. Mobility limitation in older adults is common and associated with poor health outcomes and loss of independence. Identification of at-risk individuals remains challenging because of time-consuming clinical assessments and limitations of statistical models for dynamic outcomes over time. Therefore, we aimed to develop machine learning models for predicting future mobility limitation in older adults using repeated measures data.",0,0
2284,"Redesigning Kidney Disease Care to Improve Value Delivery. This article describes the articulation, development, and deployment of a machine learning (ML) model-driven value solution for chronic kidney disease (CKD) in a health system. The ML model activated an electronic medical record (EMR) trigger that alerted CKD patients to seek primary care. Simultaneously, primary care physicians (PCPs) received an alert that a CKD patient needed an appointment. Using structured checklists, PCPs addressed and controlled comorbid conditions, reconciled drug dosing and choice to CKD stage, and ordered prespecified laboratory and imaging tests pertinent to CKD. After completion of checklist prescribed tasks, PCPs referred patients to nephrology. CKD patients had multiple comorbidities and ML recognition of CKD provided a facile insight into comorbid burden. Operational results of this program have exceeded expectations and the program is being expanded to the entire health system. This paradigm of ML-driven, checklist-enabled care can be used agnostic of EMR platform to deliver value in CKD through structured engagement of complexity in health systems.",0,0
2291,Predicting survival after radical prostatectomy: Variation of machine learning performance by race. Robust prediction of survival can facilitate clinical decision-making and patient counselling. Non-Caucasian males are underrepresented in most prostate cancer databases. We evaluated the variation in performance of a machine learning (ML) algorithm trained to predict survival after radical prostatectomy in race subgroups.,0,0
2297,"Comparing ecological momentary assessment to sensor-based approaches in predicting dietary lapse. Ecological momentary assessment (EMA; brief self-report surveys) of dietary lapse risk factors (e.g., cravings) has shown promise in predicting and preventing dietary lapse (nonadherence to a dietary prescription), which can improve weight loss interventions. Passive sensors also can measure lapse risk factors and may offer advantages over EMA (e.g., objective, automatic, semicontinuous data collection), but currently can measure only a few lapse predictors, a notable limitation. This study preliminarily compared the burden and accuracy of commercially available sensors versus established EMA in lapse prediction. N = 23 adults with overweight/obesity completed a 6-week commercial app-based weight loss program. Participants wore a Fitbit, enabled GPS tracking, completed EMA, and reported on EMA and sensor burden poststudy via a 5-point Likert scale. Sensed risk factors were physical activity and sleep (accelerometer), geolocation (GPS), and time, from which 233 features (measurable characteristics of sensor signals) were extracted. EMA measured 19 risk factors, lapse, and categorized GPS into meaningful geolocations. Two supervised binary classification models (LASSO) were created: the sensor model predicted lapse with 63% sensitivity (true prediction rate of lapse) and 60% specificity (true prediction rate of non-lapse) and EMA model with 59% sensitivity and 72% specificity. EMA model accuracy was higher, but self-reported EMA burden (M = 2.96, SD = 1.02) also was higher (M = 1.50, SD = 0.94). EMA model accuracy was superior, but EMA burden was higher than sensor burden. Findings highlight the promise of sensors in contributing to lapse prediction, and future research may use EMA, sensors, or both depending on prioritization of accuracy versus participant burden.",0,0
2299,"Raman tweezers as an alternative diagnostic tool for paroxysmal nocturnal hemoglobinuria. Paroxysmal nocturnal hemoglobinuria (PNH) is a rare disease characterized by hemolysis of red blood cells (RBC) and venous thrombosis. The gold standard method for the diagnosis of this disease is flow cytometry. Here, we propose a combined optical tweezers and Raman spectral (Raman tweezers) approach to analyze blood samples from volunteers with or without PNH conditions. Raman spectroscopy is a well-known method for investigating a material's chemical structure and is also used in molecular analysis of biological compounds. In this study, we trap individual RBCs found in whole blood samples drawn from PNH patients and the control group. Evaluation of the Raman spectra of these cells by band component analysis and machine learning shows a significant difference between the two groups. The specificity and the sensitivity of the training performed by support vector machine (SVM) analysis were found to be 81.8% and 78.3%, respectively. This study shows that an immediate and high accuracy test result is possible for PNH disease by employing Raman tweezers and machine learning.",0,0
2300,"Machine Learning Technique Reveals Prognostic Factors of Vibrant Soundbridge for Conductive or Mixed Hearing Loss Patients. Vibrant Soundbridge (VSB) was developed for treatment of hearing loss, but clinical outcomes vary and prognostic factors predicting the success of the treatment remain unknown. We examined clinical outcomes of VSB for conductive or mixed hearing loss, prognostic factors by analyzing prediction models, and cut-off values to predict the outcomes.",0,0
2306,Development and validation of a predictive model for feeding intolerance in intensive care unit patients with sepsis. Feeding intolerance in patients with sepsis is associated with a lower enteral nutrition (EN) intake and worse clinical outcomes. The aim of this study was to develop and validate a predictive model for enteral feeding intolerance in the intensive care unit patients with sepsis.,0,0
2310,"CARes-UNet: Content-aware residual UNet for lesion segmentation of COVID-19 from chest CT images. Coronavirus disease 2019 (COVID-19) has caused a serious global health crisis. It has been proven that the deep learning method has great potential to assist doctors in diagnosing COVID-19 by automatically segmenting the lesions in computed tomography (CT) slices. However, there are still several challenges restricting the application of these methods, including high variation in lesion characteristics and low contrast between lesion areas and healthy tissues. Moreover, the lack of high-quality labeled samples and large number of patients lead to the urgency to develop a high accuracy model, which performs well not only under supervision but also with semi-supervised methods.",0,0
2313,The added value of an artificial intelligence system in assisting radiologists on indeterminate BI-RADS 0 mammograms. To investigate the value of an artificial intelligence (AI) system in assisting radiologists to improve the assessment accuracy of BI-RADS 0 cases in mammograms.,1,1
2321,A Novel Classifier Based on Urinary Proteomics for Distinguishing Between Benign and Malignant Ovarian Tumors. Preoperative differentiation of benign and malignant tumor types is critical for providing individualized treatment interventions to improve prognosis of patients with ovarian cancer. High-throughput proteomics analysis of urine samples was performed to identify reliable and non-invasive biomarkers that could effectively discriminate between the two ovarian tumor types.,0,0
2324,"Estimation of Blood Alcohol Concentration From Smartphone Gait Data Using Neural Networks. Driving is a dynamic activity, which requires quick reflexes and decision making in order to respond to sudden changes in traffic conditions. Alcohol consumption impairs motor and cognitive skills, and causes many driving-related accidents annually. Passive methods of proactively detecting drivers who are too drunk to drive in order to notify them and prevent accidents, have recently been proposed. The effects of alcohol on a drinker's gait (walk) is a reliable indicator of their intoxication level. In this paper, we investigate detecting drinkers' intoxication levels from their gait by using neural networks to analyze sensor data gathered from their smartphone. Using data gathered from a large controlled alcohol study, we perform regression analysis using a Bi-directional Long Short Term Memory (Bi-LSTM) and Convolutional Neural Network (CNN) architectures to predict a person's Blood Alcohol Concentration (BAC) from their smartphone's accelerometer and gyroscope data. We innovatively proposed a comprehensive suite of pre-processing techniques and model-specific extensions to vanilla CNN and bi-LSTM models, which are well thought out and adapted specifically for BAC estimation. Our Bi-LSTM architecture achieves an RMSE of 0.0167 and the CNN architecture achieves an RMSE of 0.0168, outperforming state-of-the-art intoxication detection models using Bayesian Regularized Multilayer Perceptrons (MLP) (RMSE of 0.017) and the Random Forest (RF), with hand-crafted features. Moreover, our models learn features from raw sensor data, obviating the need for hand-crafted features, which is time consuming. Moreover, they achieve lower variance across folds and are hence more generalizable.",0,0
2335,"Research on Key Algorithms of the Lung CAD System Based on Cascade Feature and Hybrid Swarm Intelligence Optimization for MKL-SVM. Feature selection and lung nodule recognition are the core modules of the lung computer-aided detection (Lung CAD) system. To improve the performance of the Lung CAD system, algorithmic research is carried out for the above two parts, respectively. First, in view of the poor interpretability of deep features and the incomplete expression of clinically defined handcrafted features, a feature cascade method is proposed to obtain richer feature information of nodules as the final input of the classifier. Second, to better map the global characteristics of samples, the multiple kernel learning support vector machine (MKL-SVM) algorithm with a linear convex combination of polynomial kernel and sigmoid kernel is proposed. Furthermore, this paper applied the methods for speed contraction factor and roulette strategy, and a mixture of simulated annealing (SA) and particle swarm optimization (PSO) is used for global optimization, so as to solve the problem that the PSO is easy to lose particle diversity and fall into the local optimal solution as well as improve the model's training speed. Therefore, the MKL-SVM algorithm is presented in this paper, which is based on swarm intelligence optimization is proposed for lung nodule recognition. Finally, the algorithm construction experiments are conducted on the cooperative hospital dataset and compared with 8 advanced algorithms on the public dataset LUNA16. The experimental results show that the proposed algorithms can improve the accuracy of lung nodule recognition and reduce the missed detection of nodules.",0,0
2337,"Federated learning for predicting clinical outcomes in patients with COVID-19. Federated learning (FL) is a method used for training artificial intelligence models with data from multiple sources while maintaining data anonymity, thus removing many barriers to data sharing. Here we used data from 20â€‰institutes across the globe to train a FL model, called EXAM (electronic medical record (EMR) chest X-ray AI model), that predicts the future oxygen requirements of symptomatic patients with COVID-19 using inputs of vital signs, laboratory data and chest X-rays. EXAM achieved an average area under the curve (AUC) >0.92 for predicting outcomes at 24 and 72â€‰h from the time of initial presentation to the emergency room, and it provided 16% improvement in average AUC measured across all participating sites and an average increase in generalizability of 38% when compared with models trained at a single site using that site's data. For prediction of mechanical ventilation treatment or death at 24â€‰h at the largest independent test site, EXAM achieved a sensitivity of 0.950 and specificity of 0.882. In this study, FL facilitated rapid data science collaboration without data exchange and generated a model that generalized across heterogeneous, unharmonized datasets for prediction of clinical outcomes in patients with COVID-19, setting the stage for the broader use of FL in healthcare.",0,0
2340,"A deep transfer learning approach for wearable sleep stage classification with photoplethysmography. Unobtrusive home sleep monitoring using wrist-worn wearable photoplethysmography (PPG) could open the way for better sleep disorder screening and health monitoring. However, PPG is rarely included in large sleep studies with gold-standard sleep annotation from polysomnography. Therefore, training data-intensive state-of-the-art deep neural networks is challenging. In this work a deep recurrent neural network is first trained using a large sleep data set with electrocardiogram (ECG) data (292 participants, 584 recordings) to perform 4-class sleep stage classification (wake, rapid-eye-movement, N1/N2, and N3). A small part of its weights is adapted to a smaller, newer PPG data set (60 healthy participants, 101 recordings) through three variations of transfer learning. Best results (Cohen's kappa of 0.65â€‰Â±â€‰0.11, accuracy of 76.36â€‰Â±â€‰7.57%) were achieved with the domain and decision combined transfer learning strategy, significantly outperforming the PPG-trained and ECG-trained baselines. This performance for PPG-based 4-class sleep stage classification is unprecedented in literature, bringing home sleep stage monitoring closer to clinical use. The work demonstrates the merit of transfer learning in developing reliable methods for new sensor technologies by reusing similar, older non-wearable data sets. Further study should evaluate our approach in patients with sleep disorders such as insomnia and sleep apnoea.",0,0
2341,"Non-invasive diagnosis of deep vein thrombosis from ultrasound imaging with machine learning. Deep vein thrombosis (DVT) is a blood clot most commonly found in the leg, which can lead to fatal pulmonary embolism (PE). Compression ultrasound of the legs is the diagnostic gold standard, leading to a definitive diagnosis. However, many patients with possible symptoms are not found to have a DVT, resulting in long referral waiting times for patients and a large clinical burden for specialists. Thus, diagnosis at the point of care by non-specialists is desired. We collect images in a pre-clinical study and investigate a deep learning approach for the automatic interpretation of compression ultrasound images. Our method provides guidance for free-hand ultrasound and aids non-specialists in detecting DVT. We train a deep learning algorithm on ultrasound videos from 255 volunteers and evaluate on a sample size of 53 prospectively enrolled patients from an NHS DVT diagnostic clinic and 30 prospectively enrolled patients from a German DVT clinic. Algorithmic DVT diagnosis performance results in a sensitivity within a 95% CI range of (0.82, 0.94), specificity of (0.70, 0.82), a positive predictive value of (0.65, 0.89), and a negative predictive value of (0.99, 1.00) when compared to the clinical gold standard. To assess the potential benefits of this technology in healthcare we evaluate the entire clinical DVT decision algorithm and provide cost analysis when integrating our approach into diagnostic pathways for DVT. Our approach is estimated to generate a positive net monetary benefit at costs up to Â£72 to Â£175 per software-supported examination, assuming a willingness to pay of Â£20,000/QALY.",0,1
2345,"Decision making on vestibular schwannoma treatment: predictions based on machine-learning analysis. Decision making on the treatment of vestibular schwannoma (VS) is mainly based on the symptoms, tumor size, patient's preference, and experience of the medical team. Here we provide objective tools to support the decision process by answering two questions: can a single checkup predict the need of active treatment?, and which attributes of VS development are important in decision making on active treatment? Using a machine-learning analysis of medical records of 93 patients, the objectives were addressed using two classification tasks: a time-independent case-based reasoning (CBR), where each medical record was treated as independent, and a personalized dynamic analysis (PDA), during which we analyzed the individual development of each patient's state in time. Using the CBR method we found that Koos classification of tumor size, speech reception threshold, and pure tone audiometry, collectively predict the need for active treatment with approximately 90% accuracy; in the PDA task, only the increase of Koos classification and VS size were sufficient. Our results indicate that VS treatment may be reliably predicted using only a small set of basic parameters, even without the knowledge of individual development, which may help to simplify VS treatment strategies, reduce the number of examinations, and increase cause effectiveness.",0,0
2346,"Predicting the gender of individuals with tinnitus based on daily life data of the TrackYourTinnitus mHealth platform. Tinnitus is an auditory phantom perception in the absence of an external sound stimulation. People with tinnitus often report severe constraints in their daily life. Interestingly, indications exist on gender differences between women and men both in the symptom profile as well as in the response to specific tinnitus treatments. In this paper, data of the TrackYourTinnitus platform (TYT) were analyzed to investigate whether the gender of users can be predicted. In general, the TYT mobile Health crowdsensing platform was developed to demystify the daily and momentary variations of tinnitus symptoms over time. The goal of the presented investigation is a better understanding of gender-related differences in the symptom profiles of users from TYT. Based on two questionnaires of TYT, four machine learning based classifiers were trained and analyzed. With respect to the provided daily answers, the gender of TYT users can be predicted with an accuracy of 81.7%. In this context, worries, difficulties in concentration, and irritability towards the family are the three most important characteristics for predicting the gender. Note that in contrast to existing studies on TYT, daily answers to the worst symptom question were firstly investigated in more detail. It was found that results of this question significantly contribute to the prediction of the gender of TYT users. Overall, our findings indicate gender-related differences in tinnitus and tinnitus-related symptoms. Based on evidence that gender impacts the development of tinnitus, the gathered insights can be considered relevant and justify further investigations in this direction.",0,0
2347,"Machine learning risk prediction model for acute coronary syndrome and death from use of non-steroidal anti-inflammatory drugs in administrative data. Our aim was to investigate the usefulness of machine learning approaches on linked administrative health data at the population level in predicting older patients' one-year risk of acute coronary syndrome and death following the use of non-steroidal anti-inflammatory drugs (NSAIDs). Patients from a Western Australian cardiovascular population who were supplied with NSAIDs between 1 Jan 2003 and 31 Dec 2004 were identified from Pharmaceutical Benefits Scheme data. Comorbidities from linked hospital admissions data and medication history were inputs. Admissions for acute coronary syndrome or death within one year from the first supply date were outputs. Machine learning classification methods were used to build models to predict ACS and death. Model performance was measured by the area under the receiver operating characteristic curve (AUC-ROC), sensitivity and specificity. There were 68,889 patients in the NSAIDs cohort with mean age 76Â years and 54% were female. 1882 patients were admitted for acute coronary syndrome and 5405 patients died within one year after their first supply of NSAIDs. The multi-layer neural network, gradient boosting machine and support vector machine were applied to build various classification models. The gradient boosting machine achieved the best performance with an average AUC-ROC of 0.72 predicting ACS and 0.84 predicting death. Machine learning models applied to linked administrative data can potentially improve adverse outcome risk prediction. Further investigation of additional data and approaches are required to improve the performance for adverse outcome risk prediction.",0,0
2353,"Machine Learning Prediction for Supplemental Oxygen Requirement in Patients with COVID-19. The coronavirus disease (COVID-19) poses an urgent threat to global public health and is characterized by rapid disease progression even in mild cases. In this study, we investigated whether machine learning can be used to predict which patients will have a deteriorated condition and require oxygenation in asymptomatic or mild cases of COVID-19.",0,0
2354,"Artificial Intelligence Trained by Deep Learning Can Improve Computed Tomography Diagnosis of Nontraumatic Subarachnoid Hemorrhage by Nonspecialists. Subarachnoid hemorrhage (SAH) is a serious cerebrovascular disease with a high mortality rate and is known as a disease that is hard to diagnose because it may be overlooked by noncontrast computed tomography (NCCT) examinations that are most frequently used for diagnosis. To create a system preventing this oversight of SAH, we trained artificial intelligence (AI) with NCCT images obtained from 419 patients with nontraumatic SAH and 338 healthy subjects and created an AI system capable of diagnosing the presence and location of SAH. Then, we conducted experiments in which five neurosurgery specialists, five nonspecialists, and the AI system interpreted NCCT images obtained from 135 patients with SAH and 196 normal subjects. The AI system was capable of performing a diagnosis of SAH with equal accuracy to that of five neurosurgery specialists, and the accuracy was higher than that of nonspecialists. Furthermore, the diagnostic accuracy of four out of five nonspecialists improved by interpreting NCCT images using the diagnostic results of the AI system as a reference, and the number of oversight cases was significantly reduced by the support of the AI system. This is the first report demonstrating that an AI system improved the diagnostic accuracy of SAH by nonspecialists.",1,1
2360,"Data analysis with Shapley values for automatic subject selection in Alzheimer's disease data sets using interpretable machine learning. For the recruitment and monitoring of subjects for therapy studies, it is important to predict whether mild cognitive impaired (MCI) subjects will prospectively develop Alzheimer's disease (AD). Machine learning (ML) is suitable to improve early AD prediction. The etiology of AD is heterogeneous, which leads to high variability in disease patterns. Further variability originates from multicentric study designs, varying acquisition protocols, and errors in the preprocessing of magnetic resonance imaging (MRI) scans. The high variability makes the differentiation between signal and noise difficult and may lead to overfitting. This article examines whether an automatic and fair data valuation method based on Shapley values can identify the most informative subjects to improve ML classification.",0,0
2383,"Predicting length of stay and mortality among hospitalized patients with type 2 diabetes mellitus and hypertension. Type 2 diabetes mellitus (T2DM) and hypertension (HTN), both non-communicable diseases, are leading causes of death globally, with more imbalances in lower middle-income countries. Furthermore, poor treatment and management are known to lead to intensified healthcare utilization and increased medical care costs and impose a significant societal burden, in these countries, including Indonesia. Predicting future clinical outcomes can determine the line of treatment and value of healthcare costs, while ensuring effective patient care. In this paper, we present the prediction of length of stay (LoS) and mortality among hospitalized patients at a tertiary referral hospital in Tasikmalaya, Indonesia, between 2016 and 2019. We also aimed to determine how socio-demographic characteristics, and T2DM- or HTN-related comorbidities affect inpatient LoS and mortality.",0,0
2384,"Applying interpretable deep learning models to identify chronic cough patients using EHR data. Chronic cough (CC) affects approximately 10% of adults. Many disease states are associated with chronic cough, such as asthma, upper airway cough syndrome, bronchitis, and gastroesophageal reflux disease. The lack of an ICD code specific for chronic cough makes it challenging to identify such patients from electronic health records (EHRs). For clinical and research purposes, computational methods using EHR data are urgently needed to identify chronic cough cases. This research aims to investigate the data representations and deep learning algorithms for chronic cough prediction.",0,0
2395,"Implementing a Machine Learning Strategy to Predict Pathologic Response in Patients With Soft Tissue Sarcomas Treated With Neoadjuvant Chemotherapy. Neoadjuvant chemotherapy (NAC) has been increasingly used in patients with locally advanced high-risk soft tissue sarcomas in the past decade, but definition and prognostic impact of a good histologic response (GHR) are lacking. Our aim was to investigate which histologic feature from the post-NAC surgical specimen independently correlated with metastatic relapse-free survival (MFS) in combination with clinical, radiologic, and pathologic features using a machine learning approach.",0,0
2401,"Polycystic ovary syndrome: clinical and laboratory variables related to new phenotypes using machine-learning models. Polycystic Ovary Syndrome (PCOS) is the most frequent endocrinopathy in women of reproductive age. Machine learning (ML) is the area of artificial intelligence with a focus on predictive computing algorithms. We aimed to define the most relevant clinical and laboratory variables related to PCOS diagnosis, and to stratify patients into different phenotypic groups (clusters) using ML algorithms.",0,0
2402,"Automatic segmentation of whole-body adipose tissue from magnetic resonance fat fraction images based on machine learning. To propose a fully automated algorithm, which is implemented to segment subcutaneous adipose tissue (SAT) and internal adipose tissue (IAT) from the total adipose tissue for whole-body fat distribution analysis using proton density fat fraction (PDFF) magnetic resonance images.",0,0
2408,"Deep-Learning-Based Pre-Diagnosis Assessment Module for Retinal Photographs: A Multicenter Study. Artificial intelligence (AI) deep learning (DL) has been shown to have significant potential for eye disease detection and screening on retinal photographs in different clinical settings, particular in primary care. However, an automated pre-diagnosis image assessment is essential to streamline the application of the developed AI-DL algorithms. In this study, we developed and validated a DL-based pre-diagnosis assessment module for retinal photographs, targeting image quality (gradable vs. ungradable), field of view (macula-centered vs. optic-disc-centered), and laterality of the eye (right vs. left).",0,0
2418,"Image Quality and Diagnostic Performance of Accelerated Shoulder MRI With Deep Learning-Based Reconstruction. <b>Background:</b> Shoulder MRI using standard multiplanar sequences requires long scan times. Accelerated sequences have tradeoffs in noise and resolution. Deep learning-based reconstruction (DLR) may allow reduced scan time with preserved image quality. <b>Objectives:</b> To compare standard shoulder MRI sequences and accelerated sequences without and with DLR in terms of image quality and diagnostic performance. <b>Methods:</b> This retrospective study included 105 patients (45 men, 60 women; mean age 57.6Â±10.9 years) who underwent a total of 110 3-T shoulder MRI examinations. Examinations included standard sequences (scan time, 9 minutes 23 seconds) and accelerated sequences (3 minutes 5 seconds; 67% reduction), both including fast spin echo sequences in three planes. Standard sequences were reconstructed using the conventional pipeline; accelerated sequences were reconstructed using both conventional pipeline and a commercially available DLR pipeline. Two radiologists independently assessed three image sets (standard, accelerated without DLR, accelerated with DLR) for subjective image quality and artifacts using 4-point scales (4=highest quality), and identified pathologies of subscapularis tendon, supraspinatus-infraspinatus tendon, biceps brachii long head tendon, and glenoid labrum. Interobserver and inter-image set agreement for the evaluated pathologies was assessed using weighted kappa statistics. In 27 patients who underwent arthroscopy, diagnostic performance was calculated using arthroscopic findings as reference. <b>Results:</b> Mean subjective image quality for readers 1 and 2 was 10.6Â±1.2 and 10.5Â±1.4 for standard, 8.1Â±1.3 and 7.2Â±1.1 for accelerated without DLR, and 10.7Â±1.2 and 10.5Â±1.6 for accelerated with DLR. Mean artifact score for readers 1 and 2 was 9.3Â±1.2 and 10.0Â±1.0 for standard, 7.3Â±1.3 and 9.1Â±0.8 for accelerated without DLR, and 9.4Â±1.2 and 9.8Â±0.8 for accelerated with DLR. Interobserver agreement ranged from kappa=0.813-0.951 except for accelerated without DLR for SST-IST (Îº=0.673). Inter-image set agreement ranged from kappa=0.809-0.957 except for reader 1 for SST-IST (Îº=0.663-0.700). Accuracy, sensitivity, and specificity for tears of the four structures was not different (p>.05) among image sets. <b>Conclusions:</b> Accelerated sequences with DLR provide 67% scan time reduction with similar subjective image quality, artifacts, and diagnostic performance as standard sequences. <b>Clinical impact:</b> Accelerated sequences with DLR may provide an alternative to standard sequences for clinical shoulder MRI.",1,1
2423,"ASU-Net++: A nested U-Net with adaptive feature extractions for liver tumor segmentation. Locating tumors from medical images is of high importance in medical analysis and diagnosis. To tackle the complicated shape of tumors, we propose a multi-leves.l feature extraction neural network to automatically segment the data. Our proposed model is trained and tested with one liver tumor ultrasound and two CT datasets. We employ ++, a collaborative model that uses modified nested U-Net, as our backbone. The model is integrated with dilated dense short skip connections within convolution blocks to further improve the gradient flow and feature preservation. In addition, we modify the original Atrous Spatial Pyramid Pooling (ASPP) to an adaptive pooling structure for better compatibility with nested U-Net. Adaptive ASPP is designed to extract features from different levels and cover the increasing range of feature extraction with regard to the depth of the nested network. Our model showed its advantage in accurately segmenting different tumor sizes with complex edges and was able to generalize with small and diverse datasets. We further improved our model with the newly introduced AdaBelief optimizer and achieved a faster convergence rate. Segmentation results showed that the proposed model outperformed multiple network structures, and achieved a 0.9153 dice coefficient for the ultrasound dataset, a 0.9413 and a 0.9246 dice coefficient for the two CT datasets.",0,0
2428,"Targeted fatty acid metabolomics to discover Parkinson's disease associated metabolic alteration. The pathogenesis of Parkinson's disease (PD) remains to be elucidated, and the metabolomics analysis has the potential to identify metabolic profiles that are involved in PD pathogenesis. Here we applied a target metabolomics approach to measure the plasma levels of 158 fatty acid metabolites in a discovery cohort including 42 PD patients and 54 health volunteers, and found two upregulated (arachidonic acid and 13-hydroxy-octadecatrienoic acid) and eleven down-regulated (docosahexaenoic acid, lyso-platelet-activating factor, 12-hydroxy-eicosatetraenoic acid, dihydroxy-eicosatrienoic acids, dihidroxy-octadecenoic acids, 17,18-dihydroxy-eicosatetraenoic acid, and hydroperoxy-octadecadienoic acids) metabolites as primary candidate marker of PD. A support vector machine algorithm with primary candidate marker was used in an independent validation cohort to identify PD. Arachidonic acid and 13-hydroxy-octadecatrienoic acid were evaluated as an effective tool in that area under the receiver operating characteristic curve reached 0.995 and 0.912 in the validation set for diagnosing PD from healthy volunteers. Besides, the sensitivity and specificity of arachidonic acid as diagnostic factor of PD in validation set were 100% and 94.10%. Similarly, the sensitivity and specificity of 13-hydroxy-octadecatrienoic acid were 100% and 82.40% for identifying PD. This target fatty acid metabolomics demonstrated a series of plasma fatty acid metabolite as PD candidate marker with high efficiency and provided insights into the understanding of PD metabolic regulation.",0,0
2430,Deep learning-augmented radioluminescence imaging for radiotherapy dose verification. We developed a novel dose verification method using a camera-based radioluminescence imaging system (CRIS) combined with a deep learning-based signal processing technique.,0,0
2433,"Spatio-temporal hybrid neural networks reduce erroneous human ""judgement calls"" in the diagnosis of Takotsubo syndrome. We investigate whether deep learning (DL) neural networks can reduce erroneous human ""judgment calls"" on bedside echocardiograms and help distinguish Takotsubo syndrome (TTS) from anterior wall ST segment elevation myocardial infarction (STEMI).",0,0
2443,"Application of a Neural Network Classifier to Radiofrequency-Based Osteopenia/Osteoporosis Screening. There is an unmet need for quick, physically small, and cost-effective office-based techniques that can measure bone properties without the use of ionizing radiation.",0,0
2448,"Automated COVID-19 diagnosis and classification using convolutional neural network with fusion based feature extraction model. COVID-19 was first identified in December 2019 at Wuhan, China. At present, the outbreak of COVID-19 pandemic has resulted in severe consequences on both economic and social infrastructures of the developed and developing countries. Several studies have been conducted and ongoing still to design efficient models for diagnosis and treatment of COVID-19 patients. The traditional diagnostic models that use reverse transcription-polymerase chain reaction (rt-qPCR) is a costly and time-consuming process. So, automated COVID-19 diagnosis using Deep Learning (DL) models becomes essential. The primary intention of this study is to design an effective model for diagnosis and classification of COVID-19. This research work introduces an automated COVID-19 diagnosis process using Convolutional Neural Network (CNN) with a fusion-based feature extraction model, called FM-CNN. FM-CNN model has three major phases namely, pre-processing, feature extraction, and classification. Initially, Wiener Filtering (WF)-based preprocessing is employed to discard the noise that exists in input chest X-Ray (CXR) images. Then, the pre-processed images undergo fusion-based feature extraction model which is a combination of Gray Level Co-occurrence Matrix (GLCM), Gray Level Run Length Matrix (GLRM), and Local Binary Patterns (LBP). In order to determine the optimal subset of features, Particle Swarm Optimization (PSO) algorithm is employed. At last, CNN is deployed as a classifier to identify the existence of binary and multiple classes of CXR images. In order to validate the proficiency of the proposed FM-CNN model in terms of its diagnostic performance, extension experimentation was carried out upon CXR dataset. As per the results attained from simulation, FM-CNN model classified multiple classes with the maximum sensitivity of 97.22%, specificity of 98.29%, accuracy of 98.06%, and F-measure of 97.93%.",0,0
2449,Combining Resampling Strategies and Ensemble Machine Learning Methods to Enhance Prediction of Neonates with a Low Apgar Score After Induction of Labor in Northern Tanzania. The goal of this study was to establish the most efficient boosting method in predicting neonatal low Apgar scores following labor induction intervention and to assess whether resampling strategies would improve the predictive performance of the selected boosting algorithms.,0,0
2450,"A smart healthcare framework for detection and monitoring of COVID-19 using IoT and cloud computing. Coronavirus (COVID-19) is a very contagious infection that has drawn the world's attention. Modeling such diseases can be extremely valuable in predicting their effects. Although classic statistical modeling may provide adequate models, it may also fail to understand the data's intricacy. An automatic COVID-19 detection system based on computed tomography (CT) scan or X-ray images is effective, but a robust system design is challenging. In this study, we propose an intelligent healthcare system that integrates IoT-cloud technologies. This architecture uses smart connectivity sensors and deep learning (DL) for intelligent decision-making from the perspective of the smart city. The intelligent system tracks the status of patients in real time and delivers reliable, timely, and high-quality healthcare facilities at a low cost. COVID-19 detection experiments are performed using DL to test the viability of the proposed system. We use a sensor for recording, transferring, and tracking healthcare data. CT scan images from patients are sent to the cloud by IoT sensors, where the cognitive module is stored. The system decides the patient status by examining the images of the CT scan. The DL cognitive module makes the real-time decision on the possible course of action. When information is conveyed to a cognitive module, we use a state-of-the-art classification algorithm based on DL, i.e., ResNet50, to detect and classify whether the patients are normal or infected by COVID-19. We validate the proposed system's robustness and effectiveness using two benchmark publicly available datasets (Covid-Chestxray dataset and Chex-Pert dataset). At first, a dataset of 6000 images is prepared from the above two datasets. The proposed system was trained on the collection of images from 80% of the datasets and tested with 20% of the data. Cross-validation is performed using a tenfold cross-validation technique for performance evaluation. The results indicate that the proposed system gives an accuracy of 98.6%, a sensitivity of 97.3%, a specificity of 98.2%, and an F1-score of 97.87%. Results clearly show that the accuracy, specificity, sensitivity, and F1-score of our proposed method are high. The comparison shows that the proposed system performs better than the existing state-of-the-art systems. The proposed system will be helpful in medical diagnosis research and healthcare systems. It will also support the medical experts for COVID-19 screening and lead to a precious second opinion.",0,0
2458,"ECG data dependency for atrial fibrillation detection based on residual networks. Atrial fibrillation (AF) is an arrhythmia that can cause blood clot and may lead to stroke and heart failure. To detect AF, deep learning-based detection algorithms have recently been developed. However, deep learning models were often trained with limited datasets and were evaluated within the same datasets, which makes their performance generally drops on the external datasets, known as data dependency. For this study, three different databases from PhysioNet were used to investigate the data dependency of deep learning-based AF detection algorithm using the residual neural network (Resnet). Resnet 18, 34, 50 and 152 model were trained with raw electrocardiogram (ECG) signal extracted from independent database. The highest accuracy was about 98-99% which is evaluation results of test dataset from the own database. On the other hand, the lowest accuracy was about 53-92% which was evaluation results of the external dataset extracted from different source. There are data dependency according to the train dataset and the test dataset. However, the data dependency decreased as a large amount of train data.",0,0
2462,Multicenter Validation of a Deep Learning Detection Algorithm for Focal Cortical Dysplasia. To test the hypothesis that a multicenter-validated computer deep learning algorithm detects MRI-negative focal cortical dysplasia (FCD).,0,0
2467,Evaluation of artificial intelligence using time-lapse images of IVF embryos to predict live birth. Can artificial intelligence (AI) improve the prediction of live births based on embryo images?,0,0
2469,"Strategies to develop radiomics and machine learning models for lung cancer stage and histology prediction using small data samples. Predictive models based on radiomics and machine-learning (ML) need large and annotated datasets for training, often difficult to collect. We designed an operative pipeline for model training to exploit data already available to the scientific community. The aim of this work was to explore the capability of radiomic features in predicting tumor histology and stage in patients with non-small cell lung cancer (NSCLC). We analyzed the radiotherapy planning thoracic CT scans of a proprietary sample of 47 subjects (L-RT) and integrated this dataset with a publicly available set of 130 patients from the MAASTRO NSCLC collection (Lung1). We implemented intra- and inter-sample cross-validation strategies (CV) for evaluating the ML predictive model performances with not so large datasets. We carried out two classification tasks: histology classification (3 classes) and overall stage classification (two classes: stage I and II). In the first task, the best performance was obtained by a Random Forest classifier, once the analysis has been restricted to stage I and II tumors of the Lung1 and L-RT merged dataset (AUCÂ =Â 0.72Â Â±Â 0.11). For the overall stage classification, the best results were obtained when training on Lung1 and testing of L-RT dataset (AUCÂ =Â 0.72Â Â±Â 0.04 for Random Forest and AUCÂ =Â 0.84Â Â±Â 0.03 for linear-kernel Support Vector Machine). According to the classification task to be accomplished and to the heterogeneity of the available dataset(s), different CV strategies have to be explored and compared to make a robust assessment of the potential of a predictive model based on radiomics and ML.",0,0
2470,"Radiomics analysis of EPID measurements for patient positioning error detection in thyroid associated ophthalmopathy radiotherapy. Electronic portal imaging detector (EPID)-based patient positioning verification is an important component of safe radiotherapy treatment delivery. In computer simulation studies, learning-based approaches have proven to be superior to conventional gamma analysis in the detection of positioning errors. To approximate a clinical scenario, the detectability of positioning errors via EPID measurements was assessed using radiomics analysis for patients with thyroid-associated ophthalmopathy.",0,0
2471,"Densely connected attention network for diagnosing COVID-19 based on chest CT. To fully enhance the feature extraction capabilities of deep learning models, so as to accurately diagnose coronavirus disease 2019 (COVID-19) based on chest CT images, a densely connected attention network (DenseANet) was constructed by utilizing the self-attention mechanism in deep learning.",0,0
2472,"Two-phase non-invasive multi-disease detection via sublingual region. Non-invasive multi-disease detection is an active technology that detects human diseases automatically. By observing images of the human body, computers can make inferences on disease detection based on artificial intelligence and computer vision techniques. The sublingual vein, lying on the lower part of the human tongue, is a critical identifier in non-invasive multi-disease detection, reflecting health status. However, few studies have fully investigated non-invasive multi-disease detection via the sublingual vein using a quantitative method. In this paper, a two-phase sublingual-based disease detection framework for non-invasive multi-disease detection was proposed. In this framework, sublingual vein region segmentation was performed on each image in the first phase to achieve the region with the highest probability of covering the sublingual vein. In the second phase, features in this region were extracted, and multi-class classification was applied to these features to output a detection result. To better represent the characterisation of the obtained sublingual vein region, multi-feature representations were generated of the sublingual vein region (based on color, texture, shape, and latent representation). The effectiveness of sublingual-based multi-disease detection was quantitatively evaluated, and the proposed framework was based on 1103 sublingual vein images from patients in different health status categories. The best multi-feature representation was generated based on color, texture, and latent representation features with the highest accuracy of 98.05%.",0,0
2476,Micro-Computed Tomography Guided Artificial Intelligence for Pulp Cavity and Tooth Segmentation on Cone-beam Computed Tomography. This study proposes a novel data pipeline based on micro-CT data for training the U-Net network to realize the automatic and accurate segmentation of pulp cavity and tooth on cone-beam computed tomography (CBCT) images.,0,0
2480,Machine learning algorithms using routinely collected data do not adequately predict viremia to inform targeted services in postpartum women living with HIV. Adherence to antiretroviral treatment (ART) among postpartum women with HIV is essential for optimal health and prevention of perinatal transmission. However suboptimal adherence with subsequent viremia is common and adherence challenges are often under-reported. We aimed to predict viremia to facilitate targeted adherence support in sub-Saharan Africa during this critical period.,0,0
2485,"Machine learning-based noninvasive quantification of single-imaging session dual-tracer 18F-FDG and 68Ga-DOTATATE dynamic PET-CT in oncology. 68Ga-DOTATATE PET-CT is routinely used for imaging neuroendocrine tumor (NET) somatostatin receptor subtype 2 (SSTR2) density in patients, and is complementary to FDG PET-CT for improving the accuracy of NET detection, characterization, grading, staging, and predicting/monitoring NET responses to treatment. Performing sequential 18F-FDG and 68Ga-DOTATATE PET scans would require 2 or more days and can delay patient care. To align temporal and spatial measurements of 18F-FDG and 68Ga-DOTATATE PET, and to reduce scan time and CT radiation exposure to patients, we propose a single-imaging session dual-tracer dynamic PET acquisition protocol in the study. A recurrent extreme gradient boosting (rXGBoost) machine learning algorithm was proposed to separate the mixed 18F-FDG and 68Ga-DOTATATE time activity curves (TACs) for the region of interest (ROI) based quantification with tracer kinetic modeling. A conventional parallel multi-tracer compartment modeling method was also implemented for reference. Single-scan dual-tracer dynamic PET was simulated from 12 NET patient studies with 18F-FDG and 68Ga-DOTATATE 45-min dynamic PET scans separately obtained within 2 days. Our experimental results suggested an 18F-FDG injection first followed by 68Ga-DOTATATE with a minimum 5 min delayed injection protocol for the separation of mixed 18F-FDG and 68Ga-DOTATATE TACs using rXGBoost algorithm followed by tracer kinetic modeling is highly feasible.",0,0
2486,"Predicting clinical outcomes in COVID-19 using radiomics on chest radiographs. For optimal utilization of healthcare resources, there is a critical need for early identification of COVID-19 patients at risk of poor prognosis as defined by the need for intensive unit care and mechanical ventilation. We tested the feasibility of chest X-ray (CXR)-based radiomics metrics to develop machine-learning algorithms for predicting patients with poor outcomes.",0,0
2488,"Mammography-based radiomics for predicting the risk of breast cancer recurrence: a multicenter study. This study aimed to establish a mammography-based radiomics model for predicting the risk of estrogen receptor (ER)-positive, lymph node (LN)-negative invasive breast cancer recurrence based on Oncotype DX and validated it by using multicenter data.",0,0
2489,"An explainable machine learning model for predicting in-hospital amputation rate of patients with diabetic foot ulcer. Diabetic foot ulcer (DFU) is one of the most serious and alarming diabetic complications, which often leads to high amputation rates in diabetic patients. Machine learning is a part of the field of artificial intelligence, which can automatically learn models from data and better inform clinical decision-making. We aimed to develop an accurate and explainable prediction model to estimate the risk of in-hospital amputation in patients with DFU. A total of 618 hospitalised patients with DFU were included in this study. The patients were divided into non-amputation, minor amputation or major amputation group. Light Gradient Boosting Machine (LightGBM) and 5-fold cross-validation tools were used to construct a multi-class classification model to predict the three outcomes of interest. In addition, we used the SHapley Additive exPlanations (SHAP) algorithm to interpret the predictions of the model. Our area under the receiver-operating-characteristic curve (AUC) demonstrated a 0.90, 0.85 and 0.86 predictive ability for non-amputation, minor amputation and major amputation outcomes, respectively. Taken together, our data demonstrated that the developed explainable machine learning model provided accurate estimates of the amputation rate in patients with DFU during hospitalisation. Besides, the model could inform individualised analyses of the patients' risk factors.",0,0
2491,"Predicting brain age during typical and atypical development based on structural and functional neuroimaging. Exploring typical and atypical brain developmental trajectories is very important for understanding the normal pace of brain development and the mechanisms by which mental disorders deviate from normal development. A precise and sex-specific brain age prediction model is desirable for investigating the systematic deviation and individual heterogeneity of disorders associated with atypical brain development, such as autism spectrum disorders. In this study, we used partial least squares regression and the stacking algorithm to establish a sex-specific brain age prediction model based on T1-weighted structural magnetic resonance imaging and resting-state functional magnetic resonance imaging. The model showed good generalization and high robustness on four independent datasets with different ethnic information and age ranges. A predictor weights analysis showed the differences and similarities in changes in structure and function during brain development. At the group level, the brain age gap estimation for autistic patients was significantly smaller than that for healthy controls in both the ABIDE dataset and the healthy brain network dataset, which suggested that autistic patients as a whole exhibited the characteristics of delayed development. However, within the ABIDE dataset, the premature development group had significantly higher Autism Diagnostic Observation Schedule (ADOS) scores than those of the delayed development group, implying that individuals with premature development had greater severity. Using these findings, we built an accurate typical brain development trajectory and developed a method of atypical trajectory analysis that considers sex differences and individual heterogeneity. This strategy may provide valuable clues for understanding the relationship between brain development and mental disorders.",0,0
2492,"Identification of a Rule to Predict Response to Sarilumab in Patients with Rheumatoid Arthritis Using Machine Learning and Clinical Trial Data. In rheumatoid arthritis, time spent using ineffective medications may lead to irreversible disease progression. Despite availability of targeted treatments, only a minority of patients achieve sustained remission, and little evidence exists to direct the choice of biologic disease-modifying antirheumatic drugs in individual patients. Machine learning was used to identify a rule to predict the response to sarilumab and discriminate between responses to sarilumab versus adalimumab, with a focus on clinically feasible blood biomarkers.",0,0
2494,"An [18F]FDG-PET/CT deep learning method for fully automated detection of pathological mediastinal lymph nodes in lung cancer patients. The identification of pathological mediastinal lymph nodes is an important step in the staging of lung cancer, with the presence of metastases significantly affecting survival rates. Nodes are currently identified by a physician, but this process is time-consuming and prone to errors. In this paper, we investigate the use of artificial intelligence-based methods to increase the accuracy and consistency of this process.",0,0
2495,"Digital subtraction of temporally sequential mammograms for improved detection and classification of microcalcifications. Our aim was to demonstrate that automated detection and classification of breast microcalcifications, according to Breast Imaging Reporting and Data System (BI-RADS) categorisation, can be improved with the subtraction of sequential mammograms as opposed to using the most recent image only.",0,0
2505,Deep learning-enabled EPID-based 3D dosimetry for dose verification of step-and-shoot radiotherapy. The study aims at a novel dosimetry methodology to reconstruct a 3D dose distribution as imparted to a virtual cylindrical phantom using an electronic portal imaging device (EPID).,0,0
2517,"Genetic-based adaptive momentum estimation for predicting mortality risk factors for COVID-19 patients using deep learning. The mortality risk factors for coronavirus disease (COVID-19) must be early predicted, especially for severe cases, to provide intensive care before they develop to critically ill immediately. This paper aims to develop an optimized convolution neural network (CNN) for predicting mortality risk factors for COVID-19 patients. The proposed model supports two types of input data clinical variables and the computed tomography (CT) scans. The features are extracted from the optimized CNN phase and then applied to the classification phase. The CNN model's hyperparameters were optimized using a proposed genetic-based adaptive momentum estimation (GB-ADAM) algorithm. The GB-ADAM algorithm employs the genetic algorithm (GA) to optimize Adam optimizer's configuration parameters, consequently improving the classification accuracy. The model is validated using three recent cohorts from New York, Mexico, and Wuhan, consisting of 3055, 7497,504 patients, respectively. The results indicated that the most significant mortality risk factors are: CD <math xmlns=""http://www.w3.org/1998/Math/MathML""><msup><mn>8</mn> <mo>+</mo></msup> </math> T Lymphocyte (Count), D-dimer greater than 1 Ug/ml, high values of lactate dehydrogenase (LDH), C-reactive protein (CRP), hypertension, and diabetes. Early identification of these factors would help the clinicians in providing immediate care. The results also show that the most frequent COVID-19 signs in CT scans included ground-glass opacity (GGO), followed by crazy-paving pattern, consolidations, and the number of lobes. Moreover, the experimental results show encouraging performance for the proposed model compared with different predicting models.",0,0
2518,"A novel and efficient deep learning approach for COVID-19 detection using X-ray imaging modality. With the exponential growth of COVID-19 cases, medical practitioners are searching for accurate and quick automated detection methods to prevent Covid from spreading while trying to reduce the computational requirement of devices. In this research article, a deep learning Convolutional Neural Network (CNN) based accurate and efficient ensemble model using deep learning is being proposed with 2161 COVID-19, 2022 pneumonia, and 5863 normal chest X-ray images that has been collected from previous publications and other online resources. To improve the detection accuracy contrast enhancement and image normalization have been done to produce better quality images at the pre-processing level. Further data augmentation methods are used by creating modified versions of images in the dataset to train the four efficient CNN models (Inceptionv3, DenseNet121, Xception, InceptionResNetv2) Experimental results provide 98.33% accuracy for binary class and 92.36% for multiclass. The performance evaluation metrics reveal that this tool can be very helpful for early disease diagnosis.",0,0
2522,"Artificial intelligence-assisted system for precision diagnosis of PD-L1 expression in non-small cell lung cancer. Standardized programmed death-ligand 1 (PD-L1) assessment in non-small cell lung cancer (NSCLC) is challenging, owing to inter-observer variability among pathologists and the use of different antibodies. There is a strong demand for the development of an artificial intelligence (AI) system to obtain high-precision scores of PD-L1 expression in clinical diagnostic scenarios. We developed an AI system using whole slide images (WSIs) of the 22c3 assay to automatically assess the tumor proportion score (TPS) of PD-L1 expression based on a deep learning (DL) model of tumor detection. Tests were performed to show the diagnostic ability of the AI system in the 22c3 assay to assist pathologists and the reliability of the application in the SP263 assay. A robust high-performance DL model for automated tumor detection was devised with an accuracy and specificity of 0.9326 and 0.9641, respectively, and a concrete TPS value was obtained after tumor cell segmentation. The TPS comparison test in the 22c3 assay showed strong consistency between the TPS calculated with the AI system and trained pathologists (Râ€‰=â€‰0.9429-0.9458). AI-assisted diagnosis test confirmed that the repeatability and efficiency of untrained pathologists could be improved using the AI system. The Ventana PD-L1 (SP263) assay showed high consistency in TPS calculations between the AI system and pathologists (Râ€‰=â€‰0.9787). In conclusion, a high-precision AI system is proposed for the automated TPS assessment of PD-L1 expression in the 22c3 and SP263 assays in NSCLC. Our study also indicates the benefits of using an AI-assisted system to improve diagnostic repeatability and efficiency for pathologists.",1,1
2523,"Artificial intelligence application versus physical therapist for squat evaluation: a randomized controlled trial. Artificial intelligence technology is becoming more prevalent in health care as a tool to improve practice patterns and patient outcomes. This study assessed ability of a commercialized artificial intelligence (AI) mobile application to identify and improve bodyweight squat form in adult participants when compared to a physical therapist (PT). Participants randomized to AI group (nâ€‰=â€‰15) performed 3 squat sets: 10 unassisted control squats, 10 squats with performance feedback from AI, and 10 additional unassisted test squats. Participants randomized to PT group (nâ€‰=â€‰15) also performed 3 identical sets, but instead received performance feedback from PT. AI group intervention did not differ from PT group (log ratio of two odds ratiosâ€‰=â€‰â€‰-â€‰0.462, 95% confidence interval (CI) (-â€‰1.394, 0.471), pâ€‰=â€‰0.332). AI ability to identify a correct squat generated sensitivity 0.840 (95% CI (0.753, 0.901)), specificity 0.276 (95% CI (0.191, 0.382)), PPV 0.549 (95% CI (0.423, 0.669)), NPV 0.623 (95% CI (0.436, 0.780)), and accuracy 0.565 95% CI (0.477, 0.649)). There was no statistically significant association between group allocation and improved squat performance. Current AI had satisfactory ability to identify correct squat form and limited ability to identify incorrect squat form, which reduced diagnostic capabilities.Trial Registration NCT04624594, 12/11/2020, retrospectively registered.",1,1
2532,"Simplified models to assess newborn gestational age in low-middle income countries: findings from a multicountry, prospective cohort study. Preterm birth is the leading cause of child mortality. This study aimed to develop and validate programmatically feasible and accurate approaches to estimate newborn gestational age (GA) in low resource settings.",0,0
2533,"Deep learning-based signal-independent assessment of macular avascular area on 6Ã—6 mm optical coherence tomography angiogram in diabetic retinopathy: a comparison to instrument-embedded software. A deep-learning-based macular extrafoveal avascular area (EAA) on a 6Ã—6â€‰mm optical coherence tomography (OCT) angiogram is less dependent on the signal strength and shadow artefacts, providing better diagnostic accuracy for diabetic retinopathy (DR) severity than the commercial software measured extrafoveal vessel density (EVD).",1,1
2535,"Pre-surgical and Post-surgical Aortic Aneurysm Maximum Diameter Measurement: Full Automation by Artificial Intelligence. The aim of this study was to evaluate an automatic, deep learning based method (Augmented Radiology for Vascular Aneurysm [ARVA]), to detect and assess maximum aortic diameter, providing cross sectional outer to outer aortic wall measurements.",0,0
2540,"Artificial intelligence and capsule endoscopy: automatic detection of enteric protruding lesions using a convolutional neural network. Capsule endoscopy (CE) revolutionized the study of the small intestine. Nevertheless, reviewing CE images is a time-consuming and prone to error. Artificial intelligence algorithms, particularly convolutional neural networks (CNN) are expected to overcome these drawbacks. Protruding lesions of the small intestine exhibit enormous morphological diversity in CE images. We aimed to develop a CNN-based algorithm for automatic detection small bowel protruding lesions.",0,0
2542,"Positive impact of short-term gait rehabilitation in Parkinson patients: a combined approach based on statistics and machine learning. Parkinson's disease is the second most common neurodegenerative disorder in the world. Assumed that gait dysfunctions represent a major motor symptom for the pathology, gait analysis can provide clinicians quantitative information about the rehabilitation outcome of patients. In this scenario, wearable inertial systems for gait analysis can be a valid tool to assess the functional recovery of patients in an automatic and quantitative way, helping clinicians in decision making. Aim of the study is to evaluate the impact of the short-term rehabilitation on gait and balance of patients with Parkinson's disease. A cohort of 12 patients with Idiopathic Parkinson's disease performed a gait analysis session instrumented by a wearable inertial system for gait analysis: Opal System, by APDM Inc., with spatial and temporal parameters being analyzed through a statistic and machine learning approach. Six out of fourteen motion parameters exhibited a statistically significant difference between the measurements at admission and at discharge of the patients, while the machine learning analysis confirmed the separability of the two phases in terms of Accuracy and Area under the Receiving Operating Characteristic Curve. The rehabilitation treatment especially improved the motion parameters related to the gait. The study shows the positive impact on the gait of a short-term rehabilitation in patients with Parkinson's disease and the feasibility of the wearable inertial devices, that are increasingly spreading in clinical practice, to quantitatively assess the gait improvement.",0,0
2543,"A 3D multiscale view convolutional neural network with attention for mental disease diagnosis on MRI images. Computer Assisted Diagnosis (CAD) based on brain Magnetic Resonance Imaging (MRI) is a popular research field for the computer science and medical engineering. Traditional machine learning and deep learning methods were employed in the classification of brain MRI images in the previous studies. However, the current algorithms rarely take into consideration the influence of multi-scale brain connectivity disorders on some mental diseases. To improve this defect, a deep learning structure was proposed based on MRI images, which was designed to consider the brain's connections at different sizes and the attention of connections. In this work, a Multiscale View (MV) module was proposed, which was designed to detect multi-scale brain network disorders. On the basis of the MV module, the path attention module was also proposed to simulate the attention selection of the parallel paths in the MV module. Based on the two modules, we proposed a 3D Multiscale View Convolutional Neural Network with Attention (3D MVA-CNN) for classification of MRI images for mental disease. The proposed method outperformed the previous 3D CNN structures in the structural MRI data of ADHD-200 and the functional MRI data of schizophrenia. Finally, we also proposed a preliminary framework for clinical application using 3D CNN, and discussed its limitations on data accessing and reliability. This work promoted the assisted diagnosis of mental diseases based on deep learning and provided a novel 3D CNN method based on MRI data.",0,0
2544,"Application of bi-modal signal in the classification and recognition of drug addiction degree based on machine learning. Most studies on drug addiction degree are made based on statistical scales, addicts' account, and subjective judgement of rehabilitation doctors. No objective, quantified evaluation has been made. This paper uses devises the synchronous bimodal signal collection and experimentation paradigm with electroencephalogram (EEG) and forehead high-density near-infrared spectroscopy (NIRS) device. The drug addicts are classified into mild, moderate and severe groups with reference to the suggestions of researchers and medical experts. Data of 45 drug addicts (mild: 15; moderate: 15; and severe: 15) is collected, and then used to design an addiction degree testing algorithm based on decision fusion. The algorithm is used to classify mild, moderate and severe addiction. This paper pioneers to use two types of Convolutional Neural Network (CNN) to abstract the EEG and NIR data of drug addicts, and introduces batch normalization to CNN, thus accelerating training process, reducing parameter sensitivity, and enhancing system robustness. The characteristics output by two CNNs are transformed into dimensions. Two new characteristics are assigned with a weight of 50% each. The data is used for decision fusion. In the networks, 27 subjects are used as training sets, 9 as validation sets, and 9 as testing sets. The 3-class accuracy remains to be 63.15%, preliminarily justifying this method as an effective approach to measure drug addiction degree. And the method is ready to use, objective, and offers results in real time.",0,0
2551,"Deep learning and radiomics analysis for prediction of placenta invasion based on T2WI. The purpose of this study was to explore whether the Nomogram, which was constructed by combining the Deep learning and Radiomic features of T2-weighted MR images with Clinical factors (NDRC), could accurately predict placenta invasion. This retrospective study included 72 pregnant women with pathologically confirmed placenta invasion and 40 pregnant women with normal placenta. After 24 gestational weeks, all participants underwent magnetic resonance imaging. The uterus and placenta regions were segmented in magnetic resonance images on sagittal T2WI. Ninety-three radiomics features were extracted from the placenta region, and 128 deep features were extracted from the uterus region using a deep neural network. The least absolute shrinkage and selection operator (LASSO) algorithm was used to filter these 221 features and to form the combined signature. Then the combined signature (CS) and clinical factors were combined to construct a nomogram. The accuracy, sensitivity, specificity and AUC of the nomogram were compared with four machine learning methods. The model NDRC was trained on the dataset of 78 pregnant women in the training cohort. Finally, the model NDRC was compared with four machine learning methods on the independent validation cohort of 34 pregnant women. The results showed that the prediction accuracy, sensitivity, specificity and AUC of the NDRC model were 0.941, 0.952, 0.923 and 0.985 respectively, which outperforms the traditional machine learning methods which rely on radiomics features and deep learning features alone.",0,0
2555,"A framework for efficient brain tumor classification using MRI images. A brain tumor is an abnormal growth of brain cells inside the head, which reduces the patient's survival chance if it is not diagnosed at an earlier stage. Brain tumors vary in size, different in type, irregular in shapes and require distinct therapies for different patients. Manual diagnosis of brain tumors is less efficient, prone to error and time-consuming. Besides, it is a strenuous task, which counts on radiologist experience and proficiency. Therefore, a modern and efficient automated computer-assisted diagnosis (CAD) system is required which may appropriately address the aforementioned problems at high accuracy is presently in need. Aiming to enhance performance and minimise human efforts, in this manuscript, the first brain MRI image is pre-processed to improve its visual quality and increase sample images to avoid over-fitting in the network. Second, the tumor proposals or locations are obtained based on the agglomerative clustering-based method. Third, image proposals and enhanced input image are transferred to backbone architecture for features extraction. Fourth, high-quality image proposals or locations are obtained based on a refinement network, and others are discarded. Next, these refined proposals are aligned to the same size, and finally, transferred to the head network to achieve the desired classification task. The proposed method is a potent tumor grading tool assessed on a publicly available brain tumor dataset. Extensive experiment results show that the proposed method outperformed the existing approaches evaluated on the same dataset and achieved an optimal performance with an overall classification accuracy of 98.04%. Besides, the model yielded the accuracy of 98.17, 98.66, 99.24%, sensitivity (recall) of 96.89, 97.82, 99.24%, and specificity of 98.55, 99.38, 99.25% for Meningioma, Glioma, and Pituitary classes, respectively.",0,0
2556,"Classification accuracy and functional difference prediction in different brain regions of drug abuser prefrontal lobe basing on machine-learning. Taking different types of addictive drugs such as methamphetamine, heroin, and mixed drugs causes brain functional Changes. Based on the prefrontal functional near-infrared spectroscopy, this study was designed with an experimental paradigm that included the induction of resting and drug addiction cravings. Hemoglobin concentrations of 30 drug users (10 on methamphetamine, 10 on heroin, and 10 on mixed type) were collected. For these three types of individuals, the convolutional neural networks (CNN) was designed to classify eight Brodmann areas and the entire prefrontal area, and the average accuracy of the three classifications on each functional area was obtained. As a result, the classification accuracy was lower on the left side than on the right in the dorsolateral prefrontal cortex (DLPFC) of the drug users, while it was higher on the left than on the right in the ventrolateral prefrontal cortex (VLPFC), frontopolar prefrontal cortex (FPC), and orbitofrontal cortex (OFC). Then the differences in eight functional areas between the three types of individuals were statistically analyzed, and results showed significant differences in the right VLPFC and right OFC.",0,0
2557,"Convolutional neural network with group theory and random selection particle swarm optimizer for enhancing cancer image classification. As an epitome of deep learning, convolutional neural network (CNN) has shown its advantages in solving many real-world problems. Successful CNN applications on medical prognosis and diagnosis have been achieved in recent years. Their common goal is to recognize the insights from the subtle details from medical images by building a suitable CNN model with maximum accuracy and minimum error. The CNN performance is extremely sensitive to the parameter tuning for any given network structure. To approach this concern, a novel self-tuning CNN model is proposed with a significant characteristic of having a metaheuristic-based optimizer. The most optimal set of parameters is often found via our proposed method, namely group theory and random selection-based particle swarm optimization (GTRS-PSO). The insights of symmetric essentials of model structure and parameter correlation are extracted, followed by the hierarchical partitioning of parameter space, and four operators on those partitions are designed for moving neighborhoods and formulating the swarm topology accordingly. The parameters are updated by a random selection strategy at each interval of partitions during the search process. Preliminary experiments over two radiology image datasets: breast cancer and lung cancer, are conducted for a comprehensive comparison of GTRS-PSO versus other optimization algorithms. The results show that CNN with GTRS-PSO optimizer can achieve the best performance for cancer image classifications, especially when there are symmetric components inside the data properties and model structures.",0,0
2559,"An ensemble framework based on Deep CNNs architecture for glaucoma classification using fundus photography. Glaucoma is a chronic ocular degenerative disease that can cause blindness if left untreated in its early stages. Deep Convolutional Neural Networks (Deep CNNs) and its variants have provided superior performance in glaucoma classification, segmentation, and detection. In this paper, we propose a two-staged glaucoma classification scheme based on Deep CNN architectures. In stage one, four different ImageNet pre-trained Deep CNN architectures, i.e., AlexNet, InceptionV3, InceptionResNetV2, and NasNet-Large are used and it is observed that NasNet-Large architecture provides superior performance in terms of sensitivity (99.1%), specificity (99.4%), accuracy (99.3%), and area under the receiver operating characteristic curve (97.8%) metrics. A detailed performance comparison is also presented among these on public datasets, i.e., ACRIMA, ORIGA-Light, and RIM-ONE as well as locally available datasets, i.e., AFIO, and HMC. In the second stage, we propose an ensemble classifier with two novel ensembling techniques, i.e., accuracy based weighted voting, and accuracy/score based weighted averaging to further improve the glaucoma classification results. It is shown that ensemble with accuracy/score based scheme improves the accuracy (99.5%) for diverse databases. As an outcome of this study, it is presented that the NasNet-Large architecture is a feasible option in terms of its performance as a single classifier while ensemble classifier further improves the generalized performance for automatic glaucoma classification.",0,0
2561,"Depth of anesthesia prediction via EEG signals using convolutional neural network and ensemble empirical mode decomposition. According to a recently conducted survey on surgical complication mortality rate, 47% of such cases are due to anesthetics overdose. This indicates that there is an urgent need to moderate the level of anesthesia. Recently deep learning (DL) methods have played a major role in estimating the depth of Anesthesia (DOA) of patients and has played an essential role in control anesthesia overdose. In this paper, Electroencephalography (EEG) signals have been used for the prediction of DOA. EEG signals are very complex signals which may require months of training and advanced signal processing techniques. It is a point of debate whether DL methods are an improvement over the already existing traditional EEG signal processing approaches. One of the DL algorithms is Convolutional neural network (CNN) which is very popular algorithm for object recognition and is widely growing its applications in processing hierarchy in the human visual system. In this paper, various decomposition methods have been used for extracting the features EEG signal. After acquiring the necessary signals values in image format, several CNN models have been deployed for classification of DOA depending upon their Bispectral Index (BIS) and the signal quality index (SQI). The EEG signals were converted into the frequency domain using and Empirical Mode Decomposition (EMD), and Ensemble Empirical Mode Decomposition (EEMD). However, because of the inter mode mixing observed in EMD method; EEMD have been utilized for this study. The developed CNN models were used to predict the DOA based on the EEG spectrum images without the use of handcrafted features which provides intuitive mapping with high efficiency and reliability. The best trained model gives an accuracy of 83.2%. Hence, this provides further scope and research which can be carried out in the domain of visual mapping of DOA using EEG signals and DL methods.",0,0
2562,"A hybrid deep learning model for breast cancer diagnosis based on transfer learning and pulse-coupled neural networks. Radiology experts often face difficulties in mammography mass lesion labeling, which may lead to conclusive yet unnecessary and expensive breast biopsies. This paper focuses on building an automated diagnosis tool that supports radiologists in identifying and classifying mammography mass lesions. The paper's main contribution is to design a hybrid model based on Pulse-Coupled Neural Networks (PCNN) and Deep Convolutional Neural Networks (CNN). Due to the need for large datasets to train and tune CNNs, which are not available for medical images, Transfer Learning (TL) was exploited in this research. TL can be an effective approach when working with small-sized datasets. The paper's implementation was tested on three public benchmark datasets: DDMS, INbreast, and BCDR datasets for training and testing and MIAS for testing only. The results indicated the enhancement that PCNN provides when combined with CNN compared to other methods for the same public datasets. The hybrid model achieved 98.72% accuracy for DDMS, 97.5% for INbreast, and 96.94% for BCDR. To avoid overfitting, the proposed hybrid model was tested on an unseen MIAS dataset, achieving 98.77% accuracy. Other evaluation metrics are reported in the results section.",0,0
2563,"Second-order ResU-Net for automatic MRI brain tumor segmentation. Tumor segmentation using magnetic resonance imaging (MRI) plays a significant role in assisting brain tumor diagnosis and treatment. Recently, U-Net architecture with its variants have become prevalent in the field of brain tumor segmentation. However, the existing U-Net models mainly exploit coarse first-order features for tumor segmentation, and they seldom consider the more powerful second-order statistics of deep features. Therefore, in this work, we aim to explore the effectiveness of second-order statistical features for brain tumor segmentation application, and further propose a novel second-order residual brain tumor segmentation network, i.e., SoResU-Net. SoResU-Net utilizes a number of second-order modules to replace the original skip connection operations, thus augmenting the series of transformation operations and increasing the non-linearity of the segmentation network. Extensive experimental results on the BraTS 2018 and BraTS 2019 datasets demonstrate that SoResU-Net outperforms its baseline, especially on core tumor and enhancing tumor segmentation, illuminating the effectiveness of second-order statistical features for the brain tumor segmentation application.",0,0
2566,"MFB-LANN: A lightweight and updatable myocardial infarction diagnosis system based on convolutional neural networks and active learning. 12 leads electrocardiogram (ECG) are widely used to diagnose myocardial infarction (MI). Generally, the symptoms of MI can be reflected by waveforms in the heartbeat, and the contribution of different ECG leads to different types of MI is different. Therefore, it is significant to use the heartbeat waveform features and the lead relationship features for multi-category MI diagnosis. Moreover, the challenge of individual differences and lightweight algorithms also need to be further resolved and explored in the ECG automatic diagnosis system.",0,0
2569,"Feasibility of late gadolinium enhancement (LGE) in ischemic cardiomyopathy using 2D-multisegment LGE combined with artificial intelligence reconstruction deep learning noise reduction algorithm. Despite the low spatial resolution of 2D-multisegment late gadolinium enhancement (2D-MSLGE) sequences, it may be useful in uncooperative patients instead of standard 2D single segmented inversion recovery gradient echo late gadolinium enhancement sequences (2D-SSLGE). The aim of the study is to assess the feasibility and comparison of 2D-MSLGE reconstructed with artificial intelligence reconstruction deep learning noise reduction (NR) algorithm compared to standard 2D-SSLGE in consecutive patients with ischemic cardiomyopathy (ICM).",0,0
2572,"Application of a time-series deep learning model to predict cardiac dysrhythmias in electronic health records. Cardiac dysrhythmias (CD) affect millions of Americans in the United States (US), and are associated with considerable morbidity and mortality. New strategies to combat this growing problem are urgently needed.",0,0
2577,"time-frequency analysis of scalp EEG with Hilbert-Huang transform and deep learning. Electroencephalography (EEG) is a brain imaging approach that has been widely used in neuroscience and clinical settings. The conventional EEG analyses usually require pre-defined frequency bands when characterizing neural oscillations and extracting features for classifying EEG signals. However, neural responses are naturally heterogeneous by showing variations in frequency bands of brainwaves and peak frequencies of oscillatory modes across individuals. Fail to account for such variations might result in information loss and classifiers with low accuracy but high variation across individuals. To address these issues, we present a systematic time-frequency analysis approach for analyzing scalp EEG signals. In particular, we propose a data-driven method to compute the subject-specific frequency bands for brain oscillations via Hilbert-Huang Transform, lifting the restriction of using fixed frequency bands for all subjects. Then, we propose two novel metrics to quantify the power and frequency aspects of brainwaves represented by sub-signals decomposed from the EEG signals. The effectiveness of the proposed metrics are tested on two scalp EEG datasets and compared with four commonly used features sets extracted from wavelet and Hilbert-Huang Transform. The validation results show that the proposed metrics are more discriminatory than other features leading to accuracies in the range of 94.93% to 99.84%. Besides classification, the proposed metrics show great potential in quantification of neural oscillations and serving as biomarkers in the neuroscience research.",0,0
2578,"CNN-Based Prognosis of BCI Rehabilitation Using EEG From First Session BCI Training. Stroke is a world-leading disease for causing disability. Brain-computer interaction (BCI) training has been proved to be a promising method in facilitating motor recovery. However, due to differences in each patient's neural-clinical profile, the potential of recovery for different patients can vary significantly by conducting BCI training, which remains a major problem in clinical rehabilitation practice. To address this issue, the objective of this study is to prognosticate the outcome of BCI training using motor state electroencephalographic (EEG) collected during the first session of BCI tasks, with the aim of prescribing BCI training accordingly. A Convolution Neural Network (CNN) based prognosis model was developed to predict the outcome of 11 stroke patients' recovery following a 2-week rehabilitation training with BCI. In our study, functional connectivity and power spectrum have been evaluated and applied as the inputs of CNN to regress patients' recovery rate. A saliency map was used to identify the correlation between EEG channels with the recovery outcome. The performance of our model was assessed using the leave-one-out cross-validation. Overall, the proposed model predicted patients' recovery with R<sup>2</sup> 0.98 and MSE 0.89. According to the saliency map, the highest functional connectivity occurred in Fp2/Fpz-AF8, Fp2/F4/F8-P3, P1/PO7-PO5 and AF3-AF4. Our results demonstrated that deep learning method has the potential to predict the recovery rate of BCI training, which contributes to guiding individualized prescription in the early stage of clinical rehabilitation.",0,0
2581,"A nine-hub-gene signature of metabolic syndrome identified using machine learning algorithms and integrated bioinformatics. Early risk assessments and interventions for metabolic syndrome (MetS) are limited because of a lack of effective biomarkers. In the present study, several candidate genes were selected as a blood-based transcriptomic signature for MetS. We collected so far the largest MetS-associated peripheral blood high-throughput transcriptomics data and put forward a novel feature selection strategy by combining weighted gene co-expression network analysis, protein-protein interaction network analysis, LASSO regression and random forest approaches. Two gene modules and 51 hub genes as well as a 9-hub-gene signature associated with metabolic syndrome were identified. Then, based on this 9-hub-gene signature, we performed logistic analysis and subsequently established a web nomogram calculator for metabolic syndrome risk (https://xjtulgz.shinyapps.io/DynNomapp/). This 9-hub-gene signature showed excellent classification and calibration performance (AUCÂ =Â 0.968 in training set, AUCÂ =Â 0.883 in internal validation set, AUCÂ =Â 0.861 in external validation set) as well as ideal potential clinical benefit.",0,0
2590,"Predicting the Mortality and Readmission of In-Hospital Cardiac Arrest Patients With Electronic Health Records: A Machine Learning Approach. In-hospital cardiac arrest (IHCA) is associated with high mortality and health care costs in the recovery phase. Predicting adverse outcome events, including readmission, improves the chance for appropriate interventions and reduces health care costs. However, studies related to the early prediction of adverse events of IHCA survivors are rare. Therefore, we used a deep learning model for prediction in this study.",0,0
2605,"Estimating Glioblastoma Biophysical Growth Parameters Using Deep Learning Regression. Glioblastoma ( <i><b>GBM</b></i> ) is arguably the most aggressive, infiltrative, and heterogeneous type of adult brain tumor. Biophysical modeling of GBM growth has contributed to more informed clinical decision-making. However, deploying a biophysical model to a clinical environment is challenging since underlying computations are quite expensive and can take several hours using existing technologies. Here we present a scheme to accelerate the computation. In particular, we present a deep learning ( <i><b>DL</b></i> )-based logistic regression model to estimate the GBM's biophysical growth in seconds. This growth is defined by three tumor-specific parameters: 1) a diffusion coefficient in white matter ( <i><b>Dw</b></i> ), which prescribes the rate of infiltration of tumor cells in white matter, 2) a mass-effect parameter ( <i><b>Mp</b></i> ), which defines the average tumor expansion, and 3) the estimated time ( <i><b>T</b></i> ) in number of days that the tumor has been growing. Preoperative structural multi-parametric MRI ( <i><b>mpMRI</b></i> ) scans from <i>n</i> = 135 subjects of the TCGA-GBM imaging collection are used to quantitatively evaluate our approach. We consider the mpMRI intensities within the region defined by the abnormal FLAIR signal envelope for training one DL model for each of the tumor-specific growth parameters. We train and validate the DL-based predictions against parameters derived from biophysical inversion models. The average Pearson correlation coefficients between our DL-based estimations and the biophysical parameters are 0.85 for <i>Dw</i>, 0.90 for <i>Mp</i>, and 0.94 for <i>T</i>, respectively. This study unlocks the power of tumor-specific parameters from biophysical tumor growth estimation. It paves the way towards their clinical translation and opens the door for leveraging advanced radiomic descriptors in future studies by means of a significantly faster parameter reconstruction compared to biophysical growth modeling approaches.",0,0
2608,"Predicting the Disease Outcome in COVID-19 Positive Patients Through Machine Learning: A Retrospective Cohort Study With Brazilian Data. The first officially registered case of COVID-19 in Brazil was on February 26, 2020. Since then, the situation has worsened with more than 672, 000 confirmed cases and at least 36, 000 reported deaths by June 2020. Accurate diagnosis of patients with COVID-19 is extremely important to offer adequate treatment, and avoid overloading the healthcare system. Characteristics of patients such as age, comorbidities and varied clinical symptoms can help in classifying the level of infection severity, predict the disease outcome and the need for hospitalization. Here, we present a study to predict a poor prognosis in positive COVID-19 patients and possible outcomes using machine learning. The study dataset comprises information of 8, 443 patients concerning closed cases due to cure or death. Our experimental results show the disease outcome can be predicted with a Receiver Operating Characteristic AUC of 0.92, Sensitivity of 0.88 and Specificity of 0.82 for the best prediction model. This is a preliminary retrospective study which can be improved with the inclusion of further data. Conclusion: Machine learning techniques fed with demographic and clinical data along with comorbidities of the patients can assist in the prognostic prediction and physician decision-making, allowing a faster response and contributing to the non-overload of healthcare systems.",0,0
2609,"Identification of social determinants of health using multi-label classification of electronic health record clinical notes. Social determinants of health (SDH), key contributors to health, are rarely systematically measured and collected in the electronic health record (EHR). We investigate how to leverage clinical notes using novel applications of multi-label learning (MLL) to classify SDH in mental health and substance use disorder patients who frequent the emergency department.",0,0
2613,"Quantitative image features from radiomic biopsy differentiate oncocytoma from chromophobe renal cell carcinoma. <b>Purpose</b>: To differentiate oncocytoma and chromophobe renal cell carcinoma (RCC) using radiomics features computed from spherical samples of image regions of interest, ""radiomic biopsies"" (RBs). <b>Approach</b>: In a retrospective cohort study of 102 CT cases [68 males (67%), 34 females (33%); mean age Â± SD, <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>63</mn> <mo>Â±</mo> <mn>12</mn> <mtext>â€‰â€‰</mtext> <mtext>years</mtext></mrow> </math> ], we pathology-confirmed 42 oncocytomas (41%) and 60 chromophobes (59%). A board-certified radiologist performed two RB rounds. From each RB round, we computed radiomics features and compared the performance of a random forest and AdaBoost binary classifier trained from the features. To control for overfitting, we performed 10 rounds of 70% to 30% train-test splits with feature-selection, cross-validation, and hyperparameter-optimization on each split. We evaluated the performance with test ROC AUC. We tested models on data from the other RB round and compared with the same round testing with the DeLong test. We clustered important features for each round and measured a bootstrapped adjusted Rand index agreement. <b>Results</b>: Our best classifiers achieved an average AUC of <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>0.71</mn> <mo>Â±</mo> <mn>0.024</mn></mrow> </math> . We found no evidence of an effect for RB round ( <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>p</mi> <mo>=</mo> <mn>1</mn></mrow> </math> ). We also found no evidence for a decrease in model performance when tested on the other RB round ( <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>p</mi> <mo>=</mo> <mn>0.85</mn></mrow> </math> ). Feature clustering produced seven clusters in each RB round with high agreement ( <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mtext>Rand index</mtext> <mo>=</mo> <mn>0.981</mn> <mo>Â±</mo> <mn>0.002</mn></mrow> </math> , <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>p</mi> <mo><</mo> <mn>0.00001</mn></mrow> </math> ). <b>Conclusions</b>: A consistent radiomic signature can be derived from RBs and could help distinguish oncocytoma and chromophobe RCC.",0,0
2615,"Biomarker Extraction Based on Subspace Learning for the Prediction of Mild Cognitive Impairment Conversion. Accurate recognition of progressive mild cognitive impairment (MCI) is helpful to reduce the risk of developing Alzheimer's disease (AD). However, it is still challenging to extract effective biomarkers from multivariate brain structural magnetic resonance imaging (MRI) features to accurately differentiate the progressive MCI from stable MCI. We develop novel biomarkers by combining subspace learning methods with the information of AD as well as normal control (NC) subjects for the prediction of MCI conversion using multivariate structural MRI data. Specifically, we first learn two projection matrices to map multivariate structural MRI data into a common label subspace for AD and NC subjects, where the original data structure and the one-to-one correspondence between multiple variables are kept as much as possible. Afterwards, the multivariate structural MRI features of MCI subjects are mapped into a common subspace according to the projection matrices. We then perform the self-weighted operation and weighted fusion on the features in common subspace to extract the novel biomarkers for MCI subjects. The proposed biomarkers are tested on Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Experimental results indicate that our proposed biomarkers outperform the competing biomarkers on the discrimination between progressive MCI and stable MCI. And the improvement from the proposed biomarkers is not limited to a particular classifier. Moreover, the results also confirm that the information of AD and NC subjects is conducive to predicting conversion from MCI to AD. In conclusion, we find a good representation of brain features from high-dimensional MRI data, which exhibits promising performance for predicting conversion from MCI to AD.",0,0
2616,"Deep Learning Analysis of Echocardiographic Images to Predict Positive Genotype in Patients With Hypertrophic Cardiomyopathy. Genetic testing provides valuable insights into family screening strategies, diagnosis, and prognosis in patients with hypertrophic cardiomyopathy (HCM). On the other hand, genetic testing carries socio-economical and psychological burdens. It is therefore important to identify patients with HCM who are more likely to have positive genotype. However, conventional prediction models based on clinical and echocardiographic parameters offer only modest accuracy and are subject to intra- and inter-observer variability. We therefore hypothesized that deep convolutional neural network (DCNN, a type of deep learning) analysis of echocardiographic images improves the predictive accuracy of positive genotype in patients with HCM. In each case, we obtained parasternal short- and long-axis as well as apical 2-, 3-, 4-, and 5-chamber views. We employed DCNN algorithm to predict positive genotype based on the input echocardiographic images. We performed 5-fold cross-validations. We used 2 reference models-the Mayo HCM Genotype Predictor score (Mayo score) and the Toronto HCM Genotype score (Toronto score). We compared the area under the receiver-operating-characteristic curve (AUC) between a combined model using the reference model plus DCNN-derived probability and the reference model. We calculated the <i>p</i>-value by performing 1,000 bootstrapping. We calculated sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). In addition, we examined the net reclassification improvement. We included 99 adults with HCM who underwent genetic testing. Overall, 45 patients (45%) had positive genotype. The new model combining Mayo score and DCNN-derived probability significantly outperformed Mayo score (AUC 0.86 [95% CI 0.79-0.93] vs. 0.72 [0.61-0.82]; <i>p</i> < 0.001). Similarly, the new model combining Toronto score and DCNN-derived probability exhibited a higher AUC compared to Toronto score alone (AUC 0.84 [0.76-0.92] vs. 0.75 [0.65-0.85]; <i>p</i> = 0.03). An improvement in the sensitivity, specificity, PPV, and NPV was also achieved, along with significant net reclassification improvement. In conclusion, compared to the conventional models, our new model combining the conventional and DCNN-derived models demonstrated superior accuracy to predict positive genotype in patients with HCM.",0,0
2619,"The Effect of Individual Musculoskeletal Conditions on Depression: Updated Insights From an Irish Longitudinal Study on Aging. Few longitudinal studies have systematically investigated whether or how individual musculoskeletal conditions (IMCs) convey risks for negative psychological health outcomes, and approaches to assess such risk in the older population are lacking. In this Irish nationally representative longitudinal prospective study of 6,715 individuals aged 50 and above, machine learning algorithms and various models, including mediation models, were employed to elaborate the underlying mechanisms of IMCs leading to depression and to develop an IMC-induced negative psychological risk (IMCPR) classification approach. Resultantly, arthritis [odds ratio (95% confidence interval): 2.233 (1.700-2.927)], osteoporosis [1.681 (1.133-2.421)], and musculoskeletal chronic pain [MCP, 2.404 (1.838-3.151)] were found to increase the risk of depression after 2 years, while fracture and joint replacement did not. Interestingly, mediation models further demonstrated that arthritis <i>per se</i> did not increase the risk of depression; such risk was augmented only when arthritis-induced restrictions of activities (ARA) existed [proportion of mediation: 316.3% (ARA of usual), 213.3% (ARA of social and leisure), and 251.3% (ARA of sleep)]. The random forest algorithm attested that osteoarthritis, not rheumatoid arthritis, contributed the most to depressive symptoms. Moreover, bone mineral density was negatively associated with depressive symptoms. Systemic pain contributed the most to the increased risk of depression, followed by back, knee, hip, and foot pain (mean Gini-Index: 3.778, 2.442, 1.980, 1.438, and 0.879, respectively). Based on the aforementioned findings, the IMCPR classification approach was developed using an interpretable machine learning model, which stratifies participants into three grades. Among the IMCPR grades, patients with a grade of ""severe"" had higher odds of depression than those with a ""mild"" [odds ratio (95% confidence interval): 4.055 (2.907-5.498)] or ""moderate"" [3.584 (2.101-5.883)] grade. Females with a ""severe"" grade had higher odds of depression by 334.0% relative to those with a ""mild"" grade, while males had a relative risk of 258.4%. In conclusion, the present data provide systematic insights into the IMC-induced depression risk and updated the related clinical knowledge. Furthermore, the IMCPR classification approach could be used as an effective tool to evaluate this risk.",0,0
2620,"A Convolutional Neural Network Deep Learning Model Trained on CD Ulcers Images Accurately Identifies NSAID Ulcers. <b>Background and Study Aims:</b> Deep learning (DL) for video capsule endoscopy (VCE) is an emerging research field. It has shown high accuracy for the detection of Crohn's disease (CD) ulcers. Non-steroidal anti-inflammatory drugs (NSAIDS) are commonly used medications. In the small bowel, NSAIDs may cause a variety of gastrointestinal adverse events including NSAID-induced ulcers. These ulcers are the most important differential diagnosis for small bowel ulcers in patients evaluated for suspected CD. We evaluated a DL network that was trained using CD VCE ulcer images and evaluated its performance for NSAID ulcers. <b>Patients and Methods:</b> The network was trained using CD ulcers and normal mucosa from a large image bank created from VCE of diagnosed CD patients. NSAIDs-induced enteropathy images were extracted from the prospective Bifidobacterium breve (BIf95) trial dataset. All images were acquired from studies performed using PillCam SBIII. The area under the receiver operating curve (AUC) was used as a metric. We compared the network's AUC for detecting NSAID ulcers to that of detecting CD ulcers. <b>Results:</b> Overall, the CD training dataset included 17,640 CE images. The NSAIDs testing dataset included 1,605 CE images. The DL network exhibited an AUC of 0.97 (95% CI 0.97-0.98) for identifying images with NSAID mucosal ulcers. The diagnostic accuracy was similar to that obtained for CD related ulcers (AUC 0.94-0.99). <b>Conclusions:</b> A network trained on VCE CD ulcers similarly identified NSAID findings. As deep learning is transforming gastrointestinal endoscopy, this result should be taken into consideration in the future design and analysis of VCE deep learning applications.",0,0
2621,Differentiation Between Glioblastoma Multiforme and Metastasis From the Lungs and Other Sites Using Combined Clinical/Routine MRI Radiomics. Differentiation between cerebral glioblastoma multiforme (GBM) and solitary brain metastasis (MET) is important. The existing radiomic differentiation method ignores the clinical and routine magnetic resonance imaging (MRI) features.,0,0
2622,"Deep Learning-Based Prediction of Future Extrahepatic Metastasis and Macrovascular Invasion in Hepatocellular Carcinoma. For timely treatment of extrahepatic metastasis and macrovascular invasion (aggressive progressive disease [PD]) in hepatocellular carcinoma, models aimed at stratifying the risks of subsequent aggressive PD should be constructed.",0,0
2623,CEUS-Based Radiomics Can Show Changes in Protein Levels in Liver Metastases After Incomplete Thermal Ablation. To investigate the ability of contrast-enhanced ultrasound (CEUS)-based radiomics combined with machine learning to detect early protein changes after incomplete thermal ablation.,0,0
2627,"Predicting in-hospital mortality in adult non-traumatic emergency department patients: a retrospective comparison of the Modified Early Warning Score (MEWS) and machine learning approach. A feasible and accurate risk prediction systems for emergency department (ED) patients is urgently required. The Modified Early Warning Score (MEWS) is a wide-used tool to predict clinical outcomes in ED. Literatures showed that machine learning (ML) had better predictability in specific patient population than traditional scoring system. By analyzing a large multicenter dataset, we aim to develop a ML model to predict in-hospital morality of the adult non traumatic ED patients for different time stages, and comparing performance with other ML models and MEWS.",0,1
2631,"Heuristic scoring method utilizing FDG-PET statistical parametric mapping in the evaluation of suspected Alzheimer disease and frontotemporal lobar degeneration. Distinguishing frontotemporal lobar degeneration (FTLD) and Alzheimer Disease (AD) on FDG-PET based on qualitative review alone can pose a diagnostic challenge. SPM has been shown to improve diagnostic performance in research settings, but translation to clinical practice has been lacking. Our purpose was to create a heuristic scoring method based on statistical parametric mapping z-scores. We aimed to compare the performance of the scoring method to the initial qualitative read and a machine learning (ML)-based method as benchmarks. FDG-PET/CT or PET/MRI of 65 patients with suspected dementia were processed using SPM software, yielding z-scores from either whole brain (W) or cerebellar (C) normalization relative to a healthy cohort. A non-ML, heuristic scoring system was applied using region counts below a preset z-score cutoff. W z-scores, C z-scores, or WC z-scores (z-scores from both W and C normalization) served as features to build random forest models. The neurological diagnosis was used as the gold standard. The sensitivity of the non-ML scoring system and the random forest models to detect AD was higher than the initial qualitative read of the standard FDG-PET [0.89-1.00 vs. 0.22 (95% CI, 0-0.33)]. A categorical random forest model to distinguish AD, FTLD, and normal cases had similar accuracy than the non-ML scoring model (0.63 vs. 0.61). Our non-ML-based scoring system of SPM z-scores approximated the diagnostic performance of a ML-based method and demonstrated higher sensitivity in the detection of AD compared to qualitative reads. This approach may improve the diagnostic performance.",1,1
2632,"Computer-aided detection of mantle cell lymphoma on <sup>18</sup>F-FDG PET/CT using a deep learning convolutional neural network. <sup>18</sup>F-FDG PET/CT can provide quantitative characterization with prognostic value for mantle cell lymphoma (MCL). However, detection of MCL is performed manually, which is labor intensive and not a part of the routine clinical practice. This study investigates a deep learning convolutional neural network (DLCNN) for computer-aided detection of MCL on <sup>18</sup>F-FDG PET/CT. We retrospectively analyzed 142 baseline <sup>18</sup>F-FDG PET/CT scans of biopsy-confirmed MCL acquired between May 2007 and October 2018. Of the 142 scans, 110 were from our institution and 32 were from outside institutions. An Xception-based U-Net was constructed to classify each pixel of the PET/CT images as MCL or not. The network was first trained and tested on the within-institution scans by applying five-fold cross-validation. Sensitivity and false positives (FPs) per patient were calculated for network evaluation. The network was then tested on the outside-institution scans, which were excluded from network training. For the 110 within-institution patients (85 male; median age, 58 [range: 39-84] years), the network achieved an overall median sensitivity of 88% (interquartile range [IQR]: 25%) with 15 (IQR: 12) FPs/patient. Sensitivity was dependent on lesion size and SUV<sub>max</sub> but not on lesion location. For the 32 outside-institution patients (24 male; median age, 59 [range: 40-67] years), the network achieved a median sensitivity of 84% (IQR: 24%) with 14 (IQR: 10) FPs/patient. No significant performance difference was found between the within and outside institution scans. Therefore, DLCNN can potentially help with MCL detection on <sup>18</sup>F-FDG PET/CT with high sensitivity and limited FPs.",0,0
2633,"Quantification of scar collagen texture and prediction of scar development via second harmonic generation images and a generative adversarial network. Widely used for medical analysis, the texture of the human scar tissue is characterized by irregular and extensive types. The quantitative detection and analysis of the scar texture as enabled by image analysis technology is of great significance to clinical practice. However, the existing methods remain disadvantaged by various shortcomings, such as the inability to fully extract the features of texture. Hence, the integration of second harmonic generation (SHG) imaging and deep learning algorithm is proposed in this study. Through combination with Tamura texture features, a regression model of the scar texture can be constructed to develop a novel method of computer-aided diagnosis, which can assist clinical diagnosis. Based on wavelet packet transform (WPT) and generative adversarial network (GAN), the model is trained with scar texture images of different ages. Generalized Boosted Regression Trees (GBRT) is also adopted to perform regression analysis. Then, the extracted features are further used to predict the age of scar. The experimental results obtained by our proposed model are better compared to the previously published methods. It thus contributes to the better understanding of the mechanism behind scar development and possibly the further development of SHG for skin analysis and clinic practice.",0,0
2636,"Deep learning classification of cervical dysplasia using depth-resolved angular light scattering profiles. We present a machine learning method for detecting and staging cervical dysplastic tissue using light scattering data based on a convolutional neural network (CNN) architecture. Depth-resolved angular scattering measurements from two clinical trials were used to generate independent training and validation sets as input of our model. We report 90.3% sensitivity, 85.7% specificity, and 87.5% accuracy in classifying cervical dysplasia, showing the uniformity of classification of a/LCI scans across different instruments. Further, our deep learning approach significantly improved processing speeds over the traditional Mie theory inverse light scattering analysis (ILSA) method, with a hundredfold reduction in processing time, offering a promising approach for a/LCI in the clinic for assessing cervical dysplasia.",0,0
2639,"Weakly supervised anomaly segmentation in retinal OCT images using an adversarial learning approach. Lesion detection is a critical component of disease diagnosis, but the manual segmentation of lesions in medical images is time-consuming and experience-demanding. These issues have recently been addressed through deep learning models. However, most of the existing algorithms were developed using supervised training, which requires time-intensive manual labeling and prevents the model from detecting unaware lesions. As such, this study proposes a weakly supervised learning network based on CycleGAN for lesions segmentation in full-width optical coherence tomography (OCT) images. The model was trained to reconstruct underlying normal anatomic structures from abnormal input images, then the lesions can be detected by calculating the difference between the input and output images. A customized network architecture and a multi-scale similarity perceptual reconstruction loss were used to extend the CycleGAN model to transfer between objects exhibiting shape deformations. The proposed technique was validated using an open-source retinal OCT image dataset. Image-level anomaly detection and pixel-level lesion detection results were assessed using area-under-curve (AUC) and the Dice similarity coefficient, producing results of 96.94% and 0.8239, respectively, higher than all comparative methods. The average test time required to generate a single full-width image was 0.039 s, which is shorter than that reported in recent studies. These results indicate that our model can accurately detect and segment retinopathy lesions in real-time, without the need for supervised labeling. And we hope this method will be helpful to accelerate the clinical diagnosis process and reduce the misdiagnosis rate.",0,0
2641,"Plasma-metabolite-based machine learning is a promising diagnostic approach for esophageal squamous cell carcinoma investigation. The aim of this study was to develop a diagnostic strategy for esophageal squamous cell carcinoma (ESCC) that combines plasma metabolomics with machine learning algorithms. Plasma-based untargeted metabolomics analysis was performed with samples derived from 88 ESCC patients and 52 healthy controls. The dataset was split into a training set and a test set. After identification of differential metabolites in training set, single-metabolite-based receiver operating characteristic (ROC) curves and multiple-metabolite-based machine learning models were used to distinguish between ESCC patients and healthy controls. Kaplan-Meier survival analysis and Cox proportional hazards regression analysis were performed to investigate the prognostic significance of the plasma metabolites. Finally, twelve differential plasma metabolites (six up-regulated and six down-regulated) were annotated. The predictive performance of the six most prevalent diagnostic metabolites through the diagnostic models in the test set were as follows: arachidonic acid (accuracy: 0.887), sebacic acid (accuracy: 0.867), indoxyl sulfate (accuracy: 0.850), phosphatidylcholine (PC) (14:0/0:0) (accuracy: 0.825), deoxycholic acid (accuracy: 0.773), and trimethylamine N-oxide (accuracy: 0.653). The prediction accuracies of the machine learning models in the test set were partial least-square (accuracy: 0.947), random forest (accuracy: 0.947), gradient boosting machine (accuracy: 0.960), and support vector machine (accuracy: 0.980). Additionally, survival analysis demonstrated that acetoacetic acid was an unfavorable prognostic factor (hazard ratio (HR): 1.752), while PC (14:0/0:0) (HR: 0.577) was a favorable prognostic factor for ESCC. This study devised an innovative strategy for ESCC diagnosis by combining plasma metabolomics with machine learning algorithms and revealed its potential to become a novel screening test for ESCC.",0,0
2645,"Prediction of Multidrug-Resistant Tuberculosis Using Machine Learning Algorithms in SWAT, Pakistan. In this paper, we have focused on machine learning (ML) feature selection (FS) algorithms for identifying and diagnosing multidrug-resistant (MDR) tuberculosis (TB). MDR-TB is a universal public health problem, and its early detection has been one of the burning issues. The present study has been conducted in the Malakand Division of Khyber Pakhtunkhwa, Pakistan, to further add to the knowledge on the disease and to deal with the issues of identification and early detection of MDR-TB by ML algorithms. These models also identify the most important factors causing MDR-TB infection whose study gives additional insights into the matter. ML algorithms such as random forest, k-nearest neighbors, support vector machine, logistic regression, leaset absolute shrinkage and selection operator (LASSO), artificial neural networks (ANNs), and decision trees are applied to analyse the case-control dataset. This study reveals that close contacts of MDR-TB patients, smoking, depression, previous TB history, improper treatment, and interruption in first-line TB treatment have a great impact on the status of MDR. Accordingly, weight loss, chest pain, hemoptysis, and fatigue are important symptoms. Based on accuracy, sensitivity, and specificity, SVM and RF are the suggested models to be used for patients' classifications.",0,0
2654,"Discovering Potential Taxonomic Biomarkers of Type 2 Diabetes From Human Gut Microbiota <i>via</i> Different Feature Selection Methods. Human gut microbiota is a complex community of organisms including trillions of bacteria. While these microorganisms are considered as essential regulators of our immune system, some of them can cause several diseases. In recent years, next-generation sequencing technologies accelerated the discovery of human gut microbiota. In this respect, the use of machine learning techniques became popular to analyze disease-associated metagenomics datasets. Type 2 diabetes (T2D) is a chronic disease and affects millions of people around the world. Since the early diagnosis in T2D is important for effective treatment, there is an utmost need to develop a classification technique that can accelerate T2D diagnosis. In this study, using T2D-associated metagenomics data, we aim to develop a classification model to facilitate T2D diagnosis and to discover T2D-associated biomarkers. The sequencing data of T2D patients and healthy individuals were taken from a metagenome-wide association study and categorized into disease states. The sequencing reads were assigned to taxa, and the identified species are used to train and test our model. To deal with the high dimensionality of features, we applied robust feature selection algorithms such as Conditional Mutual Information Maximization, Maximum Relevance and Minimum Redundancy, Correlation Based Feature Selection, and select K best approach. To test the performance of the classification based on the features that are selected by different methods, we used random forest classifier with 100-fold Monte Carlo cross-validation. In our experiments, we observed that 15 commonly selected features have a considerable effect in terms of minimizing the microbiota used for the diagnosis of T2D and thus reducing the time and cost. When we perform biological validation of these identified species, we found that some of them are known as related to T2D development mechanisms and we identified additional species as potential biomarkers. Additionally, we attempted to find the subgroups of T2D patients using <i>k</i>-means clustering. In summary, this study utilizes several supervised and unsupervised machine learning algorithms to increase the diagnostic accuracy of T2D, investigates potential biomarkers of T2D, and finds out which subset of microbiota is more informative than other taxa by applying state-of-the art feature selection methods.",0,0
2658,"Reinforcement Learning to Improve Image-Guidance of Ablation Therapy for Atrial Fibrillation. Atrial fibrillation (AF) is the most common cardiac arrhythmia and currently affects more than 650,000 people in the United Kingdom alone. Catheter ablation (CA) is the only AF treatment with a long-term curative effect as it involves destroying arrhythmogenic tissue in the atria. However, its success rate is suboptimal, approximately 50% after a 2-year follow-up, and this high AF recurrence rate warrants significant improvements. Image-guidance of CA procedures have shown clinical promise, enabling the identification of key patient anatomical and pathological (such as fibrosis) features of atrial tissue, which require ablation. However, the latter approach still suffers from a lack of functional information and the need to interpret structures in the images by a clinician. Deep learning plays an increasingly important role in biomedicine, facilitating efficient diagnosis and treatment of clinical problems. This study applies deep reinforcement learning in combination with patient imaging (to provide structural information of the atria) and image-based modelling (to provide functional information) to design patient-specific CA strategies to guide clinicians and improve treatment success rates. To achieve this, patient-specific 2D left atrial (LA) models were derived from late-gadolinium enhancement (LGE) MRI scans of AF patients and were used to simulate patient-specific AF scenarios. Then a reinforcement Q-learning algorithm was created, where an ablating agent moved around the 2D LA, applying CA lesions to terminate AF and learning through feedback imposed by a reward policy. The agent achieved 84% success rate in terminating AF during training and 72% success rate in testing. Finally, AF recurrence rate was measured by attempting to re-initiate AF in the 2D atrial models after CA with 11% recurrence showing a great improvement on the existing therapies. Thus, reinforcement Q-learning algorithms can predict successful CA strategies from patient MRI data and help to improve the patient-specific guidance of CA therapy.",0,0
2659,"Classification of Lung Disease in Children by Using Lung Ultrasound Images and Deep Convolutional Neural Network. Bronchiolitis is the most common cause of hospitalization of children in the first year of life and pneumonia is the leading cause of infant mortality worldwide. Lung ultrasound technology (LUS) is a novel imaging diagnostic tool for the early detection of respiratory distress and offers several advantages due to its low-cost, relative safety, portability, and easy repeatability. More precise and efficient diagnostic and therapeutic strategies are needed. Deep-learning-based computer-aided diagnosis (CADx) systems, using chest X-ray images, have recently demonstrated their potential as a screening tool for pulmonary disease (such as COVID-19 pneumonia). We present the first computer-aided diagnostic scheme for LUS images of pulmonary diseases in children. In this study, we trained from scratch four state-of-the-art deep-learning models (VGG19, Xception, Inception-v3 and Inception-ResNet-v2) for detecting children with bronchiolitis and pneumonia. In our experiments we used a data set consisting of 5,907 images from 33 healthy infants, 3,286 images from 22 infants with bronchiolitis, and 4,769 images from 7 children suffering from bacterial pneumonia. Using four-fold cross-validation, we implemented one binary classification (healthy vs. bronchiolitis) and one three-class classification (healthy vs. bronchiolitis vs. bacterial pneumonia) out of three classes. Affine transformations were applied for data augmentation. Hyperparameters were optimized for the learning rate, dropout regularization, batch size, and epoch iteration. The Inception-ResNet-v2 model provides the highest classification performance, when compared with the other models used on test sets: for healthy vs. bronchiolitis, it provides 97.75% accuracy, 97.75% sensitivity, and 97% specificity whereas for healthy vs. bronchiolitis vs. bacterial pneumonia, the Inception-v3 model provides the best results with 91.5% accuracy, 91.5% sensitivity, and 95.86% specificity. We performed a gradient-weighted class activation mapping (Grad-CAM) visualization and the results were qualitatively evaluated by a pediatrician expert in LUS imaging: heatmaps highlight areas containing diagnostic-relevant LUS imaging-artifacts, e.g., A-, B-, pleural-lines, and consolidations. These complex patterns are automatically learnt from the data, thus avoiding hand-crafted features usage. By using LUS imaging, the proposed framework might aid in the development of an accessible and rapid decision support-method for diagnosing pulmonary diseases in children using LUS imaging.",0,0
2661,"Detection of Brief Episodes of Atrial Fibrillation Based on Electrocardiomatrix and Convolutional Neural Network. <b>Background:</b> Brief episodes of atrial fibrillation (AF) may evolve into longer AF episodes increasing the chances of thrombus formation, stroke, and death. Classical methods for AF detection investigate rhythm irregularity or P-wave absence in the ECG, while deep learning approaches profit from the availability of annotated ECG databases to learn discriminatory features linked to different diagnosis. However, some deep learning approaches do not provide analysis of the features used for classification. This paper introduces a convolutional neural network (CNN) approach for automatic detection of brief AF episodes based on electrocardiomatrix-images (ECM-images) aiming to link deep learning to features with clinical meaning. <b>Materials and Methods:</b> The CNN is trained using two databases: the Long-Term Atrial Fibrillation and the MIT-BIH Normal Sinus Rhythm, and tested on three databases: the MIT-BIH Atrial Fibrillation, the MIT-BIH Arrhythmia, and the Monzino-AF. Detection of AF is done using a sliding window of 10 beats plus 3 s. Performance is quantified using both standard classification metrics and the EC57 standard for arrhythmia detection. Layer-wise relevance propagation analysis was applied to link the decisions made by the CNN to clinical characteristics in the ECG. <b>Results:</b> For all three testing databases, episode sensitivity was greater than 80.22, 89.66, and 97.45% for AF episodes shorter than 15, 30 s, and for all episodes, respectively. <b>Conclusions:</b> Rhythm and morphological characteristics of the electrocardiogram can be learned by a CNN from ECM-images for the detection of brief episodes of AF.",0,0
2662,"Early Prediction of Tacrolimus-Induced Tubular Toxicity in Pediatric Refractory Nephrotic Syndrome Using Machine Learning. <b>Background and Aims:</b> Tacrolimus(TAC)-induced nephrotoxicity, which has a large individual variation, may lead to treatment failure or even the end-stage renal disease. However, there is still a lack of effective models for the early prediction of TAC-induced nephrotoxicity, especially in nephrotic syndrome(NS). We aimed to develop and validate a predictive model of TAC-induced tubular toxicity in children with NS using machine learning based on comprehensive clinical and genetic variables. <b>Materials and Methods:</b> A retrospective cohort of 218 children with NS admitted between June 2013 and December 2018 was used to establish the models, and 11 children were prospectively enrolled for external validation. We screened 47 clinical features and 244 genetic variables. The changes in urine N- acetyl- Î²-D- glucosaminidase(NAG) levels before and after administration was used as an indicator of renal tubular toxicity. <b>Results:</b> Five machine learning algorithms, including extreme gradient boosting (XGBoost), gradient boosting decision tree (GBDT), extremely random trees (ET), random forest (RF), and logistic regression (LR) were used for model generation and validation. Four genetic variables, including <i>TRPC6</i> rs3824934_GG, HSD11B1 rs846910_AG, MAP2K6 rs17823202_GG, and SCARB2 rs6823680_CC were incorporated into the final model. The XGBoost model has the best performance: sensitivity 75%, specificity 77.8%, accuracy 77.3%, and AUC 78.9%. <b>Conclusion:</b> A pre-administration model with good performance for predicting TAC-induced nephrotoxicity in NS was developed and validated using machine learning based on genetic factors. Physicians can estimate the possibility of nephrotoxicity in NS patients using this simple and accurate model to optimize treatment regimen before administration or to intervene in time after administration to avoid kidney damage.",0,0
2663,"Multi-Head Attention-Based Long Short-Term Memory for Depression Detection From Speech. Depression is a mental disorder that threatens the health and normal life of people. Hence, it is essential to provide an effective way to detect depression. However, research on depression detection mainly focuses on utilizing different parallel features from audio, video, and text for performance enhancement regardless of making full usage of the inherent information from speech. To focus on more emotionally salient regions of depression speech, in this research, we propose a multi-head time-dimension attention-based long short-term memory (LSTM) model. We first extract frame-level features to store the original temporal relationship of a speech sequence and then analyze their difference between speeches of depression and those of health status. Then, we study the performance of various features and use a modified feature set as the input of the LSTM layer. Instead of using the output of the traditional LSTM, multi-head time-dimension attention is employed to obtain more key time information related to depression detection by projecting the output into different subspaces. The experimental results show the proposed model leads to improvements of 2.3 and 10.3% over the LSTM model on the Distress Analysis Interview Corpus-Wizard of Oz (DAIC-WOZ) and the Multi-modal Open Dataset for Mental-disorder Analysis (MODMA) corpus, respectively.",0,0
2665,"Classification of Complex Emotions Using EEG and Virtual Environment: Proof of Concept and Therapeutic Implication. During the last decades, neurofeedback training for emotional self-regulation has received significant attention from scientific and clinical communities. Most studies have investigated emotions using functional magnetic resonance imaging (fMRI), including the real-time application in neurofeedback training. However, the electroencephalogram (EEG) is a more suitable tool for therapeutic application. Our study aims at establishing a method to classify discrete complex emotions (e.g., tenderness and anguish) elicited through a near-immersive scenario that can be later used for EEG-neurofeedback. EEG-based affective computing studies have mainly focused on emotion classification based on dimensions, commonly using passive elicitation through single-modality stimuli. Here, we integrated both passive and active elicitation methods. We recorded electrophysiological data during emotion-evoking trials, combining emotional self-induction with a multimodal virtual environment. We extracted correlational and time-frequency features, including frontal-alpha asymmetry (FAA), using Complex Morlet Wavelet convolution. Thinking about future real-time applications, we performed within-subject classification using 1-s windows as samples and we applied trial-specific cross-validation. We opted for a traditional machine-learning classifier with low computational complexity and sufficient validation in online settings, the Support Vector Machine. Results of individual-based cross-validation using the whole feature sets showed considerable between-subject variability. The individual accuracies ranged from 59.2 to 92.9% using time-frequency/FAA and 62.4 to 92.4% using correlational features. We found that features of the temporal, occipital, and left-frontal channels were the most discriminative between the two emotions. Our results show that the suggested pipeline is suitable for individual-based classification of discrete emotions, paving the way for future personalized EEG-neurofeedback training.",0,0
2670,"Markers of Central Neuropathic Pain in Higuchi Fractal Analysis of EEG Signals From People With Spinal Cord Injury. Central neuropathic pain (CNP) negatively impacts the quality of life in a large proportion of people with spinal cord injury (SCI). With no cure at present, it is crucial to improve our understanding of how CNP manifests, to develop diagnostic biomarkers for drug development, and to explore prognostic biomarkers for personalised therapy. Previous work has found early evidence of diagnostic and prognostic markers analysing Electroencephalogram (EEG) oscillatory features. In this paper, we explore whether non-linear non-oscillatory EEG features, specifically Higuchi Fractal Dimension (HFD), can be used as prognostic biomarkers to increase the repertoire of available analyses on the EEG of people with subacute SCI, where having both linear and non-linear features for classifying pain may ultimately lead to higher classification accuracy and an intrinsically transferable classifier. We focus on EEG recorded during imagined movement because of the known relation between the motor cortex over-activity and CNP. Analyses were performed on two existing datasets. The first dataset consists of EEG recordings from able-bodied participants (<i>N</i> = 10), participants with chronic SCI and chronic CNP (<i>N</i> = 10), and participants with chronic SCI and no CNP (<i>N</i> = 10). We tested for statistically significant differences in HFD across all pairs of groups using bootstrapping, and found significant differences between all pairs of groups at multiple electrode locations. The second dataset consists of EEG recordings from participants with subacute SCI and no CNP (<i>N</i> = 20). They were followed-up 6 months post recording to test for CNP, at which point (<i>N</i> = 10) participants had developed CNP and (<i>N</i> = 10) participants had not developed CNP. We tested for statistically significant differences in HFD between these two groups using bootstrapping and, encouragingly, also found significant differences at multiple electrode locations. Transferable machine learning classifiers achieved over 80% accuracy discriminating between groups of participants with chronic SCI based on only a single EEG channel as input. The most significant finding is that future and chronic CNP share common features and as a result, the same classifier can be used for both. This sheds new light on pain chronification by showing that frontal areas, involved in the affective aspects of pain and believed to be influenced by long-standing pain, are affected in a much earlier phase of pain development.",0,0
2671,"Deep Feature Extraction for Resting-State Functional MRI by Self-Supervised Learning and Application to Schizophrenia Diagnosis. In this study, we propose a deep-learning technique for functional MRI analysis. We introduced a novel self-supervised learning scheme that is particularly useful for functional MRI wherein the subject identity is used as the teacher signal of a neural network. The neural network is trained solely based on functional MRI-scans, and the training does not require any explicit labels. The proposed method demonstrated that each temporal volume of resting state functional MRI contains enough information to identify the subject. The network learned a feature space in which the features were clustered per subject for the test data as well as for the training data; this is unlike the features extracted by conventional methods including region of interests (ROIs) pooling signals and principal component analysis. In addition, applying a simple linear classifier to the per-subject mean of the features (namely ""identity feature""), we demonstrated that the extracted features could contribute to schizophrenia diagnosis. The classification accuracy of our identity features was comparable to that of the conventional functional connectivity. Our results suggested that our proposed training scheme of the neural network captured brain functioning related to the diagnosis of psychiatric disorders as well as the identity of the subject. Our results together highlight the validity of our proposed technique as a design for self-supervised learning.",0,0
2674,"Home-Use and Real-Time Sleep-Staging System Based on Eye Masks and Mobile Devices with a Deep Learning Model. Sleep is an important human activity. Comfortable sensing and accurate analysis in sleep monitoring is beneficial to many healthcare and medical applications. From 2020, owing to the COVIDâ€‘19 pandemic that spreads between people when they come into close physical contact with one another, the willingness to go to hospital for receiving care has reduced; care-at-home is the trend in modern healthcare. Therefore, a home-use and real-time sleep-staging system is developed in this paper.",0,0
2675,"An optimal cascaded recurrent neural network for intelligent COVID-19 detection using Chest X-ray images. In recent times, COVID-19, has a great impact on the healthcare sector and results in a wide range of respiratory illnesses. It is a type of Ribonucleic acid (RNA) virus, which affects humans as well as animals. Though several artificial intelligence-based COVID-19 diagnosis models have been presented in the literature, most of the works have not focused on the hyperparameter tuning process. Therefore, this paper proposes an intelligent COVID-19 diagnosis model using a barnacle mating optimization (BMO) algorithm with a cascaded recurrent neural network (CRNN) model, named BMO-CRNN. The proposed BMO-CRNN model aims to detect and classify the existence of COVID-19 from Chest X-ray images. Initially, pre-processing is applied to enhance the quality of the image. Next, the CRNN model is used for feature extraction, followed by hyperparameter tuning of CRNN via the BMO algorithm to improve the classification performance. The BMO algorithm determines the optimal values of the CRNN hyperparameters namely learning rate, batch size, activation function, and epoch count. The application of CRNN and hyperparameter tuning using the BMO algorithm shows the novelty of this work. A comprehensive simulation analysis is carried out to ensure the better performance of the BMO-CRNN model, and the experimental outcome is investigated using several performance metrics. The simulation results portrayed that the BMO-CRNN model has showcased optimal performance with an average sensitivity of 97.01%, specificity of 98.15%, accuracy of 97.31%, and F-measure of 97.73% compared to state-of-the-art methods.",0,0
2676,"An integrated framework for COVID-19 classification based on classical and quantum transfer learning from a chest radiograph. COVID-19 is a quickly spreading over 10 million persons globally. The overall number of infected patients worldwide is estimated to be around 133,381,413 people. Infection rate is being increased on daily basis. It has also caused a devastating effect on the world economy and public health. Early stage detection of this disease is mandatory to reduce the mortality rate. Artificial intelligence performs a vital role for COVID-19 detection at an initial stage using chest radiographs. The proposed methods comprise of the two phases. Deep features (DFs) are derived from its last fully connected layers of pre-trained models like AlexNet and MobileNet in phase-I. Later these feature vectors are fused serially. Best features are selected through feature selection method of PCA and passed to the SVM and KNN for classification. In phase-II, quantum transfer learning model is utilized, in which a pre-trained ResNet-18 model is applied for DF collection and then these features are supplied as an input to the 4-qubit quantum circuit for model training with the tuned hyperparameters. The proposed technique is evaluated on two publicly available x-ray imaging datasets. The proposed methodology achieved an accuracy index of 99.0% with three classes including corona virus-positive images, normal images, and pneumonia radiographs. In comparison to other recently published work, the experimental findings show that the proposed approach outperforms it.",0,0
2677,"A CAUSAL DEEP LEARNING FRAMEWORK FOR CLASSIFYING PHONEMES IN COCHLEAR IMPLANTS. Speech intelligibility in cochlear implant (CI) users degrades considerably in listening environments with reverberation and noise. Previous research in automatic speech recognition (ASR) has shown that phoneme-based speech enhancement algorithms improve ASR system performance in reverberant environments as compared to a global model. However, phoneme-specific speech processing has not yet been implemented in CIs. In this paper, we propose a causal deep learning framework for classifying phonemes using features extracted at the time-frequency resolution of a CI processor. We trained and tested long short-term memory networks to classify phonemes and manner of articulation in anechoic and reverberant conditions. The results showed that CI-inspired features provide slightly higher levels of performance than traditional ASR features. To the best of our knowledge, this study is the first to provide a classification framework with the potential to categorize phonetic units in real-time in a CI.",0,0
2679,"Deep Learning-Based Available and Common Clinical-Related Feature Variables Robustly Predict Survival in Community-Acquired Pneumonia. Community-acquired pneumonia (CAP) is a leading cause of morbidity and mortality worldwide. Although there are many predictors of death for CAP, there are still some limitations. This study aimed to build a simple and accurate model based on available and common clinical-related feature variables for predicting CAP mortality by adopting machine learning techniques.",0,0
2680,Optimized Machine Learning Models to Predict In-Hospital Mortality for Patients with ST-Segment Elevation Myocardial Infarction. This study aimed to optimize machine learning (ML) models for predicting in-hospital mortality in patients with ST-segment elevation acute myocardial infarction (STEMI).,0,0
2682,"CovH2SD: A COVID-19 detection approach based on Harris Hawks Optimization and stacked deep learning. Starting from Wuhan in China at the end of 2019, coronavirus disease (COVID-19) has propagated fast all over the world, affecting the lives of billions of people and increasing the mortality rate worldwide in few months. The golden treatment against the invasive spread of COVID-19 is done by identifying and isolating the infected patients, and as a result, fast diagnosis of COVID-19 is a critical issue. The common laboratory test for confirming the infection of COVID-19 is Reverse Transcription Polymerase Chain Reaction (RT-PCR). However, these tests suffer from some problems in time, accuracy, and availability. Chest images have proven to be a powerful tool in the early detection of COVID-19. In the current study, a hybrid learning and optimization approach named CovH2SD is proposed for the COVID-19 detection from the Chest Computed Tomography (CT) images. CovH2SD uses deep learning and pre-trained models to extract the features from the CT images and learn from them. It uses Harris Hawks Optimization (HHO) algorithm to optimize the hyperparameters. Transfer learning is applied using nine pre-trained convolutional neural networks (i.e. ResNet50, ResNet101, VGG16, VGG19, Xception, MobileNetV1, MobileNetV2, DenseNet121, and DenseNet169). Fast Classification Stage (FCS) and Compact Stacking Stage (CSS) are suggested to stack the best models into a single one. Nine experiments are applied and results are reported based on the Loss, Accuracy, Precision, Recall, F1-Score, and Area Under Curve (AUC) performance metrics. The comparison between combinations is applied using the Weighted Sum Method (WSM). Six experiments report a WSM value above 96.5%. The top WSM and accuracy reported values are 99.31% and 99.33% respectively which are higher than the eleven compared state-of-the-art studies.",0,0
2684,"Self-assessment and deep learning-based coronavirus detection and medical diagnosis systems for healthcare. Coronavirus is one of the serious threat and challenge for existing healthcare systems. Several prevention methods and precautions have been proposed by medical specialists to treat the virus and secure infected patients. Deep learning methods have been adopted for disease detection, especially for medical image classification. In this paper, we proposed a deep learning-based medical image classification for COVID-19 patients namely deep learning model for coronavirus (DLM-COVID-19). The proposed model improves the medical image classification and optimization for better disease diagnosis. This paper also proposes a mobile application for COVID-19 patient detection using a self-assessment test combined with medical expertise and diagnose and prevent the virus using the online system. The proposed deep learning model is evaluated with existing algorithms where it shows better performance in terms of sensitivity, specificity, and accuracy. Whereas the proposed application also helps to overcome the virus risk and spread.",0,0
2690,"COVID-19 diagnosis system by deep learning approaches. The novel coronavirus disease 2019 (COVID-19) has been a severe health issue affecting the respiratory system and spreads very fast from one human to other overall countries. For controlling such disease, limited diagnostics techniques are utilized to identify COVID-19 patients, which are not effective. The above complex circumstances need to detect suspected COVID-19 patients based on routine techniques like chest X-Rays or CT scan analysis immediately through computerized diagnosis systems such as mass detection, segmentation, and classification. In this paper, regional deep learning approaches are used to detect infected areas by the lungs' coronavirus. For mass segmentation of the infected region, a deep Convolutional Neural Network (CNN) is used to identify the specific infected area and classify it into COVID-19 or Non-COVID-19 patients with a full-resolution convolutional network (FrCN). The proposed model is experimented with based on detection, segmentation, and classification using a trained and tested COVID-19 patient dataset. The evaluation results are generated using a fourfold cross-validation test with several technical terms such as Sensitivity, Specificity, Jaccard (Jac.), Dice (F1-score), Matthews correlation coefficient (MCC), Overall accuracy, etc. The comparative performance of classification accuracy is evaluated on both with and without mass segmentation validated test dataset.",0,0
2692,"Nature-inspired solution for coronavirus disease detection and its impact on existing healthcare systems. Coronavirus is an infectious life-threatening disease and is mainly transmitted through infected person coughs, sneezes, or exhales. This disease is a global challenge that demands advanced solutions to address multiple dimensions of this pandemic for health and wellbeing.Â  Different types of medical and technological-based solutions have been proposed to control and treat COVID-19. Machine learning is one of the technologies used in Magnetic Resonance Imaging (MRI) classification whereas nature-inspired algorithms are also adopted for image optimization. In this paper, we combined the machine learning and nature-inspired algorithm for brain MRI images of COVID-19 patients namely Machine Learning and Nature Inspired Model for Coronavirus (MLNI-COVID-19). This model improves the MRI image classification and optimization for better diagnosis. This model will improve the overall performance especially the area of brain images that is neglected due to the unavailability of the dataset. COVID-19 has a serious impact on the patient brain. The proposed model will help to improve the diagnosis process for better medical decisions and performance. The proposed model is evaluated with existing algorithms and achieved better performance in terms of sensitivity, specificity, and accuracy.",0,0
2700,"Rapidly deploying a COVID-19 decision support system in one of the largest Brazilian hospitals. The COVID-19 pandemic generated research interest in automated models to perform classification and segmentation from medical imaging of COVID-19 patients, However, applications in real-world scenarios are still needed. We describe the development and deployment of COVID-19 decision support and segmentation system. A partnership with a Brazilian radiologist consortium, gave us access to 1000s of labeled computed tomography (CT) and X-ray images from SÃ£o Paulo Hospitals. The system used EfficientNet and EfficientDet networks, state-of-the-art convolutional neural networks for natural images classification and segmentation, in a real-time scalable scenario in communication with a Picture Archiving and Communication System (PACS). Additionally, the system could reject non-related images, using header analysis and classifiers. We achieved CT and X-ray classification accuracies of 0.94 and 0.98, respectively, and Dice coefficient for lung and covid findings segmentations of 0.98 and 0.73, respectively. The median response time was 7â€‰s for X-ray and 4â€‰min for CT.",0,0
2707,"Phenotyping heart failure using model-based analysis and physiology-informed machine learning. Analysis of data from RHC and TTE of HF patients using a closed-loop model of the cardiovascular system identifies key parameters representing hemodynamic cardiovascular function in HFrEF and HFpEF patients. Analyzing optimized parameters representing cardiovascular function using machine learning shows mechanistic differences between HFpEF groups that are not seen analyzing clinical data alone. HFpEF groups presented here can be subdivided into 3 subgroups: HFpEF1 described as ""HFrEF-like HFpEF"", HFpEF2 as ""pure HFpEF"", and a third group of HFpEF patients that do not consistently cluster. Focusing purely on cardiac function consistently captures the underlying dysfunction in HFrEF, whereas HFpEF is better characterized by dysfunction in the entire cardiovascular system. Our methodology reveals that elevated left ventricular systolic and diastolic volumes are potential biomarkers for identifying HFpEF-like HFrEF patients.",0,0
2708,"Clinical Characteristics, Treatment Effectiveness, and Predictors of Response to Pharmacotherapeutic Interventions Among Patients with Herpetic-Related Neuralgia: A Retrospective Analysis. The treatment for herpetic-related neuralgia focuses on symptom control by use of antiviral drugs, anticonvulsants, and tricyclic antidepressants. We aimed to explore the clinical characteristics associated with medication responsiveness, and to build a classifier for identification of patients who have risk of inadequate pain management.",0,0
2709,"Effectiveness of cascading time series models based on meteorological factors in improving health risk prediction. Meteorological factors, which are periodic and regular in a long run, have an unignorable impact on human health. Accurate health risk prediction based on meteorological factors is essential for optimal allocation of resource in healthcare units. However, due to the non-stationary and non-linear nature of the original hospitalization sequence, traditional methods are less robust in predicting it. This study aims to investigate hospital admission prediction models using time series pre-processing algorithms and deep learning approach based on meteorological factors. Using the electronic medical record data from Panyu Central Hospital and meteorological data of Panyu district from 2003 to 2019, 46,089 eligible patients with lower respiratory tract infections (LRTIs) and four meteorological factors were identified to build and evaluate the prediction models. A novel hybrid model, Cascade GAM-CEEMDAN-LSTM Model (CGCLM), was established in combination with generalized additive model (GAM), complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN), and long-short term memory (LSTM) networks for predicting daily admissions of patients with LRTIs. The experimental results show that CGCLM multistep method proposed in this paper outperforms single LSTM model in the prediction of health risk time series at different time window sizes. Moreover, our results also indicate that CGCLM has the best prediction performance when the time window is set to 61 days (RMSE = 1.12, MAE = 0.87, R<sup>2</sup> = 0.93). Adequate extraction of exposure-response relationships between meteorological factors and diseases and suitable handling of sequence pre-processing have an important role in time series prediction. This hybrid climate-based model for predicting LRTIs disease can also be extended to time series prediction of other epidemic disease.",0,0
2712,"Multi-auxiliary domain transfer learning for diagnosis of MCI conversion. In the early stage of Alzheimer's disease (AD), mild cognitive impairment (MCI) has a higher risk of progression to AD, so the prediction of whether an MCI subject will progress to AD (known as progressive MCI, PMCI) or not (known as stable MCI, SMCI) within a certain period is particularly important in practice. It is known that such a task could benefit from jointly learning-related auxiliary tasks such as differentiating AD from PMCI or PMCI from normal control (NC) in order to take full advantage of their shared commonality. However, few existing methods along this line fully consider the correlations between the target and auxiliary tasks according to the clinical practice of AD pathology for diagnosis. To deal with this problem, in this paper, treating each task domain as a different one, we borrow the idea from transfer learning and propose a novel multi-auxiliary domain transfer learning (MaDTL) method, which explicitly utilizes the correlations between the target domain (task) and multi-auxiliary domains (tasks) according to the clinical practice. Specifically, the proposed MaDTL method incorporates two key modules. The first one is a multi-auxiliary domain transfer-based feature selection (MaDTFS) model, which can select a discriminative feature subset shared by the target domain and the multi-auxiliary domains. In the MaDTFS model, to combine more training data from multi-auxiliary domains and simultaneously suppress the negative effects resulting from the irrelevant parts of multi-auxiliary domains, we proposed a sparse group correlation Lasso that includes a proposed group correlation Lasso penalty (i.e., [Formula: see text]) and a proposed correlation Lasso penalty (i.e., [Formula: see text]). The second module in MaDTL is a multi-auxiliary domain transfer-based classification (MaDTC) model that improves the voting with linear weighting-based ensemble learning. This model extends the constraints of the linear weighting method so that it can simultaneously combine training data from multi-auxiliary domains and achieve a robust classifier by minimizing negative effects from the irrelevant part of multi-auxiliary domains. Experimental results on 409 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database with the baseline magnetic resonance imaging (MRI) and cerebrospinal fluid (CSF) data validate the effectiveness of the proposed method by significantly improving the classification accuracy to 80.37% for the identification of MCI-to-AD conversion, outperforming the state-of-the-art methods.",0,0
2716,"Novel automated PD detection system using aspirin pattern with EEG signals. Parkinson's disease (PD) is one of the most common diseases worldwide which reduces quality of life of patients and their family members. The electroencephalogram (EEG) signals coupled with various advanced machine-learning algorithms have been widely used to detect PD automatically. In this paper, we propose a novel aspirin pattern to detect PD accurately using EEG signals.",0,0
2717,"Exploring machine learning to predict depressive relapses of bipolar disorder patients. Bipolar disorder (BD) is a chronic mood disorder characterized by recurrent episodes of mania or hypomania and depression, expressed by changes in energy levels and behavior. However, most of relapse studies use evidence-based approaches with statistical methods. With the advance of the precision medicine this study aims to use machine learning (ML) approaches as a possible predictor in depressive relapses in BD.",0,0
2718,"Deep learning models for benign and malign ocular tumor growth estimation. Relatively abundant availability of medical imaging data has provided significant support in the development and testing of Neural Network based image processing methods. Clinicians often face issues in selecting suitable image processing algorithm for medical imaging data. A strategy for the selection of a proper model is presented here. The training data set comprises optical coherence tomography (OCT) and angiography (OCT-A) images of 50 mice eyes with more than 100 days follow-up. The data contains images from treated and untreated mouse eyes. Four deep learning variants are tested for automatic (a) differentiation of tumor region with healthy retinal layer and (b) segmentation of 3D ocular tumor volumes. Exhaustive sensitivity analysis of deep learning models is performed with respect to the number of training and testing images using eight performance indices to study accuracy, reliability/reproducibility, and speed. U-net with UVgg16 is best for malign tumor data set with treatment (having considerable variation) and U-net with Inception backbone for benign tumor data (with minor variation). Loss value and root mean square error (R.M.S.E.) are found most and least sensitive performance indices, respectively. The performance (via indices) is found to be exponentially improving regarding a number of training images. The segmented OCT-Angiography data shows that neovascularization drives the tumor volume. Image analysis shows that photodynamic imaging-assisted tumor treatment protocol is transforming an aggressively growing tumor into a cyst. An empirical expression is obtained to help medical professionals choose a particular model given the number of images and types of characteristics. We recommend that the presented exercise should be taken as standard practice before employing a particular deep learning model for biomedical image analysis.",0,0
2720,"Psychophysiological dynamics of emotional reactivity: Interindividual reactivity characterization and prediction by a machine learning approach. The fast reaction of the autonomic nervous system (ANS) to an emotional challenge (EC) is the result of a functional coupling between parasympathetic (PNS) and sympathetic (SNS) branches. This coupling can be characterized by measures of cross-correlations between electrodermal activity (EDA) (under the influence of the SNS) and the RR interval (the interval between R peaks) (under the influence of the PNS and the SNS). Significant interindividual variability has previously been reported in SNS-PNS coupling in emotional situations, and the present study aimed to identify interindividual cross-correlation variability in ANS reactivity. We therefore studied EDA and the RR interval in 62 healthy subjects, recorded during a 24-minute EC. A Gaussian Mixture Model was used to cluster tonic EDA-RR cross-correlations during the EC. This identified two clusters that were characterized by significant or non-significant cross-correlations (SCC and NCC clusters, respectively). The SCC cluster reported higher negative emotion after the EC, while the NCC cluster reported higher scores on the Center for Epidemiologic Studies-Depression scale. The latter finding suggests that NCC is a pathological mood pattern with altered negative perception. Furthermore, a machine learning model that included three parameters indexing the functionality of both branches of the ANS, measured at baseline, predicted cluster membership. Our results are a first step in detecting dysfunctional ANS reactivity in general population.",0,0
2721,"Clinically relevant deep learning for detection and quantification of geographic atrophy from optical coherence tomography: a model development and external validation study. Geographic atrophy is a major vision-threatening manifestation of age-related macular degeneration, one of the leading causes of blindness globally. Geographic atrophy has no proven treatment or method for easy detection. Rapid, reliable, and objective detection and quantification of geographic atrophy from optical coherence tomography (OCT) retinal scans is necessary for disease monitoring, prognostic research, and to serve as clinical endpoints for therapy development. To this end, we aimed to develop and validate a fully automated method to detect and quantify geographic atrophy from OCT.",0,0
2726,Artificial intelligence language predictors of two-year trauma-related outcomes. Recent research on artificial intelligence has demonstrated that natural language can be used to provide valid indicators of psychopathology. The present study examined artificial intelligence-based language predictors (ALPs) of seven trauma-related mental and physical health outcomes in responders to the World Trade Center disaster.,0,0
2729,Using machine learning to reduce unnecessary rehospitalization of cardiovascular patients in Saudi Arabia. Patient readmission is a costly and preventable burden on healthcare systems. The main objective of this study was to develop a machine-learning classification model to identify cardiovascular patients with a high risk of readmission.,0,0
2731,"Novel ensemble of optimized CNN and dynamic selection techniques for accurate Covid-19 screening using chest CT images. The world is significantly affected by infectious coronavirus disease (covid-19). Timely prognosis and treatment are important to control the spread of this infection. Unreliable screening systems and limited number of clinical facilities are the major hurdles in controlling the spread of covid-19. Nowadays, many automated detection systems based on deep learning techniques using computed tomography (CT) images have been proposed to detect covid-19. However, these systems have the following drawbacks: (i) limited data problem poses a major hindrance to train the deep neural network model to provide accurate diagnosis, (ii) random choice of hyperparameters of Convolutional Neural Network (CNN) significantly affects the classification performance, since the hyperparameters have to be application dependent and, (iii) the generalization ability using CNN classification is usually not validated. To address the aforementioned issues, we propose two models: (i) based on a transfer learning approach, and (ii) using novel strategy to optimize the CNN hyperparameters using Whale optimization-based BAT algorithmÂ +Â AdaBoost classifier built using dynamic ensemble selection techniques. According to our second method depending on the characteristics of test sample, the classifier is chosen, thereby reducing the risk of overfitting and simultaneously produced promising results. Our proposed methodologies are developed using 746 CT images. Our method obtained a sensitivity, specificity, accuracy, F-1 score, and precision of 0.98, 0.97, 0.98, 0.98, and 0.98, respectively with five-fold cross-validation strategy. Our developed prototype is ready to be tested with huge chest CT images database before its real-world application.",0,0
2733,"Ensemble based machine learning approach for prediction of glioma and multi-grade classification. Glioma is the most pernicious cancer of the nervous system, with histological grade influencing the survival of patients. Despite many studies on the multimodal treatment approach, survival time remains brief. In this study, a novel two-stage ensemble of an ensemble-type machine learning-based predictive framework for glioma detection and its histograde classification is proposed. In the proposed framework, five characteristics belonging to 135 subjects were considered: human telomerase reverse transcriptase (hTERT), chitinase-like protein (YKL-40), interleukin 6 (IL-6), tissue inhibitor of metalloproteinase-1 (TIMP-1) and neutrophil/lymphocyte ratio (NLR). These characteristics were examined using distinctive ensemble-based machine learning classifiers and combination strategies to develop a computer-aided diagnostic system for the non-invasive prediction of glioma cases and their grade. In the first stage, the analysis was conducted to classify glioma cases and control subjects. Machine learning approaches were applied in the second stage to classify the recognised glioma cases into three grades, from grade II, which has a good prognosis, to grade IV, which is also known as glioblastoma. All experiments were evaluated with a five-fold cross-validation method, and the classification results were analysed using different statistical parameters. The proposed approach obtained a high value of accuracy and other statistical parameters compared with other state-of-the-art machine learning classifiers. Therefore, the proposed framework can be utilised for designing other intervention strategies for the prediction of glioma cases and their grades.",0,0
2735,"MTANS: Multi-Scale Mean Teacher Combined Adversarial Network with Shape-Aware Embedding for Semi-Supervised Brain Lesion Segmentation. The annotation of brain lesion images is a key step in clinical diagnosis and treatment of a wide spectrum of brain diseases. In recent years, segmentation methods based on deep learning have gained unprecedented popularity, leveraging a large amount of data with high-quality voxel-level annotations. However, due to the limited time clinicians can provide for the cumbersome task of manual image segmentation, semi-supervised medical image segmentation methods present an alternative solution as they require only a few labeled samples for training. In this paper, we propose a novel semi-supervised segmentation framework that combines improved mean teacher and adversarial network. Specifically, our framework consists of (i) a student model and a teacher model for segmenting the target and generating the signed distance maps of object surfaces, and (ii) a discriminator network for extracting hierarchical features and distinguishing the signed distance maps of labeled and unlabeled data. Besides, based on two different adversarial learning processes, a multi-scale feature consistency loss derived from the student and teacher models is proposed, and a shape-aware embedding scheme is integrated into our framework. We evaluated the proposed method on the public brain lesion datasets from ISBI 2015, ISLES 2015, and BRATS 2018 for the multiple sclerosis lesion, ischemic stroke lesion, and brain tumor segmentation respectively. Experiments demonstrate that our method can effectively leverage unlabeled data while outperforming the supervised baseline and other state-of-the-art semi-supervised methods trained with the same labeled data. The proposed framework is suitable for joint training of limited labeled data and additional unlabeled data, which is expected to reduce the effort of obtaining annotated images.",0,0
2736,"Discrimination of vascular aging using the arterial pulse spectrum and machine-learning analysis. Aging contributes to the progression of vascular dysfunction and is a major nonreversible risk factor for cardiovascular disease. The aim of this study was to determine the effectiveness of using arterial pulse-wave measurements, frequency-domain pulse analysis, and machine-learning analysis in distinguishing vascular aging. Radial pulse signals were measured noninvasively for 3â€¯min in 280 subjects aged 40-80â€¯years. The cardio-ankle vascular index (CAVI) was used to evaluate the arterial stiffness of the subjects. Forty frequency-domain pulse indices were used as features, comprising amplitude proportion (C<sub>n</sub>), coefficient of variation of C<sub>n</sub>, phase angle (P<sub>n</sub>), and standard deviation of P<sub>n</sub> (nâ€¯=â€¯1-10). Multilayer perceptron and random forest with supervised learning were used to classify the data. The detected differences were more prominent in the subjects aged 40-50â€¯years. Several indices differed significantly between the non-vascular-aging group (aged 40-50â€¯years; CAVI <9) and the vascular-aging group (aged 70-80â€¯years). Fivefold cross-validation revealed an excellent ability to discriminate the two groups (the accuracy was >80%, and the AUC was >0.8). For subjects aged 50-60 and 60-70â€¯years, the detection accuracies of the two trained algorithms were around 80%, with AUCs of >0.73 for both, which indicated acceptable discrimination. The present method of frequency-domain analysis may improve the index reliability for further machine-learning analyses of the pulse waveform. The present noninvasive and objective methodology may be meaningful for developing a wearable-device system to reduce the threat of vascular dysfunction induced by vascular aging.",0,0
2737,"Artificial intelligence for automatic diagnosis of biliary strictures malignancy status in single-operator cholangioscopy: a pilot study. Diagnosis and characterization of biliary strictures is challenging. The introduction of digital single-operator cholangioscopy (DSOC) allowing direct visual inspection of the lesion and targeted biopsies significantly improved the diagnostic yield in patients with indeterminate biliary strictures. However, the diagnostic efficiency of DSOC remains suboptimal. Convolutional neural networks (CNNs) have shown great potential for the interpretation of medical images. We aimed to develop a CNN-based system for automatic detection of malignant biliary strictures in DSOC images.",0,0
2738,"Markerless analysis of hindlimb kinematics in spinal cord-injured mice through deep learning. Rodent models are commonly used to understand the underlying mechanisms of spinal cord injury (SCI). Kinematic analysis, an important technique to measure dysfunction of locomotion after SCI, is generally based on the capture of physical markers placed on bony landmarks. However, marker-based studies face significant experimental hurdles such as labor-intensive manual joint tracking, alteration of natural gait by markers, and skin error from soft tissue movement on the knee joint. Although the pose estimation strategy using deep neural networks can solve some of these issues, it remains unclear whether this method is adaptive to SCI mice with abnormal gait. In the present study, we developed a deep learning based markerless method of 2D kinematic analysis to automatically track joint positions. We found that a relatively small number (< 200) of manually labeled video frames was sufficient to train the network to extract trajectories. The mean test error was on average 3.43 pixels in intact mice and 3.95 pixels in SCI mice, which is comparable to the manual tracking error (3.15 pixels, less than 1 mm). Thereafter, we extracted 30 gait kinematic parameters and found that certain parameters such as step height and maximal hip joint amplitude distinguished intact and SCI locomotion.",0,0
2739,"Selection, Visualization, and Interpretation of Deep Features in Lung Adenocarcinoma and Squamous Cell Carcinoma. Although deep learning networks applied to digital images have shown impressive results for many pathology-related tasks, their black-box approach and limitation in terms of interpretability are significant obstacles for their widespread clinical utility. This study investigates the visualization of deep features (DFs) to characterize two lung cancer subtypes, adenocarcinoma and squamous cell carcinoma. This study demonstrates that a subset of DFs exist that can accurately distinguish these two cancer subtypes, prominent DFs. Visualization of such individual DFs allows us to understand better histopathologic patterns at both the whole-slide and patch levels, allowing discrimination of these cancer types. These DFs were visualized at the whole slide image level through DF-specific heatmaps and at tissue patch level through generating activation maps. In addition, we show that these prominent DFs contain information that can distinguish carcinomas of organs other than the lung. This framework may serve as a platform for evaluating the interpretability of any deep network for diagnostic decision making.",0,0
2744,"Development and validation of a novel risk assessment model to estimate the probability of pulmonary embolism in postoperative patients. Pulmonary embolism (PE) is a leading cause of mortality in postoperative patients. Numerous PE prevention clinical practice guidelines are available but not consistently implemented. This study aimed to develop and validate a novel risk assessment model to assess the risk of PE in postoperative patients. Patients who underwent Grade IV surgery between September 2012 and January 2020 (nâ€‰=â€‰26,536) at the Affiliated Dongyang Hospital of Wenzhou Medical University were enrolled in our study. PE was confirmed by an identified filling defect in the pulmonary artery system in CT pulmonary angiography. The PE incidence was evaluated before discharge. All preoperative data containing clinical and laboratory variables were extracted for each participant. A novel risk assessment model (RAM) for PE was developed with multivariate regression analysis. The discrimination ability of the RAM was evaluated by the area under the receiver operating characteristic curve, and model calibration was assessed by the Hosmer-Lemeshow statistic. We included 53 clinical and laboratory variables in this study. Among them, 296 postoperative patients developed PE before discharge, and the incidence rate was 1.04%. The distribution of variables between the training group and the validation group was balanced. After using multivariate stepwise regression, only variable age (OR 1.070 [1.054-1.087], Pâ€‰<â€‰0.001), drinking (ORâ€‰0.477 [0.304-0.749], Pâ€‰=â€‰0.001), malignant tumor (ORâ€‰2.552 [1.745-3.731], Pâ€‰<â€‰0.001), anticoagulant (ORâ€‰3.719 [2.281-6.062], Pâ€‰<â€‰0.001), lymphocyte percentage (ORâ€‰2.773 [2.342-3.285], Pâ€‰<â€‰0.001), neutrophil percentage (ORâ€‰10.703 [8.337-13.739], Pâ€‰<â€‰0.001), red blood cell (ORâ€‰1.872 [1.384-2.532], Pâ€‰<â€‰0.001), total bilirubin (ORâ€‰1.038 [1.012-1.064], Pâ€‰<â€‰0.001), direct bilirubin (ORâ€‰0.850 [0.779-0.928], Pâ€‰<â€‰0.001), prothrombin time (ORâ€‰0.768 [0.636-0.926], Pâ€‰<â€‰0.001) and fibrinogen (ORâ€‰0.772 [0.651-0.915], Pâ€‰<â€‰0.001) were selected and significantly associated with PE. The final model included four variables: neutrophil percentage, age, malignant tumor and lymphocyte percentage. The AUC of the model was 0.949 (95% CI 0.932-0.966). The risk prediction model still showed good calibration, with reasonable agreement between the observed and predicted PE outcomes in the validation set (AUC 0.958). The information on sensitivity, specificity and predictive values according to cutoff points of the score in the training set suggested a threshold of 0.012 as the optimal cutoff value to define high-risk individuals. We developed a new approach to select hazard factors for PE in postoperative patients. This tool provided a consistent, accurate, and effective method for risk assessment. This finding may help decision-makers weigh the risk of PE and appropriately select PE prevention strategies.",0,0
2747,"A multi-scale gated multi-head attention depthwise separable CNN model for recognizing COVID-19. Coronavirus 2019 (COVID-19) is a new acute respiratory disease that has spread rapidly throughout the world. In this paper, a lightweight convolutional neural network (CNN) model named multi-scale gated multi-head attention depthwise separable CNN (MGMADS-CNN) is proposed, which is based on attention mechanism and depthwise separable convolution. A multi-scale gated multi-head attention mechanism is designed to extract effective feature information from the COVID-19 X-ray and CT images for classification. Moreover, the depthwise separable convolution layers are adopted as MGMADS-CNN's backbone to reduce the model size and parameters. The LeNet-5, AlexNet, GoogLeNet, ResNet, VGGNet-16, and three MGMADS-CNN models are trained, validated and tested with tenfold cross-validation on X-ray and CT images. The results show that MGMADS-CNN with three attention layers (MGMADS-3) has achieved accuracy of 96.75% on X-ray images and 98.25% on CT images. The specificity and sensitivity are 98.06% and 96.6% on X-ray images, and 98.17% and 98.05% on CT images. The size of MGMADS-3 model is only 43.6Â M bytes. In addition, the detection speed of MGMADS-3 on X-ray images and CT images are 6.09Â ms and 4.23Â ms for per image, respectively. It is proved that the MGMADS-3 can detect and classify COVID-19 faster with higher accuracy and efficiency.",0,0
2748,"Geometric and biomechanical modeling aided by machine learning improves the prediction of growth and rupture of small abdominal aortic aneurysms. It remains difficult to predict when which patients with abdominal aortic aneurysm (AAA) will require surgery. The aim was to study the accuracy of geometric and biomechanical analysis of small AAAs to predict reaching the threshold for surgery, diameter growth rate and rupture or symptomatic aneurysm. 189 patients with AAAs of diameters 40-50Â mm were included, 161 had undergone two CTAs. Geometric and biomechanical variables were used in prediction modelling. Classifications wereÂ evaluated with area under receiver operating characteristic curve (AUC) and regressions with correlation between observed and predicted growth rates. Compared with the baseline clinical diameter, geometric-biomechanicalÂ analysis improved prediction of reaching surgical threshold within four years (AUC 0.80 vs 0.85, pâ€‰=â€‰0.031) and prediction of diameter growth rate (râ€‰=â€‰0.17 vs râ€‰=â€‰0.38, pâ€‰=â€‰0.0031), mainly due to the addition of semiautomatic diameter measurements. There was a trend towards increased precision of volume growth rate prediction (râ€‰=â€‰0.37 vs râ€‰=â€‰0.45, pâ€‰=â€‰0.081). Lumen diameter and biomechanical indices were the only variables that could predict future rupture or symptomatic AAA (AUCs 0.65-0.67). Enhanced precision of diameter measurements improves the prediction of reaching the surgical threshold and diameter growth rate, while lumenÂ diameter and biomechanical analysis predicts rupture or symptomatic AAA.",0,0
2751,"Machine Learning Used to Compare the Diagnostic Accuracy of Risk Factors, Clinical Signs and Biomarkers and to Develop a New Prediction Model for Neonatal Early-onset Sepsis. Current strategies for risk stratification and prediction of neonatal early-onset sepsis (EOS) are inefficient and lack diagnostic performance. The aim of this study was to use machine learning to analyze the diagnostic accuracy of risk factors (RFs), clinical signs and biomarkers and to develop a prediction model for culture-proven EOS. We hypothesized that the contribution to diagnostic accuracy of biomarkers is higher than of RFs or clinical signs.",0,0
2753,"Determining age and sex-specific distribution of pancreatic whole-gland CT attenuation using artificial intelligence aided image segmentation: Associations with body composition and pancreatic cancer risk. Increased intrapancreatic fat is associated with pancreatic diseases; however, there are no established objective diagnostic criteria for fatty pancreas. On non-contrast computed tomography (CT), adipose tissue shows negative Hounsfield Unit (HU) attenuations (-150 toÂ -30 HU). Using whole organ segmentation on non-contrast CT, we aimed to describe whole gland pancreatic attenuation and establish 5th and 10th percentile thresholds across a spectrum of age and sex. Subsequently, we aimed to evaluate the association between low pancreatic HU and risk of pancreatic ductal adenocarcinoma (PDAC).",0,0
2755,The BAriatic surgery SUbstitution and nutrition (BASUN) population: a data-driven exploration of predictors for obesity. The development of obesity is most likely due to a combination of biological and environmental factors some of which might still be unidentified. We used a machine learning technique to examine the relative importance of more than 100 clinical variables as predictors for BMI.,0,0
2760,"Automatic radiotherapy delineation quality assurance on prostate MRI with deep learning in a multicentre clinical trial. Volume delineation quality assurance (QA) is particularly important in clinical trial settings where consistent protocol implementation is required, as outcomes will affect future as well current patients. Currently, where feasible, this is conducted manually, which is time consuming and resource intensive. Although previous studies mostly focused on automating delineation QA on CT, magnetic resonance imaging (MRI) is being increasingly used in radiotherapy treatment. In this work, we propose to perform automatic delineation QA on prostate MRI for both the clinical target volume (CTV) and organs-at-risk (OARs) by using delineations generated by 3D Unet variants as benchmarks for QA. These networks were trained on a small gold standard atlas set and applied on a multicentre radiotherapy clinical trial dataset to generate benchmark delineations. Then, a QA stage was designed to recommend 'pass', 'minor correction' and 'major correction' for each manual delineation in the trial set by thresholding its Dice similarity coefficient to the network generated delineation. Among all 3D Unet variants explored, the Unet with anatomical gates in an AtlasNet architecture performed the best in delineation QA, achieving an area under the receiver operating characteristics curve of 0.97, 0.92, 0.89 and 0.97 for identifying unacceptable (major correction) delineations with a sensitivity of 0.93, 0.73, 0.74 and 0.90 at a specificity of 0.93, 0.86, 0.86 and 0.95 for bladder, prostate CTV, rectum and gel spacer respectively. To the best of our knowledge, this is the first study to propose automated delineation QA for a multicentre radiotherapy clinical trial with treatment planning MRI. The methods proposed in this work can potentially improve the accuracy and consistency of CTV and OAR delineation in radiotherapy treatment planning.",0,0
2761,"White matter structural connectivity as a biomarker for detecting juvenile myoclonic epilepsy by transferred deep convolutional neural networks with varying transfer rates. By detecting the abnormal white matter changes, diffusion magnetic resonance imaging (MRI) contributes to the detection of juvenile myoclonic epilepsy (JME). In addition, deep learning has greatly improved the detection performance of various brain disorders. However, there is almost no previous study effectively detecting JME by deep learning approach with diffusion MRI.",0,0
2762,"ULNet for the detection of coronavirus (COVID-19) from chest X-ray images. Novel coronavirus disease 2019 (COVID-19) is an infectious disease that spreads very rapidly and threatens the health of billions of people worldwide. With the number of cases increasing rapidly, most countries are facing the problem of a shortage of testing kits and resources, and it is necessary to use other diagnostic methods as an alternative to these test kits. In this paper, we propose a convolutional neural network (CNN) model (ULNet) to detect COVID-19 using chest X-ray images. The proposed architecture is constructed by adding a new downsampling side, skip connections and fully connected layers on the basis of U-net. Because the shape of the network is similar to UL, it is named ULNet. This model is trained and tested on a publicly available Kaggle dataset (consisting of a combination of 219 COVID-19, 1314 normal and 1345 viral pneumonia chest X-ray images), including binary classification (COVID-19 vs. Normal) and multiclass classification (COVID-19 vs. Normal vs. Viral Pneumonia). The accuracy of the proposed model in the detection of COVID-19 in the binary-class and multiclass tasks is 99.53% and 95.35%, respectively. Based on these promising results, this method is expected to help doctors diagnose and detect COVID-19. Overall, our ULNet provides a quick method for identifying patients with COVID-19, which is conducive to the control of the COVID-19 pandemic.",0,0
2763,"Incorporating clinical knowledge with constrained classifier chain into a multimodal deep network for melanoma detection. In recent years, vast developments in Computer-Aided Diagnosis (CAD) for skin diseases have generated much interest from clinicians and other eventual end-users of this technology. Introducing clinical domain knowledge to these machine learning strategies can help dispel the black box nature of these tools, strengthening clinician trust. Clinical domain knowledge also provides new information channels which can improve CAD diagnostic performance. In this paper, we propose a novel framework for malignant melanoma (MM) detection by fusing clinical images and dermoscopic images. The proposed method combines a multi-labeled deep feature extractor and clinically constrained classifier chain (CC). This allows the 7-point checklist, a clinician diagnostic algorithm, to be included in the decision level while maintaining the clinical importance of the major and minor criteria in the checklist. Our proposed framework achieved an average accuracy of 81.3% for detecting all criteria and melanoma when testing on a publicly available 7-point checklist dataset. This is the highest reported results, outperforming state-of-the-art methods in the literature by 6.4% or more. Analyses also show that the proposed system surpasses the single modality system of using either clinical images or dermoscopic images alone and the systems without adopting the approach of multi-label and clinically constrained classifier chain. Our carefully designed system demonstrates a substantial improvement over melanoma detection. By keeping the familiar major and minor criteria of the 7-point checklist and their corresponding weights, the proposed system may be more accepted by physicians as a human-interpretable CAD tool for automated melanoma detection.",0,0
2765,"Focus U-Net: A novel dual attention-gated CNN for polyp segmentation during colonoscopy. Colonoscopy remains the gold-standard screening for colorectal cancer. However, significant miss rates for polyps have been reported, particularly when there are multiple small adenomas. This presents an opportunity to leverage computer-aided systems to support clinicians and reduce the number of polyps missed.",0,0
2766,"FS-UNet: Mass segmentation in mammograms using an encoder-decoder architecture with feature strengthening. Breast mass segmentation in mammograms is still a challenging and clinically valuable task. In this paper, we propose an effective and lightweight segmentation model based on convolutional neural networks to automatically segment breast masses in whole mammograms. Specifically, we first developed feature strengthening modules to enhance relevant information about masses and other tissues and improve the representation power of low-resolution feature layers with high-resolution feature maps. Second, we applied a parallel dilated convolution module to capture the features of different scales of masses and fully extract information about the edges and internal texture of the masses. Third, a mutual information loss function was employed to optimise the accuracy of the prediction results by maximising the mutual information between the prediction results and the ground truth. Finally, the proposed model was evaluated on both available INbreast and CBIS-DDSM datasets, and the experimental results indicated that our method achieved excellent segmentation performance in terms of dice coefficient, intersection over union, and sensitivity metrics.",0,0
2767,"Feed-forward LPQNet based Automatic Alzheimer's Disease Detection Model. Alzheimer's disease (AD) is one of the most commonly seen brain ailments worldwide. Therefore, many researches have been presented about AD detection and cure. In addition, machine learning models have also been proposed to detect AD promptly.",0,0
2769,"Skin lesion image retrieval using transfer learning-based approach for query-driven distance recommendation. Content-Based Dermatological Lesion Retrieval (CBDLR) systems retrieve similar skin lesion images, with a pathology-confirmed diagnosis, for a given query image of a skin lesion. By producing an intuitive support to both inexperienced and experienced dermatologists, the early diagnosis through CBDLR screening can significantly enhance the patients' survival, while reducing the treatment cost. To deal with this issue, a CBDLR system is proposed in this study. This system integrates a similarity measure recommender which allows a dynamic selection of the adequate distance metric for each query image. The main contributions of this work reside in (i) the adoption of deep-learned features according to their performances for the classification of skin lesions into seven classes; and (ii) the automatic generation of ground truth that was investigated within the framework of transfer learning in order to recommend the most appropriate distance for any new query image. The proposed CBDLR system has been exhaustively evaluated using the challenging ISIC2018 and ISIC2019 datasets, and the obtained results show that the proposed system can provide a useful aided-decision while offering superior performances. Indeed, it outperforms similar CBDLR systems that adopt standard distances by at least 9% in terms of mAP@K.",0,0
2771,"Machine learning models of ischemia/hemorrhage in moyamoya disease and analysis of its risk factors. This study aimed to determine the risk factors of ischemic/hemorrhagic stroke in patients suffering moyamoya disease (MMD), as well as to compare the effects of six analysis methods.",0,0
2772,"Multiplexed analysis of small extracellular vesicle-derived mRNAs by droplet digital PCR and machine learning improves breast cancer diagnosis. Breast cancer has become the leading cause of global cancer incidence and a serious threat to women's health. Accurate diagnosis and early treatment are of great importance to prognosis. Although clinically used diagnostic approaches can be used for cancer screening, accurate diagnosis of breast cancer is still a critical unmet need. Here, we report a 4-plex droplet digital PCR technology for simultaneous detection of four small extracellular vesicle (sEV)-derived mRNAs (PGR, ESR1, ERBB2 and GAPDH) in combination with machine learning (ML) algorithms to improve breast cancer diagnosis. We evaluate the diagnsotic results with and without the assistance of the ML models. The results indicate that ML-assisted analysis exhibits higher diagnostic performance even using a single marker for breast cancer diagnosis, and demonstrate improved diagnostic performance under the best combination of biomarkers and suitable ML diagnostic model. Therefore, multiple sEV-derived mRNAs analysis coupled with ML not only provides the best combination of markers for breast cancer diagnosis, but also significantly improves the diagnostic efficiency of breast cancer.",1,1
2778,"Automated Collateral Flow Assessment in Patients with Acute Ischemic Stroke Using Computed Tomography with Artificial Intelligence Algorithms. Collateral circulation is associated with improved functional outcome in patients with large vessel occlusion acute ischemic stroke (AIS) who undergo reperfusion therapy. Assessment of collateral flow can be time consuming, subjective, and difficult because of complex neurovasculature. This study assessed the ability of multiple artificial intelligence algorithms in determining collateral flow of patients with AIS.",0,0
2779,"Prediction of behavioral improvement through resting-state EEG and clinical severity in a randomized controlled trial testing bumetanide in autism spectrum disorder. Mechanism-based treatments such as bumetanide are being repurposed for autism spectrum disorder (ASD). We recently reported beneficial effects on repetitive behavioral symptoms that might be related to regulating excitation-inhibition (E/I) balance in the brain. Here, we tested the neurophysiological effects of bumetanide and the relation to clinical outcome variability, and investigated the potential for machine-learning based predictions of meaningful clinical improvement.",0,0
2780,"Glomerular Disease Classification and Lesion Identification by Machine Learning. Classification of glomerular diseases and identification of glomerular lesions require careful morphological examination by experienced nephropathologists, which is labor-intensive, time-consuming, and prone to interobserver variability. In this regard, recent advance in machine learning-based image analysis is promising.",0,0
2782,"MRI-based delta-radiomics predicts pathologic complete response in high-grade soft-tissue sarcoma patients treated with neoadjuvant therapy. In high-grade soft-tissue sarcomas (STS) the standard of care encompasses multimodal therapy regimens. While there is a growing body of evidence for prognostic pretreatment radiomic models, we hypothesized that temporal changes in radiomic features following neoadjuvant treatment (""delta-radiomics"") may be able to predict the pathological complete response (pCR).",0,0
2785,Validation of a Post-Transplant Lymphoproliferative Disorder Risk Prediction Score and Derivation of a New Prediction Score Using a National Bone Marrow Transplant Registry Database. We externally validated Fujimoto's post-transplant lymphoproliferative disorder (PTLD) scoring system for risk prediction by using the Taiwan Blood and Marrow Transplant Registry Database (TBMTRD) and aimed to create a superior scoring system using machine learning methods.,0,0
2787,"Deep generative models for automated muscle segmentation in computed tomography scanning. Accurate gluteus medius (GMd) volume evaluation may aid in the analysis of muscular atrophy states and help gain an improved understanding of patient recovery via rehabilitation. However, the segmentation of muscle regions in GMd images for cubic muscle volume assessment is time-consuming and labor-intensive. This study automated GMd-region segmentation from the computed tomography (CT) images of patients diagnosed with hip osteoarthritis using deep learning and evaluated the segmentation accuracy. To this end, 5250 augmented pairs of training data were obtained from five participants, and a conditional generative adversarial network was used to identify the relationships between the image pairs. Using the preserved test datasets, the results of automatic segmentation with the trained deep learning model were compared to those of manual segmentation in terms of the dice similarity coefficient (DSC), volume similarity (VS), and shape similarity (MS). As observed, the average DSC values for automatic and manual segmentations were 0.748 and 0.812, respectively, with a significant difference (p < 0.0001); the average VS values were 0.247 and 0.203, respectively, with no significant difference (p = 0.069); and the average MS values were 1.394 and 1.156, respectively, with no significant difference (p = 0.308). The GMd volumes obtained by automatic and manual segmentation were 246.2 cm3 and 282.9 cm3, respectively. The noninferiority of the DSC obtained by automatic segmentation was verified against that obtained by manual segmentation. Accordingly, the proposed GAN-based automatic GMd-segmentation technique is confirmed to be noninferior to manual segmentation. Therefore, the findings of this research confirm that the proposed method not only reduces time and effort but also facilitates accurate assessment of the cubic muscle volume.",1,0
2793,"Recognition of Dementia Biomarkers With Deep Finer-DBN. The treatment of neurodegenerative diseases is expensive, and long-term treatment makes families bear a heavy burden. Accumulating evidence suggests that the high conversion rate can possibly be reduced if clinical interventions are applied at the early stage of brain diseases. Thus, a variety of deep learning methods are utilized to recognize the early stages of neurodegenerative diseases for clinical intervention and treatment. However, most existing methods have ignored the issue of sample imbalance, which often makes it difficult to train an effective model due to lack of a large number of negative samples. To address this problem, we propose a two-stage method, which is used to learn the compression and recover rules of normal subjects so that potential negative samples can be detected. The experimental results show that the proposed method can not only obtain a superb recognition result, but also give an explanation that conforms to the physiological mechanism. Most importantly, the deep learning model does not need to be retrained for each type of disease, which can be widely applied to the diagnosis of various brain diseases. Furthermore, this research could have great potential in understanding regional dysfunction of various brain diseases.",0,0
2796,"Visualizing Multimodal Deep Learning for Lesion Prediction. A U-Net is a type of convolutional neural network that has been shown to output impressive results in medical imaging segmentation tasks. Still, neural networks in general form a black box that is hard to interpret, especially by noncomputer scientists. This work provides a visual system that allows users to examine U-Nets that were trained to predict brain lesions caused by stroke using multimodal imaging. We provide several visualization views that allow users to load trained U-Nets, run them on different patient data, and examine the results while visually following the computation of the U-Net. With these visualizations, we can provide useful information for our medical collaborators showing how the training database can be improved and which features are best learned by the neural network.",0,0
2802,"Deep Learning: a Promising Method for Histological Class Prediction of Breast Tumors in Mammography. The objective of the study was to determine if the pathology depicted on a mammogram is either benign or malignant (ductal or non-ductal carcinoma) using deep learning and artificial intelligence techniques. A total of 559 patients underwent breast ultrasound, mammography, and ultrasound-guided breast biopsy. Based on the histopathological results, the patients were divided into three categories: benign, ductal carcinomas, and non-ductal carcinomas. The mammograms in the cranio-caudal view underwent pre-processing and segmentation. Given the large variability of the areola, an algorithm was used to remove it and the adjacent skin. Therefore, patients with breast lesions close to the skin were removed. The remaining breast image was resized on the Y axis to a square image and then resized to 512â€‰Ã—â€‰512 pixels. A variable square of 322,622 pixels was searched inside every image to identify the lesion. Each image was rotated with no information loss. For data augmentation, each image was rotated 360 times and a crop of 227â€‰Ã—â€‰227 pixels was saved, resulting in a total of 201,240 images. The reason why our images were cropped at this size is because the deep learning algorithm transfer learning used from AlexNet network has an input image size of 227â€‰Ã—â€‰227. The mean accuracy was 95.8344%â€‰Â±â€‰6.3720% and mean AUC 0.9910%â€‰Â±â€‰0.0366%, computed on 100 runs of the algorithm. Based on the results, the proposed solution can be used as a non-invasive and highly accurate computer-aided system based on deep learning that can classify breast lesions based on changes identified on mammograms in the cranio-caudal view.",0,0
2803,"Deep feed forward neural network-based screening system for diabetic retinopathy severity classification using the lion optimization algorithm. Diabetic Retinopathy (DR) has become a major cause of blindness in recent years. Diabetic patients should be screened on a regular basis for early detection, which can help them avoid blindness. Furthermore, the number of diabetic patients undergoing these screening procedures is rapidly increasing, resulting in increased workload for ophthalmologists. An efficient screening system that assists ophthalmologists in DR diagnosis saves ophthalmologists a lot of time and effort. To address this issue, an automatic DR detection screening system is required to improve diagnosis speed and detection accuracy. Appropriate treatment can be provided to patients to prevent vision loss if the severity levels of DR are accurately diagnosed in the early stages. A growing number of screening systems for DR diagnosis have been developed in recent years using various deep learning models, and the majority of the published work did not include any optimization algorithm in the neural network for severity classification. The use of an optimization algorithm with the necessary hyper parameter tuning will improve the model's performance. Considering this as motivation, we proposed a five-phase DFNN-LOA model. The DFNN-LOA algorithm presented here has five phases: (i) pre-processing, (ii) optic disc detection, (iii) segmentation, (iv) feature extraction, and (v) severity classification. The proposed model's experimental analysis is carried out on the MESSIDOR dataset. The experimental results show that the proposed DFNN-LOA model has superior characteristics, with maximum accuracy, sensitivity, specificity, F1-score, PPV, and NPV of 97.6%, 98.4%, 90.7%, 96.5%, 94.6%, and 97.1%, respectively.",0,0
2805,"Automated Detection of Acute Myocardial Infarction Using Asynchronous Electrocardiogram Signals-Preview of Implementing Artificial Intelligence With Multichannel Electrocardiographs Obtained From Smartwatches: Retrospective Study. When using a smartwatch to obtain electrocardiogram (ECG) signals from multiple leads, the device has to be placed on different parts of the body sequentially. The ECG signals measured from different leads are asynchronous. Artificial intelligence (AI) models for asynchronous ECG signals have barely been explored.",0,0
2810,"Artificial intelligence strategy integrating morphologic and architectural biomarkers provides robust diagnostic accuracy for disease progression in Chronic Lymphocytic Leukemia. Artificial intelligence-based tools designed to assist in the diagnosis of lymphoid neoplasms remain limited. The development of such tools can add value as a diagnostic aid in the evaluation of tissue samples involved by lymphoma. A common diagnostic question is the determination of chronic lymphocytic leukemia (CLL) progression to accelerated CLL (aCLL) or transformation to diffuse large B-cell lymphoma (Richter transformation; RT) in patients who develop aggressive disease. The morphologic assessment of CLL, aCLL, and RT can be diagnostically challenging. Using established diagnostic criteria of CLL progression/transformation, we designed four artificial intelligence-constructed biomarkers based on cytologic (nuclear size and nuclear intensity) and architectural (cellular density and cell to nearest-neighbor distance) features. We analyzed the predictive value of implementing these biomarkers individually and then in an iterative sequential manner to distinguish tissue samples with CLL, aCLL, and RT. Our model, based on these four morphologic biomarker attributes was able to achieve a robust analytic accuracy. This study suggests that biomarkers identified using artificial intelligence-based tools can be used to assist in the diagnostic evaluation of tissue samples from patients with CLL who develop aggressive disease features. This article is protected by copyright. All rights reserved.",0,0
2817,"Machine Learning Approach for Biopsy-Based Identification of Eosinophilic Esophagitis Reveals Importance of Global features. Eosinophilic esophagitis (EoE) is an allergic inflammatory condition characterized by eosinophil accumulation in the esophageal mucosa. EoE diagnosis includes a manual assessment of eosinophil levels in mucosal biopsies-a time-consuming, laborious task that is difficult to standardize. One of the main challenges in automating this process, like many other biopsy-based diagnostics, is detecting features that are small relative to the size of the biopsy.",0,0
2835,"Is the Combination of ADOS and ADI-R Necessary to Classify ASD? Rethinking the ""Gold Standard"" in Diagnosing ASD. Diagnosing autism spectrum disorder (ASD) requires extensive clinical expertise and training as well as a focus on differential diagnoses. The diagnostic process is particularly complex given symptom overlap with other mental disorders and high rates of co-occurring physical and mental health concerns. The aim of this study was to conduct a data-driven selection of the most relevant diagnostic information collected from a behavior observation and an anamnestic interview in two clinical samples of children/younger adolescents and adolescents/adults with suspected ASD. <i>Via</i> random forests, the present study discovered patterns of symptoms in the diagnostic data of 2310 participants (46% ASD, 54% non-ASD, age range 4-72 years) using data from the combined Autism Diagnostic Observation Schedule (ADOS) and Autism Diagnostic Interview-Revised (ADI-R) and ADOS data alone. Classifiers built on reduced subsets of diagnostic features yield satisfactory sensitivity and specificity values. For adolescents/adults specificity values were lower compared to those for children/younger adolescents. The models including ADOS and ADI-R data were mainly built on ADOS items and in the adolescent/adult sample the classifier including only ADOS items performed even better than the classifier including information from both instruments. Results suggest that reduced subsets of ADOS and ADI-R items may suffice to effectively differentiate ASD from other mental disorders. The imbalance of ADOS and ADI-R items included in the models leads to the assumption that, particularly in adolescents and adults, the ADI-R may play a lesser role than current behavior observations.",0,0
2839,"Utilizing machine learning to improve clinical trial design for acute respiratory distress syndrome. Heterogeneous patient populations, complex pharmacology and low recruitment rates in the Intensive Care Unit (ICU) have led to the failure of many clinical trials. Recently, machine learning (ML) emerged as a new technology to process and identify big data relationships, enabling a new era in clinical trial design. In this study, we designed a ML model for predictively stratifying acute respiratory distress syndrome (ARDS) patients, ultimately reducing the required number of patients by increasing statistical power through cohort homogeneity. From the Philips eICU Research Institute (eRI) database, no less than 51,555 ARDS patients were extracted. We defined three subpopulations by outcome: (1) rapid death, (2) spontaneous recovery, and (3) long-stay patients. A retrospective univariate analysis identified highly predictive variables for each outcome. All 220 variables were used to determine the most accurate and generalizable model to predict long-stay patients. Multiclass gradient boosting was identified as the best-performing ML model. Whereas alterations in pH, bicarbonate or lactate proved to be strong predictors for rapid death in the univariate analysis, only the multivariate ML model was able to reliably differentiate the disease course of the long-stay outcome population (AUC of 0.77). We demonstrate the feasibility of prospective patient stratification using ML algorithms in the by far largest ARDS cohort reported to date. Our algorithm can identify patients with sufficiently long ARDS episodes to allow time for patients to respond to therapy, increasing statistical power. Further, early enrollment alerts may increase recruitment rate.",0,0
2840,"Artificial intelligence sepsis prediction algorithm learns to say ""I don't know"". Sepsis is a leading cause of morbidity and mortality worldwide. Early identification of sepsis is important as it allows timely administration of potentially life-saving resuscitation and antimicrobial therapy. We present COMPOSER (COnformal Multidimensional Prediction Of SEpsis Risk), a deep learning model for the early prediction of sepsis, specifically designed to reduce false alarms by detecting unfamiliar patients/situations arising from erroneous data, missingness, distributional shift and data drifts. COMPOSER flags these unfamiliar cases as indeterminate rather than making spurious predictions. Six patient cohorts (515,720 patients) curated from two healthcare systems in the United States across intensive care units (ICU) and emergency departments (ED) were used to train and externally and temporally validate this model. In a sequential prediction setting, COMPOSER achieved a consistently high area under the curve (AUC) (ICU: 0.925-0.953; ED: 0.938-0.945). Out of over 6 million prediction windows roughly 20% and 8% were identified as indeterminate amongst non-septic and septic patients, respectively. COMPOSER provided early warning within a clinically actionable timeframe (ICU: 12.2 [3.2 22.8] and ED: 2.1 [0.8 4.5] hours prior to first antibiotics order) across all six cohorts, thus allowing for identification and prioritization of patients at high risk for sepsis.",0,0
2841,"Diagnostic classification of coronavirus disease 2019 (COVID-19) and other pneumonias using radiomics features in CT chest images. We propose a classification method using the radiomics features of CT chest images to identify patients with coronavirus disease 2019 (COVID-19) and other pneumonias. The chest CT images of two groups of participants (90 COVID-19 patients who were confirmed as positive by nucleic acid test of RT-PCR and 90 other pneumonias patients) were collected, and the two groups of data were manually drawn to outline the region of interest (ROI) of pneumonias. The radiomics method was used to extract textural features and histogram features of the ROI and obtain a radiomics features vector from each sample. Then, we divided the data into two independent radiomic cohorts for training (70 COVID-19 patients and 70 other pneumonias patients), and validation (20 COVID-19 patients and 20 other pneumonias patients) by using support vector machine (SVM). This model used 20 rounds of tenfold cross-validation for training. Finally, single-shot testing of the final model was performed on the independent validation cohort. In the COVID-19 patients, correlation analysis (multiple comparison correction-Bonferroni correction, Pâ€‰<â€‰0.05/7) was also conducted to determine whether the textural and histogram features were correlated with the laboratory test index of blood, i.e., blood oxygen, white blood cell, lymphocytes, neutrophils, C-reactive protein, hypersensitive C-reactive protein, and erythrocyte sedimentation rate. The final model showed good discrimination on the independent validation cohort, with an accuracy of 89.83%, sensitivity of 94.22%, specificity of 85.44%, and AUC of 0.940. This proved that the radiomics features were highly distinguishable, and this SVM model can effectively identify and diagnose patients with COVID-19 and other pneumonias. The correlation analysis results showed that some textural features were positively correlated with WBC, and NE, and also negatively related to SPO2H and NE. Our results showed that radiomic features can classify COVID-19 patients and other pneumonias patients. The SVM model can achieve an excellent diagnosis of COVID-19.",0,0
2842,"Automated machine learning for endemic active tuberculosis prediction from multiplex serological data. Serological diagnosis of active tuberculosis (TB) is enhanced by detection of multiple antibodies due to variable immune responses among patients. Clinical interpretation of these complex datasets requires development of suitable algorithms, a time consuming and tedious undertaking addressed by the automated machine learning platform MILO (Machine Intelligence Learning Optimizer). MILO seamlessly integrates data processing, feature selection, model training, and model validation to simultaneously generate and evaluate thousands of models. These models were then further tested for generalizability on out-of-sample secondary and tertiary datasets. Out of 31 antigens evaluated, a 23-antigen model was the most robust on both the secondary dataset (TB vs healthy) and the tertiary dataset (TB vs COPD) with sensitivity of 90.5% and respective specificities of 100.0% and 74.6%. MILO represents a user-friendly, end-to-end solution for automated generation and deployment of optimized models, ideal for applications where rapid clinical implementation is critical such as emerging infectious diseases.",0,0
2844,"Assessing outcomes of ear molding therapy by health care providers and convolutional neural network. Ear molding therapy is a nonsurgical technique to correct certain congenital auricular deformities. While the advantages of nonsurgical treatments over otoplasty are well-described, few studies have assessed aesthetic outcomes. In this study, we compared assessments of outcomes of ear molding therapy for 283 ears by experienced healthcare providers and a previously developed deep learning CNN model. 2D photographs of ears were obtained as a standard of care in our onsite photography studio. Physician assistants (PAs) rated the photographs using a 5-point Likert scale ranging from 1(poor) to 5(excellent) and the CNN assessment was categorical, classifying each photo as either ""normal"" or ""deformed"". On average, the PAs classified 75.6% of photographs as good to excellent outcomes (scores 4 and 5). Similarly, the CNN classified 75.3% of the photographs as normal. The inter-rater agreement between the PAs ranged between 72 and 81%, while there was a 69.6% agreement between the machine model and the inter-rater majority agreement between at least two PAs (i.e., when at least two PAs gave a simultaneous scoreâ€‰<â€‰4 orâ€‰â‰¥â€‰4). This study shows that noninvasive ear molding therapy has excellent outcomes in general. In addition, it indicates that with further training and validation, machine learning techniques, like CNN, have the capability to accurately mimic provider assessment while removing the subjectivity of human evaluation making it a robust tool for ear deformity identification and outcome evaluation.",1,1
2848,"Automatic detection and monitoring of abnormal skull shape in children with deformational plagiocephaly using deep learning. Craniofacial anomaly including deformational plagiocephaly as a result of deformities in head and facial bones evolution is a serious health problem in newbies. The impact of such condition on the affected infants is profound from both medical and social viewpoint. Indeed, timely diagnosing through different medical examinations like anthropometric measurements of the skull or even Computer Tomography (CT) image modality followed by a periodical screening and monitoring plays a vital role in treatment phase. In this paper, a classification model for detecting and monitoring deformational plagiocephaly in affected infants is presented. The presented model is based on a deep learning network architecture. The given model achieves high accuracy of 99.01% with other classification parameters. The input to the model are the images captured by commonly used smartphone cameras which waives the requirement to sophisticated medical imaging modalities. The method is deployed into a mobile application which enables the parents/caregivers and non-clinical experts to monitor and report the treatment progress at home.",0,0
2852,"Artificial Intelligence-Based 3D Angiography for Visualization of Complex Cerebrovascular Pathologies. By means of artificial intelligence, 3D angiography is a novel postprocessing method for 3D imaging of cerebral vessels. Because 3D angiography does not require a mask run like the current standard 3D-DSA, it potentially offers a considerable reduction of the patient radiation dose. Our aim was an assessment of the diagnostic value of 3D angiography for visualization of cerebrovascular pathologies.",0,0
2862,"A Comprehensive Evaluation and Benchmarking of Convolutional Neural Networks for Melanoma Diagnosis. Melanoma is the most invasive skin cancer with the highest risk of death. While it is a serious skin cancer, it is highly curable if detected early. Melanoma diagnosis is difficult, even for experienced dermatologists, due to the wide range of morphologies in skin lesions. Given the rapid development of deep learning algorithms for melanoma diagnosis, it is crucial to validate and benchmark these models, which is the main challenge of this work. This research presents a new benchmarking and selection approach based on the multi-criteria analysis method (MCDM), which integrates entropy and the preference ranking organization method for enrichment of evaluations (PROMETHEE) methods. The experimental study is carried out in four phases. Firstly, 19 convolution neural networks (CNNs) are trained and evaluated on a public dataset of 991 dermoscopic images. Secondly, to obtain the decision matrix, 10 criteria, including accuracy, classification error, precision, sensitivity, specificity, F1-score, false-positive rate, false-negative rate, Matthews correlation coefficient (MCC), and the number of parameters are established. Third, entropy and PROMETHEE methods are integrated to determine the weights of criteria and rank the models. Fourth, the proposed benchmarking framework is validated using the VIKOR method. The obtained results reveal that the ResNet101 model is selected as the optimal diagnosis model for melanoma in our case study data. Thus, the presented benchmarking framework is proven to be useful at exposing the optimal melanoma diagnosis model targeting to ease the selection process of the proper convolutional neural network architecture.",0,0
2863,"Tumor Nonimmune-Microenvironment-Related Gene Expression Signature Predicts Brain Metastasis in Lung Adenocarcinoma Patients after Surgery: A Machine Learning Approach Using Gene Expression Profiling. Using a machine learning approach with a gene expression profile, we discovered a tumor nonimmune-microenvironment-related gene expression signature, including extracellular matrix (ECM) remodeling, epithelial-mesenchymal transition (EMT), and angiogenesis, that could predict brain metastasis (BM) after the surgical resection of 64 lung adenocarcinomas (LUAD). Gene expression profiling identified a tumor nonimmune-microenvironment-related 17-gene expression signature that significantly correlated with BM. Of the 17 genes, 11 were ECM-remodeling-related genes. The 17-gene expression signature showed high BM predictive power in four machine learning classifiers (areas under the receiver operating characteristic curve = 0.845 for naÃ¯ve Bayes, 0.849 for support vector machine, 0.858 for random forest, and 0.839 for neural network). Subgroup analysis revealed that the BM predictive power of the 17-gene signature was higher in the early-stage LUAD than in the late-stage LUAD. Pathway enrichment analysis showed that the upregulated differentially expressed genes were mainly enriched in the ECM-receptor interaction pathway. The immunohistochemical expression of the top three genes of the 17-gene expression signature yielded similar results to NanoString tests. The tumor nonimmune-microenvironment-related gene expression signatures found in this study are important biological markers that can predict BM and provide patient-specific treatment options.",0,0
2865,"Automated PD-L1 Scoring Using Artificial Intelligence in Head and Neck Squamous Cell Carcinoma. Immune checkpoint inhibitors (ICI) represent a new therapeutic approach in recurrent and metastatic head and neck squamous cell carcinoma (HNSCC). The patient selection for the PD-1/PD-L1 inhibitor therapy is based on the degree of PD-L1 expression in immunohistochemistry reflected by manually determined PD-L1 scores. However, manual scoring shows variability between different investigators and is influenced by cognitive and visual traps and could therefore negatively influence treatment decisions. Automated PD-L1 scoring could facilitate reliable and reproducible results. Our novel approach uses three neural networks sequentially applied for fully automated PD-L1 scoring of all three established PD-L1 scores: tumor proportion score (TPS), combined positive score (CPS) and tumor-infiltrating immune cell score (ICS). Our approach was validated using WSIs of HNSCC cases and compared with manual PD-L1 scoring by human investigators. The inter-rater correlation (ICC) between human and machine was very similar to the human-human correlation. The ICC was slightly higher between human-machine compared to human-human for the CPS and ICS, but a slightly lower for the TPS. Our study provides deeper insights into automated PD-L1 scoring by neural networks and its limitations. This may serve as a basis to improve ICI patient selection in the future.",1,1
2868,"Histological Grade of Endometrioid Endometrial Cancer and Relapse Risk Can Be Predicted with Machine Learning from Gene Expression Data. The tumor grade of endometrioid endometrial cancer is used as an independent marker of prognosis and a key component in clinical decision making. It is reported that between grades 1 and 3, however, the intermediate grade 2 carries limited information; thus, patients with grade 2 tumors are at risk of both under- and overtreatment. We used RNA-sequencing data from the TCGA project and machine learning to develop a model which can correctly classify grade 1 and grade 3 samples. We used the trained model on grade 2 patients to subdivide them into low-risk and high-risk groups. With iterative retraining, we selected the most relevant 12 transcripts to build a simplified model without losing accuracy. Both models had a high AUC of 0.93. In both cases, there was a significant difference in the relapse-free survivals of the newly identified grade 2 subgroups. Both models could identify grade 2 patients that have a higher risk of relapse. Our approach overcomes the subjective components of the histological evaluation. The developed method can be automated to perform a prescreening of the samples before a final decision is made by pathologists. Our translational approach based on machine learning methods could allow for better therapeutic planning for grade 2 endometrial cancer patients.",0,0
2870,"Relevant and Non-Redundant Feature Selection for Cancer Classification and Subtype Detection. Biologists seek to identify a small number of significant features that are important, non-redundant, and relevant from diverse omics data. For example, statistical methods such as LIMMA and DEseq distinguish differentially expressed genes between a case and control group from the transcript profile. Researchers also apply various column subset selection algorithms on genomics datasets for a similar purpose. Unfortunately, genes selected by such statistical or machine learning methods are often highly co-regulated, making their performance inconsistent. Here, we introduce a novel feature selection algorithm that selects highly disease-related and non-redundant features from a diverse set of omics datasets. We successfully applied this algorithm to three different biological problems: (a) disease-to-normal sample classification; (b) multiclass classification of different disease samples; and (c) disease subtypes detection. Considering the classification of ROC-AUC, false-positive, and false-negative rates, our algorithm outperformed other gene selection and differential expression (DE) methods for all six types of cancer datasets from TCGA considered here for binary and multiclass classification problems. Moreover, genes picked by our algorithm improved the disease subtyping accuracy for four different cancer types over state-of-the-art methods. Hence, we posit that our proposed feature reduction method can support the community to solve various problems, including the selection of disease-specific biomarkers, precision medicine design, and disease sub-type detection.",0,0
2871,"PTEN and DNA Ploidy Status by Machine Learning in Prostate Cancer. Machine learning (ML) is expected to improve biomarker assessment. Using convolution neural networks, we developed a fully-automated method for assessing PTEN protein status in immunohistochemically-stained slides using a radical prostatectomy (RP) cohort (<i>n</i> = 253). It was validated according to a predefined protocol in an independent RP cohort (<i>n</i> = 259), alone and by measuring its prognostic value in combination with DNA ploidy status determined by ML-based image cytometry. In the primary analysis, automatically assessed dichotomized PTEN status was associated with time to biochemical recurrence (TTBCR) (hazard ratio (HR) = 3.32, 95% CI 2.05 to 5.38). Patients with both non-diploid tumors and PTEN-low had an HR of 4.63 (95% CI 2.50 to 8.57), while patients with one of these characteristics had an HR of 1.94 (95% CI 1.15 to 3.30), compared to patients with diploid tumors and PTEN-high, in univariable analysis of TTBCR in the validation cohort. Automatic PTEN scoring was strongly predictive of the PTEN status assessed by human experts (area under the curve 0.987 (95% CI 0.968 to 0.994)). This suggests that PTEN status can be accurately assessed using ML, and that the combined marker of automatically assessed PTEN and DNA ploidy status may provide an objective supplement to the existing risk stratification factors in prostate cancer.",0,0
2879,"Detection of COVID-19 from Chest X-ray Images Using Deep Convolutional Neural Networks. The COVID-19 global pandemic has wreaked havoc on every aspect of our lives. More specifically, healthcare systems were greatly stretched to their limits and beyond. Advances in artificial intelligence have enabled the implementation of sophisticated applications that can meet clinical accuracy requirements. In this study, customized and pre-trained deep learning models based on convolutional neural networks were used to detect pneumonia caused by COVID-19 respiratory complications. Chest X-ray images from 368 confirmed COVID-19 patients were collected locally. In addition, data from three publicly available datasets were used. The performance was evaluated in four ways. First, the public dataset was used for training and testing. Second, data from the local and public sources were combined and used to train and test the models. Third, the public dataset was used to train the model and the local data were used for testing only. This approach adds greater credibility to the detection models and tests their ability to generalize to new data without overfitting the model to specific samples. Fourth, the combined data were used for training and the local dataset was used for testing. The results show a high detection accuracy of 98.7% with the combined dataset, and most models handled new data with an insignificant drop in accuracy.",0,0
2883,"Schizophrenia Detection Using Machine Learning Approach from Social Media Content. Schizophrenia is a severe mental disorder that ranks among the leading causes of disability worldwide. However, many cases of schizophrenia remain untreated due to failure to diagnose, self-denial, and social stigma. With the advent of social media, individuals suffering from schizophrenia share their mental health problems and seek support and treatment options. Machine learning approaches are increasingly used for detecting schizophrenia from social media posts. This study aims to determine whether machine learning could be effectively used to detect signs of schizophrenia in social media users by analyzing their social media texts. To this end, we collected posts from the social media platform Reddit focusing on schizophrenia, along with non-mental health related posts (fitness, jokes, meditation, parenting, relationships, and teaching) for the control group. We extracted linguistic features and content topics from the posts. Using supervised machine learning, we classified posts belonging to schizophrenia and interpreted important features to identify linguistic markers of schizophrenia. We applied unsupervised clustering to the features to uncover a coherent semantic representation of words in schizophrenia. We identified significant differences in linguistic features and topics including increased use of third person plural pronouns and negative emotion words and symptom-related topics. We distinguished schizophrenic from control posts with an accuracy of 96%. Finally, we found that coherent semantic groups of words were the key to detecting schizophrenia. Our findings suggest that machine learning approaches could help us understand the linguistic characteristics of schizophrenia and identify schizophrenia or otherwise at-risk individuals using social media texts.",0,0
2893,"Age and Gender Recognition Using a Convolutional Neural Network with a Specially Designed Multi-Attention Module through Speech Spectrograms. Speech signals are being used as a primary input source in human-computer interaction (HCI) to develop several applications, such as automatic speech recognition (ASR), speech emotion recognition (SER), gender, and age recognition. Classifying speakers according to their age and gender is a challenging task in speech processing owing to the disability of the current methods of extracting salient high-level speech features and classification models. To address these problems, we introduce a novel end-to-end age and gender recognition convolutional neural network (CNN) with a specially designed multi-attention module (MAM) from speech signals. Our proposed model uses MAM to extract spatial and temporal salient features from the input data effectively. The MAM mechanism uses a rectangular shape filter as a kernel in convolution layers and comprises two separate time and frequency attention mechanisms. The time attention branch learns to detect temporal cues, whereas the frequency attention module extracts the most relevant features to the target by focusing on the spatial frequency features. The combination of the two extracted spatial and temporal features complements one another and provide high performance in terms of age and gender classification. The proposed age and gender classification system was tested using the Common Voice and locally developed Korean speech recognition datasets. Our suggested model achieved 96%, 73%, and 76% accuracy scores for gender, age, and age-gender classification, respectively, using the Common Voice dataset. The Korean speech recognition dataset results were 97%, 97%, and 90% for gender, age, and age-gender recognition, respectively. The prediction performance of our proposed model, which was obtained in the experiments, demonstrated the superiority and robustness of the tasks regarding age, gender, and age-gender recognition from speech signals.",0,0
2896,"Human-Machine Interface: Multiclass Classification by Machine Learning on 1D EOG Signals for the Control of an Omnidirectional Robot. People with severe disabilities require assistance to perform their routine activities; a Human-Machine Interface (HMI) will allow them to activate devices that respond according to their needs. In this work, an HMI based on electrooculography (EOG) is presented, the instrumentation is placed on portable glasses that have the task of acquiring both horizontal and vertical EOG signals. The registration of each eye movement is identified by a class and categorized using the one hot encoding technique to test precision and sensitivity of different machine learning classification algorithms capable of identifying new data from the eye registration; the algorithm allows to discriminate blinks in order not to disturb the acquisition of the eyeball position commands. The implementation of the classifier consists of the control of a three-wheeled omnidirectional robot to validate the response of the interface. This work proposes the classification of signals in real time and the customization of the interface, minimizing the user's learning curve. Preliminary results showed that it is possible to generate trajectories to control an omnidirectional robot to implement in the future assistance system to control position through gaze orientation.",0,0
2897,"Recognition of COVID-19 from CT Scans Using Two-Stage Deep-Learning-Based Approach: CNR-IEMN. Since the appearance of the COVID-19 pandemic (at the end of 2019, Wuhan, China), the recognition of COVID-19 with medical imaging has become an active research topic for the machine learning and computer vision community. This paper is based on the results obtained from the 2021 COVID-19 SPGC challenge, which aims to classify volumetric CT scans into normal, COVID-19, or community-acquired pneumonia (Cap) classes. To this end, we proposed a deep-learning-based approach (CNR-IEMN) that consists of two main stages. In the first stage, we trained four deep learning architectures with a multi-tasks strategy for slice-level classification. In the second stage, we used the previously trained models with an XG-boost classifier to classify the whole CT scan into normal, COVID-19, or Cap classes. Our approach achieved a good result on the validation set, with an overall accuracy of 87.75% and 96.36%, 52.63%, and 95.83% sensitivities for COVID-19, Cap, and normal, respectively. On the other hand, our approach achieved fifth place on the three test datasets of SPGC in the COVID-19 challenge, where our approach achieved the best result for COVID-19 sensitivity. In addition, our approach achieved second place on two of the three testing sets.",0,0
2898,"The Use of Synthetic IMU Signals in the Training of Deep Learning Models Significantly Improves the Accuracy of Joint Kinematic Predictions. Gait analysis based on inertial sensors has become an effective method of quantifying movement mechanics, such as joint kinematics and kinetics. Machine learning techniques are used to reliably predict joint mechanics directly from streams of IMU signals for various activities. These data-driven models require comprehensive and representative training datasets to be generalizable across the movement variability seen in the population at large. Bottlenecks in model development frequently occur due to the lack of sufficient training data and the significant time and resources necessary to acquire these datasets. Reliable methods to generate synthetic biomechanical training data could streamline model development and potentially improve model performance. In this study, we developed a methodology to generate synthetic kinematics and the associated predicted IMU signals using open source musculoskeletal modeling software. These synthetic data were used to train neural networks to predict three degree-of-freedom joint rotations at the hip and knee during gait either in lieu of or along with previously measured experimental gait data. The accuracy of the models' kinematic predictions was assessed using experimentally measured IMU signals and gait kinematics. Models trained using the synthetic data out-performed models using only the experimental data in five of the six rotational degrees of freedom at the hip and knee. On average, root mean square errors in joint angle predictions were improved by 38% at the hip (synthetic data RMSE: 2.3Â°, measured data RMSE: 4.5Â°) and 11% at the knee (synthetic data RMSE: 2.9Â°, measured data RMSE: 3.3Â°), when models trained solely on synthetic data were compared to measured data. When models were trained on both measured and synthetic data, root mean square errors were reduced by 54% at the hip (measured + synthetic data RMSE: 1.9Â°) and 45% at the knee (measured + synthetic data RMSE: 1.7Â°), compared to measured data alone. These findings enable future model development for different activities of clinical significance without the burden of generating large quantities of gait lab data for model training, streamlining model development, and ultimately improving model performance.",0,0
2903,"An LSTM Network for Apnea and Hypopnea Episodes Detection in Respiratory Signals. One of the most common sleep disorders is sleep apnea. It manifests itself by episodes of shallow breathing or pauses in breathing during the night. Diagnosis of this disease involves polysomnography examination, which is expensive. Alternatively, diagnostic doctors can be supported with recordings from the in-home polygraphy sensors. Furthermore, numerous attempts for providing an automated apnea episodes annotation algorithm have been made. Most of them, however, do not distinguish between apnea and hypopnea episodes. In this work, a novel solution for epoch-based annotation problem is presented. Utilizing an architecture based on the long short-term memory (LSTM) networks, the proposed model provides locations of sleep disordered breathing episodes and identifies them as either apnea or hypopnea. To achieve this, special pre- and postprocessing steps have been designed. The obtained labels can be then used for calculation of the respiratory event index (REI), which serves as a disease severity indicator. The input for the model consists of the oronasal airflow along with the thoracic and abdominal respiratory effort signals. Performance of the proposed architecture was verified on the SHHS-1 and PhysioNet Sleep databases, obtaining mean REI classification error of 9.24/10.52 with standard deviation of 11.61/7.92 (SHHS-1/PhysioNet). Normal breathing, hypopnea and apnea differentiation accuracy is assessed on both databases, resulting in the correctly classified samples percentage of 86.42%/84.35%, 49.30%/58.28% and 68.20%/69.50% for normal breathing, hypopnea and apnea classes, respectively. Overall accuracies are 80.66%/82.04%. Additionally, the effect of wake periods is investigated. The results show that the proposed model can be successfully used for both episode classification and REI estimation tasks.",0,0
2909,"Deep Learning-Based High-Frequency Ultrasound Skin Image Classification with Multicriteria Model Evaluation. This study presents the first application of convolutional neural networks to high-frequency ultrasound skin image classification. This type of imaging opens up new opportunities in dermatology, showing inflammatory diseases such as atopic dermatitis, psoriasis, or skin lesions. We collected a database of 631 images with healthy skin and different skin pathologies to train and assess all stages of the methodology. The proposed framework starts with the segmentation of the epidermal layer using a DeepLab v3+ model with a pre-trained Xception backbone. We employ transfer learning to train the segmentation model for two purposes: to extract the region of interest for classification and to prepare the skin layer map for classification confidence estimation. For classification, we train five models in different input data modes and data augmentation setups. We also introduce a classification confidence level to evaluate the deep model's reliability. The measure combines our skin layer map with the heatmap produced by the Grad-CAM technique designed to indicate image regions used by the deep model to make a classification decision. Moreover, we propose a multicriteria model evaluation measure to select the optimal model in terms of classification accuracy, confidence, and test dataset size. The experiments described in the paper show that the DenseNet-201 model fed with the extracted region of interest produces the most reliable and accurate results.",0,0
2918,"A CNN Deep Local and Global ASD Classification Approach with Continuous Wavelet Transform Using Task-Based FMRI. Autism spectrum disorder (ASD) is a neurodegenerative disorder characterized by lingual and social disabilities. The autism diagnostic observation schedule is the current gold standard for ASD diagnosis. Developing objective computer aided technologies for ASD diagnosis with the utilization of brain imaging modalities and machine learning is one of main tracks in current studies to understand autism. Task-based fMRI demonstrates the functional activation in the brain by measuring blood oxygen level-dependent (BOLD) variations in response to certain tasks. It is believed to hold discriminant features for autism. A novel computer aided diagnosis (CAD) framework is proposed to classify 50 ASD and 50 typically developed toddlers with the adoption of CNN deep networks. The CAD system includes both local and global diagnosis in a response to speech task. Spatial dimensionality reduction with region of interest selection and clustering has been utilized. In addition, the proposed framework performs discriminant feature extraction with continuous wavelet transform. Local diagnosis on cingulate gyri, superior temporal gyrus, primary auditory cortex and angular gyrus achieves accuracies ranging between 71% and 80% with a four-fold cross validation technique. The fused global diagnosis achieves an accuracy of 86% with 82% sensitivity, 92% specificity. A brain map indicating ASD severity level for each brain area is created, which contributes to personalized diagnosis and treatment plans.",0,0
2920,"Detection of COVID-19 Using Transfer Learning and Grad-CAM Visualization on Indigenously Collected X-ray Dataset. The COVID-19 outbreak began in December 2019 and has dreadfully affected our lives since then. More than three million lives have been engulfed by this newest member of the corona virus family. With the emergence of continuously mutating variants of this virus, it is still indispensable to successfully diagnose the virus at early stages. Although the primary technique for the diagnosis is the PCR test, the non-contact methods utilizing the chest radiographs and CT scans are always preferred. Artificial intelligence, in this regard, plays an essential role in the early and accurate detection of COVID-19 using pulmonary images. In this research, a transfer learning technique with fine tuning was utilized for the detection and classification of COVID-19. Four pre-trained models i.e., VGG16, DenseNet-121, ResNet-50, and MobileNet were used. The aforementioned deep neural networks were trained using the dataset (available on Kaggle) of 7232 (COVID-19 and normal) chest X-ray images. An indigenous dataset of 450 chest X-ray images of Pakistani patients was collected and used for testing and prediction purposes. Various important parameters, e.g., recall, specificity, F1-score, precision, loss graphs, and confusion matrices were calculated to validate the accuracy of the models. The achieved accuracies of VGG16, ResNet-50, DenseNet-121, and MobileNet are 83.27%, 92.48%, 96.49%, and 96.48%, respectively. In order to display feature maps that depict the decomposition process of an input image into various filters, a visualization of the intermediate activations is performed. Finally, the Grad-CAM technique was applied to create class-specific heatmap images in order to highlight the features extracted in the X-ray images. Various optimizers were used for error minimization purposes. DenseNet-121 outperformed the other three models in terms of both accuracy and prediction.",0,0
2930,"Experimental Study on Wound Area Measurement with Mobile Devices. Healthcare treatments might benefit from advances in artificial intelligence and technological equipment such as smartphones and smartwatches. The presence of cameras in these devices with increasingly robust and precise pattern recognition techniques can facilitate the estimation of the wound area and other telemedicine measurements. Currently, telemedicine is vital to the maintenance of the quality of the treatments remotely. This study proposes a method for measuring the wound area with mobile devices. The proposed approach relies on a multi-step process consisting of image capture, conversion to grayscale, blurring, application of a threshold with segmentation, identification of the wound part, dilation and erosion of the detected wound section, identification of accurate data related to the image, and measurement of the wound area. The proposed method was implemented with the OpenCV framework. Thus, it is a solution for healthcare systems by which to investigate and treat people with skin-related diseases. The proof-of-concept was performed with a static dataset of camera images on a desktop computer. After we validated the approach's feasibility, we implemented the method in a mobile application that allows for communication between patients, caregivers, and healthcare professionals.",0,0
2932,"Gait Phase Estimation by Using LSTM in IMU-Based Gait Analysis-Proof of Concept. Gait phase detection in IMU-based gait analysis has some limitations due to walking style variations and physical impairments of individuals. Therefore, available algorithms may not work properly when the gait data is noisy, or the person rarely reaches a steady state of walking. The aim of this work was to employ Artificial Intelligence (AI), specifically a long short-term memory (LSTM) algorithm, to overcome these weaknesses. Three supervised LSTM-based models were designed to estimate the expected gait phases, including foot-off (FO), mid-swing (MidS) and foot-contact (FC). For collecting gait data two tri-axial inertial sensors were located above each ankle. The angular velocity magnitude, rotation matrix magnitude and free acceleration magnitude were captured for data labeling and turning detection and to strengthen the model, respectively. To do so, a train dataset based on a novel movement protocol was acquired. A validation dataset similar to a train dataset was generated as well. Five test datasets from already existing data were also created to independently evaluate the models. After testing the models on validation and test datasets, all three models demonstrated promising performance in estimating desired gait phases. The proposed approach proves the possibility of employing AI-based algorithms to predict labeled gait phases from a time series of gait data.",0,0
2943,"Safe <i>Hb</i> Concentration Measurement during Bladder Irrigation Using Artificial Intelligence. We have developed a sensor for monitoring the hemoglobin (Hb) concentration in the effluent of a continuous bladder irrigation. The Hb concentration measurement is based on light absorption within a fixed measuring distance. The light frequency used is selected so that both arterial and venous Hb are equally detected. The sensor allows the measurement of the Hb concentration up to a maximum value of 3.2 g/dL (equivalent to â‰ˆ20% blood concentration). Since bubble formation in the outflow tract cannot be avoided with current irrigation systems, a neural network is implemented that can robustly detect air bubbles within the measurement section. The network considers both optical and temporal features and is able to effectively safeguard the measurement process. The sensor supports the use of different irrigants (salt and electrolyte-free solutions) as well as measurement through glass shielding. The sensor can be used in a non-invasive way with current irrigation systems. The sensor is positively tested in a clinical study.",0,0
2948,"Automatic Detection of Colorectal Polyps Using Transfer Learning. Colorectal cancer is the second leading cause of cancer death and ranks third worldwide in diagnosed malignant pathologies (1.36 million new cases annually). An increase in the diversity of treatment options as well as a rising population require novel diagnostic tools. Current diagnostics involve critical human thinking, but the decisional process loses accuracy due to the increased number of modulatory factors involved. The proposed computer-aided diagnosis system analyses each colonoscopy and provides predictions that will help the clinician to make the right decisions. Artificial intelligence is included in the system both offline and online image processing tools. Aiming to improve the diagnostic process of colon cancer patients, an application was built that allows the easiest and most intuitive interaction between medical staff and the proposed diagnosis system. The developed tool uses two networks. The first, a convolutional neural network, is capable of classifying eight classes of tissue with a sensitivity of 98.13% and an F1 score of 98.14%, while the second network, based on semantic segmentation, can identify the malignant areas with a Jaccard index of 75.18%. The results could have a direct impact on personalised medicine combining clinical knowledge with the computing power of intelligent algorithms.",0,0
2951,"On the Use of Deep Learning for Imaging-Based COVID-19 Detection Using Chest X-rays. The global COVID-19 pandemic that started in 2019 and created major disruptions around the world demonstrated the imperative need for quick, inexpensive, accessible and reliable diagnostic methods that would allow the detection of infected individuals with minimal resources. Radiography, and more specifically, chest radiography, is a relatively inexpensive medical imaging modality that can potentially offer a solution for the diagnosis of COVID-19 cases. In this work, we examined eleven deep convolutional neural network architectures for the task of classifying chest X-ray images as belonging to healthy individuals, individuals with COVID-19 or individuals with viral pneumonia. All the examined networks are established architectures that have been proven to be efficient in image classification tasks, and we evaluated three different adjustments to modify the architectures for the task at hand by expanding them with additional layers. The proposed approaches were evaluated for all the examined architectures on a dataset with real chest X-ray images, reaching the highest classification accuracy of 98.04% and the highest F1-score of 98.22% for the best-performing setting.",0,0
2959,"Machine Learning-Based Radiomics Signatures for EGFR and KRAS Mutations Prediction in Non-Small-Cell Lung Cancer. Early identification of epidermal growth factor receptor (EGFR) and Kirsten rat sarcoma viral oncogene homolog (KRAS) mutations is crucial for selecting a therapeutic strategy for patients with non-small-cell lung cancer (NSCLC). We proposed a machine learning-based model for feature selection and prediction of EGFR and KRAS mutations in patients with NSCLC by including the least number of the most semantic radiomics features. We included a cohort of 161 patients from 211 patients with NSCLC from The Cancer Imaging Archive (TCIA) and analyzed 161 low-dose computed tomography (LDCT) images for detecting EGFR and KRAS mutations. A total of 851 radiomics features, which were classified into 9 categories, were obtained through manual segmentation and radiomics feature extraction from LDCT. We evaluated our models using a validation set consisting of 18 patients derived from the same TCIA dataset. The results showed that the genetic algorithm plus XGBoost classifier exhibited the most favorable performance, with an accuracy of 0.836 and 0.86 for detecting EGFR and KRAS mutations, respectively. We demonstrated that a noninvasive machine learning-based model including the least number of the most semantic radiomics signatures could robustly predict EGFR and KRAS mutations in patients with NSCLC.",0,0
2961,"Biosignal-Based Digital Biomarkers for Prediction of Ventilator Weaning Success. We evaluated new features from biosignals comprising diverse physiological response information to predict the outcome of weaning from mechanical ventilation (MV). We enrolled 89 patients who were candidates for weaning from MV in the intensive care unit and collected continuous biosignal data: electrocardiogram (ECG), respiratory impedance, photoplethysmogram (PPG), arterial blood pressure, and ventilator parameters during a spontaneous breathing trial (SBT). We compared the collected biosignal data's variability between patients who successfully discontinued MV (<i>n</i> = 67) and patients who did not (<i>n</i> = 22). To evaluate the usefulness of the identified factors for predicting weaning success, we developed a machine learning model and evaluated its performance by bootstrapping. The following markers were different between the weaning success and failure groups: the ratio of standard deviations between the short-term and long-term heart rate variability in a PoincarÃ© plot, sample entropy of ECG and PPG, Î± values of ECG, and respiratory impedance in the detrended fluctuation analysis. The area under the receiver operating characteristic curve of the model was 0.81 (95% confidence interval: 0.70-0.92). This combination of the biosignal data-based markers obtained during SBTs provides a promising tool to assist clinicians in determining the optimal extubation time.",0,0
2962,"Medical Health Records-Based Mild Cognitive Impairment (MCI) Prediction for Effective Dementia Care. Dementia is a cognitive impairment that poses a global threat. Current dementia treatments slow the progression of the disease. The timing of starting such treatment markedly affects the effectiveness of the treatment. Some experts mentioned that the optimal timing for starting the currently available treatment in order to delay progression to dementia is the mild cognitive impairment stage, which is the prior stage of dementia. However, medical records are typically only available at a later stage, i.e., from the early or middle stage of dementia. In order to address this limitation, this study developed a model using national health information data from 5 years prior, to predict dementia development 5 years in the future. The Senior Cohort Database, comprising 550,000 samples, were used for model development. The F-measure of the model predicting dementia development after a 5-year incubation period was 77.38%. Models for a 1- and 3-year incubation period were also developed for comparative analysis of dementia risk factors. The three models had some risk factors in common, but also had unique risk factors, depending on the stage. For the common risk factors, a difference in disease severity was confirmed. These findings indicate that the diagnostic criteria and treatment strategy for dementia should differ depending on the timing. Furthermore, since the results of this study present new dementia risk factors that have not been reported previously, this study may also contribute to identification of new dementia risk factors.",0,0
2965,"Balanced Convolutional Neural Networks for Pneumoconiosis Detection. Pneumoconiosis remains one of the most common and harmful occupational diseases in China, leading to huge economic losses to society with its high prevalence and costly treatment. Diagnosis of pneumoconiosis still strongly depends on the experience of radiologists, which affects rapid detection on large populations. Recent research focuses on computer-aided detection based on machine learning. These have achieved high accuracy, among which artificial neural network (ANN) shows excellent performance. However, due to imbalanced samples and lack of interpretability, wide utilization in clinical practice meets difficulty. To address these problems, we first establish a pneumoconiosis radiograph dataset, including both positive and negative samples. Second, deep convolutional diagnosis approaches are compared in pneumoconiosis detection, and a balanced training is adopted to promote recall. Comprehensive experiments conducted on this dataset demonstrate high accuracy (88.6%). Third, we explain diagnosis results by visualizing suspected opacities on pneumoconiosis radiographs, which could provide solid diagnostic reference for surgeons.",0,0
2970,"A Machine Learning Predictive Model for Post-Ureteroscopy Urosepsis Needing Intensive Care Unit Admission: A Case-Control YAU Endourology Study from Nine European Centres. With the rise in the use of ureteroscopy and laser stone lithotripsy (URSL), a proportionate increase in the risk of post-procedural urosepsis has also been observed. The aims of our paper were to analyse the predictors for severe urosepsis using a machine learning model (ML) in patients that needed intensive care unit (ICU) admission and to make comparisons with a matched cohort.",0,0
2971,"Predicting Duration of Mechanical Ventilation in Acute Respiratory Distress Syndrome Using Supervised Machine Learning. Acute respiratory distress syndrome (ARDS) is an intense inflammatory process of the lungs. Most ARDS patients require mechanical ventilation (MV). Few studies have investigated the prediction of MV duration over time. We aimed at characterizing the best early scenario during the first two days in the intensive care unit (ICU) to predict MV duration after ARDS onset using supervised machine learning (ML) approaches. <b>Methods:</b> For model description, we extracted data from the first 3 ICU days after ARDS diagnosis from patients included in the publicly available MIMIC-III database. Disease progression was tracked along those 3 ICU days to assess lung severity according to Berlin criteria. Three robust supervised ML techniques were implemented using Python 3.7 (Light Gradient Boosting Machine (LightGBM); Random Forest (RF); and eXtreme Gradient Boosting (XGBoost)) for predicting MV duration. For external validation, we used the publicly available multicenter database eICU. <b>Results:</b> A total of 2466 and 5153 patients in MIMIC-III and eICU databases, respectively, received MV for >48 h. Median MV duration of extracted patients was 6.5 days (IQR 4.4-9.8 days) in MIMIC-III and 5.0 days (IQR 3.0-9.0 days) in eICU. LightGBM was the best model in predicting MV duration after ARDS onset in MIMIC-III with a root mean square error (RMSE) of 6.10-6.41 days, and it was externally validated in eICU with RMSE of 5.87-6.08 days. The best early prediction model was obtained with data captured in the 2nd day. <b>Conclusions:</b> Supervised ML can make early and accurate predictions of MV duration in ARDS after onset over time across ICUs. Supervised ML models might have important implications for optimizing ICU resource utilization and high acute cost reduction of MV.",0,0
2982,"Developing and validating a prediction model for lymphedema detection in breast cancer survivors. Early detection and intervention of lymphedema is essential for improving the quality of life of breast cancer survivors. Previous studies have shown that patients have symptoms such as arm tightness and arm heaviness before experiencing obvious limb swelling. Thus, this study aimed to develop a symptom-warning model for the early detection of breast cancer-related lymphedema.",0,0
2984,"Accurate diagnosis of sepsis using a neural network: Pilot study using routine clinical variables. Sepsis is a severe infection that increases mortality risk and is one if the main causes of death in intensive care units. Accurate detection is key to successful interventions, but diagnosis of sepsis is complicated because the initial signs and symptoms are not specific. Biomarkers that have been proposed have low specificity and sensitivity, are expensive, and not available in every hospital. In this study, we propose the use of artificial intelligence in the form of a neural network to diagnose sepsis using only common laboratory tests and vital signs that are routine and widely available.",0,0
2985,"Combined Transfer Learning and Test-Time Augmentation Improves Convolutional Neural Network-Based Semantic Segmentation of Prostate Cancer from Multi-Parametric MR Images. Multiparametric MRI (mp-MRI) is a widely used tool for diagnosing and staging prostate cancer. The purpose of this study was to evaluate whether transfer learning, unsupervised pre-training and test-time augmentation significantly improved the performance of a convolutional neural network (CNN) for pixel-by-pixel prediction of cancer vs. non-cancer using mp-MRI datasets.",0,0
2990,"Choquet Integral and Coalition Game-based Ensemble of Deep Learning Models for COVID-19 Screening from Chest X-ray Images. Under the present circumstances, when we are still under the threat of different strains of coronavirus, and since the most widely used method for COVID-19 detection, RT-PCR is a tedious and time-consuming manual procedure with poor precision, the application of Artificial Intelligence (AI) and Computer-Aided Diagnosis (CAD) is inevitable. In this work, we have analyzed Chest X-ray (CXR) images for the detection of the coronavirus. The primary agenda of this proposed research study is to leverage the classification performance of the deep learning models using ensemble learning. Many papers have proposed different ensemble learning techniques in this field, some methods using aggregation functions like Weighted Arithmetic Mean (WAM) among others. However, none of these methods take into consideration the decisions that subsets of the classifiers take. In this paper, we have applied Choquet integral for ensemble and propose a novel method for the evaluation of fuzzy measures using Coalition Game Theory, Information Theory, and Lambda fuzzy approximation. Three different sets of Fuzzy Measures are calculated using three different weighting schemes along with information theory and coalition game theory. Using these three sets of fuzzy measures three Choquet Integrals are calculated and their decisions are finally combined.We have created a database by combining several image repositories developed recently. Impressive results on the newly developed dataset and the challenging COVIDx dataset support the efficacy and robustness of the proposed method. To the best of our knowledge, our experimental results outperform many recently proposed methods. Source code available at https://github.com/subhankar01/Covid-Chestxray-lambda-fuzzy.",0,0
2995,"Artificial intelligence and colon capsule endoscopy: development of an automated diagnostic system of protruding lesions in colon capsule endoscopy. Colon capsule endoscopy (CCE) is a minimally invasive alternative for patients unwilling to undergo conventional colonoscopy, or for whom the latter exam is contraindicated. This is particularly important in the setting of colorectal cancer screening. Nevertheless, these exams produce large numbers of images, and reading them is a monotonous and time-consuming task, with the risk of overlooking important lesions. The development of automated tools based on artificial intelligence (AI) technology may improve some of the drawbacks of this diagnostic instrument.",0,0
3002,"Differentiation of Intrahepatic Cholangiocarcinoma and Hepatic Lymphoma Based on Radiomics and Machine Learning in Contrast-Enhanced Computer Tomography. <b>Purpose:</b> This study aimed to explore the ability of texture parameters combining with machine learning methods in distinguishing intrahepatic cholangiocarcinoma (ICCA) and hepatic lymphoma (HL). <b>Method:</b> A total of 28 patients with HL and 101 patients with ICCA were included. A total of 45 texture features were extracted by the software LifeX from contrast-enhanced computer tomography (CECT) images and 38 of them were eligible. A total of 5 feature selection methods and 9 feature classification methods were used to build the best diagnostic models, combining with the 10-fold cross-validation to assess the accuracy of these models. The discriminative ability of each model was evaluated by receiver operating characteristic analysis. <b>Result:</b> A total of 45 predictive models were built by the cross combination of each selection and classification method to differentiate ICCA from HL. According to the results of test group, most of the models performed well with a large area under the curve (AUC) (>0.85) and high accuracy (>0.85). Random Forest (RF)_Linear Discriminant Analysis (LDA) (AUCâ€‰â€‰=â€‰â€‰0.997, accuracyâ€‰â€‰=â€‰â€‰0.969) was the best model among all the 45 models. <b>Conclusion:</b> Combining texture parameters from CECT with multiple machine learning models can differentiate ICCA and HL effectively, and RF_LDA performed the best in this process.",0,0
3005,"Characterizing the hyper- and hypometabolism in temporal lobe epilepsy using multivariate machine learning. Mesial temporal lobe epilepsy (MTLE) is the most common type of focal epilepsy, presenting both structural and metabolic abnormalities in the ipsilateral mesial temporal lobe. While it has been demonstrated that the metabolic abnormalities in MTLE actually extend beyond the epileptogenic zone, how such multidimensional information is associated with the diagnosis of MTLE remains to be tested. Here, we explore the whole-brain metabolic patterns in 23 patients with MTLE and 24 healthy controls using [<sup>18</sup> F]fluorodeoxyglucose PET imaging. Based on a multivariate machine learning approach, we demonstrate that the brain metabolic patterns can discriminate patients with MTLE from controls with a superior accuracy (>95%). Importantly, voxels showing the most extreme contributing weights to the classification (i.e., the most important regional predictors) distribute across both hemispheres, involving both ipsilateral negative weights over the anterior part of lateral and medial temporal lobe, posterior insula, and lateral orbital frontal gyrus, and contralateral positive weights over the anterior frontal lobe, temporal lobe, and lingual gyrus. Through region-of-interest analyses, we verify that in patients with MTLE, the negatively weighted regions are hypometabolic, and the positively weighted regions are hypermetabolic, compared to controls. Interestingly, despite that both hypo- and hypermetabolism have mutually contributed to our model, they may reflect different pathological and/or compensative responses. For instance, patients with earlier age at epilepsy onset present greater hypometabolism in the ipsilateral inferior temporal gyrus, while we find no evidence of such association with hypermetabolism. In summary, quantitative models utilizing multidimensional brain metabolic information may provide additional assistance to presurgical workups in TLE.",0,0
3014,"Identification of a novel six-gene signature with potential prognostic and therapeutic value in cervical cancer. Cervical cancer has high mortality, high recurrence and poor prognosis. Although prognostic biomarkers such as clinicopathological features have been proposed, their accuracy and precision are far from satisfactory. Therefore, novel biomarkers are urgently needed for disease surveillance, prognosis prediction and treatment selection.",0,0
3025,"Right Ventricular Function Predicts Adverse Clinical Outcomes in Patients With Chronic Thromboembolic Pulmonary Hypertension: A Three-Dimensional Echocardiographic Study. <b>Background:</b> Right ventricular (RV) function plays a vital role in the prognosis of patients with chronic thromboembolic pulmonary hypertension (CTEPH). We used new machine learning (ML)-based fully automated software to quantify RV function using three-dimensional echocardiography (3DE) to predict adverse clinical outcomes in CTEPH patients. <b>Methods:</b> A total of 151 consecutive CTEPH patients were registered in this prospective study between April 2015 and July 2019. New ML-based methods were used for data management, and quantitative analysis of RV volume and ejection fraction (RVEF) was performed offline. RV structural and functional parameters were recorded using 3DE. CTEPH was diagnosed using right heart catheterization, and 62 patients underwent cardiac magnetic resonance to assess right heart function. Adverse clinical outcomes were defined as PH-related hospitalization with hemoptysis or increased RV failure, including conditions requiring balloon pulmonary angioplasty or pulmonary endarterectomy, as well as death. <b>Results:</b> The median follow-up time was 19.7 months (interquartile range, 0.5-54 months). Among the 151 CTEPH patients, 72 experienced adverse clinical outcomes. Multivariate Cox proportional-hazard analysis showed that ML-based 3DE analysis of RVEF was a predictor of adverse clinical outcomes (hazard ratio, 1.576; 95% confidence interval (CI), 1.046~2.372; <i>P</i> = 0.030). <b>Conclusions:</b> The new ML-based 3DE algorithm is a promising technique for rapid 3D quantification of RV function in CTEPH patients.",0,0
3027,"Integrative Analysis of Gene Expression Data by RNA Sequencing for Differential Diagnosis of Acute Leukemia: Potential Application of Machine Learning. <i>BCR-ABL1</i>-positive acute leukemia can be classified into three disease categories: B-lymphoblastic leukemia (B-ALL), acute myeloid leukemia (AML), and mixed-phenotype acute leukemia (MPAL). We conducted an integrative analysis of RNA sequencing (RNA-seq) data obtained from 12 <i>BCR-ABL1</i>-positive B-ALL, AML, and MPAL samples to evaluate its diagnostic utility. RNA-seq facilitated the identification of all p190 <i>BCR-ABL1</i> with accurate splicing sites and a new gene fusion involving <i>MAP2K2</i>. Most of the clinically significant mutations were also identified including single-nucleotide variations, insertions, and deletions. In addition, RNA-seq yielded differential gene expression profile according to the disease category. Therefore, we selected 368 genes differentially expressed between AML and B-ALL and developed two differential diagnosis models based on the gene expression data using 1) scoring algorithm and 2) machine learning. Both models showed an excellent diagnostic accuracy not only for our 12 <i>BCR-ABL1</i>-positive cases but also for 427 public gene expression datasets from acute leukemias regardless of specific genetic aberration. This is the first trial to develop models of differential diagnosis using RNA-seq, especially to evaluate the potential role of machine learning in identifying the disease category of acute leukemia. The integrative analysis of gene expression data by RNA-seq facilitates the accurate differential diagnosis of acute leukemia with successful detection of significant gene fusion and/or mutations, which warrants further investigation.",0,0
3030,"An Improved CNN Architecture to Diagnose Skin Cancer in Dermoscopic Images Based on Wildebeest Herd Optimization Algorithm. Skin cancer is one of the most common types of cancers that is sometimes difficult for doctors and experts to diagnose. The noninvasive dermatoscopic method is a popular method for observing and diagnosing skin cancer. Because this method is based on ocular inference, the skin cancer diagnosis by the dermatologists is difficult, especially in the early stages of the disease. Artificial intelligence is a proper complementary tool that can be used alongside the experts to increase the accuracy of the diagnosis. In the present study, a new computer-aided method has been introduced for the diagnosis of the skin cancer. The method is designed based on combination of deep learning and a newly introduced metaheuristic algorithm, namely, Wildebeest Herd Optimization (WHO) Algorithm. The method uses an Inception convolutional neural network for the initial features' extraction. Afterward, the WHO algorithm has been employed for selecting the useful features to decrease the analysis time complexity. The method is then performed to an ISIC-2008 skin cancer dataset. Final results of the feature selection based on the proposed WHO are compared with three other algorithms, and the results have indicated good results for the system. Finally, the total diagnosis system has been compared with five other methods to indicate its effectiveness against the studied methods. Final results showed that the proposed method has the best results than the comparative methods.",0,0
3034,"Seizure Forecasting Using a Novel Sub-Scalp Ultra-Long Term EEG Monitoring System. Accurate identification of seizure activity, both clinical and subclinical, has important implications in the management of epilepsy. Accurate recognition of seizure activity is essential for diagnostic, management and forecasting purposes, but patient-reported seizures have been shown to be unreliable. Earlier work has revealed accurate capture of electrographic seizures and forecasting is possible with an implantable intracranial device, but less invasive electroencephalography (EEG) recording systems would be optimal. Here, we present preliminary results of seizure detection and forecasting with a minimally invasive sub-scalp device that continuously records EEG. Five participants with refractory epilepsy who experience at least two clinically identifiable seizures monthly have been implanted with sub-scalp devices (Minder<sup>Â®</sup>), providing two channels of data from both hemispheres of the brain. Data is continuously captured via a behind-the-ear system, which also powers the device, and transferred wirelessly to a mobile phone, from where it is accessible remotely via cloud storage. EEG recordings from the sub-scalp device were compared to data recorded from a conventional system during a 1-week ambulatory video-EEG monitoring session. Suspect epileptiform activity (EA) was detected using machine learning algorithms and reviewed by trained neurophysiologists. Seizure forecasting was demonstrated retrospectively by utilizing cycles in EA and previous seizure times. The procedures and devices were well-tolerated and no significant complications have been reported. Seizures were accurately identified on the sub-scalp system, as visually confirmed by periods of concurrent conventional scalp EEG recordings. The data acquired also allowed seizure forecasting to be successfully undertaken. The area under the receiver operating characteristic curve (AUC score) achieved (0.88), which is comparable to the best score in recent, state-of-the-art forecasting work using intracranial EEG.",0,0
3035,"Development and Validation of a Prediction Model for Elevated Arterial Stiffness in Chinese Patients With Diabetes Using Machine Learning. Arterial stiffness assessed by pulse wave velocity is a major risk factor for cardiovascular diseases. The incidence of cardiovascular events remains high in diabetics. However, a clinical prediction model for elevated arterial stiffness using machine learning to identify subjects consequently at higher risk remains to be developed.",0,0
3038,"Establishment and validation of a computer-assisted colonic polyp localization system based on deep learning. Artificial intelligence in colonoscopy is an emerging field, and its application may help colonoscopists improve inspection quality and reduce the rate of missed polyps and adenomas. Several deep learning-based computer-assisted detection (CADe) techniques were established from small single-center datasets, and unrepresentative learning materials might confine their application and generalization in wide practice. Although CADes have been reported to identify polyps in colonoscopic images and videos in real time, their diagnostic performance deserves to be further validated in clinical practice.",0,0
3041,"CheXaid: deep learning assistance for physician diagnosis of tuberculosis using chest x-rays in patients with HIV. Tuberculosis (TB) is the leading cause of preventable death in HIV-positive patients, and yet often remains undiagnosed and untreated. Chest x-ray is often used to assist in diagnosis, yet this presents additional challenges due to atypical radiographic presentation and radiologist shortages in regions where co-infection is most common. We developed a deep learning algorithm to diagnose TB using clinical information and chest x-ray images from 677 HIV-positive patients with suspected TB from two hospitals in South Africa. We then sought to determine whether the algorithm could assist clinicians in the diagnosis of TB in HIV-positive patients as a web-based diagnostic assistant. Use of the algorithm resulted in a modest but statistically significant improvement in clinician accuracy (pâ€‰=â€‰0.002), increasing the mean clinician accuracy from 0.60 (95% CI 0.57, 0.63) without assistance to 0.65 (95% CI 0.60, 0.70) with assistance. However, the accuracy of assisted clinicians was significantly lower (pâ€‰<â€‰0.001) than that of the stand-alone algorithm, which had an accuracy of 0.79 (95% CI 0.77, 0.82) on the same unseen test cases. These results suggest that deep learning assistance may improve clinician accuracy in TB diagnosis using chest x-rays, which would be valuable in settings with a high burden of HIV/TB co-infection. Moreover, the high accuracy of the stand-alone algorithm suggests a potential value particularly in settings with a scarcity of radiological expertise.",1,1
3042,"Multi-task deep learning for cardiac rhythm detection in wearable devices. Wearable devices enable theoretically continuous, longitudinal monitoring of physiological measurements such as step count, energy expenditure, and heart rate. Although the classification of abnormal cardiac rhythms such as atrial fibrillation from wearable devices has great potential, commercial algorithms remain proprietary and tend to focus on heart rate variability derived from green spectrum LED sensors placed on the wrist, where noise remains an unsolved problem. Here we develop DeepBeat, a multitask deep learning method to jointly assess signal quality and arrhythmia event detection in wearable photoplethysmography devices for real-time detection of atrial fibrillation. The model is trained on approximately one million simulated unlabeled physiological signals and fine-tuned on a curated dataset of over 500â€‰K labeled signals from over 100 individuals from 3 different wearable devices. We demonstrate that, in comparison with a single-task model, our architecture using unsupervised transfer learning through convolutional denoising autoencoders dramatically improves the performance of atrial fibrillation detection from a F1 score of 0.54 to 0.96. We also include in our evaluation a prospectively derived replication cohort of ambulatory participants where the algorithm performed with high sensitivity (0.98), specificity (0.99), and F1 score (0.93). We show that two-stage training can help address the unbalanced data problem common to biomedical applications, where large-scale well-annotated datasets are hard to generate due to the expense of manual annotation, data acquisition, and participant privacy.",0,0
3043,"Deep learning detects acute myeloid leukemia and predicts NPM1 mutation status from bone marrow smears. The evaluation of bone marrow morphology by experienced hematopathologists is essential in the diagnosis of acute myeloid leukemia (AML); however, it suffers from a lack of standardization and inter-observer variability. Deep learning (DL) can process medical image data and provides data-driven class predictions. Here, we apply a multi-step DL approach to automatically segment cells from bone marrow images, distinguish between AML samples and healthy controls with an area under the receiver operating characteristic (AUROC) of 0.9699, and predict the mutation status of Nucleophosmin 1 (NPM1)-one of the most common mutations in AML-with an AUROC of 0.92 using only image data from bone marrow smears. Utilizing occlusion sensitivity maps, we observed so far unreported morphologic cell features such as a pattern of condensed chromatin and perinuclear lightening zones in myeloblasts of NPM1-mutated AML and prominent nucleoli in wild-type NPM1 AML enabling the DL model to provide accurate class predictions.",0,0
3049,Machine-learning-based COVID-19 mortality prediction model and identification of patients at low and high risk of dying. The coronavirus disease 2019 (COVID-19) pandemic caused by the SARS-Cov2 virus has become the greatest health and controversial issue for worldwide nations. It is associated with different clinical manifestations and a high mortality rate. Predicting mortality and identifying outcome predictors are crucial for COVID patients who are critically ill. Multivariate and machine learning methods may be used for developing prediction models and reduce the complexity of clinical phenotypes.,0,0
3052,Machine learning-based CT radiomics model distinguishes COVID-19 from non-COVID-19 pneumonia. To develop a machine learning-based CT radiomics model is critical for the accurate diagnosis of the rapid spreading coronavirus disease 2019 (COVID-19).,0,0
3055,Open Source Software for Automatic Subregional Assessment of Knee Cartilage Degradation Using Quantitative T2 Relaxometry and Deep Learning. We evaluated a fully automated femoral cartilage segmentation model for measuring T2 relaxation values and longitudinal changes using multi-echo spin-echo (MESE) magnetic resonance imaging (MRI). We open sourced this model and developed a web app available at https://kl.stanford.edu into which users can drag and drop images to segment them automatically.,0,0
3057,"Deep Learning-Based Automated Thrombolysis in Cerebral Infarction Scoring: A Timely Proof-of-Principle Study. Mechanical thrombectomy is an established procedure for treatment of acute ischemic stroke. Mechanical thrombectomy success is commonly assessed by the Thrombolysis in Cerebral Infarction (TICI) score, assigned by visual inspection of X-ray digital subtraction angiography data. However, expert-based TICI scoring is highly observer-dependent. This represents a major obstacle for mechanical thrombectomy outcome comparison in, for instance, multicentric clinical studies. Focusing on occlusions of the M1 segment of the middle cerebral artery, the present study aimed to develop a deep learning (DL) solution to automated and, therefore, objective TICI scoring, to evaluate the agreement of DL- and expert-based scoring, and to compare corresponding numbers to published scoring variability of clinical experts.",1,1
3058,"Machine Learning for Detection of Correct Peripherally Inserted Central Catheter Tip Position from Radiology Reports in Infants. â€ƒIn critically ill infants, the position of a peripherally inserted central catheter (PICC) must be confirmed frequently, as the tip may move from its original position and run the risk of hyperosmolar vascular damage or extravasation into surrounding spaces. Automated detection of PICC tip position holds great promise for alerting bedside clinicians to noncentral PICCs.",0,0
3063,"Fusion of 3D lung CT and serum biomarkers for diagnosis of multiple pathological types on pulmonary nodules. Current researches on pulmonary nodules mainly focused on the binary-classification of benign and malignant pulmonary nodules. However, in clinical applications, it is not enough to judge whether pulmonary nodules are benign or malignant. In this paper, we proposed a fusion model based on the Lung Information Dataset Containing 3D CT Images and Serum Biomarkers (LIDCCISB) we constructed to accurately diagnose the types of pulmonary nodules in squamous cell carcinoma, adenocarcinoma, inflammation and other benign diseases.",0,0
3064,"LwF-ECG: Learning-without-forgetting approach for electrocardiogram heartbeat classification based on memory with task selector. Most existing Electrocardiogram (ECG) classification methods assume that all arrhythmia classes are known during the training phase. In this paper, the problem of learning several successive tasks is addressed, where, in each new task, there are new arrhythmia classes to learn. Unfortunately, in machine learning it is known that when a model is retrained onto a new task, the machine tends to forget the old task. This is known in machine learning, as 'the catastrophic forgetting phenomenon'. To this end, a learn-without-forgetting (LwF) approach to solve this problem is proposed. This novel deep LwF method for ECG heartbeat classification is the first work of its kind in the field. This proposed LwF approach consists of a deep learning architecture that includes the following important aspects: feature extraction module, classification layers for each learned task, memory module to store one prototype for each task, and a task selection module able to identify the most suitable task for each input sample. The feature extraction module constitutes another contribution of this work. It starts with a set of deep layers that convert an ECG heartbeat signal into an image, then the pre-trained DenseNet169 CNN takes the obtained image and extracts rich and powerful features that are effective inputs for the classifications layers of the model. Whenever a new task is to be learned, the network expands with a new classification layer having a Softmax activation function. The newly added layer is responsible for learning the classes of the new task. When the network is trained for the new task, the shared layers, as well as the output layers of the old tasks, are also fine-tuned using pseudo labels. This helps in retaining knowledge of old tasks. Finally, the task selector stores feature prototypes for each task, and using a distance matching network, is trained to select which task is more suitable to classify a new test sample. The whole network uses end-to-end learning to optimize one loss functions, which is a weighted combination of the loss functions of the different network modules. The proposed model was tested on three common ECG datasets, namely the MIT-BIH, INCART, and SVDB datasets. The results obtained demonstrate the success of the proposed method in learning, without forgetting, successive ECG heartbeat classification tasks.",0,0
3067,"Optimizing Hepatitis B Virus Screening in the United States Using a Simple Demographics-Based Model. Chronic hepatitis B (CHB) affects over 290 million people globally and only 10% have been diagnosed, presenting a severe gap that must be addressed. We developed logistic regression and machine learning (random forest) models to accurately identify patients with HBV, using only easily-obtained demographic data from a population-based data set.",0,0
3069,"Multivariate random forest prediction of poverty and malnutrition prevalence. Advances in remote sensing and machine learning enable increasingly accurate, inexpensive, and timely estimation of poverty and malnutrition indicators to guide development and humanitarian agencies' programming. However, state of the art models often rely on proprietary data and/or deep or transfer learning methods whose underlying mechanics may be challenging to interpret. We demonstrate how interpretable random forest models can produce estimates of a set of (potentially correlated) malnutrition and poverty prevalence measures using free, open access, regularly updated, georeferenced data. We demonstrate two use cases: contemporaneous prediction, which might be used for poverty mapping, geographic targeting, or monitoring and evaluation tasks, and a sequential nowcasting task that can inform early warning systems. Applied to data from 11 low and lower-middle income countries, we find predictive accuracy broadly comparable for both tasks to prior studies that use proprietary data and/or deep or transfer learning methods.",0,0
3074,"Facial Anatomical Landmark Detection using Regularized Transfer Learning with Application to Fetal Alcohol Syndrome Recognition. Fetal alcohol syndrome (FAS) caused by prenatal alcohol exposure can result in a series of cranio-facial anomalies, and behavioral and neurocognitive problems. Current diagnosis of FAS is typically done by identifying a set of facial characteristics, which are often obtained by manual examination. Anatomical landmark detection, which provides rich geometric information, is important to detect the presence of FAS associated facial anomalies. This imaging application is characterized by large variations in data appearance and limited availability of labeled data. Current deep learning-based heatmap regression methods designed for facial landmark detection in natural images assume availability of large datasets and are therefore not wellsuited for this application. To address this restriction, we develop a new regularized transfer learning approach that exploits the knowledge of a network learned on large facial recognition datasets. In contrast to standard transfer learning which focuses on adjusting the pre-trained weights, the proposed learning approach regularizes the model behavior. It explicitly reuses the rich visual semantics of a domain-similar source model on the target task data as an additional supervisory signal for regularizing landmark detection optimization. Specifically, we develop four regularization constraints for the proposed transfer learning, including constraining the feature outputs from classification and intermediate layers, as well as matching activation attention maps in both spatial and channel levels. Experimental evaluation on a collected clinical imaging dataset demonstrate that the proposed approach can effectively improve model generalizability under limited training samples, and is advantageous to other approaches in the literature.",0,0
3075,"Explainable Diabetic Retinopathy Detection and Retinal Image Generation. Though deep learning has shown successful performance in classifying the label and severity stage of certain diseases, most of them give few explanations on how to make predictions. Inspired by Koch's Postulates, the foundation in evidence-based medicine (EBM) to identify the pathogen, we propose to exploit the interpretability of deep learning application in medical diagnosis. By isolating neuron activation patterns from a diabetic retinopathy (DR) detector and visualizing them, we can determine the symptoms that the DR detector identifies as evidence to make prediction. To be specific, we first define novel pathological descriptors using activated neurons of the DR detector to encode both spatial and appearance information of lesions. Then, to visualize the symptom encoded in the descriptor, we propose Patho-GAN, a new network to synthesize medically plausible retinal images. By manipulating these descriptors, we could even arbitrarily control the position, quantity, and categories of generated lesions. We also show that our synthesized images carry the symptoms directly related to diabetic retinopathy diagnosis. Our generated images are both qualitatively and quantitatively superior to the ones by previous methods. Besides, compared to existing methods that take hours to generate an image, our second level speed endows the potential to be an effective solution for data augmentation.",0,0
3082,"Development of a fertility risk calculator to predict individualized chance of ovarian failure after chemotherapy. To develop an innovative machine learning (ML) model that predicts personalized risk of primary ovarian insufficiency (POI) after chemotherapy for reproductive-aged women. Currently, individualized prediction of a patient's risk of POI is challenging.",0,0
3100,"Deep learning trained on hematoxylin and eosin tumor region of Interest predicts HER2 status and trastuzumab treatment response in HER2+ breast cancer. The current standard of care for many patients with HER2-positive breast cancer is neoadjuvant chemotherapy in combination with anti-HER2 agents, based on HER2 amplification as detected by in situ hybridization (ISH) or protein immunohistochemistry (IHC). However, hematoxylin & eosin (H&E) tumor stains are more commonly available, and accurate prediction of HER2 status and anti-HER2 treatment response from H&E would reduce costs and increase the speed of treatment selection. Computational algorithms for H&E have been effective in predicting a variety of cancer features and clinical outcomes, including moderate success in predicting HER2 status. In this work, we present a novel convolutional neural network (CNN) approach able to predict HER2 status with increased accuracy over prior methods. We trained a CNN classifier on 188 H&E whole slide images (WSIs) manually annotated for tumor Regions of interest (ROIs) by our pathology team. Our classifier achieved an area under the curve (AUC) of 0.90 in cross-validation of slide-level HER2 status and 0.81 on an independent TCGA test set. Within slides, we observed strong agreement between pathologist annotated ROIs and blinded computational predictions of tumor regions / HER2 status. Moreover, we trained our classifier on pre-treatment samples from 187 HER2+ patients that subsequently received trastuzumab therapy. Our classifier achieved an AUC of 0.80 in a five-fold cross validation. Our work provides an H&E-based algorithm that can predict HER2 status and trastuzumab response in breast cancer at an accuracy that may benefit clinical evaluations.",0,0
3101,"Machine learning approaches to predict gestational age in normal and complicated pregnancies via urinary metabolomics analysis. The elucidation of dynamic metabolomic changes during gestation is particularly important for the development of methods to evaluate pregnancy status or achieve earlier detection of pregnancy-related complications. Some studies have constructed models to evaluate pregnancy status and predict gestational age using omics data from blood biospecimens; however, less invasive methods are desired. Here we propose a model to predict gestational age, using urinary metabolite information. In our prospective cohort study, we collected 2741 urine samples from 187 healthy pregnant women, 23 patients with hypertensive disorders of pregnancy, and 14 patients with spontaneous preterm birth. Using gas chromatography-tandem mass spectrometry, we identified 184 urinary metabolites that showed dynamic systematic changes in healthy pregnant women according to gestational age. A model to predict gestational age during normal pregnancy progression was constructed; the correlation coefficient between actual and predicted weeks of gestation was 0.86. The predicted gestational ages of cases with hypertensive disorders of pregnancy exhibited significant progression, compared with actual gestational ages. This is the first study to predict gestational age in normal and complicated pregnancies by using urinary metabolite information. Minimally invasive urinary metabolomics might facilitate changes in the prediction of gestational age in various clinical settings.",0,0
3105,"Prediction of arrhythmia susceptibility through mathematical modeling and machine learning. At present, the QT interval on the electrocardiographic (ECG) waveform is the most common metric for assessing an individual's susceptibility to ventricular arrhythmias, with a long QT, or, at the cellular level, a long action potential duration (APD) considered high risk. However, the limitations of this simple approach have long been recognized. Here, we sought to improve prediction of arrhythmia susceptibility by combining mechanistic mathematical modeling with machine learning (ML). Simulations with a model of the ventricular myocyte were performed to develop a large heterogenous population of cardiomyocytes (<i>n</i> = 10,586), and we tested each variant's ability to withstand three arrhythmogenic triggers: 1) block of the rapid delayed rectifier potassium current (I<sub>Kr</sub> Block), 2) augmentation of the L-type calcium current (I<sub>CaL</sub> Increase), and 3) injection of inward current (Current Injection). Eight ML algorithms were trained to predict, based on simulated AP features in preperturbed cells, whether each cell would develop arrhythmic dynamics in response to each trigger. We found that APD can accurately predict how cells respond to the simple Current Injection trigger but cannot effectively predict the response to I<sub>Kr</sub> Block or I<sub>CaL</sub> Increase. ML predictive performance could be improved by incorporating additional AP features and simulations of additional experimental protocols. Importantly, we discovered that the most relevant features and experimental protocols were trigger specific, which shed light on the mechanisms that promoted arrhythmia formation in response to the triggers. Overall, our quantitative approach provides a means to understand and predict differences between individuals in arrhythmia susceptibility.",0,0
3106,"Accurate Machine-Learning-Based classification of Leukemia from Blood Smear Images. Conventional identification of blood disorders based on visual inspection of blood smears through microscope is time consuming, error-prone and is limited by hematologist's physical acuity. Therefore, an automated optical image processing system is required to support the clinical decision-making.",0,0
3111,"Point-of-care detection and differentiation of anticoagulant therapy - development of thromboelastometry-guided decision-making support algorithms. DOAC detection is challenging in emergency situations. Here, we demonstrated recently, that modified thromboelastometric tests can reliably detect and differentiate dabigatran and rivaroxaban. However, whether all DOACs can be detected and differentiated to other coagulopathies is unclear. Therefore, we now tested the hypothesis that a decision tree-based thromboelastometry algorithm enables detection and differentiation of all direct Xa-inhibitors (DXaIs), the direct thrombin inhibitor (DTI) dabigatran, as well as vitamin K antagonists (VKA) and dilutional coagulopathy (DIL) with high accuracy.",0,0
3112,"Machine learning guided postnatal gestational age assessment using new-born screening metabolomic data in South Asia and sub-Saharan Africa. Babies born early and/or small for gestational age in Low and Middle-income countries (LMICs) contribute substantially to global neonatal and infant mortality. Tracking this metric is critical at a population level for informed policy, advocacy, resources allocation and program evaluation and at an individual level for targeted care. Early prenatal ultrasound examination is not available in these settings, gestational age (GA) is estimated using new-born assessment, last menstrual period (LMP) recalls and birth weight, which are unreliable. Algorithms in developed settings, using metabolic screen data, provided GA estimates within 1-2â€‰weeks of ultrasonography-based GA. We sought to leverage machine learning algorithms to improve accuracy and applicability of this approach to LMICs settings.",0,0
3113,"MRI-based brain tumor segmentation using FPGA-accelerated neural network. Brain tumor segmentation is a challenging problem in medical image processing and analysis. It is a very time-consuming and error-prone task. In order to reduce the burden on physicians and improve the segmentation accuracy, the computer-aided detection (CAD) systems need to be developed. Due to the powerful feature learning ability of the deep learning technology, many deep learning-based methods have been applied to the brain tumor segmentation CAD systems and achieved satisfactory accuracy. However, deep learning neural networks have high computational complexity, and the brain tumor segmentation process consumes significant time. Therefore, in order to achieve the high segmentation accuracy of brain tumors and obtain the segmentation results efficiently, it is very demanding to speed up the segmentation process of brain tumors.",0,0
3120,"AIforCOVID: Predicting the clinical outcomes in patients with COVID-19 applying AI to chest-X-rays. An Italian multicentre study. Recent epidemiological data report that worldwide more than 53 million people have been infected by SARS-CoV-2, resulting in 1.3 million deaths. The disease has been spreading very rapidly and few months after the identification of the first infected, shortage of hospital resources quickly became a problem. In this work we investigate whether artificial intelligence working with chest X-ray (CXR) scans and clinical data can be used as a possible tool for the early identification of patients at risk of severe outcome, like intensive care or death. Indeed, further to induce lower radiation dose than computed tomography (CT), CXR is a simpler and faster radiological technique, being also more widespread. In this respect, we present three approaches that use features extracted from CXR images, either handcrafted or automatically learnt by convolutional neuronal networks, which are then integrated with the clinical data. As a further contribution, this work introduces a repository that collects data from 820 patients enrolled in six Italian hospitals in spring 2020 during the first COVID-19 emergency. The dataset includes CXR images, several clinical attributes and clinical outcomes. Exhaustive evaluation shows promising performance both in 10-fold and leave-one-centre-out cross-validation, suggesting that clinical data and images have the potential to provide useful information for the management of patients and hospital resources.",0,0
3121,"An end-to-end 3D convolutional neural network for decoding attentive mental state. The detection of attentive mental state plays an essential role in the neurofeedback process and the treatment of Attention Deficit and Hyperactivity Disorder (ADHD). However, the performance of the detection methods is still not satisfactory. One of the challenges is to find a proper representation for the electroencephalogram (EEG) data, which could preserve the temporal information and maintain the spatial topological characteristics. Inspired by the deep learning (DL) methods in the research of brain-computer interface (BCI) field, a 3D representation of EEG signal was introduced into attention detection task, and a 3D convolutional neural network model with cascade and parallel convolution operations was proposed. The model utilized three cascade blocks, each consisting of two parallel 3D convolution branches, to simultaneously extract the multi-scale features. Evaluated on a public dataset containing twenty-six subjects, the proposed model achieved better performance compared with the baseline methods under the intra-subject, inter-subject and subject-adaptive classification scenarios. This study demonstrated the promising potential of the 3D CNN model for detecting attentive mental state.",0,0
3122,"Multi-model CNN fusion for sperm morphology analysis. Infertility is a common disorder affecting 20% of couples worldwide. Furthermore, 40% of all cases are related to male infertility. The first step in the determination of male infertility is semen analysis. The morphology, concentration, and motility of sperm are important characteristics evaluated by experts during semen analysis. Most laboratories perform the tests manually. However, manual semen analysis requires much time and is subject to observer variability during the evaluation. Therefore, computer-assisted systems are required. Additionally, to obtain more objective results, a large amount of data is necessary. Deep learning networks, which have become popular in recent years, are used for processing and analysing such quantities of data. Convolutional neural networks (CNNs) are a class of deep learning algorithm that are used extensively for processing and analysing images. In this study, six different CNN models were created for completely automating the morphological classification of sperm images. Additionally, two decision-level fusion techniques namely hard-voting and soft-voting were applied over these CNNs. To evaluate the performance of the proposed approach, three publicly available sperm morphology data sets were used in the experimental tests. For an objective analysis, a cross-validation technique was applied by dividing the data sets into five sub-sets. In addition, various data augmentation scales and mini-batch analysis were employed to obtain the highest classification accuracies. Finally, in the classification, accuracies 90.73%, 85.18% and 71.91% were obtained for the SMIDS, HuSHeM and SCIAN-Morpho data sets, respectively, using the soft-voting based fusion approach over the six created CNN models. The results suggested that the proposed approach could automatically classify as well as achieve high success in three different data sets.",0,0
3128,"A deep learning model for diagnosing gastric mucosal lesions using endoscopic images: development, validation, and method comparison. Endoscopic differential diagnoses of gastric mucosal lesions (benign gastric ulcer, early gastric cancer [EGC], and advanced gastric cancer) remain challenging. We aimed to develop and validate convolutional neural network-based artificial intelligence (AI) models: lesion detection (AI-LD), differential diagnosis (AI-DDx), and invasion-depth (AI-ID, pT1a vs. pT1b among EGC) models.",0,0
3129,"Classification of ERP signal from amnestic mild cognitive impairment with type 2 diabetes mellitus using single-scale multi-input convolution neural network. The application of deep learning models to electroencephalogram (EEG) signal classification has recently become a popular research topic. Several deep learning models have been proposed to classify EEG signals in patients with various neurological diseases. However, no effective deep learning model for event-related potential (ERP) signal classification is yet available for amnestic mild cognitive impairment (aMCI) with type 2 diabetes mellitus (T2DM).",0,0
3134,"Pneumonia detection in chest X-ray images using an ensemble of deep learning models. Pneumonia is a respiratory infection caused by bacteria or viruses; it affects many individuals, especially in developing and underdeveloped nations, where high levels of pollution, unhygienic living conditions, and overcrowding are relatively common, together with inadequate medical infrastructure. Pneumonia causes pleural effusion, a condition in which fluids fill the lung, causing respiratory difficulty. Early diagnosis of pneumonia is crucial to ensure curative treatment and increase survival rates. Chest X-ray imaging is the most frequently used method for diagnosing pneumonia. However, the examination of chest X-rays is a challenging task and is prone to subjective variability. In this study, we developed a computer-aided diagnosis system for automatic pneumonia detection using chest X-ray images. We employed deep transfer learning to handle the scarcity of available data and designed an ensemble of three convolutional neural network models: GoogLeNet, ResNet-18, and DenseNet-121. A weighted average ensemble technique was adopted, wherein the weights assigned to the base learners were determined using a novel approach. The scores of four standard evaluation metrics, precision, recall, f1-score, and the area under the curve, are fused to form the weight vector, which in studies in the literature was frequently set experimentally, a method that is prone to error. The proposed approach was evaluated on two publicly available pneumonia X-ray datasets, provided by Kermany et al. and the Radiological Society of North America (RSNA), respectively, using a five-fold cross-validation scheme. The proposed method achieved accuracy rates of 98.81% and 86.85% and sensitivity rates of 98.80% and 87.02% on the Kermany and RSNA datasets, respectively. The results were superior to those of state-of-the-art methods and our method performed better than the widely used ensemble techniques. Statistical analyses on the datasets using McNemar's and ANOVA tests showed the robustness of the approach. The codes for the proposed work are available at https://github.com/Rohit-Kundu/Ensemble-Pneumonia-Detection.",0,0
3135,"Mobile microscopy and telemedicine platform assisted by deep learning for the quantification of Trichuris trichiura infection. Soil-transmitted helminths (STH) are the most prevalent pathogens among the group of neglected tropical diseases (NTDs). The Kato-Katz technique is the diagnosis method recommended by the World Health Organization (WHO) although it often presents a decreased sensitivity in low transmission settings and it is labour intensive. Visual reading of Kato-Katz preparations requires the samples to be analyzed in a short period of time since its preparation. Digitizing the samples could provide a solution which allows to store the samples in a digital database and perform remote analysis. Artificial intelligence (AI) methods based on digitized samples can support diagnosis by performing an objective and automatic quantification of disease infection. In this work, we propose an end-to-end pipeline for microscopy image digitization and automatic analysis of digitized images of STH. Our solution includes (a) a digitization system based on a mobile app that digitizes microscope samples using a 3D printed microscope adapter, (b) a telemedicine platform for remote analysis and labelling, and (c) novel deep learning algorithms for automatic assessment and quantification of parasitological infections by STH. The deep learning algorithm has been trained and tested on 51 slides of stool samples containing 949 Trichuris spp. eggs from 6 different subjects. The algorithm evaluation was performed using a cross-validation strategy, obtaining a mean precision of 98.44% and a mean recall of 80.94%. The results also proved the potential of generalization capability of the method at identifying different types of helminth eggs. Additionally, the AI-assisted quantification of STH based on digitized samples has been compared to the one performed using conventional microscopy, showing a good agreement between measurements. In conclusion, this work has presented a comprehensive pipeline using smartphone-assisted microscopy. It is integrated with a telemedicine platform for automatic image analysis and quantification of STH infection using AI models.",0,0
3136,"Derivation and external validation of a risk score for predicting HIV-associated tuberculosis to support case finding and preventive therapy scale-up: A cohort study. Among people living with HIV (PLHIV), more flexible and sensitive tuberculosis (TB) screening tools capable of detecting both symptomatic and subclinical active TB are needed to (1) reduce morbidity and mortality from undiagnosed TB; (2) facilitate scale-up of tuberculosis preventive therapy (TPT) while reducing inappropriate prescription of TPT to PLHIV with subclinical active TB; and (3) allow for differentiated HIV-TB care.",0,0
3137,"International Validation of the SORG Machine-learning Algorithm for Predicting the Survival of Patients with Extremity Metastases Undergoing Surgical Treatment. The Skeletal Oncology Research Group machine-learning algorithms (SORG-MLAs) estimate 90-day and 1-year survival in patients with long-bone metastases undergoing surgical treatment and have demonstrated good discriminatory ability on internal validation. However, the performance of a prediction model could potentially vary by race or region, and the SORG-MLA must be externally validated in an Asian cohort. Furthermore, the authors of the original developmental study did not consider the Eastern Cooperative Oncology Group (ECOG) performance status, a survival prognosticator repeatedly validated in other studies, in their algorithms because of missing data.",0,0
3141,"Cognitive Function Assessment and Prediction for Subjective Cognitive Decline and Mild Cognitive Impairment. Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative dementia. Recent studies found that subjective cognitive decline (SCD) may be the early clinical precursor that precedes mild cognitive impairment (MCI) for AD. SCD subjects with normal cognition may already have some medial temporal lobe atrophy. Although brain changes by AD have been widely studied in the literature, it is still challenging to investigate the anatomical subtle changes in SCD. This paper proposes a machine learning framework by combination of sparse coding and random forest (RF) to identify the informative imaging biomarkers for assessment and prediction of cognitive functions and their changes in individuals with MCI, SCD and normal control (NC) using magnetic resonance imaging (MRI). First, we compute the volumes from both the regions of interest from whole brain and the subregions of hippocampus and amygdala as the features of structural MRIs. Then, sparse coding is applied to identify the relevant features. Finally, the proximity-based RF is used to combine three sets of volumetric features and establish a regression model for predicting clinical scores. Our method has double feature selections to better explore the relevant features for prediction and is evaluated with the T1-weighted structural MR images from 36 MCI, 112 SCD, 78 NC subjects. The results demonstrate the effectiveness of proposed method. In addition to hippocampus and amygdala, we also found that the fimbria, basal nucleus and cortical nucleus subregions are more important than other regions for prediction of Mini-Mental State Examination (MMSE) and Montreal Cognitive Assessment (MoCA) scores and their changes.",0,0
3146,"Machine Learning Analysis of Time-Dependent Features for Predicting Adverse Events During Hemodialysis Therapy: Model Development and Validation Study. Hemodialysis (HD) therapy is an indispensable tool used in critical care management. Patients undergoing HD are at risk for intradialytic adverse events, ranging from muscle cramps to cardiac arrest. So far, there is no effective HD device-integrated algorithm to assist medical staff in response to these adverse events a step earlier during HD.",0,0
3148,"Deep Learning Predicts Interval and Screening-detected Cancer from Screening Mammograms: A Case-Case-Control Study in 6369 Women. Background The ability of deep learning (DL) models to classify women as at risk for either screening mammography-detected or interval cancer (not detected at mammography) has not yet been explored in the literature. Purpose To examine the ability of DL models to estimate the risk of interval and screening-detected breast cancers with and without clinical risk factors. Materials and Methods This study was performed on 25â€‰096 digital screening mammograms obtained from January 2006 to December 2013. The mammograms were obtained in 6369 women without breast cancer, 1609 of whom developed screening-detected breast cancer and 351 of whom developed interval invasive breast cancer. A DL model was trained on the negative mammograms to classify women into those who did not develop cancer and those who developed screening-detected cancer or interval invasive cancer. Model effectiveness was evaluated as a matched concordance statistic (C statistic) in a held-out 26% (1669 of 6369) test set of the mammograms. Results The C statistics and odds ratios for comparing patients with screening-detected cancer versus matched controls were 0.66 (95% CI: 0.63, 0.69) and 1.25 (95% CI: 1.17, 1.33), respectively, for the DL model, 0.62 (95% CI: 0.59, 0.65) and 2.14 (95% CI: 1.32, 3.45) for the clinical risk factors with the Breast Imaging Reporting and Data System (BI-RADS) density model, and 0.66 (95% CI: 0.63, 0.69) and 1.21 (95% CI: 1.13, 1.30) for the combined DL and clinical risk factors model. For comparing patients with interval cancer versus controls, the C statistics and odds ratios were 0.64 (95% CI: 0.58, 0.71) and 1.26 (95% CI: 1.10, 1.45), respectively, for the DL model, 0.71 (95% CI: 0.65, 0.77) and 7.25 (95% CI: 2.94, 17.9) for the risk factors with BI-RADS density (b rated vs non-b rated) model, and 0.72 (95% CI: 0.66, 0.78) and 1.10 (95% CI: 0.94, 1.29) for the combined DL and clinical risk factors model. The <i>P</i> values between the DL, BI-RADS, and combined model's ability to detect screen and interval cancer were .99, .002, and .03, respectively. Conclusion The deep learning model outperformed in determining screening-detected cancer risk but underperformed for interval cancer risk when compared with clinical risk factors including breast density. Â© RSNA, 2021 See also the editorial by Bae and Kim in this issue.",0,0
3150,"Multitask Deep Learning for Segmentation and Classification of Primary Bone Tumors on Radiographs. Background An artificial intelligence model that assesses primary bone tumors on radiographs may assist in the diagnostic workflow. Purpose To develop a multitask deep learning (DL) model for simultaneous bounding box placement, segmentation, and classification of primary bone tumors on radiographs. Materials and Methods This retrospective study analyzed bone tumors on radiographs acquired prior to treatment and obtained from patient data from January 2000 to June 2020. Benign or malignant bone tumors were diagnosed in all patients by using the histopathologic findings as the reference standard. By using split-sample validation, 70% of the patients were assigned to the training set, 15% were assigned to the validation set, and 15% were assigned to the test set. The final performance was evaluated on an external test set by using geographic validation, with accuracy, sensitivity, specificity, and 95% CIs being used for classification, the intersection over union (IoU) being used for bounding box placements, and the Dice score being used for segmentations. Results Radiographs from 934 patients (mean age, 33 years Â± 19 [standard deviation]; 419 women) were evaluated in the internal data set, which included 667 benign bone tumors and 267 malignant bone tumors. Six hundred fifty-four patients were in the training set, 140 were in the validation set, and 140 were in the test set. One hundred eleven patients were in the external test set. The multitask DL model achieved 80.2% (89 of 111; 95% CI: 72.8, 87.6) accuracy, 62.9% (22 of 35; 95% CI: 47, 79) sensitivity, and 88.2% (67 of 76; CI: 81, 96) specificity in the classification of bone tumors as malignant or benign. The model achieved an IoU of 0.52 Â± 0.34 for bounding box placements and a mean Dice score of 0.60 Â± 0.37 for segmentations. The model accuracy was higher than that of two radiologic residents (71.2% and 64.9%; <i>P</i> = .002 and <i>P</i> < .001, respectively) and was comparable with that of two musculoskeletal fellowship-trained radiologists (83.8% and 82.9%; <i>P</i> = .13 and <i>P</i> = .25, respectively) in classifying a tumor as malignant or benign. Conclusion The developed multitask deep learning model allowed for accurate and simultaneous bounding box placement, segmentation, and classification of primary bone tumors on radiographs. Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Carrino in this issue.",1,1
3152,"Improved diagnosis of thyroid cancer aided with deep learning applied to sonographic text reports: a retrospective, multi-cohort, diagnostic study. Large volume radiological text data have been accumulated since the incorporation of electronic health record (EHR) systems in clinical practice. We aimed to determine whether deep natural language processing algorithms could aid radiologists in improving thyroid cancer diagnosis.",1,1
3155,"Detection of sarcopenic obesity and prediction of long-term survival in patients with gastric cancer using preoperative computed tomography and machine learning. Previous studies evaluating the prognostic value of computed tomography (CT)-derived body composition data have included few patients. Thus, we assessed the prevalence and prognostic value of sarcopenic obesity in a large population of gastric cancer patients using preoperative CT, as nutritional status is a predictor of long-term survival after gastric cancer surgery.",0,0
3157,"Incorporating Glucose Variability into Glucose Forecasting Accuracy Assessment Using the New Glucose Variability Impact Index and the Prediction Consistency Index: An LSTM Case Example. In this work, we developed glucose forecasting algorithms trained and evaluated on a large dataset of free-living people with type 1 diabetes (T1D) using closed-loop (CL) and sensor-augmented pump (SAP) therapies; and we demonstrate how glucose variability impacts accuracy. We introduce the glucose variability impact index (GVII) and the glucose prediction consistency index (GPCI) to assess the accuracy of prediction algorithms.",0,0
3160,"Estimation and Discriminability of Doppler Ultrasound Fetal Heart Rate Variability Measures. Continuous electronic fetal monitoring and the access to databases of fetal heart rate (FHR) data have sparked the application of machine learning classifiers to identify fetal pathologies. However, most fetal heart rate data are acquired using Doppler ultrasound (DUS). DUS signals use autocorrelation (AC) to estimate the average heartbeat period within a window. In consequence, DUS FHR signals loses high frequency information to an extent that depends on the length of the AC window. We examined the effect of this on the estimation bias and discriminability of frequency domain features: low frequency power (LF: 0.03-0.15Â Hz), movement frequency power (MF: 0.15-0.5Â Hz), high frequency power (HF: 0.5-1Â Hz), the LF/(MF + HF) ratio, and the nonlinear approximate entropy (ApEn) as a function of AC window length and signal to noise ratio. We found that the average discriminability loss across all evaluated AC window lengths and SNRs was 10.99% for LF 14.23% for MF, 13.33% for the HF, 10.39% for the LF/(MF + HF) ratio, and 24.17% for ApEn. This indicates that the frequency domain features are more robust to the AC method and additive noise than the ApEn. This is likely because additive noise increases the irregularity of the signals, which results in an overestimation of ApEn. In conclusion, our study found that the LF features are the most robust to the effects of the AC method and noise. Future studies should investigate the effect of other variables such as signal drop, gestational age, and the length of the analysis window on the estimation of fHRV features and their discriminability.",0,0
3167,"Using Machine Learning Algorithms to Predict Candidaemia in ICU Patients With New-Onset Systemic Inflammatory Response Syndrome. <b>Background:</b> Distinguishing ICU patients with candidaemia can help with the precise prescription of antifungal drugs to create personalized guidelines. Previous prediction models of candidaemia have primarily used traditional logistic models and had some limitations. In this study, we developed a machine learning algorithm trained to predict candidaemia in patients with new-onset systemic inflammatory response syndrome (SIRS). <b>Methods:</b> This retrospective, observational study used clinical information collected between January 2013 and December 2017 from three hospitals. The ICU patient data were used to train 4 machine learning algorithms-XGBoost, Support Vector Machine (SVM), Random Forest (RF), ExtraTrees (ET)-and a logistic regression (LR) model to predict patients with candidaemia. <b>Results:</b> Of the 8,002 cases of new-onset SIRS (in 7,932 patients) included in the analysis, 137 new-onset SIRS cases (in 137 patients) were blood culture positive for candidaemia. Risk factors, such as fungal colonization, diabetes, acute kidney injury, the total number of parenteral nutrition days and renal replacement therapy, were important predictors of candidaemia. The XGBoost machine learning model outperformed the other models in distinguishing patients with candidaemia [XGBoost vs. SVM vs. RF vs. ET vs. LR; area under the curve (AUC): 0.92 vs. 0.86 vs. 0.91 vs. 0.90 vs. 0.52, respectively]. The XGBoost model had a sensitivity of 84%, specificity of 89% and negative predictive value of 99.6% at the best cut-off value. <b>Conclusions:</b> Machine learning algorithms can potentially predict candidaemia in the ICU and have better efficiency than previous models. These prediction models can be used to guide antifungal treatment for ICU patients when SIRS occurs.",0,0
3168,"Validation of the Relationship Between Iris Color and Uveal Melanoma Using Artificial Intelligence With Multiple Paths in a Large Chinese Population. Previous studies have shown that light iris color is a predisposing factor for the development of uveal melanoma (UM) in a population of Caucasian ancestry. However, in all these studies, a remarkably low percentage of patients have brown eyes, so we applied deep learning methods to investigate the correlation between iris color and the prevalence of UM in the Chinese population. All anterior segment photos were automatically segmented with U-NET, and only the iris regions were retained. Then the iris was analyzed with machine learning methods (random forests and convolutional neural networks) to obtain the corresponding iris color spectra (classification probability). We obtained satisfactory segmentation results with high consistency with those from experts. The iris color spectrum is consistent with the raters' view, but there is no significant correlation with UM incidence.",0,0
3169,"Lumbar Disc Herniation Automatic Detection in Magnetic Resonance Imaging Based on Deep Learning. <b>Background:</b> Lumbar disc herniation (LDH) is among the most common causes of lower back pain and sciatica. The causes of LDH have not been fully elucidated but most likely involve a complex combination of mechanical and biological processes. Magnetic resonance imaging (MRI) is a tool most frequently used for LDH because it can show abnormal soft tissue areas around the spine. Deep learning models may be trained to recognize images with high speed and accuracy to diagnose LDH. Although the deep learning model requires huge numbers of image datasets to train and establish the best model, this study processed enhanced medical image features for training the small-scale deep learning dataset. <b>Methods:</b> We propose automatic detection to assist the initial LDH exam for lower back pain. The subjects were between 20 and 65Â years old with at least 6Â months of work experience. The deep learning method employed the YOLOv3 model to train and detect small object changes such as LDH on MRI. The dataset images were processed and combined with labeling and annotation from the radiologist's diagnosis record. <b>Results:</b> Our method proves the possibility of using deep learning with a small-scale dataset with limited medical images. The highest mean average precision (mAP) was 92.4% at 550 images with data augmentation (550-aug), and the YOLOv3 LDH training was 100% with the best average precision at 550-aug among all datasets. This study used data augmentation to prevent under- or overfitting in an object detection model that was trained with the small-scale dataset. <b>Conclusions:</b> The data augmentation technique plays a crucial role in YOLOv3 training and detection results. This method displays a high possibility for rapid initial tests and auto-detection for a limited clinical dataset.",0,0
3170,"Machine Learning Approach Identified Multi-Platform Factors for Caries Prediction in Child-Mother Dyads. Untreated tooth decays affect nearly one third of the world and is the most prevalent disease burden among children. The disease progression of tooth decay is multifactorial and involves a prolonged decrease in pH, resulting in the demineralization of tooth surfaces. Bacterial species that are capable of fermenting carbohydrates contribute to the demineralization process by the production of organic acids. The combined use of machine learning and 16s rRNA sequencing offers the potential to predict tooth decay by identifying the bacterial community that is present in an individual's oral cavity. A few recent studies have demonstrated machine learning predictive modeling using 16s rRNA sequencing of oral samples, but they lack consideration of the multifactorial nature of tooth decay, as well as the role of fungal species within their models. Here, the oral microbiome of mother-child dyads (both healthy and caries-active) was used in combination with demographic-environmental factors and relevant fungal information to create a multifactorial machine learning model based on the LASSO-penalized logistic regression. For the children, not only were several bacterial species found to be caries-associated (<i>Prevotella histicola, Streptococcus mutans</i>, and <i>Rothia muciloginosa</i>) but also <i>Candida</i> detection and lower toothbrushing frequency were also caries-associated. Mothers enrolled in this study had a higher detection of <i>S. mutans</i> and <i>Candida</i> and a higher plaque index. This proof-of-concept study demonstrates the significant impact machine learning could have in prevention and diagnostic advancements for tooth decay, as well as the importance of considering fungal and demographic-environmental factors.",0,0
3171,"Overall Survival Prediction for Gliomas Using a Novel Compound Approach. As a highly malignant tumor, the incidence and mortality of glioma are not optimistic. Predicting the survival time of patients with glioma by extracting the feature information from gliomas is beneficial for doctors to develop more targeted treatments. Magnetic resonance imaging (MRI) is a way to quickly and clearly capture the details of brain tissue. However, manually segmenting brain tumors from MRI will cost doctors a lot of energy, and doctors can only vaguely estimate the survival time of glioma patients, which are not conducive to the formulation of treatment plans. Therefore, automatically segmenting brain tumors and accurately predicting survival time has important significance. In this article, we first propose the NLSE-VNet model, which integrates the Non-Local module and the Squeeze-and-Excitation module into V-Net to segment three brain tumor sub-regions in multimodal MRI. Then extract the intensity, texture, wavelet, shape and other radiological features from the tumor area, and use the CNN network to extract the deep features. The factor analysis method is used to reduce the dimensionality of features, and finally the dimensionality-reduced features and clinical features such as age and tumor grade are combined into the random forest regression model to predict survival. We evaluate the effect on the BraTS 2019 and BraTS 2020 datasets. The average Dice of brain tumor segmentation tasks up to 79% and the average RMSE of the survival predictive task is as low as 311.5. The results indicate that the method in this paper has great advantages in segmentation and survival prediction of gliomas.",0,0
3172,Multi-Parametric MRI-Based Radiomics Models for Predicting Molecular Subtype and Androgen Receptor Expression in Breast Cancer. To investigate whether radiomics features extracted from multi-parametric MRI combining machine learning approach can predict molecular subtype and androgen receptor (AR) expression of breast cancer in a non-invasive way.,0,0
3173,An Adversarial Deep-Learning-Based Model for Cervical Cancer CTV Segmentation With Multicenter Blinded Randomized Controlled Validation. To propose a novel deep-learning-based auto-segmentation model for CTV delineation in cervical cancer and to evaluate whether it can perform comparably well to manual delineation by a three-stage multicenter evaluation framework.,1,1
3174,Machine Learning-Based Analysis of Magnetic Resonance Radiomics for the Classification of Gliosarcoma and Glioblastoma. To identify optimalÂ machine-learningÂ methods for the radiomics-based differentiationÂ ofÂ gliosarcoma (GSM) from glioblastoma (GBM).,0,0
3175,"Deep Learning With Data Enhancement for the Differentiation of Solitary and Multiple Cerebral Glioblastoma, Lymphoma, and Tumefactive Demyelinating Lesion. To explore the MRI-based differential diagnosis of deep learning with data enhancement for cerebral glioblastoma (GBM), primary central nervous system lymphoma (PCNSL), and tumefactive demyelinating lesion (TDL).",0,0
3176,"Detection of COVID-19 findings by the local interpretable model-agnostic explanations method of types-based activations extracted from CNNs. Covid-19 is a disease that affects the upper and lower respiratory tract and has fatal consequences in individuals. Early diagnosis of COVID-19 disease is important. Datasets used in this study were collected from hospitals in Istanbul. The first dataset consists of COVID-19, viral pneumonia, and bacterial pneumonia types. The second dataset consists of the following findings of COVID-19: ground glass opacity, ground glass opacity, and nodule, crazy paving pattern, consolidation, consolidation, and ground glass. The approach suggested in this paper is based on artificial intelligence. The proposed approach consists of three steps. As a first step, preprocessing was applied and, in this step, the Fourier Transform and Gradient-weighted Class Activation Mapping methods were applied to the input images together. In the second step, type-based activation sets were created with three different ResNet models before the Softmax method. In the third step, the best type-based activations were selected among the CNN models using the local interpretable model-agnostic explanations method and re-classified with the Softmax method. An overall accuracy success of 99.15% was achieved with the proposed approach in the dataset containing three types of image sets. In the dataset consisting of COVID-19 findings, an overall accuracy success of 99.62% was achieved with the recommended approach.",0,0
3177,"A Multimodal Affinity Fusion Network for Predicting the Survival of Breast Cancer Patients. Accurate survival prediction of breast cancer holds significant meaning for improving patient care. Approaches using multiple heterogeneous modalities such as gene expression, copy number alteration, and clinical data have showed significant advantages over those with only one modality for patient survival prediction. However, existing survival prediction methods tend to ignore the structured information between patients and multimodal data. We propose a multimodal data fusion model based on a novel multimodal affinity fusion network (MAFN) for survival prediction of breast cancer by integrating gene expression, copy number alteration, and clinical data. First, a stack-based shallow self-attention network is utilized to guide the amplification of tiny lesion regions on the original data, which locates and enhances the survival-related features. Then, an affinity fusion module is proposed to map the structured information between patients and multimodal data. The module endows the network with a stronger fusion feature representation and discrimination capability. Finally, the fusion feature embedding and a specific feature embedding from a triple modal network are fused to make the classification of long-term survival or short-term survival for each patient. As expected, the evaluation results on comprehensive performance indicate that MAFN achieves better predictive performance than existing methods. Additionally, our method can be extended to the survival prediction of other cancer diseases, providing a new strategy for other diseases prognosis.",0,0
3181,"Prospective Study of a Multimodal Convulsive Seizure Detection Wearable System on Pediatric and Adult Patients in the Epilepsy Monitoring Unit. <b>Background:</b> Using machine learning to combine wrist accelerometer (ACM) and electrodermal activity (EDA) has been shown effective to detect primarily and secondarily generalized tonic-clonic seizures, here termed as convulsive seizures (CS). A prospective study was conducted for the FDA clearance of an ACM and EDA-based CS-detection device based on a predefined machine learning algorithm. Here we present its performance on pediatric and adult patients in epilepsy monitoring units (EMUs). <b>Methods:</b> Patients diagnosed with epilepsy participated in a prospective multi-center clinical study. Three board-certified neurologists independently labeled CS from video-EEG. The Detection Algorithm was evaluated in terms of Sensitivity and false alarm rate per 24 h-worn (FAR) on all the data and on only periods of rest. Performance were analyzed also applying the Detection Algorithm offline, with a less sensitive but more specific parameters configuration (""Active mode""). <b>Results:</b> Data from 152 patients (429 days) were used for performance evaluation (85 pediatric aged 6-20 years, and 67 adult aged 21-63 years). Thirty-six patients (18 pediatric) experienced a total of 66 CS (35 pediatric). The Sensitivity (corrected for clustered data) was 0.92, with a 95% confidence interval (CI) of [0.85-1.00] for the pediatric population, not significantly different (<i>p</i> > 0.05) from the adult population's Sensitivity (0.94, CI: [0.89-1.00]). The FAR on the pediatric population was 1.26 (CI: [0.87-1.73]), higher (<i>p</i> < 0.001) than in the adult population (0.57, CI: [0.36-0.81]). Using the Active mode, the FAR decreased by 68% while reducing Sensitivity to 0.95 across the population. During rest periods, the FAR's were 0 for all patients, lower than during activity periods (<i>p</i> < 0.001). <b>Conclusions:</b> Performance complies with FDA's requirements of a lower bound of CI for Sensitivity higher than 0.7 and of a FAR lower than 2, for both age groups. The pediatric FAR was higher than the adult FAR, likely due to higher pediatric activity. The high Sensitivity and precision (having no false alarms) during sleep might help mitigate SUDEP risk by summoning caregiver intervention. The Active mode may be advantageous for some patients, reducing the impact of the FAR on daily life. Future work will examine the performance and usability outside of EMUs.",0,0
3188,"Inflammatory Biomarkers Aid in Diagnosis of Dementia. Dual pathology of Alzheimer's disease (AD) and vascular cognitive impairment and dementia (VCID) commonly are found together at autopsy, but mixed dementia (MX) is difficult to diagnose during life. Biological criteria to diagnose AD have been defined, but are not available for vascular disease. We used the biological criteria for AD and white matter injury based on MRI to diagnose MX. Then we measured multiple biomarkers in CSF and blood with multiplex biomarker kits for proteases, angiogenic factors, and cytokines to explore pathophysiology in each group. Finally, we used machine learning with the Random forest algorithm to select the biomarkers of maximal importance; that analysis identified three proteases, matrix metalloproteinase-10 (MMP-10), MMP-3 and MMP-1; three angiogenic factors, VEGF-C, Tie-2 and PLGF, and three cytokines interleukin-2 (IL-2), IL-6, IL-13. To confirm the clinical importance of the variables, we showed that they correlated with results of neuropsychological testing.",0,0
3195,"Development of an exosomal gene signature to detect residual disease in dogs with osteosarcoma using a novel xenograft platform and machine learning. Osteosarcoma has a guarded prognosis. A major hurdle in developing more effective osteosarcoma therapies is the lack of disease-specific biomarkers to predict risk, prognosis, or therapeutic response. Exosomes are secreted extracellular microvesicles emerging as powerful diagnostic tools. However, their clinical application is precluded by challenges in identifying disease-associated cargo from the vastly larger background of normal exosome cargo. We developed a method using canine osteosarcoma in mouse xenografts to distinguish tumor-derived from host-response exosomal messenger RNAs (mRNAs). The model allows for the identification of canine osteosarcoma-specific gene signatures by RNA sequencing and a species-differentiating bioinformatics pipeline. An osteosarcoma-associated signature consisting of five gene transcripts (SKA2, NEU1, PAF1, PSMG2, and NOB1) was validated in dogs with spontaneous osteosarcoma by real-time quantitative reverse transcription PCR (qRT-PCR), while a machine learning model assigned dogs into healthy or disease groups. Serum/plasma exosomes were isolated from 53 dogs in distinct clinical groups (""healthy"", ""osteosarcoma"", ""other bone tumor"", or ""non-neoplastic disease""). Pre-treatment samples from osteosarcoma cases were used as the training set, and a validation set from post-treatment samples was used for testing, classifying as ""osteosarcoma detected"" or ""osteosarcoma-NOT detected"". Dogs in a validation set whose post-treatment samples were classified as ""osteosarcoma-NOT detected"" had longer remissions, up to 15 months after treatment. In conclusion, we identified a gene signature predictive of molecular remissions with potential applications in the early detection and minimal residual disease settings. These results provide proof of concept for our discovery platform and its utilization in future studies to inform cancer risk, diagnosis, prognosis, and therapeutic response.",0,0
3204,Big-data and artificial-intelligence-assisted vault prediction and EVO-ICL size selection for myopia correction. To predict the vault and the EVO-implantable collamer lens (ICL) size by artificial intelligence (AI) and big data analytics.,0,0
3205,"Reallocation of time between device-measured movement behaviours and risk of incident cardiovascular disease. To improve classification of movement behaviours in free-living accelerometer data using machine-learning methods, and to investigate the association between machine-learned movement behaviours and risk of incident cardiovascular disease (CVD) in adults.",0,0
3207,"Predicting progression and cognitive decline in amyloid-positive patients with Alzheimer's disease. In Alzheimer's disease, amyloid- Î² (A Î²) peptides aggregate in the lowering CSF amyloid levels - a key pathological hallmark of the disease. However, lowered CSF amyloid levels may also be present in cognitively unimpaired elderly individuals. Therefore, it is of great value to explain the variance in disease progression among patients with A Î² pathology.",0,0
3211,"Multi-parametric MRI phenotype with trustworthy machine learning for differentiating CNS demyelinating diseases. Misdiagnosis of multiple sclerosis (MS) and neuromyelitis optica (NMO) may delay the treatment, resulting in poor prognosis. However, the precise identification of these two diseases is still challenging in clinical practice. We aimed to evaluate the value of quantitative radiomic features extracted from the brain white matter lesions for differential diagnosis of MS and NMO.",0,0
3216,"Robust Discovery of Mild Cognitive Impairment Subtypes and Their Risk of Alzheimer's Disease Conversion Using Unsupervised Machine Learning and Gaussian Mixture Modeling. Alzheimer's disease (AD) is an irreversible, progressive brain disorder that slowly destroys memory and thinking skills. The ability to correctly predict the diagnosis of Alzheimer's disease in its earliest stages can help physicians make more informed clinical decisions on therapy plans.",0,0
3218,"Clinical Score and Machine Learning-Based Model to Predict Diagnosis of Primary Aldosteronism in Arterial Hypertension. Primary aldosteronism (PA) is the cause of arterial hypertension in 4% to 6% of patients, and 30% of patients with PA are affected by unilateral and surgically curable forms. Current guidelines recommend screening for PA â‰ˆ50% of patients with hypertension on the basis of individual factors, while some experts suggest screening all patients with hypertension. To define the risk of PA and tailor the diagnostic workup to the individual risk of each patient, we developed a conventional scoring system and supervised machine learning algorithms using a retrospective cohort of 4059 patients with hypertension. On the basis of 6 widely available parameters, we developed a numerical score and 308 machine learning-based models, selecting the one with the highest diagnostic performance. After validation, we obtained high predictive performance with our score (optimized sensitivity of 90.7% for PA and 92.3% for unilateral PA [UPA]). The machine learning-based model provided the highest performance, with an area under the curve of 0.834 for PA and 0.905 for diagnosis of UPA, with optimized sensitivity of 96.6% for PA, and 100.0% for UPA, at validation. The application of the predicting tools allowed the identification of a subgroup of patients with very low risk of PA (0.6% for both models) and null probability of having UPA. In conclusion, this score and the machine learning algorithm can accurately predict the individual pretest probability of PA in patients with hypertension and circumvent screening in up to 32.7% of patients using a machine learning-based model, without omitting patients with surgically curable UPA.",0,0
3223,Deep learning-based Hounsfield unit value measurement method for bolus tracking images in cerebral computed tomography angiography. Patient movement during bolus tracking (BT) impairs the accuracy of Hounsfield unit (HU) measurements. This study assesses the accuracy of measuring HU values in the internal carotid artery (ICA) using an original deep learning (DL)-based method as compared with using the conventional region of interest (ROI) setting method.,0,0
3224,"Simple methods for the lesion detection and severity grading of diabetic retinopathy by image processing and transfer learning. Diabetic retinopathy (DR) has become one of the major causes of blindness. Due to the increased prevalence of diabetes worldwide, diabetic patients exhibit high probabilities of developing DR. There is a need to develop a labor-less computer-aided diagnosis system to support the clinical diagnosis. Here, we attempted to develop simple methods for severity grading and lesion detection from retinal fundus images. We developed a severity grading system for DR by transfer learning with a recent convolutional neural network called EfficientNet-B3 and the publicly available Kaggle Asia Pacific Tele-Ophthalmology Society (APTOS) 2019 training dataset, which includes artificial noise. After removing the blurred and duplicated images from the dataset using a numerical threshold, the trained model achieved specificity and sensitivity valuesÂ â‰³Â 0.98 in the identification of DR retinas. For severity grading, the classification accuracy values of 0.84, 0.95, and 0.98 were recorded for the 1st, 2nd, and 3rd predicted labels, respectively. The utility of EfficientNets-B3 for the severity grading of DR as well as the detailed retinal areas referred were confirmed via visual explanation methods of convolutional neural networks. Lesion extraction was performed by applying an empirically defined threshold value to the enhanced retinal images. Although the extraction of blood vessels and detection of red lesions occurred simultaneously, the red and white lesions, including both soft and hard exudates, were clearly extracted. The detected lesion areas were further confirmed with ground truth using the DIARETDB1 database images with general accuracy. The simple and easily applicable methods proposed in this study will aid in the detection and severity grading of DR, which might help in the selection of appropriate treatment strategies for DR.",0,0
3229,"Normative ascent with local gaussians for unsupervised lesion detection. Unsupervised abnormality detection is an appealing approach to identify patterns that are not present in training data without specific annotations for such patterns. In the medical imaging field, methods taking this approach have been proposed to detect lesions. The appeal of this approach stems from the fact that it does not require lesion-specific supervision and can potentially generalize to any sort of abnormal patterns. The principle is to train a generative model on images from healthy individuals to estimate the distribution of images of the normal anatomy, i.e., a normative distribution, and detect lesions as out-of-distribution regions. Restoration-based techniques that modify a given image by taking gradient ascent steps with respect to a posterior distribution composed of a normative distribution and a likelihood term recently yielded state-of-the-art results. However, these methods do not explicitly model ascent directions with respect to the normative distribution, i.e. normative ascent direction, which is essential for successful restoration. In this work, we introduce a novel approach for unsupervised lesion detection by modeling normative ascent directions. We present different modelling options based on the defined ascent directions with local Gaussians. We further extend the proposed method to efficiently utilize 3D information, which has not been explored in most existing works. We experimentally show that the proposed method provides higher accuracy in detection and produces more realistic restored images. The performance of the proposed method is evaluated against baselines on publicly available BRATS and ATLAS stroke lesion datasets; the detection accuracy of the proposed method surpasses the current state-of-the-art results.",0,0
3230,"Automatic annotation of cervical vertebrae in videofluoroscopy images via deep learning. Judging swallowing kinematic impairments via videofluoroscopy represents the gold standard for the detection and evaluation of swallowing disorders. However, the efficiency and accuracy of such a biomechanical kinematic analysis vary significantly among human judges affected mainly by their training and experience. Here, we showed that a novel machine learning algorithm can with high accuracy automatically detect key anatomical points needed for a routine swallowing assessment in real-time. We trained a novel two-stage convolutional neural network to localize and measure the vertebral bodies using 1518 swallowing videofluoroscopies from 265 patients. Our network model yielded high accuracy as the mean distance between predicted points and annotations was 4.20 Â± 5.54Â pixels. In comparison, human inter-rater error was 4.35 Â± 3.12Â pixels. Furthermore, 93% of predicted points were less than five pixels from annotated pixels when tested on an independent dataset from 70 subjects. Our model offers more choices for speech language pathologists in their routine clinical swallowing assessments as it provides an efficient and accurate method for anatomic landmark localization in real-time, a task previously accomplished using an off-line time-sinking procedure.",0,0
3232,Development of a clinical prediction rule for patients with cervical spinal cord injury who have difficulty in obtaining independent living. A simple and easy to use clinical prediction rule (CPR) to detect patients with a cervical spinal cord injury (SCI) who would have difficulty in obtaining independent living status is vital for providing the optimal rehabilitation and education in both care recipients and caregivers. A machine learning approach was recently applied to the field of rehabilitation and has the possibility to develop an accurate and useful CPR.,0,0
3237,"Stratifying the Risk of Cardiovascular Disease in Obstructive Sleep Apnea Using Machine Learning. Obstructive sleep apnea (OSA) is associated with higher risk of morbidity and mortality related to cardiovascular disease (CVD). Due to overlapping clinical risk factors, identifying high-risk patients with OSA who are likely to develop CVD remains challenging. We aimed to identify baseline clinical factors associated with the future development of CVD in patients with OSA.",0,0
3240,"Multi-View Spatial-Temporal Graph Convolutional Networks With Domain Generalization for Sleep Stage Classification. Sleep stage classification is essential for sleep assessment and disease diagnosis. Although previous attempts to classify sleep stages have achieved high classification performance, several challenges remain open: 1) How to effectively utilize time-varying spatial and temporal features from multi-channel brain signals remains challenging. Prior works have not been able to fully utilize the spatial topological information among brain regions. 2) Due to the many differences found in individual biological signals, how to overcome the differences of subjects and improve the generalization of deep neural networks is important. 3) Most deep learning methods ignore the interpretability of the model to the brain. To address the above challenges, we propose a multi-view spatial-temporal graph convolutional networks (MSTGCN) with domain generalization for sleep stage classification. Specifically, we construct two brain view graphs for MSTGCN based on the functional connectivity and physical distance proximity of the brain regions. The MSTGCN consists of graph convolutions for extracting spatial features and temporal convolutions for capturing the transition rules among sleep stages. In addition, attention mechanism is employed for capturing the most relevant spatial-temporal information for sleep stage classification. Finally, domain generalization and MSTGCN are integrated into a unified framework to extract subject-invariant sleep features. Experiments on two public datasets demonstrate that the proposed model outperforms the state-of-the-art baselines.",0,0
3244,"Machine Learning Approach to Differentiation of Peripheral Schwannomas and Neurofibromas: A Multi-Center Study. Non-invasive differentiation between schwannomas and neurofibromas is important for appropriate management, preoperative counseling, and surgical planning, but has proven difficult using conventional imaging. The objective of this study was to develop and evaluate machine learning approaches for differentiating peripheral schwannomas from neurofibromas.",0,0
3249,Nonenhanced MRI-based radiomics model for preoperative prediction of nonperfused volume ratio for high-intensity focused ultrasound ablation of uterine leiomyomas. To develop and assess nonenhanced MRI-based radiomics model for the preoperative prediction of nonperfused volume (NPV) ratio of uterine leiomyomas after high-intensity focused ultrasound (HIFU) treatment.,0,0
3256,"Diagnostic magnetic resonance imaging biomarkers for facioscapulohumeral muscular dystrophy identified by machine learning. The diagnosis of facioscapulohumeral muscular dystrophy (FSHD) can be challenging in patients not displaying the classical phenotype or with atypical clinical features. Despite the identification by magnetic resonance imaging (MRI) of selective patterns of muscle involvement, their specificity and added diagnostic value are unknown.",0,0
3267,Prediction of treatment response to transarterial radioembolization of liver metastases: Radiomics analysis of pre-treatment cone-beam CT: A proof of concept study. To investigate the potential of texture analysis and machine learning to predict treatment response to transarterial radioembolization (TARE) on pre-interventional cone-beam computed tomography (CBCT) images in patients with liver metastases.,0,0
3270,"Ability of a Machine Learning Algorithm to Predict the Need for Perioperative Red Blood Cells Transfusion in Pelvic Fracture Patients: A Multicenter Cohort Study in China. <b>Background:</b> Predicting the perioperative requirement for red blood cells (RBCs) transfusion in patients with the pelvic fracture may be challenging. In this study, we constructed a perioperative RBCs transfusion predictive model (ternary classifications) based on a machine learning algorithm. <b>Materials and Methods:</b> This study included perioperative adult patients with pelvic trauma hospitalized across six Chinese centers between September 2012 and June 2019. An extreme gradient boosting (XGBoost) algorithm was used to predict the need for perioperative RBCs transfusion, with data being split into training test (80%), which was subjected to 5-fold cross-validation, and test set (20%). The ability of the predictive transfusion model was compared with blood preparation based on surgeons' experience and other predictive models, including random forest, gradient boosting decision tree, K-nearest neighbor, logistic regression, and Gaussian naÃ¯ve Bayes classifier models. Data of 33 patients from one of the hospitals were prospectively collected for model validation. <b>Results:</b> Among 510 patients, 192 (37.65%) have not received any perioperative RBCs transfusion, 127 (24.90%) received less-transfusion (RBCs < 4U), and 191 (37.45%) received more-transfusion (RBCs â‰¥ 4U). Machine learning-based transfusion predictive model produced the best performance with the accuracy of 83.34%, and Kappa coefficient of 0.7967 compared with other methods (blood preparation based on surgeons' experience with the accuracy of 65.94%, and Kappa coefficient of 0.5704; the random forest method with an accuracy of 82.35%, and Kappa coefficient of 0.7858; the gradient boosting decision tree with an accuracy of 79.41%, and Kappa coefficient of 0.7742; the K-nearest neighbor with an accuracy of 53.92%, and Kappa coefficient of 0.3341). In the prospective dataset, it also had a food performance with accuracy 81.82%. <b>Conclusion:</b> This multicenter retrospective cohort study described the construction of an accurate model that could predict perioperative RBCs transfusion in patients with pelvic fractures.",0,1
3271,"Algorithm for Detection and Quantification of Hyperreflective Dots on Optical Coherence Tomography in Diabetic Macular Edema. <b>Purpose:</b> To develop an algorithm to detect and quantify hyperreflective dots (HRDs) on optical coherence tomography (OCT) in patients with diabetic macular edema (DME). <b>Materials and Methods:</b> Twenty OCTs (each OCT contains 128 b scans) from 20 patients diagnosed with DME were included in this study. Two types of HRDs, hard exudates and small HRDs (hypothesized to be activated microglia), were identified and labeled independently by two raters. An algorithm using deep learning technology was developed based on input (in total 2,560 OCT b scans) of manual labeling and differentiation of HRDs from rater 1. 4-fold cross-validation was used to train and validate the algorithm. Dice coefficient, intraclass coefficient (ICC), correlation coefficient, and Bland-Altman plot were used to evaluate agreement of the output parameters between two methods (either between two raters or between one rater and proposed algorithm). <b>Results:</b> The Dice coefficients of total HRDs, hard exudates, and small HRDs area of the algorithm were 0.70 Â± 0.10, 0.72 Â± 0.11, and 0.46 Â± 0.06, respectively. The correlations between rater 1 and proposed algorithm (range: 0.95-0.99, all <i>p</i> < 0.001) were stronger than the correlations between the two raters (range: 0.84-0.96, all <i>p</i> < 0.001) for all parameters. The ICCs were higher for all the parameters between rater 1 and proposed algorithm (range: 0.972-0.997) than those between the two raters (range: 0.860-0.953). <b>Conclusions:</b> Our proposed algorithm is a good tool to detect and quantify HRDs and can provide objective and repeatable information of OCT for DME patients in clinical practice and studies.",1,1
3273,"An Ovarian Cancer Susceptible Gene Prediction Method Based on Deep Learning Methods. Ovarian cancer (OC) is one of the most fatal diseases among women all around the world. It is highly lethal because it is usually diagnosed at an advanced stage which may reduce the survival rate greatly. Even though most of the patients are treated timely and effectively, the survival rate is still low due to the high recurrence rate of OC. With a large number of genome-wide association analysis (GWAS)-discovered risk regions of OC, expression quantitative trait locus (eQTL) analyses can explore candidate susceptible genes based on these risk loci. However, a large number of OC-related genes remain unknown. In this study, we proposed a novel gene prediction method based on different omics data and deep learning methods to identify OC causal genes. We first employed graph attention network (GAT) to obtain a compact gene feature representation, then a deep neural network (DNN) is utilized to predict OC-related genes. As a result, our model achieved a high AUC of 0.761 and AUPR of 0.788, which proved the accuracy and effectiveness of our proposed method. At last, we conducted a gene-set enrichment analysis to further explore the mechanism of OC. Finally, we predicted 245 novel OC causal genes and 10 top related KEGG pathways.",0,0
3277,"Risk Identification of Bronchopulmonary Dysplasia in Premature Infants Based on Machine Learning. Bronchopulmonary dysplasia (BPD) is one of the most common complications in premature infants. This disease is caused by long-time use of supplemental oxygen, which seriously affects the lung function of the child and imposes a heavy burden on the family and society. This research aims to adopt the method of ensemble learning in machine learning, combining the Boruta algorithm and the random forest algorithm to determine the predictors of premature infants with BPD and establish a predictive model to help clinicians to conduct an optimal treatment plan. Data were collected from clinical records of 996 premature infants treated in the neonatology department of Liuzhou Maternal and Child Health Hospital in Western China. In this study, premature infants with congenital anomaly, premature infants who died, and premature infants with incomplete data before the diagnosis of BPD were excluded from the data set. After exclusion, we included 648 premature infants in the study. The Boruta algorithm and 10-fold cross-validation were used for feature selection in this study. Six variables were finally selected from the 26 variables, and the random forest model was established. The area under the curve (AUC) of the model was as high as 0.929 with excellent predictive performance. The use of machine learning methods can help clinicians predict the disease so as to formulate the best treatment plan.",0,0
3278,"Early Prediction of Multiple Organ Dysfunction in the Pediatric Intensive Care Unit. <b>Objective:</b> The objective of the study is to build models for early prediction of risk for developing multiple organ dysfunction (MOD) in pediatric intensive care unit (PICU) patients. <b>Design:</b> The design of the study is a retrospective observational cohort study. <b>Setting:</b> The setting of the study is at a single academic PICU at the Johns Hopkins Hospital, Baltimore, MD. <b>Patients:</b> The patients included in the study were <18 years of age admitted to the PICU between July 2014 and October 2015. <b>Measurements and main results:</b> Organ dysfunction labels were generated every minute from preceding 24-h time windows using the International Pediatric Sepsis Consensus Conference (IPSCC) and Proulx et al. MOD criteria. Early MOD prediction models were built using four machine learning methods: random forest, XGBoost, GLMBoost, and Lasso-GLM. An optimal threshold learned from training data was used to detect high-risk alert events (HRAs). The early prediction models from all methods achieved an area under the receiver operating characteristics curve â‰¥0.91 for both IPSCC and Proulx criteria. The best performance in terms of maximum F1-score was achieved with random forest (sensitivity: 0.72, positive predictive value: 0.70, F1-score: 0.71) and XGBoost (sensitivity: 0.8, positive predictive value: 0.81, F1-score: 0.81) for IPSCC and Proulx criteria, respectively. The median early warning time was 22.7 h for random forest and 37 h for XGBoost models for IPSCC and Proulx criteria, respectively. Applying spectral clustering on risk-score trajectories over 24 h following early warning provided a high-risk group with â‰¥0.93 positive predictive value. <b>Conclusions:</b> Early predictions from risk-based patient monitoring could provide more than 22 h of lead time for MOD onset, with â‰¥0.93 positive predictive value for a high-risk group identified pre-MOD.",0,0
3279,"Higher Serum Lysophosphatidic Acids Predict Left Ventricular Reverse Remodeling in Pediatric Dilated Cardiomyopathy. <b>Background:</b> The prognosis of pediatric dilated cardiomyopathy (PDCM) is highly variable, ranging from death to cardiac function recovery. Left ventricular reverse remodeling (LVRR) represents a favorable prognosis in PDCM. Disturbance of lipid metabolism is associated with the change of cardiac function, but no studies have examined lipidomics data and LVRR. <b>Methods:</b> Discovery analyses were based on 540 targeted lipids in an observational, prospective China-AOCC (An Integrative-Omics Study of Cardiomyopathy Patients for Diagnosis and Prognosis in China) study. The OPLS-DA and random forest (RF) analysis were used to screen the candidate lipids. Associations of the candidate lipids were examined in Cox proportional hazards regression models. Furthermore, we developed a risk score comprising the significant lipids, with each attributed a score of 1 when the concentration was above the median. All significant findings were replicated in a validation set of the China-AOCC study. <b>Results:</b> There were 59 patients in the discovery set and 24 patients in the validation set. LVRR was observed in 27 patients (32.5%). After adjusting for age, left ventricular ejection fraction (LVEF), and left ventricular end-diastolic dimension (LVEDD) z-score, lysophosphatidic acids (LysoPA) 16:0, LysoPA 18:2, LysoPA 18:1, and LysoPA 18:0 were significantly associated with LVRR in the discovery set, and hazard ratios (HRs) were 2.793 (95% CI, 1.545-5.048), 2.812 (95% CI, 1.542-5.128), 2.831 (95% CI, 1.555-5.154), and 2.782 (95% CI, 1.548-5.002), respectively. We developed a LysoPA score comprising the four LysoPA. When the LysoPA score reached 4, LVRR was more likely to be observed in both sets. The AUC increased with the addition of the LysoPA score to the LVEDD z-score (from 0.693 to 0.875 in the discovery set, from 0.708 to 0.854 in the validation set) for prediction of LVRR. <b>Conclusions:</b> Serum LysoPA can predict LVRR in PDCM patients. When the LysoPA score was combined with the LVEDD z-score, it may help in ascertaining the prognosis and monitoring effects of anti-heart failure pharmacotherapy.",0,0
3283,"Multiple Sclerosis Lesion Segmentation in Brain MRI Using Inception Modules Embedded in a Convolutional Neural Network. Multiple sclerosis (MS) is a chronic and autoimmune disease that forms lesions in the central nervous system. Quantitative analysis of these lesions has proved to be very useful in clinical trials for therapies and assessing disease prognosis. However, the efficacy of these quantitative analyses greatly depends on how accurately the MS lesions have been identified and segmented in brain MRI. This is usually carried out by radiologists who label 3D MR images slice by slice using commonly available segmentation tools. However, such manual practices are time consuming and error prone. To circumvent this problem, several automatic segmentation techniques have been investigated in recent years. In this paper, we propose a new framework for automatic brain lesion segmentation that employs a novel convolutional neural network (CNN) architecture. In order to segment lesions of different sizes, we have to pick a specific filter or size 3 Ã— 3 or 5 Ã— 5. Sometimes, it is hard to decide which filter will work better to get the best results. Google Net has solved this problem by introducing an inception module. An inception module uses 3 Ã— 3, 5 Ã— 5, 1 Ã— 1 and max pooling filters in parallel fashion. Results show that incorporating inception modules in a CNN has improved the performance of the network in the segmentation of MS lesions. We compared the results of the proposed CNN architecture for two loss functions: binary cross entropy (BCE) and structural similarity index measure (SSIM) using the publicly available ISBI-2015 challenge dataset. A score of 93.81 which is higher than the human rater with BCE loss function is achieved.",0,0
3284,"Stress Classification by Multimodal Physiological Signals Using Variational Mode Decomposition and Machine Learning. In this pandemic situation, importance and awareness about mental health are getting more attention. Stress recognition from multimodal sensor based physiological signals such as electroencephalogram (EEG) and electrocardiography (ECG) signals is a very cost-effective way due to its noninvasive nature. A dataset, recorded during the mental arithmetic task, consisting of EEGâ€‰+â€‰ECG signals of 36 participants is used. It contains two categories of performance, namely, ""Good"" (nonstressed) and ""Bad"" (stressed) (Gupta et al. 2018 and EraldeÃ­r et al. 2018). This paper presents an effective approach for the recognition of stress marker at frontal, temporal, central, and occipital lobes. It processes the multimodality physiological signals. The variational mode decomposition (VMD) strategy is used for data preprocessing and for the decomposition of signals into various oscillatory mode functions. Poincare plots (PP) are derived from the first eight variational modes and features from these plots have been extracted such as mean, area, and central tendency measure of the elliptical region. The statistical significance of the extracted features with <i>p</i>â€‰<â€‰0.5 has been performed using the Wilcoxson test. The multilayer perceptron (MPLN) and Support Vector Machine (SVM) algorithms are used for the classification of stress and nonstress categories. MLPN has achieved the maximum accuracies of 100% for frontal and temporal lobes. The suggested method can be incorporated in noninvasive EEG signal processing based automated stress identification systems.",0,0
3285,"Deep Learning for Intelligent Recognition and Prediction of Endometrial Cancer. The aim of the study was to investigate the intelligent recognition of radiomics based on the convolutional neural network (CNN) in predicting endometrial cancer (EC). In this study, 158 patients with EC in hospital were selected as the research objects and divided into a training group and a test group. All the patients underwent magnetic resonance imaging (MRI) before surgery. Based on the CNN, the imaging model of EC prediction was constructed according to the characteristics. Besides, the comprehensive prediction model was established through the clinical information and imaging parameters. The results showed that the area under the working characteristic curve (AUC) of the radiomics model and comprehensive prediction model was 0.897 and 0.913 in the training group, respectively. In addition, the AUC of the radiomics model was 0.889 in the test group and that of the comprehensive prediction model was 0.897. The comprehensive prediction model was established through specific imaging parameters and clinical pathological information, and its prediction performance was good, indicating that radiomics parameters could be applied as noninvasive markers to predict EC.",0,0
3287,"Diagnosing hospital bacteraemia in the framework of predictive, preventive and personalised medicine using electronic health records and machine learning classifiers. The bacteraemia prediction is relevant because sepsis is one of the most important causes of morbidity and mortality. Bacteraemia prognosis primarily depends on a rapid diagnosis. The bacteraemia prediction would shorten up to 6 days the diagnosis, and, in conjunction with individual patient variables, should be considered to start the early administration of personalised antibiotic treatment and medical services, the election of specific diagnostic techniques and the determination of additional treatments, such as surgery, that would prevent subsequent complications. Machine learning techniques could help physicians make these informed decisions by predicting bacteraemia using the data already available in electronic hospital records.",0,0
3289,"Landscape of Immune Microenvironment in Epithelial Ovarian Cancer and Establishing Risk Model by Machine Learning. Epithelial ovarian cancer (EOC) is an extremely lethal gynecological malignancy and has the potential to benefit from the immune checkpoint blockade (ICB) therapy, whose efficacy highly depends on the complex tumor microenvironment (TME).",0,0
3290,"Development of a Mobile Application Platform for Self-Management of Obesity Using Artificial Intelligence Techniques. Obesity is a major global health challenge and a risk factor for the leading causes of death, including heart disease, stroke, diabetes, and several types of cancer. Attempts to manage and regulate obesity have led to the implementation of various dietary regulatory initiatives to provide information on the calorie contents of meals. Although knowledge of the calorie content is useful for meal planning, it is not sufficient as other factors, including health status (diabetes, hypertension, etc.) and level of physical activity, are essential in the decision process for obesity management. In this work, we present an artificial intelligence- (AI-) based application that is driven by a genetic algorithm (GA) as a potential tool for tracking a user's energy balance and predicting possible calorie intake required to meet daily calorie needs for obesity management. The algorithm takes the users' input information on desired foods which are selected from a database and extracted records of users on cholesterol level, diabetes status, and level of physical activity, to predict possible meals required to meet the users need. The micro- and macronutrients of food content are used for the computation and prediction of the potential foods required to meet the daily calorie needs. The functionality and performance of the model were tested using a sample of 30 volunteers from the University of Ghana. Results revealed that the model was able to predict both glycemic and non-glycemic foods based on the condition of the user as well as the macro- and micronutrients requirements. Moreover, the system is able to adequately track the progress of the user's weight loss over time, daily nutritional needs, daily calorie intake, and predictions of meals that must be taken to avoid compromising their health. The proposed system can serve as a useful resource for individuals, dieticians, and other health management personnel for managing obesity, patients, and for training students in fields of dietetics and consumer science.",0,0
3292,"A Hierarchical View Pooling Network for Multichannel Surface Electromyography-Based Gesture Recognition. Hand gesture recognition based on surface electromyography (sEMG) plays an important role in the field of biomedical and rehabilitation engineering. Recently, there is a remarkable progress in gesture recognition using high-density surface electromyography (HD-sEMG) recorded by sensor arrays. On the other hand, robust gesture recognition using multichannel sEMG recorded by sparsely placed sensors remains a major challenge. In the context of multiview deep learning, this paper presents a hierarchical view pooling network (HVPN) framework, which improves multichannel sEMG-based gesture recognition by learning not only view-specific deep features but also view-shared deep features from hierarchically pooled multiview feature spaces. Extensive intrasubject and intersubject evaluations were conducted on the large-scale noninvasive adaptive prosthetics (NinaPro) database to comprehensively evaluate our proposed HVPN framework. Results showed that when using 200â€‰ms sliding windows to segment data, the proposed HVPN framework could achieve the intrasubject gesture recognition accuracy of 88.4%, 85.8%, 68.2%, 72.9%, and 90.3% and the intersubject gesture recognition accuracy of 84.9%, 82.0%, 65.6%, 70.2%, and 88.9% on the first five subdatabases of NinaPro, respectively, which outperformed the state-of-the-art methods.",0,0
3298,"Integrative Analysis of Gene Expression Through One-Class Logistic Regression Machine Learning Identifies Stemness Features in Multiple Myeloma. Tumor progression includes the obtainment of progenitor and stem cell-like features and the gradual loss of a differentiated phenotype. Stemness was defined as the potential for differentiation and self-renewal from the cell of origin. Previous studies have confirmed the effective application of stemness in a number of malignancies. However, the mechanisms underlying the growth and maintenance of multiple myeloma (MM) stem cells remain unclear. We calculated the stemness index for samples of MM by utilizing a novel one-class logistic regression (OCLR) machine learning algorithm and found that mRNA expression-based stemness index (mRNAsi) was an independent prognostic factor of MM. Based on the same cutoff value, mRNAsi could stratify MM patients into low and high groups with different outcomes. We identified 127 stemness-related signatures using weighted gene co-expression network analysis (WGCNA) and differential expression analysis. Functional annotation and pathway enrichment analysis indicated that these genes were mainly involved in the cell cycle, cell differentiation, and DNA replication and repair. Using the molecular complex detection (MCODE) algorithm, we identified 34 pivotal signatures. Meanwhile, we conducted unsupervised clustering and classified the MM cohorts into three MM stemness (MMS) clusters with distinct prognoses. Samples in MMS-cluster3 possessed the highest stemness fractions and the worst prognosis. Additionally, we applied the ESTIMATE algorithm to infer differential immune infiltration among the three MMS clusters. The immune core and stromal score were significantly lower in MMS-cluster3 than in the other clusters, supporting the negative relation between stemness and anticancer immunity. Finally, we proposed a prognostic nomogram that allows for individualized assessment of the 3- and 5-year overall survival (OS) probabilities among patients with MM. Our study comprehensively assessed the MM stemness index based on large cohorts and built a 34-gene based classifier for predicting prognosis and potential strategies for stemness treatment.",0,0
3304,"Identification of Major Psychiatric Disorders From Resting-State Electroencephalography Using a Machine Learning Approach. We aimed to develop a machine learning (ML) classifier to detect and compare major psychiatric disorders using electroencephalography (EEG). We retrospectively collected data from medical records, intelligence quotient (IQ) scores from psychological assessments, and quantitative EEG (QEEG) at resting-state assessments from 945 subjects [850 patients with major psychiatric disorders (six large-categorical and nine specific disorders) and 95 healthy controls (HCs)]. A combination of QEEG parameters including power spectrum density (PSD) and functional connectivity (FC) at frequency bands was used to establish models for the binary classification between patients with each disorder and HCs. The support vector machine, random forest, and elastic net ML methods were applied, and prediction performances were compared. The elastic net model with IQ adjustment showed the highest accuracy. The best feature combinations and classification accuracies for discrimination between patients and HCs with adjusted IQ were as follows: schizophrenia = alpha PSD, 93.83%; trauma and stress-related disorders = beta FC, 91.21%; anxiety disorders = whole band PSD, 91.03%; mood disorders = theta FC, 89.26%; addictive disorders = theta PSD, 85.66%; and obsessive-compulsive disorder = gamma FC, 74.52%. Our findings suggest that ML in EEG may predict major psychiatric disorders and provide an objective index of psychiatric disorders.",0,0
3305,"Development of Digitally Obtainable 10-Year Risk Scores for Depression and Anxiety in the General Population. The burden of depression and anxiety in the world is rising. Identification of individuals at increased risk of developing these conditions would help to target them for prevention and ultimately reduce the healthcare burden. We developed a 10-year predictive algorithm for depression and anxiety using the full cohort of over 400,000 UK Biobank (UKB) participants without pre-existing depression or anxiety using digitally obtainable information. From the initial 167 variables selected from UKB, processed into 429 features, iterative backward elimination using Cox proportional hazards model was performed to select predictors which account for the majority of its predictive capability. Baseline and reduced models were then trained for depression and anxiety using both Cox and DeepSurv, a deep neural network approach to survival analysis. The baseline Cox model achieved concordance of 0.7772 and 0.7720 on the validation dataset for depression and anxiety, respectively. For the DeepSurv model, respective concordance indices were 0.7810 and 0.7728. After feature selection, the depression model contained 39 predictors and the concordance index was 0.7769 for Cox and 0.7772 for DeepSurv. The reduced anxiety model, with 53 predictors, achieved concordance of 0.7699 for Cox and 0.7710 for DeepSurv. The final models showed good discrimination and calibration in the test datasets. We developed predictive risk scores with high discrimination for depression and anxiety using the UKB cohort, incorporating predictors which are easily obtainable <i>via</i> smartphone. If deployed in a digital solution, it would allow individuals to track their risk, as well as provide some pointers to how to decrease it through lifestyle changes.",0,0
3306,"Clustering of Multiple Psychiatric Disorders Using Functional Connectivity in the Data-Driven Brain Subnetwork. Recently, the dimensional approach has attracted much attention, bringing a paradigm shift to a continuum of understanding of different psychiatric disorders. In line with this new paradigm, we examined whether there was common functional connectivity related to various psychiatric disorders in an unsupervised manner without explicitly using diagnostic label information. To this end, we uniquely applied a newly developed network-based multiple clustering method to resting-state functional connectivity data, which allowed us to identify pairs of relevant brain subnetworks and subject cluster solutions accordingly. Thus, we identified four subject clusters, which were characterized as major depressive disorder (MDD), young healthy control (young HC), schizophrenia (SCZ)/bipolar disorder (BD), and autism spectrum disorder (ASD), respectively, with the relevant brain subnetwork represented by the cerebellum-thalamus-pallidum-temporal circuit. The clustering results were validated using independent datasets. This study is the first cross-disorder analysis in the framework of unsupervised learning of functional connectivity based on a data-driven brain subnetwork.",0,0
3307,"Machine Learning Identification of Pro-arrhythmic Structures in Cardiac Fibrosis. Cardiac fibrosis and other scarring of the heart, arising from conditions ranging from myocardial infarction to ageing, promotes dangerous arrhythmias by blocking the healthy propagation of cardiac excitation. Owing to the complexity of the dynamics of electrical signalling in the heart, however, the connection between different arrangements of blockage and various arrhythmic consequences remains poorly understood. Where a mechanism defies traditional understanding, machine learning can be invaluable for enabling accurate prediction of quantities of interest (measures of arrhythmic risk) in terms of predictor variables (such as the arrangement or pattern of obstructive scarring). In this study, we simulate the propagation of the action potential (AP) in tissue affected by fibrotic changes and hence detect sites that initiate re-entrant activation patterns. By separately considering multiple different stimulus regimes, we directly observe and quantify the sensitivity of re-entry formation to activation sequence in the fibrotic region. Then, by extracting the fibrotic structures around locations that both do and do not initiate re-entries, we use neural networks to determine to what extent re-entry initiation is predictable, and over what spatial scale conduction heterogeneities appear to act to produce this effect. We find that structural information within about 0.5 mm of a given point is sufficient to predict structures that initiate re-entry with more than 90% accuracy.",0,0
3309,"Deep Convolutional Neural Networks With Ensemble Learning and Generative Adversarial Networks for Alzheimer's Disease Image Data Classification. Recent advancements in deep learning (DL) have made possible new methodologies for analyzing massive datasets with intriguing implications in healthcare. Convolutional neural networks (CNN), which have proven to be successful supervised algorithms for classifying imaging data, are of particular interest in the neuroscience community for their utility in the classification of Alzheimer's disease (AD). AD is the leading cause of dementia in the aging population. There remains a critical unmet need for early detection of AD pathogenesis based on non-invasive neuroimaging techniques, such as magnetic resonance imaging (MRI) and positron emission tomography (PET). In this comprehensive review, we explore potential interdisciplinary approaches for early detection and provide insight into recent advances on AD classification using 3D CNN architectures for multi-modal PET/MRI data. We also consider the application of generative adversarial networks (GANs) to overcome pitfalls associated with limited data. Finally, we discuss increasing the robustness of CNNs by combining them with ensemble learning (EL).",0,0
3312,"Decoding Neural Activity in Sulcal and White Matter Areas of the Brain to Accurately Predict Individual Finger Movement and Tactile Stimuli of the Human Hand. Millions of people worldwide suffer motor or sensory impairment due to stroke, spinal cord injury, multiple sclerosis, traumatic brain injury, diabetes, and motor neuron diseases such as ALS (amyotrophic lateral sclerosis). A brain-computer interface (BCI), which links the brain directly to a computer, offers a new way to study the brain and potentially restore impairments in patients living with these debilitating conditions. One of the challenges currently facing BCI technology, however, is to minimize surgical risk while maintaining efficacy. Minimally invasive techniques, such as stereoelectroencephalography (SEEG) have become more widely used in clinical applications in epilepsy patients since they can lead to fewer complications. SEEG depth electrodes also give access to sulcal and white matter areas of the brain but have not been widely studied in brain-computer interfaces. Here we show the first demonstration of decoding sulcal and subcortical activity related to both movement and tactile sensation in the human hand. Furthermore, we have compared decoding performance in SEEG-based depth recordings versus those obtained with electrocorticography electrodes (ECoG) placed on gyri. Initial poor decoding performance and the observation that most neural modulation patterns varied in amplitude trial-to-trial and were transient (significantly shorter than the sustained finger movements studied), led to the development of a feature selection method based on a repeatability metric using temporal correlation. An algorithm based on temporal correlation was developed to isolate features that consistently repeated (required for accurate decoding) and possessed information content related to movement or touch-related stimuli. We subsequently used these features, along with deep learning methods, to automatically classify various motor and sensory events for individual fingers with high accuracy. Repeating features were found in sulcal, gyral, and white matter areas and were predominantly phasic or phasic-tonic across a wide frequency range for both HD (high density) ECoG and SEEG recordings. These findings motivated the use of long short-term memory (LSTM) recurrent neural networks (RNNs) which are well-suited to handling transient input features. Combining temporal correlation-based feature selection with LSTM yielded decoding accuracies of up to 92.04 Â± 1.51% for hand movements, up to 91.69 Â± 0.49% for individual finger movements, and up to 83.49 Â± 0.72% for focal tactile stimuli to individual finger pads while using a relatively small number of SEEG electrodes. These findings may lead to a new class of minimally invasive brain-computer interface systems in the future, increasing its applicability to a wide variety of conditions.",0,0
3314,"Multi-objective Genetic Algorithm Based Deep Learning Model for Automated COVID-19 Detection Using Medical Image Data. In early 2020, the world is amid a significant pandemic due to the novel coronavirus disease outbreak, commonly called the COVID-19. Coronavirus is a lung infection disease caused by the Severe Acute Respiratory Syndrome Coronavirus 2 virus (SARS-CoV-2). Because of its high transmission rate, it is crucial to detect cases as soon as possible to effectively control the spread of this pandemic and treat patients in the early stages. RT-PCR-based kits are the current standard kits used for COVID-19 diagnosis, but these tests take much time despite their high precision. A faster automated diagnostic tool is required for the effective screening of COVID-19.",0,0
3315,"ET-NET: an ensemble of transfer learning models for prediction of COVID-19 infection through chest CT-scan images. The COVID-19 virus has caused a worldwide pandemic, affecting numerous individuals and accounting for more than a million deaths. The countries of the world had to declare complete lockdown when the coronavirus led to community spread. Although the real-time Polymerase Chain Reaction (RT-PCR) test is the gold-standard test for COVID-19 screening, it is not satisfactorily accurate and sensitive. On the other hand, Computer Tomography (CT) scan images are much more sensitive and can be suitable for COVID-19 detection. To this end, in this paper, we develop a fully automated method for fast COVID-19 screening by using chest CT-scan images employing Deep Learning techniques. For this supervised image classification problem, a bootstrap aggregating or Bagging ensemble of three transfer learning models, namely, Inception v3, ResNet34 and DenseNet201, has been used to boost the performance of the individual models. The proposed framework, called ET-NET, has been evaluated on a publicly available dataset, achieving <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>97.81</mn> <mo>Â±</mo> <mn>0.53</mn> <mo>%</mo></mrow> </math> accuracy, <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>97.77</mn> <mo>Â±</mo> <mn>0.58</mn> <mo>%</mo></mrow> </math> precision, <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>97.81</mn> <mo>Â±</mo> <mn>0.52</mn> <mo>%</mo></mrow> </math> sensitivity and <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>97.77</mn> <mo>Â±</mo> <mn>0.57</mn> <mo>%</mo></mrow> </math> specificity on 5-fold cross-validation outperforming the state-of-the-art method on the same dataset by 1.56%. The relevant codes for the proposed approach are accessible in: https://github.com/Rohit-Kundu/ET-NET_Covid-Detection.",0,0
3316,"Machine Learning Model Applied on Chest X-Ray Images Enables Automatic Detection of COVID-19 Cases with High Accuracy. This research was designed to investigate the application of artificial intelligence (AI) in the rapid and accurate diagnosis of coronavirus disease 2019 (COVID-19) using digital chest X-ray images, and to develop a robust computer-aided application for the automatic classification of COVID-19 pneumonia from other pneumonia and normal images.",0,0
3321,"NUVA: A Naming Utterance Verifier for Aphasia Treatment. Anomia (word-finding difficulties) is the hallmark of aphasia, an acquired language disorder most commonly caused by stroke. Assessment of speech performance using picture naming tasks is a key method for both diagnosis and monitoring of responses to treatment interventions by people with aphasia (PWA). Currently, this assessment is conducted manually by speech and language therapists (SLT). Surprisingly, despite advancements in automatic speech recognition (ASR) and artificial intelligence with technologies like deep learning, research on developing automated systems for this task has been scarce. Here we present NUVA, an utterance verification system incorporating a deep learning element that classifies 'correct' versus' incorrect' naming attempts from aphasic stroke patients. When tested on eight native British-English speaking PWA the system's performance accuracy ranged between 83.6% to 93.6%, with a 10-fold cross-validation mean of 89.5%. This performance was not only significantly better than a baseline created for this study using one of the leading commercially available ASRs (Google speech-to-text service) but also comparable in some instances with two independent SLT ratings for the same dataset.",1,1
3325,Development and validation of a deep learning model to screen hypokalemia from electrocardiogram in emergency patients. A deep learning model (DLM) that enables non-invasive hypokalemia screening from an electrocardiogram (ECG) may improve the detection of this life-threatening condition. This study aimed to develop and evaluate the performance of a DLM for the detection of hypokalemia from the ECGs of emergency patients.,0,0
3340,Multiparameter MRI-based radiomics for preoperative prediction of extramural venous invasion in rectal cancer. To compare multiparameter MRI-based radiomics for preoperative prediction of extramural venous invasion (EMVI) in rectal cancer using different machine learning algorithms and to develop and validate the best diagnostic model.,0,0
3341,Diagnosing autism spectrum disorder in children using conventional MRI and apparent diffusion coefficient based deep learning algorithms. To develop and validate deep learning (DL) methods for diagnosing autism spectrum disorder (ASD) based on conventional MRI (cMRI) and apparent diffusion coefficient (ADC) images.,0,0
3344,"COVID-19 detection in chest X-ray images using deep boosted hybrid learning. The new emerging COVID-19, declared a pandemic disease, has affected millions of human lives and caused a massive burden on healthcare centers. Therefore, a quick, accurate, and low-cost computer-based tool is required to timely detect and treat COVID-19 patients. In this work, two new deep learning frameworks: Deep Hybrid Learning (DHL) and Deep Boosted Hybrid Learning (DBHL), is proposed for effective COVID-19 detection in X-ray dataset. In the proposed DHL framework, the representation learning ability of the two developed COVID-RENet-1 & 2 models is exploited individually through a machine learning (ML) classifier. In COVID-RENet models, Region and Edge-based operations are carefully applied to learn region homogeneity and extract boundaries features. While in the case of the proposed DBHL framework, COVID-RENet-1 & 2 are fine-tuned using transfer learning on the chest X-rays. Furthermore, deep feature spaces are generated from the penultimate layers of the two models and then concatenated to get a single enriched boosted feature space. A conventional ML classifier exploits the enriched feature space to achieve better COVID-19 detection performance. The proposed COVID-19 detection frameworks are evaluated on radiologist's authenticated chest X-ray data, and their performance is compared with the well-established CNNs. It is observed through experiments that the proposed DBHL framework, which merges the two-deep CNN feature spaces, yields good performance (accuracy: 98.53%, sensitivity: 0.99, F-score: 0.98, and precision: 0.98). Furthermore, a web-based interface is developed, which takes only 5-10s to detect COVID-19 in each unseen chest X-ray image. This web-predictor is expected to help early diagnosis, save precious lives, and thus positively impact society.",0,0
3345,"Computation of a probabilistic and anisotropic failure metric on the aortic wall using a machine learning-based surrogate model. Scalar-valued failure metrics are commonly used to assess the risk of aortic aneurysm rupture and dissection, which occurs under hypertensive blood pressures brought on by extreme emotional or physical stress. To compute failure metrics under an elevated blood pressure, a classical patient-specific computer model consists of multiple computation steps involving inverse and forward analyses. These classical procedures may be impractical for time-sensitive clinical applications that require prompt feedback to clinicians. In this study, we developed a machine learning-based surrogate model to directly predict a probabilistic and anisotropic failure metric, namely failure probability (FP), on the aortic wall using aorta geometries at the systolic and diastolic phases. Ascending thoracic aortic aneurysm (ATAA) geometries of 60 patients were obtained from their CT scans, and biaxial mechanical testing data of ATAA tissues from 79 patients were collected. Finite element simulations were used to generate datasets for training, validation, and testing of the ML-surrogate model. The testing results demonstrated that the ML-surrogate can compute the maximum FP failure metric, with 0.42% normalized mean absolute error, in 1Â s. To compare the performance of the ML-predicted probabilistic FP metric with other isotropic or deterministic metrics, a numerical case study was performed using synthetic ""baseline"" data. Our results showed that the probabilistic FP metric had more discriminative power than the deterministic Tsai-Hill metric, isotropic maximum principal stress, and aortic diameter criterion.",0,0
3347,"Machine-learning-based predictions of direct-acting antiviral therapy duration for patients with hepatitis C. Hepatitis C, which affects 71 million persons worldwide, is the most common blood-borne pathogen in the United States. Chronic infections can be treated effectively thanks to the availability of modern direct-acting antiviral (DAA) therapies. Real-world data on the duration of DAA therapy, which can be used to optimize and guide the course of therapy, may also be useful in determining quality of life enhancements based upon total required supply of medication and long-term improvements to quality of life. We developed a machine learning model to identify patient characteristics associated with prolonged DAA treatment duration.",0,0
3348,"Risk prediction of diabetic nephropathy using machine learning techniques: A pilot study with secondary data. This research work presented a comparative study of machine learning (ML), including two objectives: (i) determination of the risk factors of diabetic nephropathy (DN) based on principal component analysis (PCA) via different cutoffs; (ii) prediction of DN patients using ML-based techniques.",0,0
3352,"Development and evaluation of a machine learning-based point-of-care screening tool for genetic syndromes in children: a multinational retrospective study. Delays in the diagnosis of genetic syndromes are common, particularly in low and middle-income countries with limited access to genetic screening services. We, therefore, aimed to develop and evaluate a machine learning-based screening technology using facial photographs to evaluate a child's risk of presenting with a genetic syndrome for use at the point of care.",0,0
3359,Automatic identification of suspicious bone metastatic lesions in bone scintigraphy using convolutional neural network. We aimed to construct an artificial intelligence (AI) guided identification of suspicious bone metastatic lesions from the whole-body bone scintigraphy (WBS) images by convolutional neural networks (CNNs).,0,0
3360,[Application of machine learning for predicting the outcome of treatment of patients with schizophrenia according to the indicators of Â«ThrombodynamicsÂ» test]. To identify relationships between thrombodynamic values and the severity of the condition in patients with schizophrenia spectrum disorders (SSD) before and after treatment.,0,0
3363,"A DNA-derived phage nose using machine learning and artificial neural processing for diagnosing lung cancer. There is a growing interest in electronic nose-based diagnostic systems that are fast and portable. However, existing technologies are suitable only for operation in the laboratory, making them difficult to apply in a rapid, non-face-to-face, and field-suitable manner. Here, we demonstrate a DNA-derived phage nose (D<sup>2</sup>pNose) as a portable respiratory disease diagnosis system requiring no pretreatment. D<sup>2</sup>pNose was produced based on phage colour films implanted with DNA sequences from mammalian olfactory receptor cells, and as a result, it possesses the comprehensive reactivity of these cells. The manipulated surface chemistry of the genetically engineered phages was verified through a correlation analysis between the calculated and the experimentally measured reactivity. Breaths from 31 healthy subjects and 31 lung cancer patients were collected and exposed to D<sup>2</sup>pNose without pretreatment. With the help of deep learning and neural pattern separation, D<sup>2</sup>pNose has achieved a diagnostic success rate of over 75% and a classification success rate of over 86% for lung cancer based on raw human breath. Based on these results, D<sup>2</sup>pNose can be expected to be directly applicable to other respiratory diseases.",0,0
3366,"Automated detection and explainability of pathological gait patterns using a one-class support vector machine trained on inertial measurement unit based gait data. Machine learning approaches for the classification of pathological gait based on kinematic data, e.g. derived from inertial sensors, are commonly used in terms of a multi-class classification problem. However, there is a lack of research regarding one-class classifiers that are independent of certain pathologies. Therefore, it was the aim of this work to design a one-class classifier based on healthy norm-data that provides not only a prediction probability but rather an explanation of the classification decision, increasing the acceptance of this machine learning approach.",0,0
3368,Interpretable prediction of 3-year all-cause mortality in patients with heart failure caused by coronary heart disease based on machine learning and SHAP. This study sought to evaluate the performance of machine learning (ML) models and establish an explainable ML model with good prediction of 3-year all-cause mortality in patients with heart failure (HF) caused by coronary heart disease (CHD).,0,0
3369,"AFCNNet: Automated detection of AF using chirplet transform and deep convolutional bidirectional long short term memory network with ECG signals. Atrial fibrillation (AF) is the most common type of cardiac arrhythmia and is characterized by the heart's beating in an uncoordinated manner. In clinical studies, patients often do not have visible symptoms during AF, and hence it is harder to detect this cardiac ailment. Therefore, automated detection of AF using the electrocardiogram (ECG) signals can reduce the risk of stroke, coronary artery disease, and other cardiovascular complications. In this paper, a novel time-frequency domain deep learning-based approach is proposed to detect AF and classify terminating and non-terminating AF episodes using ECG signals. This approach involves evaluating the time-frequency representation (TFR) of ECG signals using the chirplet transform. The two-dimensional (2D) deep convolutional bidirectional long short-term memory (BLSTM) neural network model is used to detect and classify AF episodes using the time-frequency images of ECG signals. The proposed TFR based 2D deep learning approach is evaluated using the ECG signals from three public databases. Our developed approach has obtained an accuracy, sensitivity, and specificity of 99.18% (Confidence interval (CI) as [98.86, 99.49]), 99.17% (CI as [98.85 99.49]), and 99.18% (CI as [98.86 99.49]), respectively, with 10-fold cross-validation (CV) technique to detect AF automatically. The proposed approach also classified terminating and non-terminating AF episodes with an average accuracy of 75.86%. The average accuracy value obtained using the proposed approach is higher than the short-time Fourier transform (STFT), discrete-time continuous wavelet transform (DT-CWT), and Stockwell transform (ST) based time-frequency analysis methods with deep convolutional BLSTM models to detect AF. The proposed approach has better AF detection performance than the existing deep learning-based techniques using ECG signals from the MIT-BIH database.",0,0
3372,Preoperative prediction of pathological grading of hepatocellular carcinoma using machine learning-based ultrasomics: A multicenter study. The present study investigated the value of ultrasomics signatures in the preoperative prediction of the pathological grading of hepatocellular carcinoma (HCC) via machine learning.,0,0
3384,"Catheter position prediction using deep-learning-based multi-atlas registration for high-dose rate prostate brachytherapy. High-dose-rate (HDR) prostate brachytherapy involves treatment catheter placement, which is currently empirical and physician dependent. The lack of proper catheter placement guidance during the procedure has left the physicians to rely on a heuristic thinking-while-doing technique, which may cause large catheter placement variation and increased plan quality uncertainty. Therefore, the achievable dose distribution could not be quantified prior to the catheter placement. To overcome this challenge, we proposed a learning-based method to provide HDR catheter placement guidance for prostate cancer patients undergoing HDR brachytherapy.",0,0
3391,Gd-EOB-DTPA-enhanced MRI radiomics to predict vessels encapsulating tumor clusters (VETC) and patient prognosis in hepatocellular carcinoma. The study was to develop a Gd-EOB-DTPA-enhanced MRI radiomics model for preoperative prediction of VETC and patient prognosis in hepatocellular cancer (HCC).,0,0
3393,"A machine learning-based biological aging prediction and its associations with healthy lifestyles: the Dongfeng-Tongji cohort. This study aims to establish a biological age (BA) predictor and to investigate the roles of lifestyles on biological aging. The 14,848 participants with the available information of multisystem measurements from the Dongfeng-Tongji cohort were used to estimate BA. We developed a composite BA predictor showing a high correlation with chronological age (CA) (rÂ =Â 0.82) by using an extreme gradient boosting (XGBoost) algorithm. The average frequency hearing threshold, forced expiratory volume in 1 second (FEV<sub>1</sub> ), gender, systolic blood pressure, and homocysteine ranked as the top five important features for the BA predictor. Two aging indexes, recorded as the AgingAccel (the residual from regressing predicted age on CA) and aging rate (the ratio of predicted age to CA), showed positive associations with the risks of all-cause (HR (95% CI)Â =Â 1.12 (1.10-1.14) and 1.08 (1.07-1.10), respectively) and cause-specific (HRs ranged from 1.06 to âˆ¼1.15) mortality. Each 1-point increase in healthy lifestyle score (including normal body mass index, never smoking, moderate alcohol drinking, physically active, and sleep 7-9 h/night) was associated with a 0.21-year decrease in the AgingAccel (95% CI: -0.27 to -0.15) and a 0.4% decrease in the aging rate (95% CI: -0.5% to -0.3%). This study developed a machine learning-based BA predictor in a prospective Chinese cohort. Adherence to healthy lifestyles showed associations with delayed biological aging, which highlights potential preventive interventions.",0,0
3399,"Identifying the predictive effectiveness of a genetic risk score for incident hypertension using machine learning methods among populations in rural China. Current studies have shown the controversial effect of genetic risk scores (GRSs) in hypertension prediction. Machine learning methods are used extensively in the medical field but rarely in the mining of genetic information. This study aims to determine whether genetic information can improve the prediction of incident hypertension using machine learning approaches in a prospective study. The study recruited 4592 subjects without hypertension at baseline from a cohort study conducted in rural China. A polygenic risk score (PGGRS) was calculated using 13 SNPs. According to a ratio of 7:3, subjects were randomly allocated to the train and test datasets. Models with and without the PGGRS were established using the train dataset with Cox regression, artificial neural network (ANN), random forest (RF), and gradient boosting machine (GBM) methods. The discrimination and reclassification of models were estimated using the test dataset. The PGGRS showed a significant association with the risk of incident hypertension (HR (95% CI), 1.046 (1.004, 1.090), Pâ€‰=â€‰0.031) irrespective of baseline blood pressure. Models that did not include the PGGRS achieved AUCs (95% CI) of 0.785 (0.763, 0.807), 0.790 (0.768, 0.811), 0.838 (0.817, 0.857), and 0.854 (0.835, 0.873) for the Cox, ANN, RF, and GBM methods, respectively. The addition of the PGGRS led to the improvement of the AUC by 0.001, 0.008, 0.023, and 0.017; IDI by 1.39%, 2.86%, 4.73%, and 4.68%; and NRI by 25.05%, 13.01%, 44.87%, and 22.94%, respectively. Incident hypertension risk was better predicted by the traditional+PGGRS model, especially when machine learning approaches were used, suggesting that genetic information may have the potential to identify new hypertension cases using machine learning methods in resource-limited areas. CLINICAL TRIAL REGISTRATION: The Henan Rural Cohort Study has been registered at the Chinese Clinical Trial Register (Registration number: ChiCTR-OOC-15006699). http://www.chictr.org.cn/showproj.aspx?proj=11375 .",0,0
3400,"Facial expressions can detect Parkinson's disease: preliminary evidence from videos collected online. A prevalent symptom of Parkinson's disease (PD) is hypomimia - reduced facial expressions. In this paper, we present a method for diagnosing PD that utilizes the study of micro-expressions. We analyzed the facial action units (AU) from 1812 videos of 604 individuals (61 with PD and 543 without PD, with a mean age 63.9â€‰y/o, sd. 7.8) collected online through a web-based tool ( www.parktest.net ). In these videos, participants were asked to make three facial expressions (a smiling, disgusted, and surprised face) followed by a neutral face. Using techniques from computer vision and machine learning, we objectively measured the variance of the facial muscle movements and used it to distinguish between individuals with and without PD. The prediction accuracy using the facial micro-expressions was comparable to methodologies that utilize motor symptoms. Logistic regression analysis revealed that participants with PD had less variance in AU6 (cheek raiser), AU12 (lip corner puller), and AU4 (brow lowerer) than non-PD individuals. An automated classifier using Support Vector Machine was trained on the variances and achieved 95.6% accuracy. Using facial expressions as a future digital biomarker for PD could be potentially transformative for patients in need of remote diagnoses due to physical separation (e.g., due to COVID) or immobility.",0,0
3401,Artificial intelligence for target prostate biopsy outcomes prediction the potential application of fuzzy logic. In current precision prostate cancer (PCa) surgery era the identification of the best patients candidate for prostate biopsy still remains an open issue. The aim of this study was to evaluate if the prostate target biopsy (TB) outcomes could be predicted by using artificial intelligence approach based on a set of clinical pre-biopsy.,0,0
3404,"PodoSighter: A Cloud-Based Tool for Label-Free Podocyte Detection in Kidney Whole Slide Images. <b>Background:</b> Podocyte depletion precedes progressive glomerular damage in several renal diseases. However, the current standard of visual detection and quantification of podocyte nuclei from brightfield microscopy images is laborious and imprecise. <b>Methods:</b> We have developed PodoSighter, an online cloud-based tool, to automatically identify and quantify podocyte nuclei from giga-pixel brightfield whole-slide images (WSIs) using deep learning. Ground-truth to train the tool used immunohistochemically or immunofluorescence-labeled images from a multi-institutional cohort of 122 histologic sections from mouse, rat, and human kidneys. To demonstrate generalizability of our tool in investigating podocyte loss in clinically relevant samples, we tested it in rodent models of glomerular diseases, including diabetic kidney disease, crescentic glomerulonephritis, and dose-dependent direct podocyte toxicity and depletion, as well as in human biopsies from steroid resistant nephrotic syndrome and from human autopsy tissues. <b>Results:</b> The optimal model yielded high sensitivity/specificity of 0.80/0.80, 0.81/0.86, and 0.80/0.91, in mouse, rat, and human images, respectively, from periodic-acid Schiff-stained WSIs. Furthermore, the podocyte nuclear morphometrics extracted using PodoSighter were informative in identifying diseased glomeruli. We have made PodoSighter freely available to the general public as turnkey plugins in a cloud-based web application for end-users. <b>Conclusion:</b> Our study demonstrates an automated computational approach to detect and quantify podocyte nuclei in standard histologically-stained WSIs, facilitating podocyte research and enabling possible future clinical applications.",0,0
3408,"Anatomical subject validation of an instrumented hammer using machine learning for the classification of osteotomy fracture in rhinoplasty. Osteotomies during rhinoplasty are usually based on the surgeon's proprioception to determine the number and the strength of the impacts. The aim of this study is to determine whether a hammer instrumented with a force sensor can be used to classify fractures and to determine the location of the osteotome tip. Two lateral osteotomies were realized in nine anatomical subjects using an instrumented hammer recording the evolution of the impact force. Two indicators Ï„ and Î» were derived from the signal, and video analysis was used to determine whether the osteotome tip was located in nasal or frontal bone as well as the condition of the bone tissue around the osteotome tip. A machine-learning algorithm was used to predict the condition of bone tissue after each impact. The algorithm was able to predict the condition of the bone after the impacts with an accuracy of 83%, 91%, and 93% when considering a tolerance of 0, 1, and 2 impacts, respectively. Moreover, in nasal bone, the values of Ï„ and Î» were significantly lower (pÂ <Â 10<sup>-10</sup>) and higher (pÂ <Â 10<sup>-4</sup>) than in frontal bone, respectively. This study paves the way for the development of the instrumented hammer as a decision support system.",0,0
3411,"Hyperspectral imaging and artificial intelligence to detect oral malignancy - part 1 - automated tissue classification of oral muscle, fat and mucosa using a light-weight 6-layer deep neural network. Hyperspectral imaging (HSI) is a promising non-contact approach to tissue diagnostics, generating large amounts of raw data for whose processing computer vision (i.e. deep learning) is particularly suitable. Aim of this proof of principle study was the classification of hyperspectral (HS)-reflectance values into the human-oral tissue types fat, muscle and mucosa using deep learning methods. Furthermore, the tissue-specific hyperspectral signatures collected will serve as a representative reference for the future assessment of oral pathological changes in the sense of a HS-library.",0,0
3430,"Identification of impulsive adolescents with a functional near infrared spectroscopy (fNIRS) based decision support system. <i>Background.</i>The gold standard for diagnosing impulsivity relies on clinical interviews, behavioral questionnaires and rating scales which are highly subjective.<i>Objective.</i>The aim of this study was to develop a functional near infrared spectroscopy (fNIRS) based classification approach for correct identification of impulsive adolescents. Taking into account the multifaceted nature of impulsivity, we propose that combining informative features from clinical, behavioral and neurophysiological domains might better elucidate the neurobiological distinction underlying symptoms of impulsivity.<i>Approach</i>. Hemodynamic and behavioral information was collected from 38 impulsive adolescents and from 33 non-impulsive adolescents during a Stroop task with concurrent fNIRS recordings. Connectivity-based features were computed from the hemodynamic signals and a neural efficiency metric was computed by fusing the behavioral and connectivity-based features. We tested the efficacy of two commonly used supervised machine-learning methods, namely the support vector machines (SVM) and artificial neural networks (ANN) in discriminating impulsive adolescents from their non-impulsive peers when trained with multi-domain features. Wrapper method was adapted to identify the informative biomarkers in each domain. Classification accuracies of each algorithm were computed after 10 runs of a 10-fold cross-validation procedure, conducted for 7 different combinations of the 3-domain feature set.<i>Main results.</i>Both SVM and ANN achieved diagnostic accuracies above 90% when trained with Wrapper-selected clinical, behavioral and fNIRS derived features. SVM performed significantly higher than ANN in terms of the accuracy metric (92.2% and 90.16%, respectively,<i>p</i>= 0.005).<i>Significance.</i>Preliminary findings show the feasibility and applicability of both machine-learning based methods for correct identification of impulsive adolescents when trained with multi-domain data involving clinical interviews, fNIRS based biomarkers and neuropsychiatric test measures. The proposed automated classification approach holds promise for assisting the clinical practice of diagnosing impulsivity and other psychiatric disorders. Our results also pave the path for a computer-aided diagnosis perspective for rating the severity of impulsivity.",0,0
3432,"Data-driven electrophysiological feature based on deep learning to detect epileptic seizures. <i>Objective</i>. To identify a new electrophysiological feature characterising the epileptic seizures, which is commonly observed in different types of epilepsy.<i>Methods</i>. We recorded the intracranial electroencephalogram (iEEG) of 21 patients (12 women and 9 men) with multiple types of refractory epilepsy. The raw iEEG signals of the early phase of epileptic seizures and interictal states were classified by a convolutional neural network (Epi-Net). For comparison, the same signals were classified by a support vector machine (SVM) using the spectral power and phase-amplitude coupling. The features learned by Epi-Net were derived by a modified integrated gradients method. We considered the product of powers multiplied by the relative contribution of each frequency amplitude as a data-driven epileptogenicity index (d-EI). We compared the d-EI and other conventional features in terms of accuracy to detect the epileptic seizures. Finally, we compared the d-EI among the electrodes to evaluate its relationship with the resected area and the Engel classification.<i>Results</i>. Epi-Net successfully identified the epileptic seizures, with an area under the receiver operating characteristic curve of 0.944 Â± 0.067, which was significantly larger than that of the SVM (0.808 Â± 0.253,<i>n =</i>21;<i>p =</i>0.025). The learned iEEG signals were characterised by increased powers of 17-92 Hz and >180 Hz in addition to decreased powers of other frequencies. The proposed d-EI detected them with better accuracy than the other iEEG features. Moreover, the surgical resection of areas with a larger increase in d-EI was observed for all nine patients with Engel class â©½1, but not for the 4 of 12 patients with Engel class >1, demonstrating the significant association with seizure outcomes.<i>Significance.</i>We derived an iEEG feature from the trained Epi-Net, which identified the epileptic seizures with improved accuracy and might contribute to identification of the epileptogenic zone.",0,0
3436,"Feature selection and predicting chemotherapy-induced ulcerative mucositis using machine learning methods. Ulcerative mucositis (UM) is a devastating complication of most cancer therapies with less recognized risk factors. Whilst risk predictions are most vital in adverse events, we utilized Machine learning (ML) approaches for predicting chemotherapy-induced UM.",0,0
3439,"EEG feature fusion for motor imagery: A new robust framework towards stroke patients rehabilitation. Stroke is the second foremost cause of death worldwide and is one of the most common causes of disability. Several approaches have been proposed to manage stroke patient rehabilitation such as robotic devices and virtual reality systems, and researchers have found that the brain-computer interfaces (BCI) approaches can provide better results. Therefore, the most challenging tasks with BCI applications involve identifying the best technique(s) that can reveal the neuron stimulus information from the patients' brains and extracting the most effective features from these signals as well. Accordingly, the main novelty of this paper is twofold: propose a new feature fusion method for motor imagery (MI)-based BCI and develop an automatic MI framework to detect the changes pre- and post-rehabilitation. This study investigated the electroencephalography (EEG) dataset from post-stroke patients with upper extremity hemiparesis. All patients performed 25 MI-based BCI sessions with follow up assessment visits to examine the functional changes before and after EEG neurorehabilitation. In the first stage, conventional filters and automatic independent component analysis with wavelet transform (AICA-WT) denoising technique were used. Next, attributes from time, entropy and frequency domains were computed, and the effective features were combined into time-entropy-frequency (TEF) attributes. Consequently, the AICA-WT and the TEF fusion set were utilised to develop an AICA-WT-TEF framework. Then, support vector machine (SVM), k-nearest neighbours (kNN) and random forest (RF) classification technique were tested for MI-based BCI rehabilitation. The proposed AICA-WT-TEF framework with RF classifier achieves the best results compared with other classifiers. Finally, the proposed framework and feature fusion set achieve a significant performance in terms of accuracy measures compared to the state-of-the-art. Therefore, the proposed methods could be crucial for improving the process of automatic MI rehabilitation and are recommended for implementation in real-time applications.",0,0
3441,"TP-CNN: A Detection Method for atrial fibrillation based on transposed projection signals with compressed sensed ECG. Atrial fibrillation (AF) is the most prevalent arrhythmia, which increases the mortality of several complications. The use of wearable devices to detect atrial fibrillation is currently attracting a great deal of attention. Patients use wearable devices to continuously collect individual ECG signals and transmit them to the cloud for diagnosis. However, the ECG acquisition and transmission of wearable devices consumes a lot of energy. In order to solve this problem, some scholars have skipped the complex reconstruction process of compressed ECG signals and directly classified the compressed ECG signals, but the AF recognition rate is not high by this method. There is no explanation as to why the compressed ECG signals can be used for AF detection.",0,0
3442,"Hippocampal Resting-State Functional Connectivity Forecasts Individual PTSD Symptoms: A Data-Driven Approach. Posttraumatic Stress Disorder (PTSD) is a debilitating disorder and there is no current accurate prediction of who develops it after trauma. Neurobiologically, individuals with chronic PTSD exhibit aberrant resting-state functional connectivity (rsFC) between the hippocampus and other brain regions (e.g., amygdala, prefrontal cortex, posterior cingulate), and these aberrations correlate with severity of illness. Prior small-scale research (n < 25) has also shown that hippocampal-rsFC measured acutely after trauma is predictive of future severity using an ROI-based approach. While a promising biomarker, to-date no study has employed a data-driven approach to test whole-brain hippocampal-FC patterns in forecasting the development of PTSD symptoms.",0,0
3448,Deep Learning-Enabled Identification of Autoimmune Encephalitis on 3D Multi-Sequence MRI. Autoimmune encephalitis (AE) is a noninfectious emergency with severe clinical attacks. It is difficult for the earlier diagnosis of acute AE due to the lack of antibody detection resources.,0,0
3453,"Self-supervised Multi-modal Hybrid Fusion Network for Brain Tumor Segmentation. Accurate medical image segmentation of brain tumors is necessary for the diagnosing, monitoring, and treating disease. In recent years, with the gradual emergence of multi-sequence magnetic resonance imaging (MRI), multi-modal MRI diagnosis has played an increasingly important role in the early diagnosis of brain tumors by providing complementary information for a given lesion. Different MRI modalities vary significantly in context, as well as in coarse and fine information. As the manual identification of brain tumors is very complicated, it usually requires the lengthy consultation of multiple experts. The automatic segmentation of brain tumors from MRI images can thus greatly reduce the workload of doctors and buy more time for treating patients. In this paper, we propose a multi-modal brain tumor segmentation framework that adopts the hybrid fusion of modality-specific features using a self-supervised learning strategy. The algorithm is based on a fully convolutional neural network. Firstly, we propose a multi-input architecture that learns independent features from multi-modal data, and can be adapted to different numbers of multi-modal inputs. Compared with single-modal multi-channel networks, our model provides a better feature extractor for segmentation tasks, which learns cross-modal information from multi-modal data. Secondly, we propose a new feature fusion scheme, named hybrid attentional fusion. This scheme enables the network to learn the hybrid representation of multiple features and capture the correlation information between them through an attention mechanism. Unlike popular methods, such as feature map concatenation, this scheme focuses on the complementarity between multi-modal data, which can significantly improve the segmentation results of specific regions. Thirdly, we propose a self-supervised learning strategy for brain tumor segmentation tasks. Our experimental results demonstrate the effectiveness of the proposed model against other state-of-the-art multi-modal medical segmentation methods.",0,0
3460,Development of multi-class computer-aided diagnostic systems using the NICE/JNET classifications for colorectal lesions. Diagnostic support using artificial intelligence may contribute to the equalization of endoscopic diagnosis of colorectal lesions. We developed computer-aided diagnosis (CADx) support system for diagnosing colorectal lesions using the NBI International Colorectal Endoscopic (NICE) classification and the Japan NBI Expert Team (JNET) classification.,0,0
3461,"Extraction of metastasis hotspots in a whole-body bone scintigram based on bilateral asymmetry. A hotspot of bone metastatic lesion in a whole-body bone scintigram is often observed as left-right asymmetry. The purpose of this study is to present a network to evaluate bilateral difference of a whole-body bone scintigram, and to subsequently integrate it with our previous network that extracts the hotspot from a pair of anterior and posterior images.",0,0
3462,Automatic machine learning based on native T1 mapping can identify myocardial fibrosis in patients with hypertrophic cardiomyopathy. To investigate the feasibility of automatic machine learning (autoML) based on native T1 mapping to predict late gadolinium enhancement (LGE) status in hypertrophic cardiomyopathy (HCM).,0,0
3465,"Metagenomic evidence for a polymicrobial signature of sepsis. Our understanding of the host component of sepsis has made significant progress. However, detailed study of the microorganisms causing sepsis, either as single pathogens or microbial assemblages, has received far less attention. Metagenomic data offer opportunities to characterize the microbial communities found in septic and healthy individuals. In this study we apply gradient-boosted tree classifiers and a novel computational decontamination technique built upon SHapley Additive exPlanations (SHAP) to identify microbial hallmarks which discriminate blood metagenomic samples of septic patients from that of healthy individuals. Classifiers had high performance when using the read assignments to microbial genera [area under the receiver operating characteristic (AUROC=0.995)], including after removal of species 'culture-confirmed' as the cause of sepsis through clinical testing (AUROC=0.915). Models trained on single genera were inferior to those employing a polymicrobial model and we identified multiple co-occurring bacterial genera absent from healthy controls. While prevailing diagnostic paradigms seek to identify single pathogens, our results point to the involvement of a polymicrobial community in sepsis. We demonstrate the importance of the microbial component in characterising sepsis, which may offer new biological insights into the aetiology of sepsis, and ultimately support the development of clinical diagnostic or even prognostic tools.",0,0
3472,Heterogeneity by global and textural feature analysis in F-18 FP-CIT brain PET images for diagnosis of Parkinson's disease. The quantification of heterogeneity for the striatum and whole brain with F-18 FP-CIT PET images will be useful for diagnosis. The index obtained from texture analysis on PET images is related to pathological change that the neuronal loss of the nigrostriatal tract is heterogeneous according to the disease state. The aim of this study is to evaluate various heterogeneity indices of F-18 FP-CIT PET images in the diagnosis of Parkinson's disease (PD) patients and to access the diagnostic accuracy of the indices using machine learning (ML).,0,0
3475,"Automated segmentation of biventricular contours in tissue phase mapping using deep learning. Tissue phase mapping (TPM) is an MRI technique for quantification of regional biventricular myocardial velocities. Despite its potential, clinical use is limited due to the requisite labor-intensive manual segmentation of cardiac contours for all time frames. The purpose of this study was to develop a deep learning (DL) network for automated segmentation of TPM images, without significant loss in segmentation and myocardial velocity quantification accuracy compared with manual segmentation. We implemented a multi-channel 3D (three dimensional; 2Dâ€‰+â€‰time) dense U-Net that trained on magnitude and phase images and combined cross-entropy, Dice, and Hausdorff distance loss terms to improve the segmentation accuracy and suppress unnatural boundaries. The dense U-Net was trained and tested with 150 multi-slice, multi-phase TPM scans (114 scans for training, 36 for testing) from 99 heart transplant patients (44 females, 1-4 scans/patient), where the magnitude and velocity-encoded (V<sub>x</sub> , V<sub>y</sub> , V<sub>z</sub> ) images were used as input and the corresponding manual segmentation masks were used as reference. The accuracy of DL segmentation was evaluated using quantitative metrics (Dice scores, Hausdorff distance) and linear regression and Bland-Altman analyses on the resulting peak radial and longitudinal velocities (V<sub>r</sub> and V<sub>z</sub> ). The mean segmentation time was about 2â€‰h per patient for manual and 1.9â€‰Â±â€‰0.3â€‰s for DL. Our network produced good accuracy (median Diceâ€‰=â€‰0.85 for left ventricle (LV), 0.64 for right ventricle (RV), Hausdorff distanceâ€‰=â€‰3.17 pixels) compared with manual segmentation. Peak V<sub>r</sub> and V<sub>z</sub> measured from manual and DL segmentations were strongly correlated (RÂ â‰¥â€‰0.88) and in good agreement with manual analysis (mean difference and limits of agreement for V<sub>z</sub> and V<sub>r</sub> were -0.05â€‰Â±â€‰0.98â€‰cm/s and -0.06â€‰Â±â€‰1.18â€‰cm/s for LV, and -0.21â€‰Â±â€‰2.33â€‰cm/s and 0.46â€‰Â±â€‰4.00â€‰cm/s for RV, respectively). The proposed multi-channel 3D dense U-Net was capable of reducing the segmentation time by 3,600-fold, without significant loss in accuracy in tissue velocity measurements.",0,0
3480,"Your mileage may vary: impact of data input method for a deep learning bone age app's predictions. The purpose of this study was to evaluate agreement in predictions made by a bone age prediction application (""app"") among three data input methods.",0,0
3481,"Detecting hip osteoarthritis on clinical CT: a deep learning application based on 2-D summation images derived from CT. We developed and compared deep learning models to detect hip osteoarthritis on clinical CT. The CT-based summation images, CT-AP, that resemble X-ray radiographs can detect radiographic hip osteoarthritis and in the absence of large training data, a reliable deep learning model can be optimized by combining CT-AP and X-ray images.",0,0
3483,Machine Learning Prediction of Death in Critically Ill Patients With Coronavirus Disease 2019. Critically ill patients with coronavirus disease 2019 have variable mortality. Risk scores could improve care and be used for prognostic enrichment in trials. We aimed to compare machine learning algorithms and develop a simple tool for predicting 28-day mortality in ICU patients with coronavirus disease 2019.,0,0
3490,Ensemble learning accurately predicts the potential benefits of thrombolytic therapy in acute ischemic stroke. Finding methods to accurately predict the final infarct volumes for acute ischemic stroke patients with full or no recanalization would significantly help to evaluate the potential benefits of thrombolytic therapy. We proposed such a method by constructing a model of ensemble deep learning and machine learning using diffusion-weighted imaging (DWI) only.,0,0
3496,"An integrated mass spectrometry imaging and digital pathology workflow for objective detection of colorectal tumours by unique atomic signatures. Tumours are abnormal growths of cells that reproduce by redirecting essential nutrients and resources from surrounding tissue. Changes to cell metabolism that trigger the growth of tumours are reflected in subtle differences between the chemical composition of healthy and malignant cells. We used LA-ICP-MS imaging to investigate whether these chemical differences can be used to spatially identify tumours and support detection of primary colorectal tumours in anatomical pathology. First, we generated quantitative LA-ICP-MS images of three colorectal surgical resections with case-matched normal intestinal wall tissue and used this data in a Monte Carlo optimisation experiment to develop an algorithm that can classify pixels as tumour positive or negative. Blinded testing and interrogation of LA-ICP-MS images with micrographs of haematoxylin and eosin stained and Ki67 immunolabelled sections revealed Monte Carlo optimisation accurately identified primary tumour cells, as well as returning false positive pixels in areas of high cell proliferation. We analysed an additional 11 surgical resections of primary colorectal tumours and re-developed our image processing method to include a random forest regression machine learning model to correctly identify heterogenous tumours and exclude false positive pixels in images of non-malignant tissue. Our final model used over 1.6 billion calculations to correctly discern healthy cells from various types and stages of invasive colorectal tumours. The imaging mass spectrometry and data analysis methods described, developed in partnership with clinical cancer researchers, have the potential to further support cancer detection as part of a comprehensive digital pathology approach to cancer care through validation of a new chemical biomarker of tumour cells.",0,0
3498,"Deep Learning-Based Image Automatic Assessment and Nursing of Upper Limb Motor Function in Stroke Patients. This paper mainly introduces the relevant contents of automatic assessment of upper limb mobility after stroke, including the relevant knowledge of clinical assessment of upper limb mobility, Kinect sensor to realize spatial location tracking of upper limb bone points, and GCRNN model construction process. Through the detailed analysis of all FMA evaluation items, a unique experimental data acquisition environment and evaluation tasks were set up, and the results of FMA prediction using bone point data of each evaluation task were obtained. Through different number and combination of tasks, the best coefficient of determination was achieved when task 1, task 2, and task 5 were simultaneously used as input for FMA prediction. At the same time, in order to verify the superior performance of the proposed method, a comparative experiment was set with LSTM, CNN, and other deep learning algorithms widely used. <i>Conclusion</i>. GCRNN was able to extract the motion features of the upper limb during the process of movement from the two dimensions of space and time and finally reached the best prediction performance with a coefficient of determination of 0.89.",0,0
3503,"Image-based assessment of extracellular mucin-to-tumor area predicts consensus molecular subtypes (CMS) in colorectal cancer. The backbone of all colorectal cancer classifications including the consensus molecular subtypes (CMS) highlights microsatellite instability (MSI) as a key molecular pathway. Although mucinous histology (generally defined asÂ >50% extracellular mucin-to-tumor area) is a ""typical"" feature of MSI, it is not limited to this subgroup. Here, we investigate the association of CMS classification and mucin-to-tumor area quantified using a deep learning algorithm, and Â the expression of specific mucins in predicting CMS groups and clinical outcome. A weakly supervised segmentation method was developed to quantify extracellular mucin-to-tumor area in H&E images. Performance was compared to two pathologists' scores, then applied to two cohorts: (1) TCGA (nâ€‰=â€‰871 slides/412 patients) used for mucin-CMS group correlation and (2) Bern (nâ€‰=â€‰775 slides/517 patients) for histopathological correlations and next-generation Tissue Microarray construction. TCGA and CPTAC (nâ€‰=â€‰85 patients) were used to further validate mucin detection and CMS classification by gene and protein expression analysis for MUC2, MUC4, MUC5AC and MUC5B. An excellent inter-observer agreement between pathologists' scores and the algorithm wasÂ obtained (ICCâ€‰=â€‰0.92). In TCGA, mucinous tumors were predominantly CMS1 (25.7%), CMS3 (24.6%) and CMS4 (16.2%). Average mucin in CMS2 was 1.8%, indicating negligible amounts. RNA and protein expression of MUC2, MUC4, MUC5AC and MUC5B were low-to-absent in CMS2. MUC5AC protein expressionÂ correlated with aggressive tumor features (e.g., distant metastases (pâ€‰=â€‰0.0334), BRAF mutation (pâ€‰<â€‰0.0001), mismatch repair-deficiency (pâ€‰<â€‰0.0001), andÂ unfavorable 5-year overall survival (44% versus 65% for positive/negative staining). MUC2 expression showed the opposite trend, correlating with less lymphatic (pâ€‰=â€‰0.0096) and venous vessel invasion (pâ€‰=â€‰0.0023), no impact on survival.The absence of mucin-expressing tumors in CMS2 provides an important phenotype-genotype correlation. Together with MSI, mucinous histology may help predict CMS classification using only histopathology and should be considered in future image classifiers of molecular subtypes.",1,1
3511,"5G-enabled contactless multi-user presence and activity detection for independent assisted living. Wireless sensing is the state-of-the-art technique for next generation health activity monitoring. Smart homes and healthcare centres have a demand for multi-subject health activity monitoring to cater for future requirements. 5G-sensing coupled with deep learning models has enabled smart health monitoring systems, which have the potential to classify multiple activities based on variations in channel state information (CSI) of wireless signals. Proposed is the first 5G-enabled system operating at 3.75 GHz for multi-subject, in-home health activity monitoring, to the best of the authors' knowledge. Classified are activities of daily life performed by up to 4 subjects, in 16 categories. The proposed system combines subject count and activities performed in different classes together, resulting in simultaneous identification of occupancy count and activities performed. The CSI amplitudes obtained from 51 subcarriers of the wireless signal are processed and combined to capture variations due to simultaneous multi-subject movements. A deep learning convolutional neural network is engineered and trained on the CSI data to differentiate multi-subject activities. The proposed system provides a high average accuracy of 91.25% for single subject movements and an overall high multi-class accuracy of 83% for 4 subjects and 16 classification categories. The proposed system can potentially fulfill the needs of future in-home health activity monitoring and is a viable alternative for monitoring public health and well being.",0,0
3513,"Utility of single versus sequential measurements of risk factors for prediction of stroke in Chinese adults. Absolute risks of stroke are typically estimated using measurements of cardiovascular disease risk factors recorded at a single visit. However, the comparative utility of single versus sequential risk factor measurements for stroke prediction is unclear. Risk factors were recorded on three separate visits on 13,753 individuals in the prospective China Kadoorie Biobank. All participants were stroke-free at baseline (2004-2008), first resurvey (2008), and second resurvey (2013-2014), and were followed-up for incident cases of first stroke in the 3Â years following the second resurvey. To reflect the models currently used in clinical practice, sex-specific Cox models were developed to estimate 3-year risks of stroke using single measurements recorded at second resurvey and were retrospectively applied to risk factor data from previous visits. Temporal trends in the Cox-generated risk estimates from 2004 to 2014 were analyzed using linear mixed effects models. To assess the value of more flexible machine learning approaches and the incorporation of longitudinal data, we developed gradient boosted tree (GBT) models for 3-year prediction of stroke using both single measurements and sequential measurements of risk factor inputs. Overall, Cox-generated estimates for 3-year stroke risk increased by 0.3% per annum in men and 0.2% per annum in women, but varied substantially between individuals. The risk estimates at second resurvey were highly correlated with the annual increase of risk for each individual (men: râ€‰=â€‰0.91, women: râ€‰=â€‰0.89), and performance of the longitudinal GBT models was comparable with both Cox and GBT models that considered measurements from only a single visit (AUCs: 0.779-0.811 in men, 0.724-0.756 in women). These results provide support for current clinical guidelines, which recommend using risk factor measurements recorded at a single visit for stroke prediction.",0,0
3516,"Deep learning with digital holographic microscopy discriminates apoptosis and necroptosis. Regulated cell death modalities such as apoptosis and necroptosis play an important role in regulating different cellular processes. Currently, regulated cell death is identified using the golden standard techniques such as fluorescence microscopy and flow cytometry. However, they require fluorescent labels, which are potentially phototoxic. Therefore, there is a need for the development of new label-free methods. In this work, we apply Digital Holographic Microscopy (DHM) coupled with a deep learning algorithm to distinguish between alive, apoptotic and necroptotic cells in murine cancer cells. This method is solely based on label-free quantitative phase images, where the phase delay of light by cells is quantified and is used to calculate their topography. We show that a combination of label-free DHM in a high-throughput set-up (~10,000 cells per condition) can discriminate between apoptosis, necroptosis and alive cells in the L929sAhFas cell line with a precision of over 85%. To the best of our knowledge, this is the first time deep learning in the form of convolutional neural networks is applied to distinguish-with a high accuracy-apoptosis and necroptosis and alive cancer cells from each other in a label-free manner. It is expected that the approach described here will have a profound impact on research in regulated cell death, biomedicine and the field of (cancer) cell biology in general.",0,0
3520,"An MRI-Based Machine Learning Prediction Framework to Lateralize Hippocampal Sclerosis in Patients With Temporal Lobe Epilepsy. MRI fails to reveal hippocampal pathology in 30-50% of temporal lobe epilepsy (TLE) surgical candidates. To address this clinical challenge, we developed an automated MRI-based classifier that lateralizes the side of covert hippocampal pathology in TLE.",0,0
3521,A Novel Prediction Model for Colon Cancer Recurrence Using Auto-artificial Intelligence. We aimed to develop a novel recurrence prediction model for stage II-III colon cancer using simple auto-artificial intelligence (AI) with improved accuracy compared to conventional statistical models.,0,0
3534,"Automated eloquent cortex localization in brain tumor patients using multi-task graph neural networks. Localizing the eloquent cortex is a crucial part of presurgical planning. While invasive mapping is the gold standard, there is increasing interest in using noninvasive fMRI to shorten and improve the process. However, many surgical patients cannot adequately perform task-based fMRI protocols. Resting-state fMRI has emerged as an alternative modality, but automated eloquent cortex localization remains an open challenge. In this paper, we develop a novel deep learning architecture to simultaneously identify language and primary motor cortex from rs-fMRI connectivity. Our approach uses the representational power of convolutional neural networks alongside the generalization power of multi-task learning to find a shared representation between the eloquent subnetworks. We validate our method on data from the publicly available Human Connectome Project and on a brain tumor dataset acquired at the Johns Hopkins Hospital. We compare our method against feature-based machine learning approaches and a fully-connected deep learning model that does not account for the shared network organization of the data. Our model achieves significantly better performance than competing baselines. We also assess the generalizability and robustness of our method. Our results clearly demonstrate the advantages of our graph convolution architecture combined with multi-task learning and highlight the promise of using rs-fMRI as a presurgical mapping tool.",0,0
3535,"On computational classification of genetic cardiac diseases applying iPSC cardiomyocytes. Cardiomyocytes differentiated from human induced pluripotent stem cells (iPSC-CMs) can be used to study genetic cardiac diseases. In patients these diseases are manifested e.g. with impaired contractility and fatal cardiac arrhythmias, and both of these can be due to abnormal calcium transients in cardiomyocytes. Here we classify different genetic cardiac diseases using Ca<sup>2+</sup> transient data and different machine learning algorithms.",0,0
3536,"Diagnosis and grading of vesicoureteral reflux on voiding cystourethrography images in children using a deep hybrid model. Vesicoureteral reflux is the leakage of urine from the bladder into the ureter. As a result, urinary tract infections and kidney scarring can occur in children. Voiding cystourethrography is the primary radiological imaging method used to diagnose vesicoureteral reflux in children with a history of recurrent urinary tract infection. Besides the diagnosis of reflux, it is graded with voiding cystourethrography. In this study, we aimed to diagnose and grade vesicoureteral reflux in Voiding cystourethrography images using hybrid CNN in deep learning methods.",0,0
3538,"Surveillance Strategy after Complete Ablation of Initial Recurrent Hepatocellular Carcinoma: A Risk-Based Machine Learning Study. To investigate surveillance strategies for initial recurrent hepatocellular carcinoma (irHCC) after ablation to support clinical decision making, as there is no consensus regarding the monitoring strategy for irHCC after ablation.",0,0
3541,"Redefining Î²-blocker response in heart failure patients with sinus rhythm and atrial fibrillation: a machine learning cluster analysis. Mortality remains unacceptably high in patients with heart failure and reduced left ventricular ejection fraction (LVEF) despite advances in therapeutics. We hypothesised that a novel artificial intelligence approach could better assess multiple and higher-dimension interactions of comorbidities, and define clusters of Î²-blocker efficacy in patients with sinus rhythm and atrial fibrillation.",0,0
3547,Machine learning model for predicting the optimal depth of tracheal tube insertion in pediatric patients: A retrospective cohort study. To construct a prediction model for optimal tracheal tube depth in pediatric patients using machine learning.,0,0
3554,Improving Early Identification of Significant Weight Loss Using Clinical Decision Support System in Lung Cancer Radiation Therapy. Early identification of patients who may be at high risk of significant weight loss (SWL) is important for timely clinical intervention in lung cancer radiotherapy (RT). A clinical decision support system (CDSS) for SWL prediction was implemented within the routine clinical workflow and assessed on a prospective cohort of patients.,0,0
3559,"An Artificial Intelligence System for the Detection of Bladder Cancer via Cystoscopy: A Multicenter Diagnostic Study. Cystoscopy plays an important role in bladder cancer (BCa) diagnosis and treatment, but its sensitivity needs improvement. Artificial intelligence has shown promise in endoscopy, but few cystoscopic applications have been reported. We report a Cystoscopy Artificial Intelligence Diagnostic System (CAIDS) for BCa diagnosis.",0,0
3562,"Predicting Olfactory Loss In Chronic Rhinosinusitis Using Machine Learning. Compare machine learning (ML) based predictive analytics methods to traditional logistic regression in classification of olfactory dysfunction in chronic rhinosinusitis (CRS-OD), and identify predictors within a large multi-institutional cohort of refractory CRS patients.",0,0
3570,"Using Machine Learning Techniques to Predict Factors Contributing to the Incidence of Metabolic Syndrome in Tehran: Cohort Study. Metabolic syndrome (MetS), a major contributor to cardiovascular disease and diabetes, is considered to be among the most common public health problems worldwide.",0,0
3571,"Upper-Limb Motion Recognition Based on Hybrid Feature Selection: Algorithm Development and Validation. For rehabilitation training systems, it is essential to automatically record and recognize exercises, especially when more than one type of exercise is performed without a predefined sequence. Most motion recognition methods are based on feature engineering and machine learning algorithms. Time-domain and frequency-domain features are extracted from original time series data collected by sensor nodes. For high-dimensional data, feature selection plays an important role in improving the performance of motion recognition. Existing feature selection methods can be categorized into filter and wrapper methods. Wrapper methods usually achieve better performance than filter methods; however, in most cases, they are computationally intensive, and the feature subset obtained is usually optimized only for the specific learning algorithm.",0,0
3572,Designing a Clinical Decision Support Tool That Leverages Machine Learning for Suicide Risk Prediction: Development Study in Partnership With Native American Care Providers. Machine learning algorithms for suicide risk prediction have been developed with notable improvements in accuracy. Implementing these algorithms to enhance clinical care and reduce suicide has not been well studied.,0,0
3579,Expected clinical utility of automatable prediction models for improving palliative and end-of-life care outcomes: Toward routine decision analysis before implementation. The study sought to evaluate the expected clinical utility of automatable prediction models for increasing goals-of-care discussions (GOCDs) among hospitalized patients at the end of life (EOL).,0,0
3589,"Automated healthcare-associated infection surveillance using an artificial intelligence algorithm. Healthcare-associated infections (HAIs) are among the most common adverse events in hospitals. We used artificial intelligence (AI) algorithms for infection surveillance in a cohort study. The model correctly detected 67 out of 73 patients with HAIs. The final model used a multilayer perceptron neural network achieving an area under receiver operating curve (AUROC) of 90.27%; specificity of 78.86%; sensitivity of 88.57%. Respiratory infections had the best results (AUROC â‰¥93.47%). The AI algorithm could identify most HAIs. AI is a feasible method for HAI surveillance, has the potential to save time, promote accurate hospital-wide surveillance, and improve infection prevention performance.",0,0
3596,"COVID-19 detection method based on SVRNet and SVDNet in lung x-rays. <b>Purpose:</b> To detect and diagnose coronavirus disease 2019 (COVID-19) better and faster, separable VGG-ResNet (SVRNet) and separable VGG-DenseNet (SVDNet) models are proposed, and a detection system is designed, based on lung x-rays to diagnose whether patients are infected with COVID-19. <b>Approach:</b> Combining deep learning and transfer learning, 1560 lung x-ray images in the COVID-19 x-ray image database (COVID-19 Radiography Database) were used as the experimental data set, and the most representative image classification models, VGG16, ResNet50, InceptionV3, and Xception, were fine-tuned and trained. Then, two new models for lung x-ray detection, SVRNet and SVDNet, were proposed on this basis. Finally, 312 test set images (including 44 COVID-19 and 268 normal images) were used as input to evaluate the classification accuracy, sensitivity, and specificity of SVRNet and SVDNet models. <b>Results:</b> In the classification experiment of lung x-rays that tested positive and negative for COVID-19, the classification accuracy, sensitivity, and specificity of SVRNet and SVDNet are 99.13%, 99.14%, 99.12% and 99.37%, 99.43%, 99.31%, respectively. Compared with the VGG16 network, SVRNet and SVDNet increased by 3.07%, 2.84%, 3.31% and 3.31%, 3.13%, 3.50%, respectively. On the other hand, the parameters of SVRNet and SVDNet are <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>5.65</mn> <mo>Ã—</mo> <msup><mrow><mn>10</mn></mrow> <mrow><mn>6</mn></mrow> </msup> </mrow> </math> and <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>6.57</mn> <mo>Ã—</mo> <msup><mrow><mn>10</mn></mrow> <mrow><mn>6</mn></mrow> </msup> </mrow> </math> , respectively. These are 61.56% and 55.31% less than VGG16, respectively. <b>Conclusions:</b> The SVRNet and SVDNet models proposed greatly reduce the number of parameters, while improving the accuracy and increasing the operating speed, and can accurately and quickly detect lung x-rays containing COVID-19.",0,0
3597,"Assessment of Acoustic Features and Machine Learning for Parkinson's Detection. This article presents a machine learning approach for Parkinson's disease detection. Potential multiple acoustic signal features of Parkinson's and control subjects are ascertained. A collaborated feature bank is created through correlated feature selection, Fisher score feature selection, and mutual information-based feature selection schemes. A detection model on top of the feature bank has been developed using the traditional NaÃ¯ve Bayes, which proved state of the art. The NaÃ¯ve Bayes detector on collaborative acoustic features can detect the presence of Parkinson's magnificently with a detection accuracy of 78.97% and precision of 0.926, under the hold-out cross validation. The collaborative feature bank on NaÃ¯ve Bayes revealed distinguishable results as compared to many other recently proposed approaches. The simplicity of NaÃ¯ve Bayes makes the system robust and effective throughout the detection process.",0,0
3606,"Method for Diagnosis of Acute Lymphoblastic Leukemia Based on ViT-CNN Ensemble Model. Acute lymphocytic leukemia (ALL) is a deadly cancer that not only affects adults but also accounts for about 25% of childhood cancers. Timely and accurate diagnosis of the cancer is an important premise for effective treatment to improve survival rate. Since the image of leukemic B-lymphoblast cells (cancer cells) under the microscope is very similar in morphology to that of normal B-lymphoid precursors (normal cells), it is difficult to distinguish between cancer cells and normal cells. Therefore, we propose the ViT-CNN ensemble model to classify cancer cells images and normal cells images to assist in the diagnosis of acute lymphoblastic leukemia. The ViT-CNN ensemble model is an ensemble model that combines the vision transformer model and convolutional neural network (CNN) model. The vision transformer model is an image classification model based entirely on the transformer structure, which has completely different feature extraction method from the CNN model. The ViT-CNN ensemble model can extract the features of cells images in two completely different ways to achieve better classification results. In addition, the data set used in this article is an unbalanced data set and has a certain amount of noise, and we propose a difference enhancement-random sampling (DERS) data enhancement method, create a new balanced data set, and use the symmetric cross-entropy loss function to reduce the impact of noise in the data set. The classification accuracy of the ViT-CNN ensemble model on the test set has reached 99.03%, and it is proved through experimental comparison that the effect is better than other models. The proposed method can accurately distinguish between cancer cells and normal cells and can be used as an effective method for computer-aided diagnosis of acute lymphoblastic leukemia.",0,0
3612,"Machine-learning algorithm to predict multidisciplinary team treatment recommendations in the management of basal cell carcinoma. Basal cell carcinoma (BCC) is the most common human cancer. Facial BCCs most commonly occur on the nose and the management of these lesions is particularly complex, given the functional and complex implications of treatment. Multidisciplinary team (MDT) meetings are routinely held to integrate expertise from dermatologists, surgeons, oncologists, radiologists, pathologists and allied health professionals. The aim of this research was to develop a supervised machine-learning algorithm to predict MDT recommendations for nasal BCC to potentially reduce MDT caseload, provide automatic decision support and permit data audit in a health service context.",0,0
3616,"AI outperformed every dermatologist in dermoscopic melanoma diagnosis, using an optimized deep-CNN architecture with custom mini-batch logic and loss function. Melanoma, one of the most dangerous types of skin cancer, results in a very high mortality rate. Early detection and resection are two key points for a successful cure. Recent researches have used artificial intelligence to classify melanoma and nevus and to compare the assessment of these algorithms to that of dermatologists. However, training neural networks on an imbalanced dataset leads to imbalanced performance, the specificity is very high but the sensitivity is very low. This study proposes a method for improving melanoma prediction on an imbalanced dataset by reconstructed appropriate CNN architecture and optimized algorithms. The contributions involve three key features as custom loss function, custom mini-batch logic, and reformed fully connected layers. In the experiment, the training dataset is kept up to date including 17,302 images of melanoma and nevus which is the largest dataset by far. The model performance is compared to that of 157 dermatologists from 12 university hospitals in Germany based on the same dataset. The experimental results prove that our proposed approach outperforms all 157 dermatologists and achieves higher performance than the state-of-the-art approach with area under the curve of 94.4%, sensitivity of 85.0%, and specificity of 95.0%. Moreover, using the best threshold shows the most balanced measure compare to other researches, and is promisingly application to medical diagnosis, with sensitivity of 90.0% and specificity of 93.8%. To foster further research and allow for replicability, we made the source code and data splits of all our experiments publicly available.",1,1
3618,"Quantitative analysis of metastatic breast cancer in mice using deep learning on cryo-image data. Cryo-imaging sections and images a whole mouse and providesâ€‰~â€‰120-GBytes of microscopic 3D color anatomy and fluorescence images, making fully manual analysis of metastases an onerous task. A convolutional neural network (CNN)-based metastases segmentation algorithm included three steps: candidate segmentation, candidate classification, and semi-automatic correction of the classification result. The candidate segmentation generatedâ€‰>â€‰5000 candidates in each of the breast cancer-bearing mice. Random forest classifier with multi-scale CNN features and hand-crafted intensity and morphology features achieved 0.8645â€‰Â±â€‰0.0858, 0.9738â€‰Â±â€‰0.0074, and 0.9709â€‰Â±â€‰0.0182 sensitivity, specificity, and area under the curve (AUC) of the receiver operating characteristic (ROC), with fourfold cross validation. Classification results guided manual correction by an expert with our in-house MATLAB software. Finally, 225, 148, 165, and 344 metastases were identified in the four cancer mice. With CNN-based segmentation, the human intervention time was reduced fromâ€‰>â€‰12 toâ€‰~â€‰2Â h. We demonstrated that 4T1 breast cancer metastases spread to the lung, liver, bone, and brain. Assessing the size and distribution of metastases proves the usefulness and robustness of cryo-imaging and our software for evaluating new cancer imaging and therapeutics technologies. Application of the method with only minor modification to a pancreatic metastatic cancer model demonstrated generalizability to other tumor models.",0,0
3620,"Deep learning for distinguishing normal versus abnormal chest radiographs and generalization to two unseen diseases tuberculosis and COVID-19. Chest radiography (CXR) is the most widely-used thoracic clinical imaging modality and is crucial for guiding the management of cardiothoracic conditions. The detection of specific CXR findings has been the main focus of several artificial intelligence (AI) systems. However, the wide range of possible CXR abnormalities makes it impractical to detect every possible condition by building multiple separate systems, each of which detects one or more pre-specified conditions. In this work, we developed and evaluated an AI system to classify CXRs as normal or abnormal. For training and tuning the system, we used a de-identified dataset of 248,445 patients from a multi-city hospital network in India. To assess generalizability, we evaluated our system using 6 international datasets from India, China, and the United States. Of these datasets, 4 focused on diseases that the AI was not trained to detect: 2 datasets with tuberculosis and 2 datasets with coronavirus disease 2019. Our results suggest that the AI system trained using a large dataset containing a diverse array of CXR abnormalities generalizes to new patient populations and unseen diseases. In a simulated workflow where the AI system prioritized abnormal cases, the turnaround time for abnormal cases reduced by 7-28%. These results represent an important step towards evaluating whether AI can be safely used to flag cases in a general setting where previously unseen abnormalities exist. Lastly, to facilitate the continued development of AI models for CXR, we release our collected labels for the publicly available dataset.",0,0
3622,"An artificial intelligence approach for selecting effective teacher communication strategies in autism education. Effective inclusive education is key in promoting the long-term outcomes of children with autism spectrum conditions (ASC). However, no concrete consensus exists to guide teacher-student interactions in the classroom. In this work, we explore the potential of artificial intelligence as an approach in autism education to assist teachers in effective practice in developing social and educational outcomes for children with ASC. We form a protocol to systematically capture such interactions, and conduct a statistical analysis to uncover basic patterns in the collected observations, including the longer-term effect of specific teacher communication strategies on student response. In addition, we deploy machine learning techniques to predict student response given the form of communication used by teachers under specific classroom conditions and in relation to specified student attributes. Our analysis, drawn on a sample of 5460 coded interactions between teachers and seven students, sheds light on the varying effectiveness of different communication strategies and demonstrates the potential of this approach in making a contribution to autism education.",0,0
3631,"Auto informing COVID-19 detection result from x-ray/CT images based on deep learning. It is no secret to all that the corona pandemic has caused a decline in all aspects of the world. Therefore, offering an accurate automatic diagnostic system is very important. This paper proposed an accurate COVID-19 system by testing various deep learning models for x-ray/computed tomography (CT) medical images. A deep preprocessing procedure was done with two filters and segmentation to increase classification results. According to the results obtained, 99.94% of accuracy, 98.70% of sensitivity, and 100% of specificity scores were obtained by the Xception model in the x-ray dataset and the InceptionV3 model for CT scan images. The compared results have demonstrated that the proposed model is proven to be more successful than the deep learning algorithms in previous studies. Moreover, it has the ability to automatically notify the examination results to the patients, the health authority, and the community after taking any x-ray or CT images.",0,0
3653,"Quantifying Meibomian Gland Morphology Using Artificial Intelligence. Quantifying meibomian gland morphology from meibography images is used for the diagnosis, treatment, and management of meibomian gland dysfunction in clinics. A novel and automated method is described for quantifying meibomian gland morphology from meibography images.",0,0
3654,"An attention-based deep learning model for predicting microvascular invasion of hepatocellular carcinoma using an intra-voxel incoherent motion model of diffusion-weighted magnetic resonance imaging. The intra-voxel incoherent motion model of diffusion-weighted magnetic resonance imaging (IVIM-DWI) with a series of images with different<i>b</i>-values has great potential as a tool for detecting, diagnosing, staging, and monitoring disease progression or the response to treatment. The current clinical tumour characterisation using IVIM-DWI is based on the parameter values derived from the IVIM model. On the one hand, the calculation accuracy of such parameter values is susceptible to deviations due to noise and motion; on the other hand, the performance of the parameter values is rather limited with respect to tumour characterisation. In this article, we propose a deep learning approach to directly extract spatiotemporal features from a series of<i>b</i>-value images of IVIM-DWI using a deep learning network for lesion characterisation. Specifically, we introduce an attention mechanism to select dominant features from specific<i>b</i>-values, channels, and spatial areas of the multiple<i>b</i>-value images for better lesion characterisation. The experimental results for clinical hepatocellular carcinoma (HCC) when using IVIM-DWI demonstrate the superiority of the proposed deep learning model for predicting the microvascular invasion (MVI) of HCC. In addition, the ablation study reflects the effectiveness of the attention mechanism for improving MVI prediction. We believe that the proposed model may be a useful tool for the lesion characterisation of IVIM-DWI in clinical practice.",0,0
3655,"Deep learning enabled brain shunt valve identification using mobile phones. Accurate information concerning implanted medical devices prior to a Magnetic resonance imaging (MRI) examination is crucial to assure safety of the patient and to address MRI induced unintended changes in device settings. The identification of these devices still remains a very challenging task. In this paper, with the aim of providing a faster device detection, we propose the adoption of deep learning for medical device detection from X-rays.",0,0
3659,"Automatic segmentation of gadolinium-enhancing lesions in multiple sclerosis using deep learning from clinical MRI. Gadolinium-enhancing lesions reflect active disease and are critical for in-patient monitoring in multiple sclerosis (MS). In this work, we have developed the first fully automated method to segment and count the gadolinium-enhancing lesions from routine clinical MRI of MS patients. The proposed method first segments the potential lesions using 2D-UNet from multi-channel scans (T1 post-contrast, T1 pre-contrast, FLAIR, T2, and proton-density) and classifies the lesions using a random forest classifier. The algorithm was trained and validated on 600 MRIs with manual segmentation. We compared the effect of loss functions (Dice, cross entropy, and bootstrapping cross entropy) and number of input contrasts. We compared the lesion counts with those by radiologists using 2,846 images. Dice, lesion-wise sensitivity, and false discovery rate with full 5 contrasts were 0.698, 0.844, and 0.307, which improved to 0.767, 0.969, and 0.00 in large lesions (>100 voxels). The model using bootstrapping loss function provided a statistically significant increase of 7.1% in sensitivity and of 2.3% in Dice compared with the model using cross entropy loss. T1 post/pre-contrast and FLAIR were the most important contrasts. For large lesions, the 2D-UNet model trained using T1 pre-contrast, FLAIR, T2, PD had a lesion-wise sensitivity of 0.688 and false discovery rate 0.083, even without T1 post-contrast. For counting lesions in 2846 routine MRI images, the model with 2D-UNet and random forest, which was trained with bootstrapping cross entropy, achieved accuracy of 87.7% using T1 pre-contrast, T1 post-contrast, and FLAIR when lesion counts were categorized as 0, 1, and 2 or more. The model performs well in routine non-standardized MRI datasets, allows large-scale analysis of clinical datasets, and may have clinical applications.",1,1
3661,"Deep Attention and Graphical Neural Network for Multiple Sclerosis Lesion Segmentation from MR Imaging Sequences. The segmentation of multiple sclerosis (MS) lesions from MR imaging sequences remains a challenging task, due to the characteristics of variant shapes, scattered distributions and unknown numbers of lesions. However, the current automated MS segmentation methods with deep learning models face the challenges of (1) capturing the multiple scattered lesions in multiple regions and (2) delineating the global contour of variant lesions. To address these challenges, in this paper, we propose a novel attention and graph-driven network (DAG-Net), which incorporates (1) the spatial correlations for embracing the lesions in distant regions and (2) the global context for better representing lesions of variant features in a unified architecture. Firstly, the novel local attention coherence mechanism is designed to construct dynamic and expansible graphs for the spatial correlations between pixels and their proximities. Secondly, the proposed spatial-channel attention module enhances features to optimize the global contour delineation, by aggregating relevant features. Moreover, with the dynamic graphs, the learning process of the DAG-Net is interpretable, which in turns support the reliability of segmentation results. Extensive experiments were conducted on a public ISBI2015 dataset and an in-house dataset in comparison to state-of-the-art methods, based on the geometrical and clinical metrics. The experimental results validate the effectiveness of the proposed DAG-Net on segmenting variant and scatted lesions in multiple regions.",0,0
3662,"FABNet: Fusion Attention Block and Transfer Learning for Laryngeal cancer Tumor Grading in P63 IHC Histopathology Images. Laryngeal cancer tumor (LCT) grading is a challenging task in P63 Immunohistochemical (IHC) histopathology images due to small differences between LCT levels in pathology images, the lack of precision in lesion regions of interest (LROIs) and the paucity of LCT pathology image samples. The key to solving the LCT grading problem is to transfer knowledge from other images and to identify more accurate LROIs, but the following problems occur: 1) transferring knowledge without a priori experience often causes negative transfer and creates a heavy workload due to the abundance of image types, and 2) convolutional neural networks (CNNs) constructing deep models by stacking cannot sufficiently identify LROIs, often deviate significantly from the LROIs focused on by experienced pathologists, and are prone to providing misleading second opinions. So we propose a novel fusion attention block network (FABNet) to address these problems. First, we propose a model transfer method based on clinical a priori experience and sample analysis (CPESA) that analyzes the transfer ability by integrating clinical a priori experience using indicators such as the relationship between the cancer onset location and morphology and the texture and staining degree of cell nuclei in histopathology images; our method further validates these indicators by the probability distribution of cancer image samples. Then, we propose a fusion attention block (FAB) structure, which can both provide an advanced non-uniform sparse representation of images and extract spatial relationship information between nuclei; consequently, the LROI can be more accurate and more relevant to pathologists. We conducted extensive experiments, compared with the best Baseline model, the classification accuracy is improved 25%, and It is demonstrated that FABNet performs better on different cancer pathology image datasets and outperforms other state of the art (SOTA) models.",0,0
3671,A Novel Tissue Identification Framework in Cataract Surgery using an Integrated Bioimpedance-Based Probe and Machine Learning Algorithms. The objective of this work was to develop and experimentally validate a bioimpedance-based framework to identify tissues in contact with the surgical instrument during cataract surgery.,0,0
3676,"Mapping Drug-Induced Neuropathy through In-Situ Motor Protein Tracking and Machine Learning. Chemotherapy can induce toxicity in the central and peripheral nervous systems and result in chronic adverse reactions that impede continuous treatment and reduce patient quality of life. There is a current lack of research to predict, identify, and offset drug-induced neurotoxicity. Rapid and accurate assessment of potential neuropathy is crucial for cost-effective diagnosis and treatment. Here we report dynamic near-infrared upconversion imaging that allows intraneuronal transport to be traced in real time with millisecond resolution, but without photobleaching or blinking. Drug-induced neurotoxicity can be screened prior to phenotyping, on the basis of subtle abnormalities of kinetic characteristics in intraneuronal transport. Moreover, we demonstrate that combining the upconverting nanoplatform with machine learning offers a powerful tool for mapping chemotherapy-induced peripheral neuropathy and assessing drug-induced neurotoxicity.",0,0
3679,"Machine learning gene expression predicting model for ustekinumab response in patients with Crohn's disease. Recent studies reported the responses of ustekinumab (UST) for the treatment of Crohn's disease (CD) differ among patients, while the cause was unrevealed. The study aimed to develop a prediction model based on the gene transcription profiling of patients with CD in response to UST.",0,0
3681,"Lung tumor segmentation in 4D CT images using motion convolutional neural networks. Manual delineation on all breathing phases of lung cancer 4D CT image datasets can be challenging, exhaustive, and prone to subjective errors because of both the large number of images in the datasets and variations in the spatial location of tumors secondary to respiratory motion. The purpose of this work is to present a new deep learning-based framework for fast and accurate segmentation of lung tumors on 4D CT image sets.",0,0
3682,"Binary polyp-size classification based on deep-learned spatial information. The size information of detected polyps is an essential factor for diagnosis in colon cancer screening. For example, adenomas and sessile serrated polyps that are [Formula: see text] mm are considered advanced, and shorter surveillance intervals are recommended for smaller polyps. However, sometimes the subjective estimations of endoscopists are incorrect and overestimate the sizes. To circumvent these difficulties, we developed a method for automatic binary polyp-size classification between two polyp sizes: from 1 to 9 mm and [Formula: see text] mm.",0,0
3683,"Deep learning based smart health monitoring for automated prediction of epileptic seizures using spectral analysis of scalp EEG. Being one of the most prevalent neurological disorders, epilepsy affects the lives of patients through the infrequent occurrence of spontaneous seizures. These seizures can result in serious injuries or unexpected deaths in individuals due to accidents. So, there exists a crucial need for an automatic prediction of epileptic seizures to alert the patients well before the onset of seizures, enabling them to have a healthier quality of life. In this era, the Internet of Things (IoT) technologies are being used in a cloud-fog integrated environment to address such healthcare challenges using deep learning approaches. The present paper also proposes a smart health monitoring approach for automated prediction of epileptic seizures using deep learning-based spectral analysis of EEG signals. This approach processes EEG signals using filtering, segmentation into short duration segments and spectral-domain transformation. These signals are then analysed spectrally by separating them into several spectral bands, such as delta, theta, alpha, beta, and sub-bands of gamma. Furthermore, the mean spectral amplitude and spectral power features are retrieved from each spectral band to characterize various seizure states, which are fed to the proposed LSTM and CNN models. The results of the proposed CNN model show a maximum accuracy of 98.3% and 97.4% to obtain a binary classification of preictal and interictal seizure states for two different spectral band combinations respectively. Thus, the proposed CNN architecture accompanied by spectral analysis of EEG signals provides a viable method for reliable and real-time prediction of epileptic seizures.",0,0
3686,Development and Validation of a Model to Predict Posttraumatic Stress Disorder and Major Depression After a Motor Vehicle Collision. A substantial proportion of the 40 million people in the US who present to emergency departments (EDs) each year after traumatic events develop posttraumatic stress disorder (PTSD) or major depressive episode (MDE). Accurately identifying patients at high risk in the ED would facilitate the targeting of preventive interventions.,0,0
3687,"Deep learning analysis of electrocardiogram for risk prediction of drug-induced arrhythmias and diagnosis of long QT syndrome. Congenital long-QT syndromes (cLQTS) or drug-induced long-QT syndromes (diLQTS) can cause torsade de pointes (TdP), a life-threatening ventricular arrhythmia. The current strategy for the identification of drugs at the high risk of TdP relies on measuring the QT interval corrected for heart rate (QTc) on the electrocardiogram (ECG). However, QTc has a low positive predictive value.",0,0
3689,"Machine learning analysis to predict health outcomes among emergency department users in Southern Brazil: a protocol study. Emergency services are essential to the organization of the health care system. Nevertheless, they face different operational difficulties, including overcrowded services, largely explained by their inappropriate use and the repeated visits from users. Although a known situation, information on the theme is scarce in Brazil, particularly regarding longitudinal user monitoring. Thus, this project aims to evaluate the predictive performance of different machine learning algorithms to estimate the inappropriate and repeated use of emergency services and mortality.",0,0
3690,"An Early Warning Risk Prediction Tool (RECAP-V1) for Patients Diagnosed With COVID-19: Protocol for a Statistical Analysis Plan. Since the start of the COVID-19 pandemic, efforts have been made to develop early warning risk scores to help clinicians decide which patient is likely to deteriorate and require hospitalization. The RECAP (Remote COVID-19 Assessment in Primary Care) study investigates the predictive risk of hospitalization, deterioration, and death of patients with confirmed COVID-19, based on a set of parameters chosen through a Delphi process performed by clinicians. We aim to use rich data collected remotely through the use of electronic data templates integrated in the electronic health systems of several general practices across the United Kingdom to construct accurate predictive models. The models will be based on preexisting conditions and monitoring data of a patient's clinical parameters (eg, blood oxygen saturation) to make reliable predictions as to the patient's risk of hospital admission, deterioration, and death.",0,0
3702,"Ambulatory Cardiovascular Monitoring Via a Machine-Learning-Assisted Textile Triboelectric Sensor. Wearable bioelectronics for continuous and reliable pulse wave monitoring against body motion and perspiration remains a great challenge and highly desired. Here, a low-cost, lightweight, and mechanically durable textile triboelectric sensor that can convert subtle skin deformation caused by arterial pulsatility into electricity for high-fidelity and continuous pulse waveform monitoring in an ambulatory and sweaty setting is developed. The sensor holds a signal-to-noise ratio of 23.3 dB, a response time of 40 ms, and a sensitivity of 0.21 ÂµA kPa<sup>-1</sup> . With the assistance of machine learning algorithms, the textile triboelectric sensor can continuously and precisely measure systolic and diastolic pressure, and the accuracy is validated via a commercial blood pressure cuff at the hospital. Additionally, a customized cellphone application (APP) based on built-in algorithm is developed for one-click health data sharing and data-driven cardiovascular diagnosis. The textile triboelectric sensor enabled wireless biomonitoring system is expected to offer a practical paradigm for continuous and personalized cardiovascular system characterization in the era of the Internet of Things.",0,0
3707,Utility of machine learning of apparent diffusion coefficient (ADC) and T2-weighted (T2W) radiomic features in PI-RADS version 2.1 category 3 lesions to predict prostate cancer diagnosis. To evaluate if machine learning (ML) of radiomic features extracted from apparent diffusion coefficient (ADC) and T2-weighted (T2W) MRI can predict prostate cancer (PCa) diagnosis in Prostate Imaging-Reporting and Data System (PI-RADS) version 2.1 category 3 lesions.,0,0
3709,"Synthetic breath-hold CT generation from free-breathing CT: a novel deep learning approach to predict cardiac dose reduction in deep-inspiration breath-hold radiotherapy. Deep-inspiration breath-hold radiotherapy (DIBH-RT) to reduce the cardiac dose irradiation is widely used but some patients experience little or no reduction. We constructed and compared two prediction models to evaluate the usefulness of our new synthetic DIBH-CT (sCT) model. Ninety-four left-sided breast cancer patients (training cohort: n = 64, test cohort: n = 30) underwent both free-breathing and DIBH planning. The U-Net-based sCT generation model was developed to create the sCT treatment plan. A linear prediction model was constructed for comparison by selecting anatomical predictors of past literature. The primary prediction outcome is the mean heart dose (MHD) reduction, and the coefficient of determination (R2), root mean square error (RMSE) and mean absolute error (MAE) were calculated. Moreover, we evaluated the heart and lungs contours' similarity and Hounsfield unit (HU) difference between both images. The median MHD reduction was 1.14 Gy in DIBH plans and 1.09 Gy in sCT plans (P = 0.96). The sCT model achieved better performance than the linear model (R2: 0.972 vs 0.450, RMSE: 0.120 vs 0.551, MAE: 0.087 vs 0.412). The organ contours were similar between DIBH-CT and sCT: the median Dice (DSC) and Jaccard similarity coefficients (JSC) were 0.912 and 0.838 for the heart and 0.910 and 0.834 for the lungs. The HU difference in the soft-tissue region was smaller than in the air or bone. In conclusion, our new model can generate the affected CT by breath-holding, resulting in high performance and well-visualized prediction, which may have many potential uses in radiation oncology.",0,0
3718,"A deep learning framework for autonomous detection and classification of Crohn's disease lesions in the small bowel and colon with capsule endoscopy. <b>Background and study aimsâ€‚</b> Small bowel ulcerations are efficiently detected with deep learning techniques, whereas the ability to diagnose Crohn's disease (CD) in the colon with it is unknown. This study examined the ability of a deep learning framework to detect CD lesions with pan-enteric capsule endoscopy (CE) and classify lesions of different severity. <b>Patients and methodsâ€‚</b> CEs from patients with suspected or known CD were included in the analysis. Two experienced gastroenterologists classified anonymized images into normal mucosa, non-ulcerated inflammation, aphthous ulceration, ulcer, or fissure/extensive ulceration. An automated framework incorporating multiple ResNet-50 architectures was trained. To improve its robustness and ability to characterize lesions, image processing methods focused on texture enhancement were employed. <b>Resultsâ€‚</b> A total of 7744 images from 38 patients with CD were collected (small bowel 4972, colon 2772) of which 2748 contained at least one ulceration (small bowel 1857, colon 891). With a patient-dependent split of images for training, validation, and testing, ulcerations were diagnosed with a sensitivity, specificity, and diagnostic accuracy of 95.7â€Š% (CI 93.4-97.4), 99.8â€Š% (CI 99.2-100), and 98.4â€Š% (CI 97.6-99.0), respectively. The diagnostic accuracy was 98.5â€Š% (CI 97.5-99.2) for the small bowel and 98.1â€Š% (CI 96.3-99.2) for the colon. Ulcerations of different severities were classified with substantial agreement (Îºâ€Š=â€Š0.72). <b>Conclusionsâ€‚</b> Our proposed framework is in excellent agreement with the clinical standard, and diagnostic accuracies are equally high for the small bowel and colon. Deep learning approaches have a great potential to help clinicians detect, localize, and determine the severity of CD with pan-enteric CE.",0,0
3719,"Deep Learning-Based Functional Independence Measure Score Prediction After Stroke in Kaifukuki (Convalescent) Rehabilitation Ward Annexed to Acute Care Hospital. Introduction Prediction models of functional independent measure (FIM) score after kaifukuki (convalescent) rehabilitation ward (KRW) are needed to decide the treatment strategies and save medical resources. Statistical models were reported, but their accuracies were not satisfactory. We made such prediction models using the deep learning (DL) framework, Prediction One (Sony Network Communications Inc., Tokyo, Japan). Methods Of the 559 consecutive stroke patients, 122 patients were transferred to our KRW. We divided our 122 patients' data randomly into halves of training and validation datasets. Prediction One made three prediction models from the training dataset using (1) variables at the acute care ward admission, (2) those at the KRW admission, and (3) those combined (1) and (2). The models' determination coefficients (R<sup>2</sup>), correlation coefficients (rs), and residuals were calculated using the validation dataset. Results Of the 122 patients, the median age was 71, length of stay (LOS) in acute care ward 23 (17-30) days, LOS in KRW 53 days, total FIM scores at the admission of KRW 85, those at discharge 108. The mean FIM gain and FIM efficiency were 19 and 0.417. All patients were discharged home. Model (1), (2), and (3)'s R<sup>2</sup> were 0.794, 0.970, and 0.972. Their mean residuals between the predicted and actual total FIM scores were -1.56Â±24.6, -4.49Â±17.1, and -2.69Â±15.7. Conclusion Our FIM gain and efficiency were better than national averages of FIM gain 17.1 and FIM efficiency 0.187. We made DL-based total FIM score prediction models, and their accuracies were superior to those of previous statistically calculated ones. The DL-based FIM score prediction models would save medical costs and perform efficient stroke and rehabilitation medicine.",0,0
3720,"A Comparison of Deep Learning Techniques for Arterial Blood Pressure Prediction. Continuous vital signal monitoring is becoming more relevant in preventing diseases that afflict a large part of the world's population; for this reason, healthcare equipment should be easy to wear and simple to use. Non-intrusive and non-invasive detection methods are a basic requirement for wearable medical devices, especially when these are used in sports applications or by the elderly for self-monitoring. Arterial blood pressure (ABP) is an essential physiological parameter for health monitoring. Most blood pressure measurement devices determine the systolic and diastolic arterial blood pressure through the inflation and the deflation of a cuff. This technique is uncomfortable for the user and may result in anxiety, and consequently affect the blood pressure and its measurement. The purpose of this paper is the continuous measurement of the ABP through a cuffless, non-intrusive approach. The approach of this paper is based on deep learning techniques where several neural networks are used to infer ABP, starting from photoplethysmogram (PPG) and electrocardiogram (ECG) signals. The ABP was predicted first by utilizing only PPG and then by using both PPG and ECG. Convolutional neural networks (ResNet and WaveNet) and recurrent neural networks (LSTM) were compared and analyzed for the regression task. Results show that the use of the ECG has resulted in improved performance for every proposed configuration. The best performing configuration was obtained with a ResNet followed by three LSTM layers: this led to a mean absolute error (MAE) of 4.118Â mmHg on and 2.228Â mmHg on systolic and diastolic blood pressures, respectively. The results comply with the American National Standards of the Association for the Advancement of Medical Instrumentation. ECG, PPG, and ABP measurements were extracted from the MIMIC database, which contains clinical signal data reflecting real measurements. The results were validated on a custom dataset created at Neuronica Lab, Politecnico di Torino.",0,0
3722,Artificial Intelligence Analysis of Mandibular Movements Enables Accurate Detection of Phasic Sleep Bruxism in OSA Patients: A Pilot Study. Sleep bruxism (SBx) activity is classically identified by capturing masseter and/or temporalis masticatory muscles electromyographic activity (EMG-MMA) during in-laboratory polysomnography (PSG). We aimed to identify stereotypical mandibular jaw movements (MJM) in patients with SBx and to develop rhythmic masticatory muscles activities (RMMA) automatic detection using an artificial intelligence (AI) based approach.,0,0
3724,"Machine learning-based approach for disease severity classification of carpal tunnel syndrome. Identifying the severity of carpal tunnel syndrome (CTS) is essential to providing appropriate therapeutic interventions. We developed and validated machine-learning (ML) models for classifying CTS severity. Here, 1037 CTS hands with 11 variables each were retrospectively analyzed. CTS was confirmed using electrodiagnosis, and its severity was classified into three grades: mild, moderate, and severe. The dataset was randomly split into a training (70%) and test (30%) set. A total of 507 mild, 276 moderate, and 254 severe CTS hands were included. Extreme gradient boosting (XGB) showed the highest external validation accuracy in the multi-class classification at 76.6% (95% confidence interval [CI] 71.2-81.5). XGB also had an optimal model training accuracy of 76.1%. Random forest (RF) and k-nearest neighbors had the second-highest external validation accuracy of 75.6% (95% CI 70.0-80.5). For the RF and XGB models, the numeric rating scale of pain was the most important variable, and body mass index was the second most important. The one-versus-rest classification yielded improved external validation accuracies for each severity grade compared with the multi-class classification (mild, 83.6%; moderate, 78.8%; severe, 90.9%). The CTS severity classification based on the ML model was validated and is readily applicable to aiding clinical evaluations.",0,0
3730,"Predicting post-operative right ventricular failure using video-based deep learning. Despite progressive improvements over the decades, the rich temporally resolved data in an echocardiogram remain underutilized. Human assessments reduce the complex patterns of cardiac wall motion, to a small list of measurements of heart function. All modern echocardiography artificial intelligence (AI) systems are similarly limited by design - automating measurements of the same reductionist metrics rather than utilizing the embedded wealth of data. This underutilization is most evident where clinical decision making is guided by subjective assessments of disease acuity. Predicting the likelihood of developing post-operative right ventricular failure (RV failure) in the setting of mechanical circulatory support is one such example. Here we describe a video AI system trained to predict post-operative RV failure using the full spatiotemporal density of information in pre-operative echocardiography. We achieve an AUC of 0.729, and show that this ML system significantly outperforms a team of human experts at the same task on independent evaluation.",1,1
3734,"A machine learning approach to predict progression on active surveillance for prostate cancer. Robust prediction of progression on active surveillance (AS) for prostate cancer can allow for risk-adapted protocols. To date, models predicting progression on AS have invariably used traditional statistical approaches. We sought to evaluate whether a machine learning (ML) approach could improve prediction of progression on AS.",0,0
3736,"Detection of dementia on voice recordings using deep learning: a Framingham Heart Study. Identification of reliable, affordable, and easy-to-use strategies for detection of dementia is sorely needed. Digital technologies, such as individual voice recordings, offer an attractive modality to assess cognition but methods that could automatically analyze such data are not readily available.",0,0
3740,"Exploring the diagnostic effectiveness for myocardial ischaemia based on CCTA myocardial texture features. To explore the characteristics of myocardial textures on coronary computed tomography angiography (CCTA) images in patients with coronary atherosclerotic heart disease, a classification model was established, and the diagnostic effectiveness of CCTA for myocardial ischaemia patients was explored.",0,0
3742,"Predicting Chronic Wound Healing Time using Machine Learning to Support Real-Time Clinical Decisions. <b>Objective</b>: Chronic wounds have risen to epidemic proportions in the United States and can have an emotional, physical, and financial toll on patients. By leveraging data within the electronic health record (EHR), machine learning models offer the opportunity to facilitate earlier identification of wounds at risk of not healing or healing after an abnormally long time, which may improve treatment decisions and patient outcomes. Machine learning models in this study were built to predict chronic wound healing time. <b>Approach</b>: Machine learning models were developed using EHR data to predict patients at risk of having wounds not heal within 4, 8, and 12 weeks from the start of treatment. The models were trained on three data sets of 1,220,576 wounds, including 187 covariates describing patient demographics, comorbidities, and wound characteristics. The area under the receiver operating characteristic curve (AUC) was used to assess the accuracy of the models. Shapley Additive Explanations (SHAP) were used to analyze variable importance in predictions and enhance clinical interpretations. <b>Results</b>: The 4, 8, and 12-week gradient boosted decision tree models achieved AUC's of 0.854, 0.855, and 0.853, respectively. Days in treatment, wound depth and location, and wound area were the most influential predictors of wounds at risk of not healing. <b>Innovation</b>: Machine learning models can accurately predict chronic wound healing time using EHR data. SHAP values can give insight into how patient-specific variables influenced predictions. <b>Conclusion</b>: Accurate models identifying patients with chronic wounds at risk of non or slow-healing are feasible and can be incorporated into routine wound care.",0,0
3749,"False Negative Rates in Benign Thyroid Nodule Diagnosis: Machine Learning for Detecting Malignancy. Thyroid nodules are common; up to 67% of adults will show nodules on high-quality ultrasound, and 95% of these nodules are benign. FNA cytology is a crucial step in determining the risk of malignancy, and a false negative diagnosis at this stage delays cancer treatment. The purpose of this study is to develop a predictive model using machine learning which can identify false negative FNA results based on less-invasive clinical data.",0,0
3750,Using State Data to Predict a Single Institution Mortality for Patients That Fall. Falls are the most common cause of injury-related death for patients older than 45.Â  We hypothesized that a machine learning algorithm developed from state-level registry data could make accurate outcome predictions at a level 1 trauma hospital.,0,0
3751,"Accurate lateralization and classification of MRI-negative 18F-FDG-PET-positive temporal lobe epilepsy using double inversion recovery and machine-learning. The main objective of this study was to determine the ability of double inversion recovery (DIR) data coupled with machine-learning algorithms to distinguish normal individuals from epileptic subjects and to identify the laterality of the focus side in MRI-negative, PET-positive temporal lobe epilepsy (TLE) patients.",0,0
3752,An AI-based radiomics nomogram for disease prognosis in patients with COVID-19 pneumonia using initial CT images and clinical indicators. This study utilized a comprehensive nomogram to evaluate the prognosis of patients with COVID-19 pneumonia.,0,0
3758,A machine-learning-based method to predict adverse events in patients with dilated cardiomyopathy and severely reduced ejection fractions. Patients with dilated cardiomyopathy (DCM) and severely reduced left ventricular ejection fractions (LVEFs) are at very high risks of experiencing adverse cardiac events. A machine learning (ML) method could enable more effective risk stratification for these high-risk patients by incorporating various types of data. The aim of this study was to build an ML model to predict adverse events including all-cause deaths and heart transplantation in DCM patients with severely impaired LV systolic function.,0,0
3760,Predicting mortality among patients with liver cirrhosis in electronic health records with machine learning. Liver cirrhosis is a leading cause of death and effects millions of people in the United States. Early mortality prediction among patients with cirrhosis might give healthcare providers more opportunity to effectively treat the condition. We hypothesized that laboratory test results and other related diagnoses would be associated with mortality in this population. Our another assumption was that a deep learning model could outperform the current Model for End Stage Liver disease (MELD) score in predicting mortality.,0,0
3761,"Sociodemographic risk factors of under-five stunting in Bangladesh: Assessing the role of interactions using a machine learning method. This paper aims to demonstrate the importance of studying interactions among various sociodemographic risk factors of childhood stunting in Bangladesh with the help of an interpretable machine learning method. Data used for the analyses are extracted from the Bangladesh Demographic and Health Survey (BDHS) 2014 and pertain to a sample of 6,170 under-5 children. Social and economic determinants such as wealth, mother's decision making on healthcare, parental education are considered in addition to geographic divisions and common demographic characteristics of children including age, sex and birth order. A classification tree was first constructed to identify important interaction-based rules that characterize children with different profiles of risk for stunting. Then binary logistic regression models were fitted to measure the importance of these interactions along with the individual risk factors. Results revealed that, as individual factors, living in Sylhet division (OR: 1.57; CI: 1.26-1.96), being an urban resident (OR: 1.28; CI: 1.03-1.96) and having working mothers (OR: 1.21; CI: 1.02-1.44) were associated with higher likelihoods of childhood stunting, whereas belonging to the richest households (OR: 0.56; CI: 0.35-0.90), higher BMI of mothers (OR: 0.68 CI: 0.56-0.84) and mothers' involvement in decision making about children's healthcare with father (OR: 0.83, CI: 0.71-0.97) were linked to lower likelihoods of stunting. Importantly however, risk classifications defined by the interplay of multiple sociodemographic factors showed more extreme odds ratios (OR) of stunting than single factor ORs. For example, children aged 14 months or above who belong to poor wealth class, have lowly educated fathers and reside in either Dhaka, Barisal, Chittagong or Sylhet division are the most vulnerable to stunting (OR: 2.52, CI: 1.85-3.44). The findings endorse the need for tailored-intervention programs for children based on their distinct risk profiles and sociodemographic characteristics.",0,0
3768,Prediction of Neutropenic Events in Chemotherapy Patients: A Machine Learning Approach. Severe and febrile neutropenia present serious hazards to patients with cancer undergoing chemotherapy. We seek to develop a machine learning-based neutropenia prediction model that can be used to assess risk at the initiation of a chemotherapy cycle.,0,0
3770,"Predicting Future Service Use in Dutch Mental Healthcare: A Machine Learning Approach. A mental healthcare system in which the scarce resources are equitably and efficiently allocated, benefits from a predictive model about expected service use. The skewness in service use is a challenge for such models. In this study, we applied a machine learning approach to forecast expected service use, as a starting point for agreements between financiers and suppliers of mental healthcare. This study used administrative data from a large mental healthcare organization in the Netherlands. A training set was selected using records from 2017 (Nâ€‰=â€‰10,911), and a test set was selected using records from 2018 (Nâ€‰=â€‰10,201). A baseline model and three random forest models were created from different types of input data to predict (the remainder of) numeric individual treatment hours. A visual analysis was performed on the individual predictions. Patients consumed 62Â h of mental healthcare on average in 2018. The model that best predicted service use had a mean error of 21Â min at the insurance group level and an average absolute error of 28Â h at the patient level. There was a systematic under prediction of service use for high service use patients. The application of machine learning techniques on mental healthcare data is useful for predicting expected service on group level. The results indicate that these models could support financiers and suppliers of healthcare in the planning and allocation of resources. Nevertheless, uncertainty in the prediction of high-cost patients remains a challenge.",0,0
3772,Automated Detection of Ischemic Stroke and Subsequent Patient Triage in Routinely Acquired Head CT. Advanced machine-learning (ML) techniques can potentially detect the entire spectrum of pathology through deviations from aÂ learned norm. We investigated the utility of aÂ weakly supervised ML tool to detect characteristic findings related to ischemic stroke in head CT and provide subsequent patient triage.,0,0
3775,"An Artificial Neural Network-Based Pediatric Mortality Risk Score: Development and Performance Evaluation Using Data From a Large North American Registry. In the pediatric intensive care unit (PICU), quantifying illness severity can be guided by risk models to enable timely identification and appropriate intervention. Logistic regression models, including the pediatric index of mortality 2 (PIM-2) and pediatric risk of mortality III (PRISM-III), produce a mortality risk score using data that are routinely available at PICU admission. Artificial neural networks (ANNs) outperform regression models in some medical fields.",0,0
3778,"Deep Learning for Detection of Pulmonary Metastasis on Chest Radiographs. Background A computer-aided detection (CAD) system may help surveillance for pulmonary metastasis at chest radiography in situations where there is limited access to CT. Purpose To evaluate whether a deep learning (DL)-based CAD system can improve diagnostic yield for newly visible lung metastasis on chest radiographs in patients with cancer. Materials and Methods A regulatory-approved CAD system for lung nodules was implemented to interpret chest radiographs from patients referred by the medical oncology department in clinical practice. In this retrospective diagnostic cohort study, chest radiographs interpreted with assistance from a CAD system after the implementation (January to April 2019, CAD-assisted interpretation group) and those interpreted before the implementation (September to December 2018, conventional interpretation group) of the CAD system were consecutively included. The diagnostic yield (frequency of true-positive detections) and false-referral rate (frequency of false-positive detections) of formal reports of chest radiographs for newly visible lung metastasis were compared between the two groups using generalized estimating equations. Propensity score matching was performed between the two groups for age, sex, and primary cancer. Results A total of 2916 chest radiographs from 1521 patients (1546 men, 1370 women; mean age, 62 years) and 5681 chest radiographs from 3456 patients (2941 men, 2740 women; mean age, 62 years) were analyzed in the CAD-assisted interpretation and conventional interpretation groups, respectively. The diagnostic yield for newly visible metastasis was higher in the CAD-assisted interpretation group (0.86%, 25 of 2916 [95% CI: 0.58, 1.3] vs 0.32%, 18 of 568 [95% CI: 0.20, 0.50%]; <i>P = .</i>004). The false-referral rate in the CAD-assisted interpretation group (0.34%, 10 of 2916 [95% CI: 0.19, 0.64]) was not inferior to that in the conventional interpretation group (0.25%, 14 of 5681 [95% CI: 0.15, 0.42]) at the noninferiority margin of 0.5% (95% CI of difference: -0.15, 0.35). Conclusion A deep learning-based computer-aided detection system improved the diagnostic yield for newly visible metastasis on chest radiographs in patients with cancer with a similar false-referral rate. Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i>",1,1
3782,"Covid-19 rapid test by combining a Random Forest-based web system and blood tests. The disease caused by the new type of coronavirus, Covid-19, has posed major public health challenges for many countries. With its rapid spread, since the beginning of the outbreak in December 2019, the disease transmitted by SARS-CoV-2 has already caused over 2 million deaths to date. In this work, we propose a web solution, called Heg.IA, to optimize the diagnosis of Covid-19 through the use of artificial intelligence. Our system aims to support decision-making regarding to diagnosis of Covid-19 and to the indication of hospitalization on regular ward, semi-ICU or ICU based on decision a Random Forest architecture with 90 trees. The main idea is that healthcare professionals can insert 41 hematological parameters from common blood tests and arterial gasometry into the system. Then, Heg.IA will provide a diagnostic report. The system reached good results for both Covid-19 diagnosis and to recommend hospitalization. For the first scenario we found average results of accuracy of 92.891%Â±0.851, kappa index of 0.858â€‰Â±â€‰0.017, sensitivity of 0.936â€‰Â±â€‰0.011, precision of 0.923â€‰Â±â€‰0.011, specificity of 0.921â€‰Â±â€‰0.012 and area under ROC of 0.984â€‰Â±â€‰0.003. As for the indication of hospitalization, we achieved excellent performance of accuracies above 99% and more than 0.99 for the other metrics in all situations. By using a computationally simple method, based on the classical decision trees, we were able to achieve high diagnosis performance. Heg.IA system may be a way to overcome the testing unavailability in the context of Covid-19.Communicated by Ramaswamy H. Sarma.",0,0
3784,Differentiating Benign from Malignant Renal Tumors Using T2- and Diffusion-Weighted Images: A Comparison of Deep Learning and Radiomics Models Versus Assessment from Radiologists. Differentiating benign from malignant renal tumors is important for selection of the most effective treatment.,1,1
3786,"Relationship Between Medical Questionnaire and Influenza Rapid Test Positivity: Subjective Pretest Probability, ""I Think I Have Influenza,"" Contributes to the Positivity Rate. Introduction Rapid influenza diagnostic tests (RIDTs) are considered essential for determining when to start influenza treatment using anti-influenza drugs, but their accuracy is about 70%. Under the COVID-19 pandemic, we hope to refrain from performing unnecessary RIDTs considering droplet infection of COVID-19 and influenza. We re-examined the medical questionnaire's importance and its relationship to the positivity of RIDTs. Then we built a positivity prediction model for RIDTs using automated artificial intelligence (AI). Methods We retrospectively investigated 96 patients who underwent RIDTs at the outpatient department from December 2019 to March 2020. We used a questionnaire sheet with 24 itemsÂ before conducting RIDTs. The factors associated with the positivity of RIDTs were statistically analyzed. We then used an automated AI framework to produce the positivity prediction model using the 24 items, sex, and age, with five-fold cross-validation. Results Of the 47 women and 49 men (median age was 39 years), 56 patients were RIDTÂ positive with influenza A. The AI-based model using 26 variables had an area under the curve (AUC) of 0.980. The stronger variables are subjective pretest probability, which is a numerically described score ranging from 0% to 100% of ""I think I have influenza,"" cough, past hours after the onset, muscle pain, and maximum body temperature in order. Conclusion We easily built the RIDTÂ positivity prediction model using automated AI. Its AUC was satisfactory, and it suggested the importance of a detailed medical interview. Both the univariate analysis and AI-based model suggested that subjective pretest probability, ""I think I have influenza,"" might be useful.",0,0
3787,"A Fact-Finding Procedure Integrating Machine Learning and AHP Technique to Predict Delayed Diagnosis of Bladder Patients with Hematuria. Bladder cancer, the ninth most common cancer worldwide, requires fast diagnosis and treatment to prevent disease progression and improve patient survival. However, patients with bladder cancer often experience considerable delays in diagnosis. One reason for such delays is that hematuria, a major symptom of bladder cancer, has a high probability of also being a warning sign for urinary tract diseases. Another reason is that the sensitivity of the body parts affected by bladder cancer deters patients from undergoing cystoscopy and influences patients' ""physician shopping"" behavior. In this study, the analytic hierarchy process was used to determine critical variables influencing delayed diagnosis; moreover, the variables were used to construct models for predicting delayed diagnosis in patients with hematuria by using several machine learning techniques. Furthermore, the critical variables associated with delayed diagnosis of bladder cancer in patients with hematuria were evaluated using GainRatio technology. The study sample was selected from a population-based database. The model evaluation results indicated that the prediction model established using decision tree algorithms outperformed the other models. The critical risk factors for delayed diagnosis of bladder cancer were as follows: (1) cystoscopy performed 6 months after hematuria diagnosis and (2) physician shopping.",0,0
3789,"GraphXCOVID: Explainable deep graph diffusion pseudo-Labelling for identifying COVID-19 on chest X-rays. Can one learn to diagnose COVID-19 under extreme minimal supervision? Since the outbreak of the novel COVID-19 there has been a rush for developing automatic techniques for expert-level disease identification on Chest X-ray data. In particular, the use of deep supervised learning has become the go-to paradigm. However, the performance of such models is heavily dependent on the availability of a large and representative labelled dataset. The creation of which is a heavily expensive and time consuming task, and especially imposes a great challenge for a novel disease. Semi-supervised learning has shown the ability to match the incredible performance of supervised models whilst requiring a small fraction of the labelled examples. This makes the semi supervised paradigm an attractive option for identifying COVID-19. In this work, we introduce a graph based deep semi-supervised framework for classifying COVID-19 from chest X-rays. Our framework introduces an optimisation model for graph diffusion that reinforces the natural relation among the tiny labelled set and the vast unlabelled data. We then connect the diffusion prediction output as pseudo-labels that are used in an iterative scheme in a deep net. We demonstrate, through our experiments, that our model is able to outperform the current leading supervised model with a tiny fraction of the labelled examples. Finally, we provide attention maps to accommodate the radiologist's mental model, better fitting their perceptual and cognitive abilities. These visualisation aims to assist the radiologist in judging whether the diagnostic is correct or not, and in consequence to accelerate the decision.",0,0
3794,"Deep learning from HE slides predicts the clinical benefit from adjuvant chemotherapy in hormone receptor-positive breast cancer patients. We hypothesized that a deep-learning algorithm using HE images might be capable of predicting the benefits of adjuvant chemotherapy in cancer patients. HE slides were retrospectively collected from 1343 de-identified breast cancer patients at the Samsung Medical Center and used to develop the Lunit SCOPE algorithm. Lunit SCOPE was trained to predict the recurrence using the 21-gene assay (Oncotype DX) and histological parameters. The risk prediction model predicted the Oncotype DX scoreâ€‰>â€‰25 and the recurrence survival of the prognosis validation cohort and TCGA cohorts. The most important predictive variable was the mitotic cells in the cancer epithelium. Of the 363 patients who did not receive adjuvant therapy, 104 predicted high risk had a significantly lower survival rate. The top-300 genes highly correlated with the predicted risk were enriched for cell cycle, nuclear division, and cell division. From the Oncotype DX genes, the predicted risk was positively correlated with proliferation-associated genes and negatively correlated with prognostic genes from the estrogen category. An integrative analysis using Lunit SCOPE predicted the risk of cancer recurrence and the early-stage hormone receptor-positive breast cancer patients who would benefit from adjuvant chemotherapy.",0,0
3795,"A multi-site, multi-disorder resting-state magnetic resonance image database. Machine learning classifiers for psychiatric disorders using resting-state functional magnetic resonance imaging (rs-fMRI) have recently attracted attention as a method for directly examining relationships between neural circuits and psychiatric disorders. To develop accurate and generalizable classifiers, we compiled a large-scale, multi-site, multi-disorder neuroimaging database. The database comprises resting-state fMRI and structural images of the brain from 993 patients and 1,421 healthy individuals, as well as demographic information such as age, sex, and clinical rating scales. To harmonize the multi-site data, nine healthy participants (""traveling subjects"") visited the sites from which the above datasets were obtained and underwent neuroimaging with 12 scanners. All participants consented to having their data shared and analyzed at multiple medical and research institutions participating in the project, and 706 patients and 1,122 healthy individuals consented to having their data disclosed. Finally, we have published four datasets: 1) the SRPBS Multi-disorder Connectivity Dataset 2), the SRPBS Multi-disorder MRI Dataset (restricted), 3) the SRPBS Multi-disorder MRI Dataset (unrestricted), and 4) the SRPBS Traveling Subject MRI Dataset.",0,0
3800,"Application of an extreme learning machine network with particle swarm optimization in syndrome classification of primary liver cancer. By optimizing the extreme learning machine network with particle swarm optimization, we established a syndrome classification and prediction model for primary liver cancer (PLC), classified and predicted the syndrome diagnosis of medical record data for PLC and compared and analyzed the prediction results with different algorithms and the clinical diagnosis results. This paper provides modern technical support for clinical diagnosis and treatment, and improves the objectivity, accuracy and rigor of the classification of traditional Chinese medicine (TCM) syndromes.",0,0
3803,GenTB: A user-friendly genome-based predictor for tuberculosis resistance powered by machine learning. Multidrug-resistant Mycobacterium tuberculosis (Mtb) is a significant global public health threat. Genotypic resistance prediction from Mtb DNA sequences offers an alternative to laboratory-based drug-susceptibility testing. User-friendly and accurate resistance prediction tools are needed to enable public health and clinical practitioners to rapidly diagnose resistance and inform treatment regimens.,0,0
3805,"Modeling and prediction of pressure injury in hospitalized patients using artificial intelligence. Hospital-acquired pressure injuries (PIs) induce significant patient suffering, inflate healthcare costs, and increase clinical co-morbidities. PIs are mostly due to bed-immobility, sensory impairment, bed positioning, and length of hospital stay. In this study, we use electronic health records and administrative data to examine the contributing factors to PI development using artificial intelligence (AI).",0,0
3807,Machine learning prediction of diabetic foot ulcers in the inpatient population. The objective of this study was to create an algorithm that could predict diabetic foot ulcer (DFU) incidence in the in-patient population.,0,0
3812,"CSR-Net: Cross-Scale Residual Network for multi-objective scaphoid fracture segmentation. The scaphoid is located in the carpals. Owing to the body structure and location of the scaphoid, scaphoid fractures are common and it is difficult to heal. Three-dimensional reconstruction of scaphoid fracture can accurately display the fracture surface and provide important support for the surgical plan involving screw placement. To achieve this goal, in this study, the cross-scale residual network (CSR-Net) is proposed for scaphoid fracture segmentation. In the CSR-Net, the features of different layers are used to achieve fusion through cross-scale residual connection, which realizes scale and channel conversions between the features of different layers. It can establish close connections between different scale features. The structures of the output layer and channel are designed to establish the CSR-Net as a multi-objective architecture, which can realize scaphoid fracture and hand bone segmentations synchronously. In this study, 65 computed tomography images of scaphoid fracture are tested. Quantitative metrics are used for assessment, and the results obtained show that the CSR-Net achieves higher performance in hand bone and scaphoid fracture segmentations. In the visually detailed display, the fracture surface is clearer and more intuitive than those obtained from other methods. Therefore, the CSR-Net can achieve accurate and rapid scaphoid fracture segmentation. Its multi-objective design provides not only an accurate digital model, but also a prerequisite for navigation in the hand bone.",0,0
3819,"Sleep disturbance-related neuroimaging features as potential biomarkers for the diagnosis of major depressive disorder: A multicenter study based on machine learning. Objective biomarkers are crucial for overcoming the clinical dilemma in major depressive disorder (MDD), and the individualized diagnosis is essential to facilitate the precise medicine for MDD.",0,0
3823,"A Deep Learning-enabled Electrocardiogram Model for the Identification of a Rare Inherited Arrhythmia: Brugada Syndrome. Brugada syndrome is a major cause of sudden cardiac death in young people with a distinctive electrocardiogram (ECG) feature. We aimed to develop a deep learning-enabled ECG model for automatic screening Brugada syndrome to identify these patients at an early time, thus allowing for life-saving therapy.",0,0
3825,Early recognition of a caller's emotion in out-of-hospital cardiac arrest dispatching: An artificial intelligence approach. This study aimed to develop an AI model for detecting a caller's emotional state during out-of-hospital cardiac arrest calls by processing audio recordings of dispatch communications.,0,0
3833,"Predicting Range of Initial Warfarin Dose Based on Pharmacometabolomic and Genetic Inputs. Anticoagulation response to warfarin during the initial stage of therapy varies among individuals. In this study, we aimed to combine pharmacometabolomic and pharmacogenetic data to predict interindividual variation in warfarin response, and, on this basis, suggest an initial daily dose range. The baseline metabolic profiles, genotypes, and clinical information of 160 patients with heart valve disease served as the variables of the function of the last international normalized ratio measured before a patient's discharge (INR<sub>day7</sub> ) to screen for potential biomarkers. The partial least-squares model showed that two baseline metabolites (uridine and guanosine), one single-nucleotide variation (VKORC1), and four clinical parameters (weight, creatinine level, amiodarone usage, and initial daily dose) had good predictive power for INR<sub>day7</sub> (R<sup>2</sup> Â =Â 0.753 for the training set, 0.643 for the test set). With these biomarkers, a machine learning algorithm (two-dimensional linear discriminant analysis-multinomial logit model) was used to predict the subgroups with extremely warfarin-sensitive or less warfarin-sensitive patients with a prediction accuracy of 91% for the training set and 90% for the test set, indicating that individual responses to warfarin could be effectively predicted. Based on this model, we have successfully designed an algorithm,""IniWarD,"" for predicting an effective dose range in the initial 7-day warfarin therapy. The results indicate that the daily dose range suggested by the IniWarD system is more appropriate than that of the conventional genotype-based method, and the risk of bleeding or thrombus due to warfarin could thus be avoided.",0,0
3834,"Machine Learning Using Multiparametric Magnetic Resonance Imaging Radiomic Feature Analysis to Predict Ki-67 in World Health Organization Grade I Meningiomas. Although World Health Organization (WHO) grade I meningiomas are considered ""benign"" tumors, an elevated Ki-67 is one crucial factor that has been shown to influence tumor behavior and clinical outcomes. The ability to preoperatively discern Ki-67 would confer the ability to guide surgical strategy.",0,0
3835,"AAWS-Net: Anatomy-aware weakly-supervised learning network for breast mass segmentation. Accurate segmentation of breast masses is an essential step in computer aided diagnosis of breast cancer. The scarcity of annotated training data greatly hinders the model's generalization ability, especially for the deep learning based methods. However, high-quality image-level annotations are time-consuming and cumbersome in medical image analysis scenarios. In addition, a large amount of weak annotations is under-utilized which comprise common anatomy features. To this end, inspired by teacher-student networks, we propose an Anatomy-Aware Weakly-Supervised learning Network (AAWS-Net) for extracting useful information from mammograms with weak annotations for efficient and accurate breast mass segmentation. Specifically, we adopt a weakly-supervised learning strategy in the Teacher to extract anatomy structure from mammograms with weak annotations by reconstructing the original image. Besides, knowledge distillation is used to suggest morphological differences between benign and malignant masses. Moreover, the prior knowledge learned from the Teacher is introduced to the Student in an end-to-end way, which improves the ability of the student network to locate and segment masses. Experiments on CBIS-DDSM have shown that our method yields promising performance compared with state-of-the-art alternative models for breast mass segmentation in terms of segmentation accuracy and IoU.",0,0
3845,"An Iterative Algorithm for Semisupervised Classification of Hotspots on Bone Scintigraphies of Patients with Prostate Cancer. Prostate cancer (PCa) is the second most diagnosed cancer in men. Patients with PCa often develop metastases, with more than 80% of this metastases occurring in bone. The most common imaging technique used for screening, diagnosis and follow-up of disease evolution is bone scintigraphy, due to its high sensitivity and widespread availability at nuclear medicine facilities. To date, the assessment of bone scans relies solely on the interpretation of an expert physician who visually assesses the scan. Besides this being a time consuming task, it is also subjective, as there is no absolute criteria neither to identify bone metastases neither to quantify them by a straightforward and universally accepted procedure. In this paper, a new algorithm for the false positives reduction of automatically detected hotspots in bone scintigraphy images is proposed. The motivation relies in the difficulty of building a fully annotated database. In this way, our algorithm is a semisupervised method that works in an iterative way. The ultimate goal is to provide the physician with a fast, precise and reliable tool to quantify bone scans and evaluate disease progression and response to treatment. The algorithm is tested in a set of bone scans manually labeled according to the patient's medical record. The achieved classification sensitivity, specificity and false negative rate were 63%, 58% and 37%, respectively. Comparison with other state-of-the-art classification algorithms shows superiority of the proposed method.",0,0
3848,"Unsupervised Approaches for the Segmentation of Dry ARMD Lesions in Eye Fundus cSLO Images. Age-related macular degeneration (ARMD), a major cause of sight impairment for elderly people, is still not well understood despite intensive research. Measuring the size of the lesions in the fundus is the main biomarker of the severity of the disease and as such is widely used in clinical trials yet only relies on manual segmentation. Artificial intelligence, in particular automatic image analysis based on neural networks, has a major role to play in better understanding the disease, by analyzing the intrinsic optical properties of dry ARMD lesions from patient images. In this paper, we propose a comparison of automatic segmentation methods (classical computer vision method, machine learning method and deep learning method) in an unsupervised context applied on cSLO IR images. Among the methods compared, we propose an adaptation of a fully convolutional network, called W-net, as an efficient method for the segmentation of ARMD lesions. Unlike supervised segmentation methods, our algorithm does not require annotated data which are very difficult to obtain in this application. Our method was tested on a dataset of 328 images and has shown to reach higher quality results than other compared unsupervised methods with a F1 score of 0.87, while having a more stable model, even though in some specific cases, texture/edges-based methods can produce relevant results.",0,0
3853,"Customized Efficient Neural Network for COVID-19 Infected Region Identification in CT Images. In the field of biomedical imaging, radiomics is a promising approach that aims to provide quantitative features from images. It is highly dependent on accurate identification and delineation of the volume of interest to avoid mistakes in the implementation of the texture-based prediction model. In this context, we present a customized deep learning approach aimed at addressing the real-time, and fully automated identification and segmentation of COVID-19 infected regions in computed tomography images.",0,0
3862,"Comparative Study of First Order Optimizers for Image Classification Using Convolutional Neural Networks on Histopathology Images. The classification of histopathology images requires an experienced physician with years of experience to classify the histopathology images accurately. In this study, an algorithm was developed to assist physicians in classifying histopathology images; the algorithm receives the histopathology image as an input and produces the percentage of cancer presence. The primary classifier used in this algorithm is the convolutional neural network, which is a state-of-the-art classifier used in image classification as it can classify images without relying on the manual selection of features from each image. The main aim of this research is to improve the robustness of the classifier used by comparing six different first-order stochastic gradient-based optimizers to select the best for this particular dataset. The dataset used to train the classifier is the PatchCamelyon public dataset, which consists of 220,025 images to train the classifier; the dataset is composed of 60% positive images and 40% negative images, and 57,458 images to test its performance. The classifier was trained on 80% of the images and validated on the rest of 20% of the images; then, it was tested on the test set. The optimizers were evaluated based on their AUC of the ROC curve. The results show that the adaptative based optimizers achieved the highest results except for AdaGrad that achieved the lowest results.",0,0
3865,"Detection of HER2 from Haematoxylin-Eosin Slides Through a Cascade of Deep Learning Classifiers via Multi-Instance Learning. Breast cancer is the most frequently diagnosed cancer in woman. The correct identification of the HER2 receptor is a matter of major importance when dealing with breast cancer: an over-expression of HER2 is associated with aggressive clinical behaviour; moreover, HER2 targeted therapy results in a significant improvement in the overall survival rate. In this work, we employ a pipeline based on a cascade of deep neural network classifiers and multi-instance learning to detect the presence of HER2 from Haematoxylin-Eosin slides, which partly mimics the pathologist's behaviour by first recognizing cancer and then evaluating HER2. Our results show that the proposed system presents a good overall effectiveness. Furthermore, the system design is prone to further improvements that can be easily deployed in order to increase the effectiveness score.",0,0
3869,"Two Ensemble-CNN Approaches for Colorectal Cancer Tissue Type Classification. In recent years, automatic tissue phenotyping has attracted increasing interest in the Digital Pathology (DP) field. For Colorectal Cancer (CRC), tissue phenotyping can diagnose the cancer and differentiate between different cancer grades. The development of Whole Slide Images (WSIs) has provided the required data for creating automatic tissue phenotyping systems. In this paper, we study different hand-crafted feature-based and deep learning methods using two popular multi-classes CRC-tissue-type databases: Kather-CRC-2016 and CRC-TP. For the hand-crafted features, we use two texture descriptors (LPQ and BSIF) and their combination. In addition, two classifiers are used (SVM and NN) to classify the texture features into distinct CRC tissue types. For the deep learning methods, we evaluate four Convolutional Neural Network (CNN) architectures (ResNet-101, ResNeXt-50, Inception-v3, and DenseNet-161). Moreover, we propose two Ensemble CNN approaches: Mean-Ensemble-CNN and NN-Ensemble-CNN. The experimental results show that the proposed approaches outperformed the hand-crafted feature-based methods, CNN architectures and the state-of-the-art methods in both databases.",0,0
3873,"Full 3D Microwave Breast Imaging Using a Deep-Learning Technique. A deep learning technique to enhance 3D images of the complex-valued permittivity of the breast obtained via microwave imaging is investigated. The developed technique is an extension of one created to enhance 2D images. We employ a 3D Convolutional Neural Network, based on the U-Net architecture, that takes in 3D images obtained using the Contrast-Source Inversion (CSI) method and attempts to produce the true 3D image of the permittivity. The training set consists of 3D CSI images, along with the true numerical phantom images from which the microwave scattered field utilized to create the CSI reconstructions was synthetically generated. Each numerical phantom varies with respect to the size, number, and location of tumors within the fibroglandular region. The reconstructed permittivity images produced by the proposed 3D U-Net show that the network is not only able to remove the artifacts that are typical of CSI reconstructions, but it also enhances the detectability of the tumors. We test the trained U-Net with 3D images obtained from experimentally collected microwave data as well as with images obtained synthetically. Significantly, the results illustrate that although the network was trained using only images obtained from synthetic data, it performed well with images obtained from both synthetic and experimental data. Quantitative evaluations are reported using Receiver Operating Characteristics (ROC) curves for the tumor detectability and RMS error for the enhancement of the reconstructions.",0,0
3878,"CORONA-Net: Diagnosing COVID-19 from X-ray Images Using Re-Initialization and Classification Networks. The COVID-19 pandemic has been deemed a global health pandemic. The early detection of COVID-19 is key to combating its outbreak and could help bring this pandemic to an end. One of the biggest challenges in combating COVID-19 is accurate testing for the disease. Utilizing the power of Convolutional Neural Networks (CNNs) to detect COVID-19 from chest X-ray images can help radiologists compare and validate their results with an automated system. In this paper, we propose a carefully designed network, dubbed CORONA-Net, that can accurately detect COVID-19 from chest X-ray images. CORONA-Net is divided into two phases: (1) The reinitialization phase and (2) the classification phase. In the reinitialization phase, the network consists of encoder and decoder networks. The objective of this phase is to train and initialize the encoder and decoder networks by a distribution that comes out of medical images. In the classification phase, the decoder network is removed from CORONA-Net, and the encoder network acts as a backbone network to fine-tune the classification phase based on the learned weights from the reinitialization phase. Extensive experiments were performed on a publicly available dataset, COVIDx, and the results show that CORONA-Net significantly outperforms the current state-of-the-art networks with an overall accuracy of 95.84%.",0,0
3881,"Polyp Segmentation with Fully Convolutional Deep Neural Networks-Extended Evaluation Study. Analysis of colonoscopy images plays a significant role in early detection of colorectal cancer. Automated tissue segmentation can be useful for two of the most relevant clinical target applications-lesion detection and classification, thereby providing important means to make both processes more accurate and robust. To automate video colonoscopy analysis, computer vision and machine learning methods have been utilized and shown to enhance polyp detectability and segmentation objectivity. This paper describes a polyp segmentation algorithm, developed based on fully convolutional network models, that was originally developed for the Endoscopic Vision Gastrointestinal Image Analysis (GIANA) polyp segmentation challenges. The key contribution of the paper is an extended evaluation of the proposed architecture, by comparing it against established image segmentation benchmarks utilizing several metrics with cross-validation on the GIANA training dataset. Different experiments are described, including examination of various network configurations, values of design parameters, data augmentation approaches, and polyp characteristics. The reported results demonstrate the significance of the data augmentation, and careful selection of the method's design parameters. The proposed method delivers state-of-the-art results with near real-time performance. The described solution was instrumental in securing the top spot for the polyp segmentation sub-challenge at the 2017 GIANA challenge and second place for the standard image resolution segmentation task at the 2018 GIANA challenge.",0,0
3886,"Clinical Utility of Artificial Intelligence Algorithms to Enhance Wide-Field Optical Coherence Tomography Angiography Images. The aim of this paper is to investigate the clinical utility of the application of deep learning denoise algorithms on standard wide-field Optical Coherence Tomography Angiography (OCT-A) images. This was a retrospective case-series assessing forty-nine 10 Ã— 10 mm OCT-A1 macula scans of 49 consecutive patients attending a medical retina clinic over a 6-month period. Thirty-seven patients had pathology; 13 had none. Retinal vascular layers were categorised into superficial or deep capillary plexus. For each category, the retinal experts compared the original standard image with the same image that had intelligent denoise applied. When analysing the Superficial Capillary Plexus (SCP), the denoised image was selected as ""best for clinical assessment"" in 98% of comparisons. No difference was established in the remaining 2%. On evaluating the Deep Capillary Plexus (DCP), the denoised image was preferred in 35% of comparisons. No difference was found in 65%. There was no evidence of new artefactual features nor loss of anatomical detail in denoised compared to the standard images. The wide-field denoise feature of the Canon Xephilio OCT-A1 produced scans that were clinically preferable over their original OCT-A images, especially for SCP assessment, without evidence for causing a new artefactual error.",1,1
3888,"Personal Heart Health Monitoring Based on 1D Convolutional Neural Network. The automated detection of suspicious anomalies in electrocardiogram (ECG) recordings allows frequent personal heart health monitoring and can drastically reduce the number of ECGs that need to be manually examined by the cardiologists, excluding those classified as normal, facilitating healthcare decision-making and reducing a considerable amount of time and money. In this paper, we present a system able to automatically detect the suspect of cardiac pathologies in ECG signals from personal monitoring devices, with the aim to alert the patient to send the ECG to the medical specialist for a correct diagnosis and a proper therapy. The main contributes of this work are: (a) the implementation of a binary classifier based on a 1D-CNN architecture for detecting the suspect of anomalies in ECGs, regardless of the kind of cardiac pathology; (b) the analysis was carried out on 21 classes of different cardiac pathologies classified as anomalous; and (c) the possibility to classify anomalies even in ECG segments containing, at the same time, more than one class of cardiac pathologies. Moreover, 1D-CNN based architectures can allow an implementation of the system on cheap smart devices with low computational complexity. The system was tested on the ECG signals from the MIT-BIH ECG Arrhythmia Database for the MLII derivation. Two different experiments were carried out, showing remarkable performance compared to other similar systems. The best result showed high accuracy and recall, computed in terms of ECG segments and even higher accuracy and recall in terms of patients alerted, therefore considering the detection of anomalies with respect to entire ECG recordings.",0,0
3890,"Enhanced Region Growing for Brain Tumor MR Image Segmentation. A brain tumor is one of the foremost reasons for the rise in mortality among children and adults. A brain tumor is a mass of tissue that propagates out of control of the normal forces that regulate growth inside the brain. A brain tumor appears when one type of cell changes from its normal characteristics and grows and multiplies abnormally. The unusual growth of cells within the brain or inside the skull, which can be cancerous or non-cancerous has been the reason for the death of adults in developed countries and children in under developing countries like Ethiopia. The studies have shown that the region growing algorithm initializes the seed point either manually or semi-manually which as a result affects the segmentation result. However, in this paper, we proposed an enhanced region-growing algorithm for the automatic seed point initialization. The proposed approach's performance was compared with the state-of-the-art deep learning algorithms using the common dataset, BRATS2015. In the proposed approach, we applied a thresholding technique to strip the skull from each input brain image. After the skull is stripped the brain image is divided into 8 blocks. Then, for each block, we computed the mean intensities and from which the five blocks with maximum mean intensities were selected out of the eight blocks. Next, the five maximum mean intensities were used as a seed point for the region growing algorithm separately and obtained five different regions of interest (ROIs) for each skull stripped input brain image. The five ROIs generated using the proposed approach were evaluated using dice similarity score (DSS), intersection over union (IoU), and accuracy (Acc) against the ground truth (GT), and the best region of interest is selected as a final ROI. Finally, the final ROI was compared with different state-of-the-art deep learning algorithms and region-based segmentation algorithms in terms of DSS. Our proposed approach was validated in three different experimental setups. In the first experimental setup where 15 randomly selected brain images were used for testing and achieved a DSS value of 0.89. In the second and third experimental setups, the proposed approach scored a DSS value of 0.90 and 0.80 for 12 randomly selected and 800 brain images respectively. The average DSS value for the three experimental setups was 0.86.",0,0
3899,"Data Augmentation Using Adversarial Image-to-Image Translation for the Segmentation of Mobile-Acquired Dermatological Images. Dermoscopic images allow the detailed examination of subsurface characteristics of the skin, which led to creating several substantial databases of diverse skin lesions. However, the dermoscope is not an easily accessible tool in some regions. A less expensive alternative could be acquiring medium resolution clinical macroscopic images of skin lesions. However, the limited volume of macroscopic images available, especially mobile-acquired, hinders developing a clinical mobile-based deep learning approach. In this work, we present a technique to efficiently utilize the sizable number of dermoscopic images to improve the segmentation capacity of macroscopic skin lesion images. A Cycle-Consistent Adversarial Network is used to translate the image between the two distinct domains created by the different image acquisition devices. A visual inspection was performed on several databases for qualitative evaluation of the results, based on the disappearance and appearance of intrinsic dermoscopic and macroscopic features. Moreover, the FrÃ©chet Inception Distance was used as a quantitative metric. The quantitative segmentation results are demonstrated on the available macroscopic segmentation databases, SMARTSKINS and Dermofit Image Library, yielding test set thresholded Jaccard Index of 85.13% and 74.30%. These results establish a new state-of-the-art performance in the SMARTSKINS database.",0,0
3900,"Musculoskeletal Images Classification for Detection of Fractures Using Transfer Learning. The classification of the musculoskeletal images can be very challenging, mostly when it is being done in the emergency room, where a decision must be made rapidly. The computer vision domain has gained increasing attention in recent years, due to its achievements in image classification. The convolutional neural network (CNN) is one of the latest computer vision algorithms that achieved state-of-the-art results. A CNN requires an enormous number of images to be adequately trained, and these are always scarce in the medical field. Transfer learning is a technique that is being used to train the CNN by using fewer images. In this paper, we study the appropriate method to classify musculoskeletal images by transfer learning and by training from scratch. We applied six state-of-the-art architectures and compared their performance with transfer learning and with a network trained from scratch. From our results, transfer learning did increase the model performance significantly, and, additionally, it made the model less prone to overfitting.",0,0
3902,"Lung Segmentation on High-Resolution Computerized Tomography Images Using Deep Learning: A Preliminary Step for Radiomics Studies. The aim of this work is to identify an automatic, accurate, and fast deep learning segmentation approach, applied to the parenchyma, using a very small dataset of high-resolution computed tomography images of patients with idiopathic pulmonary fibrosis. In this way, we aim to enhance the methodology performed by healthcare operators in radiomics studies where operator-independent segmentation methods must be used to correctly identify the target and, consequently, the texture-based prediction model.",0,0
3905,"Fully 3D Active Surface with Machine Learning for PET Image Segmentation. In order to tackle three-dimensional tumor volume reconstruction from Positron Emission Tomography (PET) images, most of the existing algorithms rely on the segmentation of independent PET slices. To exploit cross-slice information, typically overlooked in these 2D implementations, I present an algorithm capable of achieving the volume reconstruction directly in 3D, by leveraging an active surface algorithm. The evolution of such surface performs the segmentation of the whole stack of slices simultaneously and can handle changes in topology. Furthermore, no artificial stop condition is required, as the active surface will naturally converge to a stable topology. In addition, I include a machine learning component to enhance the accuracy of the segmentation process. The latter consists of a forcing term based on classification results from a discriminant analysis algorithm, which is included directly in the mathematical formulation of the energy function driving surface evolution. It is worth noting that the training of such a component requires minimal data compared to more involved deep learning methods. Only eight patients (i.e., two lung, four head and neck, and two brain cancers) were used for training and testing the machine learning component, while fifty patients (i.e., 10 lung, 25 head and neck, and 15 brain cancers) were used to test the full 3D reconstruction algorithm. Performance evaluation is based on the same dataset of patients discussed in my previous work, where the segmentation was performed using the 2D active contour. The results confirm that the active surface algorithm is superior to the active contour algorithm, outperforming the earlier approach on all the investigated anatomical districts with a dice similarity coefficient of 90.47 Â± 2.36% for lung cancer, 88.30 Â± 2.89% for head and neck cancer, and 90.29 Â± 2.52% for brain cancer. Based on the reported results, it can be claimed that the migration into a 3D system yielded a practical benefit justifying the effort to rewrite an existing 2D system for PET imaging segmentation.",0,0
3908,"Morphological Estimation of Cellularity on Neo-Adjuvant Treated Breast Cancer Histological Images. This paper describes a methodology that extracts key morphological features from histological breast cancer images in order to automatically assess Tumour Cellularity (TC) in Neo-Adjuvant treatment (NAT) patients. The response to NAT gives information on therapy efficacy and it is measured by the residual cancer burden index, which is composed of two metrics: TC and the assessment of lymph nodes. The data consist of whole slide images (WSIs) of breast tissue stained with Hematoxylin and Eosin (H&E) released in the 2019 SPIE Breast Challenge. The methodology proposed is based on traditional computer vision methods (K-means, watershed segmentation, Otsu's binarisation, and morphological operations), implementing colour separation, segmentation, and feature extraction. Correlation between morphological features and the residual TC after a NAT treatment was examined. Linear regression and statistical methods were used and twenty-two key morphological parameters from the nuclei, epithelial region, and the full image were extracted. Subsequently, an automated TC assessment that was based on Machine Learning (ML) algorithms was implemented and trained with only selected key parameters. The methodology was validated with the score assigned by two pathologists through the intra-class correlation coefficient (ICC). The selection of key morphological parameters improved the results reported over other ML methodologies and it was very close to deep learning methodologies. These results are encouraging, as a traditionally-trained ML algorithm can be useful when limited training data are available preventing the use of deep learning approaches.",0,0
3917,"Bucket of Deep Transfer Learning Features and Classification Models for Melanoma Detection. Malignant melanoma is the deadliest form of skin cancer and, in recent years, is rapidly growing in terms of the incidence worldwide rate. The most effective approach to targeted treatment is early diagnosis. Deep learning algorithms, specifically convolutional neural networks, represent a methodology for the image analysis and representation. They optimize the features design task, essential for an automatic approach on different types of images, including medical. In this paper, we adopted pretrained deep convolutional neural networks architectures for the image representation with purpose to predict skin lesion melanoma. Firstly, we applied a transfer learning approach to extract image features. Secondly, we adopted the transferred learning features inside an ensemble classification context. Specifically, the framework trains individual classifiers on balanced subspaces and combines the provided predictions through statistical measures. Experimental phase on datasets of skin lesion images is performed and results obtained show the effectiveness of the proposed approach with respect to state-of-the-art competitors.",0,0
3920,"Deeply Supervised UNet for Semantic Segmentation to Assist Dermatopathological Assessment of Basal Cell Carcinoma. Accurate and fast assessment of resection margins is an essential part of a dermatopathologist's clinical routine. In this work, we successfully develop a deep learning method to assist the dermatopathologists by marking critical regions that have a high probability of exhibiting pathological features in whole slide images (WSI). We focus on detecting basal cell carcinoma (BCC) through semantic segmentation using several models based on the UNet architecture. The study includes 650 WSI with 3443 tissue sections in total. Two clinical dermatopathologists annotated the data, marking tumor tissues' exact location on 100 WSI. The rest of the data, with ground-truth sectionwise labels, are used to further validate and test the models. We analyze two different encoders for the first part of the UNet network and two additional training strategies: (a) deep supervision, (b) linear combination of decoder outputs, and obtain some interpretations about what the network's decoder does in each case. The best model achieves over 96%, accuracy, sensitivity, and specificity on the Test set.",0,0
3922,"Skin Lesion Segmentation Using Deep Learning with Auxiliary Task. Skin lesion segmentation is a primary step for skin lesion analysis, which can benefit the subsequent classification task. It is a challenging task since the boundaries of pigment regions may be fuzzy and the entire lesion may share a similar color. Prevalent deep learning methods for skin lesion segmentation make predictions by ensembling different convolutional neural networks (CNN), aggregating multi-scale information, or by multi-task learning framework. The main purpose of doing so is trying to make use of as much information as possible so as to make robust predictions. A multi-task learning framework has been proved to be beneficial for the skin lesion segmentation task, which is usually incorporated with the skin lesion classification task. However, multi-task learning requires extra labeling information which may not be available for the skin lesion images. In this paper, a novel CNN architecture using auxiliary information is proposed. Edge prediction, as an auxiliary task, is performed simultaneously with the segmentation task. A cross-connection layer module is proposed, where the intermediate feature maps of each task are fed into the subblocks of the other task which can implicitly guide the neural network to focus on the boundary region of the segmentation task. In addition, a multi-scale feature aggregation module is proposed, which makes use of features of different scales and enhances the performance of the proposed method. Experimental results show that the proposed method obtains a better performance compared with the state-of-the-art methods with a Jaccard Index (JA) of 79.46, Accuracy (ACC) of 94.32, SEN of 88.76 with only one integrated model, which can be learned in an end-to-end manner.",0,0
3929,"Data pre-processing using Neural Processes for Modelling Personalised Vital-Sign Time-Series Data. Clinical time-series data retrieved from electronic medical records are widely used to build predictive models of adverse events to support resource management. Such data is often sparse and irregularly-sampled, which makes it challenging to use many common machine learning methods. Missing values may be interpolated by carrying the last value forward, based on pre-specified physiological normality ranges, or through linear regression. Increasingly popular is the use of Gaussian process (GP) regression for performing imputation, and often re-sampling of time-series at regular intervals. However, the use of GPs can require extensive, and likely adhoc, investigation to determine model structure, such as an appropriate covariance function. This can be challenging for multivariate real-world clinical data, in which time-series variables exhibit different dynamics to one another. In this work, we construct generative models to estimate missing values in clinical time-series data using a neural latent variable model, known as a Neural Process (NP). The NP model employs a conditional prior distribution in the latent space to learn global uncertainty in the data by modelling variations at a local level. In contrast to conventional generative modeling, such as via a GP, this prior is not fixed and is itself learned during the training process. Thus, an NP model provides the flexibility to adapt to the dynamics of the available clinical data. We propose a variant of the NP framework for efficient modelling of the mutual information between the latent and input spaces, ensuring meaningful learned priors. Experiments using the MIMIC III dataset are used to demonstrate the effectiveness of the proposed approach as compared to conventional data interpolation methods.",0,0
3937,"A Machine Learning Pipeline for Measurement of Arterial Stiffness in A-Mode Ultrasound. Arterial stiffness (AS) of the carotid artery is an early marker of stratifying cardiovascular disease risk. This paper aims to improve performance of ARTSENS, a non-invasive A-mode ultrasound-based device for measuring AS. The primary objective of ARTSENS is to enable measurement of elastic modulus using A-Mode ultrasound and Blood pressure. As this device is image-free, there is a need to automate - a) carotid detection, b) wall localization and c) inner lumen diameter measurement. This has been performed using conventional signal processing methods in some of the earlier works in this domain. In this paper, deep neural network (DNN) models are employed to perform the above three tasks. The DNNs were trained over data acquired from 82 subjects at two different medical centers. Ground truth labeling was performed by a trained operator using corresponding measurements from state-of-the-art Aloka e-Tracking system. All three DNN models had significantly lower error compared to earlier signal processing methods and could perform their measurements using a single A-Mode frame. Using the DNNs, two different machine learning pipelines have been proposed here to measure the elastic modulus; best among them could achieve an error of 9.3% with Pearson correlation coefficient of 0.94 (p < 0.001). The models were tested on Raspberry Pi and Jetson Nano single board computers to demonstrate real-time processing on low computational resources.",0,0
3938,"Global-Local Transformer for Brain Age Estimation. Deep learning can provide rapid brain age estimation based on brain magnetic resonance imaging (MRI). However, most studies use one neural network to extract the global information from the whole input image, ignoring the local fine-grained details. In this paper, we propose a global-local transformer, which consists of a global-pathway to extract the global-context information from the whole input image and a local-pathway to extract the local fine-grained details from local patches. The fine-grained information from the local patches are fused with the global-context information by the attention mechanism, inspired by the transformer, to estimate the brain age. We evaluate the proposed method on 8 public datasets with 8,379 healthy brain MRIs with the age range of 0-97 years. 6 datasets are used for cross-validation and 2 datasets are used for evaluating the generality. Comparing with other state-of-the-art methods, the proposed global-local transformer reduces the mean absolute error of the estimated ages to 2.70 years and increases the correlation coefficient of the estimated age and the chronological age to 0.9853. In addition, our proposed method provides regional information of which local patches are most informative for brain age estimation. Our source code is available on: https://github.com/shengfly/global-local-transformer.",0,0
3942,"MCUa: Multi-level Context and Uncertainty aware Dynamic Deep Ensemble for Breast Cancer Histology Image Classification. Breast histology image classification is a crucial step in the early diagnosis of breast cancer. In breast pathological diagnosis, Convolutional Neural Networks (CNNs) have demonstrated great success using digitized histology slides. However, tissue classification is still challenging due to the high visual variability of the large-sized digitized samples and the lack of contextual information. In this paper, we propose a novel CNN, called Multi-level Context and Uncertainty aware (MCUa) dynamic deep learning ensemble model. MCUa model consists of several multi-level context-aware models to learn the spatial dependency between image patches in a layer-wise fashion. It exploits the high sensitivity to the multi-level contextual information using an uncertainty quantification component to accomplish a novel dynamic ensemble model. MCUa model has achieved a high accuracy of 98.11% on a breast cancer histology image dataset. Experimental results show the superior effectiveness of the proposed solution compared to the state-of-the-art histology classification models.",0,0
3947,"Machine Learning-Based Prediction of Early Recurrence in Glioblastoma Patients: A Glance Towards Precision Medicine. Ability to thrive and time-to-recurrence following treatment are important parameters to assess in patients with glioblastoma multiforme (GBM), given its dismal prognosis. Though there is an ongoing debate whether it can be considered an appropriate surrogate endpoint for overall survival in clinical trials, progression-free survival (PFS) is routinely used for clinical decision-making.",0,0
3949,"Unsupervised Machine Learning Identifies Quantifiable Patterns of Visual Field Loss in Idiopathic Intracranial Hypertension. Archetypal analysis, a form of unsupervised machine learning, identifies archetypal patterns within a visual field (VF) dataset such that any VF is described as a weighted sum of its archetypes (ATs) and has been used to quantify VF defects in glaucoma. We applied archetypal analysis to VFs affected by nonglaucomatous optic neuropathy caused by idiopathic intracranial hypertension (IIH).",0,0
3951,"Patient-Level Cancer Prediction Models From a Nationwide Patient Cohort: Model Development and Validation. Nationwide population-based cohorts provide a new opportunity to build automated risk prediction models at the patient level, and claim data are one of the more useful resources to this end. To avoid unnecessary diagnostic intervention after cancer screening tests, patient-level prediction models should be developed.",0,0
3956,"Tuberculosis detection in chest X-ray usingÂ Mayfly-algorithm optimized dual-deep-learning features. World-Health-Organization (WHO) has listed Tuberculosis (TB) as one among the top 10 reasons for death and an early diagnosis will help to cure the patient by giving suitable treatment. TB usually affects the lungs and an accurate bio-imaging scheme will be apt to diagnose the infection. This research aims to implement an automated scheme to detect TB infection in chest radiographs (X-ray) using a chosen Deep-Learning (DL) approach. The primary objective of the proposed scheme is to attain better classification accuracy while detecting TB in X-ray images. The proposed scheme consists of the following phases namely, (1) image collection and pre-processing, (2) feature extraction with pre-trained VGG16 and VGG19, (3) Mayfly-algorithm (MA) based optimal feature selection, (4) serial feature concatenation and (5) binary classification with a 5-fold cross validation. In this work, the performance of the proposed DL scheme is separately validated for (1) VGG16 with conventional features, (2) VGG19 with conventional features, (3) VGG16 with optimal features, (4) VGG19 with optimal features and (5) concatenated dual-deep-features (DDF). All experimental investigations are conducted and achieved using MATLABÂ® program. Experimental outcome confirms that the proposed system with DDF yields a classification accuracy of 97.8%using a K Nearest-Neighbor (KNN) classifier.",0,0
3958,"A Role for Prior Knowledge in Statistical Classification of the Transition from Mild Cognitive Impairment to Alzheimer's Disease. The transition from mild cognitive impairment (MCI) to dementia is of great interest to clinical research on Alzheimer's disease and related dementias. This phenomenon also serves as a valuable data source for quantitative methodological researchers developing new approaches for classification. However, the growth of machine learning (ML) approaches for classification may falsely lead many clinical researchers to underestimate the value of logistic regression (LR), which often demonstrates classification accuracy equivalent or superior to other ML methods. Further, when faced with many potential features that could be used for classifying the transition, clinical researchers are often unaware of the relative value of different approaches for variable selection.",0,0
3962,"[Automatic segmentation of kidney tumor based on cascaded multiscale convolutional neural networks]. The background of abdominal computed tomography (CT) images is complex, and kidney tumors have different shapes, sizes and unclear edges. Consequently, the segmentation methods applying to the whole CT images are often unable to effectively segment the kidney tumors. To solve these problems, this paper proposes a multi-scale network based on cascaded 3D U-Net and DeepLabV3+ for kidney tumor segmentation, which uses atrous convolution feature pyramid to adaptively control receptive field. Through the fusion of high-level and low-level features, the segmented edges of large tumors and the segmentation accuracies of small tumors are effectively improved. A total of 210 CT data published by Kits2019 were used for five-fold cross validation, and 30 CT volume data collected from Suzhou Science and Technology Town Hospital were independently tested by trained segmentation models. The results of five-fold cross validation experiments showed that the Dice coefficient, sensitivity and precision were 0.796 2 Â± 0.274 1, 0.824 5 Â± 0.276 3, and 0.805 1 Â± 0.284 0, respectively. On the external test set, the Dice coefficient, sensitivity and precision were 0.817 2 Â± 0.110 0, 0.829 6 Â± 0.150 7, and 0.831 8 Â± 0.116 8, respectively. The results show a great improvement in the segmentation accuracy compared with other semantic segmentation methods.",0,0
3963,"[Atrial fibrillation diagnosis algorithm based on improved convolutional neural network]. Atrial fibrillation (AF) is a common arrhythmia, which can lead to thrombosis and increase the risk of a stroke or even death. In order to meet the need for a low false-negative rate (FNR) of the screening test in clinical application, a convolutional neural network with a low false-negative rate (LFNR-CNN) was proposed. Regularization coefficients were added to the cross-entropy loss function which could make the cost of positive and negative samples different, and the penalty for false negatives could be increased during network training. The inter-patient clinical database of 21 077 patients (CD-21077) collected from the large general hospital was used to verify the effectiveness of the proposed method. For the convolutional neural network (CNN) with the same structure, the improved loss function could reduce the FNR from 2.22% to 0.97% compared with the traditional cross-entropy loss function. The selected regularization coefficient could increase the sensitivity (SE) from 97.78% to 98.35%, and the accuracy (ACC) was 96.62%, which was an increase from 96.49%. The proposed algorithm can reduce the FNR without losing ACC, and reduce the possibility of missed diagnosis to avoid missing the best treatment period. Meanwhile, it provides a universal loss function for the clinical auxiliary diagnosis of other diseases.",0,0
3964,"[Sleep apnea automatic detection method based on convolutional neural network]. Sleep apnea (SA) detection method based on traditional machine learning needs a lot of efforts in feature engineering and classifier design. We constructed a one-dimensional convolutional neural network (CNN) model, which consists in four convolution layers, four pooling layers, two full connection layers and one classification layer. The automatic feature extraction and classification were realized by the structure of the proposed CNN model. The model was verified by the whole night single-channel sleep electrocardiogram (ECG) signals of 70 subjects from the Apnea-ECG dataset. Our results showed that the accuracy of per-segment SA detection was ranged from 80.1% to 88.0%, using the input signals of single-channel ECG signal, RR interval (RRI) sequence, R peak sequence and RRI sequence + R peak sequence respectively. These results indicated that the proposed CNN model was effective and can automatically extract and classify features from the original single-channel ECG signal or its derived signal RRI and R peak sequence. When the input signals were RRI sequence + R peak sequence, the CNN model achieved the best performance. The accuracy, sensitivity and specificity of per-segment SA detection were 88.0%, 85.1% and 89.9%, respectively. And the accuracy of per-recording SA diagnosis was 100%. These findings indicated that the proposed method can effectively improve the accuracy and robustness of SA detection and outperform the methods reported in recent years. The proposed CNN model can be applied to portable screening diagnosis equipment for SA with remote server.",0,0
3965,"[Electroencephalogram feature extraction and classification of autistic children based on recurrence quantification analysis]. Extraction and analysis of electroencephalogram (EEG) signal characteristics of patients with autism spectrum disorder (ASD) is of great significance for the diagnosis and treatment of the disease. Based on recurrence quantitative analysis (RQA)method, this study explored the differences in the nonlinear characteristics of EEG signals between ASD children and children with typical development (TD). In the experiment, RQA method was used to extract nonlinear features such as recurrence rate (RR), determinism (DET) and length of average diagonal line (LADL) of EEG signals in different brain regions of subjects, and support vector machine was combined to classify children with ASD and TD. The research results show that for the whole brain area (including parietal lobe, frontal lobe, occipital lobe and temporal lobe), when the three feature combinations of RR, DET and LADL are selected, the maximum classification accuracy rate is 84%, the sensitivity is 76%, the specificity is 92%, and the corresponding area under the curve (AUC) value is 0.875. For parietal lobe and frontal lobe (including parietal lobe, frontal lobe), when the three features of RR, DET and LADL are combined, the maximum classification accuracy rate is 82%, the sensitivity is 72%, and the specificity is 92%, which corresponds to an AUC value of 0.781. The research in this paper shows that the nonlinear characteristics of EEG signals extracted based on RQA method can become an objective indicator to distinguish children with ASD and TD, and combined with machine learning methods, the method can provide auxiliary evaluation indicators for clinical diagnosis. At the same time, the difference in the nonlinear characteristics of EEG signals between ASD children and TD children is statistically significant in the parietal-frontal lobe. This study analyzes the clinical characteristics of children with ASD based on the functions of the brain regions, and provides help for future diagnosis and treatment.",0,0
3969,"Weakly supervised pneumonia localization in chest x-rays using generative adversarial networks. Automatic localization of pneumonia on chest X-rays (CXRs) is highly desirable both as an interpretive aid to the radiologist and for timely diagnosis of the disease. However, pneumonia's amorphous appearance on CXRs and complexity of normal anatomy in the chest present key challenges that hinder accurate localization. Existing studies in this area are either not optimized to preserve spatial information of abnormality or depend on expensive expert annotated bounding boxes. We present a novel generative adversarial network (GAN) based machine learning approach for this problem, that is weakly supervised (does not require any location annotations), was trained to retain spatial information, and can produce pixel-wise abnormality maps highlighting regions of abnormality (as opposed to bounding boxes around abnormality).",0,0
3977,"Ordinal SuStaIn: Subtype and Stage Inference for Clinical Scores, Visual Ratings, and Other Ordinal Data. Subtype and Stage Inference (SuStaIn) is an unsupervised learning algorithm that uniquely enables the identification of subgroups of individuals with distinct pseudo-temporal disease progression patterns from cross-sectional datasets. SuStaIn has been used to identify data-driven subgroups and perform patient stratification in neurodegenerative diseases and in lung diseases from continuous biomarker measurements predominantly obtained from imaging. However, the SuStaIn algorithm is not currently applicable to discrete ordinal data, such as visual ratings of images, neuropathological ratings, and clinical and neuropsychological test scores, restricting the applicability of SuStaIn to a narrower range of settings. Here we propose 'Ordinal SuStaIn', an ordinal version of the SuStaIn algorithm that uses a scored events model of disease progression to enable the application of SuStaIn to ordinal data. We demonstrate the validity of Ordinal SuStaIn by benchmarking the performance of the algorithm on simulated data. We further demonstrate that Ordinal SuStaIn out-performs the existing continuous version of SuStaIn (Z-score SuStaIn) on discrete scored data, providing much more accurate subtype progression patterns, better subtyping and staging of individuals, and accurate uncertainty estimates. We then apply Ordinal SuStaIn to six different sub-scales of the Clinical Dementia Rating scale (CDR) using data from the Alzheimer's disease Neuroimaging Initiative (ADNI) study to identify individuals with distinct patterns of functional decline. Using data from 819 ADNI1 participants we identified three distinct CDR subtype progression patterns, which were independently verified using data from 790 ADNI2 participants. Our results provide insight into patterns of decline in daily activities in Alzheimer's disease and a mechanism for stratifying individuals into groups with difficulties in different domains. Ordinal SuStaIn is broadly applicable across different types of ratings data, including visual ratings from imaging, neuropathological ratings and clinical or behavioural ratings data.",0,0
3978,"Application of Convolutional Neural Network Algorithms for Advancing Sedentary and Activity Bout Classification. Machine learning has been used for classification of physical behavior bouts from hip-worn accelerometers; however, this research has been limited due to the challenges of directly observing and coding human behavior ""in the wild."" Deep learning algorithms, such as convolutional neural networks (CNNs), may offer better representation of data than other machine learning algorithms without the need for engineered features and may be better suited to dealing with free-living data. The purpose of this study was to develop a modeling pipeline for evaluation of a CNN model on a free-living data set and compare CNN inputs and results with the commonly used machine learning random forest and logistic regression algorithms.",0,0
3982,"An Automatic Deep Learning-Based Workflow for Glioblastoma Survival Prediction Using Preoperative Multimodal MR Images: A Feasibility Study. Most radiomic studies use the features extracted from the manually drawn tumor contours for classification or survival prediction. However, large interobserver segmentation variations lead to inconsistent features and hence introduce more challenges in constructing robust prediction models. Here, we proposed an automatic workflow for glioblastoma (GBM) survival prediction based on multimodal magnetic resonance (MR) images.",0,0
3990,"Improving Diuretic Response in Heart Failure by Implementing a Patient-Tailored Variability and Chronotherapy-Guided Algorithm. Heart failure is a major public health problem, which is associated with significant mortality, morbidity, and healthcare expenditures. A substantial amount of the morbidity is attributed to volume overload, for which loop diuretics are a mandatory treatment. However, the variability in response to diuretics and development of diuretic resistance adversely affect the clinical outcomes. Morevoer, there exists a marked intra- and inter-patient variability in response to diuretics that affects the clinical course and related adverse outcomes. In the present article, we review the mechanisms underlying the development of diuretic resistance. The role of the autonomic nervous system and chronobiology in the pathogenesis of congestive heart failure and response to therapy are also discussed. Establishing a novel model for overcoming diuretic resistance is presented based on a patient-tailored variability and chronotherapy-guided machine learning algorithm that comprises clinical, laboratory, and sensor-derived inputs, including inputs from pulmonary artery measurements. Inter- and intra-patient signatures of variabilities, alterations of biological clock, and autonomic nervous system responses are embedded into the algorithm; thus, it may enable a tailored dose regimen in a continuous manner that accommodates the highly dynamic complex system.",0,0
3992,"Reconstructed State Space Features for Classification of ECG Signals. Cardiac arrhythmias are considered as one of the most serious health conditions; therefore, accurate and quick diagnosis of these conditions is highly paramount for the electrocardiogram (ECG) signals. Moreover, are rather difficult for the cardiologists to diagnose with unaided eyes due to a close similarity of these signals in the time domain.",0,0
3998,"Explainable liver tumor delineation in surgical specimens using hyperspectral imaging and deep learning. Surgical removal is the primary treatment for liver cancer, but frequent recurrence caused by residual malignant tissue remains an important challenge, as recurrence leads to high mortality. It is unreliable to distinguish tumors from normal tissues merely under visual inspection. Hyperspectral imaging (HSI) has been proved to be a promising technology for intra-operative use by capturing the spatial and spectral information of tissue in a fast, non-contact and label-free manner. In this work, we investigated the feasibility of HSI for liver tumor delineation on surgical specimens using a multi-task U-Net framework. Measurements are performed on 19 patients and a dataset of 36 specimens was collected with corresponding pathological results serving as the ground truth. The developed framework can achieve an overall sensitivity of 94.48% and a specificity of 87.22%, outperforming the baseline SVM method by a large margin. In particular, we propose to add explanations on the well-trained model from the spatial and spectral dimensions to show the contribution of pixels and spectral channels explicitly. On that basis, a novel saliency-weighted channel selection method is further proposed to select a small subset of 5 spectral channels which provide essentially as much information as using all 224 channels. According to the dominant channels, the absorption difference of hemoglobin and bile content in the normal and malignant tissues seems to be promising markers that could be further exploited.",0,0
3999,"Predictive data clustering of laser-induced breakdown spectroscopy for brain tumor analysis. Limited by the lack of training spectral data in different kinds of tissues, the diagnostic accuracy of laser-induced breakdown spectroscopy (LIBS) is hard to reach the desired level with normal supervised learning identification methods. In this paper, we proposed to apply the predictive data clustering methods with supervised learning methods together to identify tissue information accurately. The meanshift clustering method is introduced to compare with three other clustering methods which have been used in LIBS field. We proposed the cluster precision (CP) score as a new criterion to work with Calinski-Harabasz (CH) score together for the evaluation of the clustering effect. The influences of principal component analysis (PCA) on all four kinds of clustering methods are also analyzed. PCA-meanshift shows the best clustering effect based on the comprehensive evaluation combined CH and CP scores. Based on the spatial location and feature similarity information provided by the predictive clustering, the PCA-Meanshift can improve diagnosis accuracy from less than 95% to 100% for all classifiers including support vector machine (SVM), <i>k</i> nearest neighbor (<i>k</i>-NN), soft independent modeling of class analogy (Simca) and random forests (RF) models.",0,0
4002,"Space curvature-inspired nanoplasmonic sensor for breast cancer extracellular vesicle fingerprinting and machine learning classification. Extracellular vesicles (EVs) are micro and nanoscale lipid-enclosed packages that have shown potential as liquid biopsy targets for cancer because their structure and contents reflect their cell of origin. However, progress towards the clinical applications of EVs has been hindered due to the low abundance of disease-specific EVs compared to EVs from healthy cells; such applications thus require highly sensitive and adaptable characterization tools. To address this obstacle, we designed and fabricated a novel space curvature-inspired surfaced-enhanced Raman spectroscopy (SERS) substrate and tested its capabilities using bioreactor-produced and size exclusion chromatography-purified breast cancer EVs of three different subtypes. Our findings demonstrate the platform's ability to effectively fingerprint and efficiently classify, for the first time, three distinct subtypes of breast cancer EVs following the application of machine learning algorithms on the acquired spectra. This platform and characterization approach will enhance the viability of EVs and nanoplasmonic sensors towards clinical utility for breast cancer and many other applications to improve human health.",0,0
4004,"Personality first in emotion: a deep neural network based on electroencephalogram channel attention for cross-subject emotion recognition. In recent years, more and more researchers have focused on emotion recognition methods based on electroencephalogram (EEG) signals. However, most studies only consider the spatio-temporal characteristics of EEG and the modelling based on this feature, without considering personality factors, let alone studying the potential correlation between different subjects. Considering the particularity of emotions, different individuals may have different subjective responses to the same physical stimulus. Therefore, emotion recognition methods based on EEG signals should tend to be personalized. This paper models the personalized EEG emotion recognition from the macro and micro levels. At the macro level, we use personality characteristics to classify the individuals' personalities from the perspective of 'birds of a feather flock together'. At the micro level, we employ deep learning models to extract the spatio-temporal feature information of EEG. To evaluate the effectiveness of our method, we conduct an EEG emotion recognition experiment on the ASCERTAIN dataset. Our experimental results demonstrate that the recognition accuracy of our proposed method is 72.4% and 75.9% on valence and arousal, respectively, which is 10.2% and 9.1% higher than that of no consideration of personalization.",0,0
4006,"Prediction Algorithm of Young Students' Physical Health Risk Factors Based on Deep Learning. Young people's physical and mental health is the foundation of society's overall development and the key to improving people's health quality. Middle school students' physical examinations and monitoring work are a surefire way to ensure their healthy development. Poor vision, dental caries, overweight and obesity, and high blood pressure are the most common adverse health outcomes of students caused by adolescent health risk behavior factors. Researchers have been concerned about the retinal fundus vascular system, which is the only internal vascular system that can be observed in a noninvasive state of the human body. Fundus images contain a wealth of disease-related information. Fundus images have been widely used in the field of medical auxiliary diagnosis because many important systemic diseases of the human body cause specific reactions in the fundus. Aiming to solve the problem of inseparable tiny blood vessels, this paper proposes a model of retinal vessel segmentation based on attention mechanisms. In light of the retinal arteriovenous division of discontinuous challenges, the topological structure of the constraint system along with overcoming the network and topology restrictions is monitored. Finally, simulation experiments were conducted on two publicly available datasets. The findings show that the proposed method is reliable, effective, and accurate in predicting physical health risk factors in adolescent students.",0,0
4008,"Research on Classification of COVID-19 Chest X-Ray Image Modal Feature Fusion Based on Deep Learning. Most detection methods of coronavirus disease 2019 (COVID-19) use classic image classification models, which have problems of low recognition accuracy and inaccurate capture of modal features when detecting chest X-rays of COVID-19. This study proposes a COVID-19 detection method based on image modal feature fusion. This method first performs small-sample enhancement processing on chest X-rays, such as rotation, translation, and random transformation. Five classic pretraining models are used when extracting modal features. A global average pooling layer reduces training parameters and prevents overfitting. The model is trained and fine-tuned, the machine learning evaluation standard is used to evaluate the model, and the receiver operating characteristic (ROC) curve is drawn. Experiments show that compared with the classic model, the classification method in this study can more effectively detect COVID-19 image modal information, and it achieves the expected effect of accurately detecting cases.",0,0
4011,"Explainable AI-based clinical decision support system for hearing disorders. In clinical system design, human-computer interaction and explainability are important topics of research. Clinical systems need to provide users with not only results but also an account of their behaviors. In this research, we propose a knowledge-based clinical decision support system (CDSS) for the diagnosis and therapy of hearing disorders, such as tinnitus, hyperacusis, and misophonia. Our prototype eTRT system offers an explainable output that we expect to increase its trustworthiness and acceptance in the clinical setting. Within this paper, we: (1) present the problem area of tinnitus and its treatment; (2) describe our data-driven approach based on machine learning, such as association- and action rule discovery; (3) present the evaluation results from the inference on the extracted rule-based knowledge and chosen test cases of patients; (4) discuss advantages of explainable output incorporated into a graphical user interface; (5) conclude with the results achieved and directions for future work.",0,0
4019,"Integration of NLP2FHIR Representation with Deep Learning Models for EHR Phenotyping: A Pilot Study on Obesity Datasets. HL7 Fast Healthcare Interoperability Resources (FHIR) is one of the current data standards for enabling electronic healthcare information exchange. Previous studies have shown that FHIR is capable of modeling both structured and unstructured data from electronic health records (EHRs). However, the capability of FHIR in enabling clinical data analytics has not been well investigated. The objective of the study is to demonstrate how FHIR-based representation of unstructured EHR data can be ported to deep learning models for text classification in clinical phenotyping. We leverage and extend the NLP2FHIR clinical data normalization pipeline and conduct a case study with two obesity datasets. We tested several deep learning-based text classifiers such as convolutional neural networks, gated recurrent unit, and text graph convolutional networks on both raw text and NLP2FHIR inputs. We found that the combination of NLP2FHIR input and text graph convolutional networks has the highest F1 score. Therefore, FHIR-based deep learning methods has the potential to be leveraged in supporting EHR phenotyping, making the phenotyping algorithms more portable across EHR systems and institutions.",0,0
4021,"Severity Prediction for COVID-19 Patients via Recurrent Neural Networks. The novel coronavirus disease-2019 (COVID-19) pandemic has threatened the health of tens of millions of people worldwide and imposed heavy burden on global healthcare systems. In this paper, we propose a model to predict whether a patient infected with COVID-19 will develop severe outcomes based only on the patient's historical electronic health records (EHR) prior to hospital admission using recurrent neural networks. The model predicts risk score that represents the probability for a patient to progress into severe status (mechanical ventilation, tracheostomy, or death) after being infected with COVID-19. The model achieved 0.846 area under the receiver operating characteristic curve in predicting patients' outcomes averaged over 5-fold cross validation. While many of the existing models use features obtained after diagnosis of COVID-19, our proposed model only utilizes a patient's historical EHR to enable proactive risk management at the time of hospital admission.",0,0
4029,"Applications of Aspect-based Sentiment Analysis on Psychiatric Clinical Notes to Study Suicide in Youth. Understanding and identifying the risk factors associated with suicide in youth experiencing mental health concerns is paramount to early intervention. 45% of patients are admitted annually for suicidality at BC Children's Hospital. Natural Language Processing (NLP) approaches have been applied with moderate success to psychiatric clinical notes to predict suicidality. Our objective was to explore whether machine-learning-based sentiment analysis could be informative in such a prediction task. We developed a psychiatry-relevant lexicon and identified specific categories of words, such as thought content and thought process that had significantly different polarity between suicidal and non-suicidal cases. In addition, we demonstrated that the individual words with their associated polarity can be used as features in classification models and carry informative content to differentiate between suicidal and non-suicidal cases. In conclusion, our study reveals that there is much value in applying NLP to psychiatric clinical notes and suicidal prediction.",0,0
4030,"More Generalizable Models For Sepsis Detection Under Covariate Shift. Sepsis is a major cause of mortality in the intensive care units (ICUs). Early intervention of sepsis can improve clinical outcomes for sepsis patients<sup>1,2,3</sup>. Machine learning models have been developed for clinical recognition of sepsis<sup>4,5,6</sup>. A common assumption of supervised machine learning models is that the covariates in the testing data follow the same distributions as those in the training data. When this assumption is violated (e.g., there is covariate shift), models that performed well for training data could perform badly for testing data. Covariate shift happens when the relationships between covariates and the outcome stay the same, but the marginal distributions of the covariates differ among training and testing data. Covariate shift could make clinical risk prediction model nongeneralizable. In this study, we applied covariate shift corrections onto common machine learning models and have observed that these corrections can help the models be more generalizable under the occurrence of covariate shift when detecting the onset of sepsis.",0,0
4031,"Blending Knowledge in Deep Recurrent Networks for Adverse Event Prediction at Hospital Discharge. Deep learning architectures have an extremely high-capacity for modeling complex data in a wide variety of domains. However, these architectures have been limited in their ability to support complex prediction problems using insurance claims data, such as readmission at 30 days, mainly due to data sparsity issue. Consequently, classical machine learning methods, especially those that embed domain knowledge in handcrafted features, are often on par with, and sometimes outperform, deep learning approaches. In this paper, we illustrate how the potential of deep learning can be achieved by blending domain knowledge within deep learning architectures to predict adverse events at hospital discharge, including readmissions. More specifically, we introduce a learning architecture that fuses a representation of patient data computed by a self-attention based recurrent neural network, with clinically relevant features. We conduct extensive experiments on a large claims dataset and show that the blended method outperforms the standard machine learning approaches.",0,0
4037,"COVID-19 disease identification from chest CT images using empirical wavelet transformation and transfer learning. In the current scenario, novel coronavirus disease (COVID-19) spread is increasing day-by-day. It is very important to control and cure this disease. Reverse transcription-polymerase chain reaction (RT-PCR), chest computerized tomography (CT) imaging options are available as a significantly useful and more truthful tool to classify COVID-19 within the epidemic region. Most of the hospitals have CT imaging machines. It will be fruitful to utilize the chest CT images for early diagnosis and classification of COVID-19 patients. This requires a radiology expert and a good amount of time to classify the chest CT-based COVID-19 images especially when the disease is spreading at a rapid rate. During this pandemic COVID-19, there is a need for an efficient automated way to check for infection. CT is one of the best ways to detect infection inpatients. This paper introduces a new method for preprocessing and classifying COVID-19 positive and negative from CT scan images. The method which is being proposed uses the concept of empirical wavelet transformation for preprocessing, selecting the best components of the red, green, and blue channels of the image are trained on the proposed network. With the proposed methodology, the classification accuracy of 85.5%, F1 score of 85.28%, and AUC of 96.6% are achieved.",0,0
4049,"Identifying Methamphetamine Abstainers With Convolutional Neural Networks and Short-Time Fourier Transform. Few studies have investigated the functional patterns of methamphetamine abstainers. A better understanding of the underlying neurobiological mechanism in the brains of methamphetamine abstainers will help to explain their abnormal behaviors. Forty-two male methamphetamine abstainers, currently in a long-term abstinence status (for at least 14 months), and 32 male healthy controls were recruited. All subjects underwent functional MRI while responding to drug-associated cues. This study proposes to combine a convolutional neural network with a short-time Fourier transform to identify different brain patterns between methamphetamine abstainers and controls. The short-time Fourier transformation provides time-localized frequency information, while the convolutional neural network extracts the structural features of the time-frequency spectrograms. The results showed that the classifier achieved a satisfactory performance (98.9% accuracy) and could extract robust brain voxel information. The highly discriminative power voxels were mainly concentrated in the left inferior orbital frontal gyrus, the bilateral postcentral gyri, and the bilateral paracentral lobules. This study provides a novel insight into the different functional patterns between methamphetamine abstainers and healthy controls. It also elucidates the pathological mechanism of methamphetamine abstainers from the view of time-frequency spectrograms.",0,0
4051,"Toward More Robust Hand Gesture Recognition on EIT Data. Striving for more robust and natural control of multi-fingered hand prostheses, we are studying electrical impedance tomography (EIT) as a method to monitor residual muscle activations. Previous work has shown promising results for hand gesture recognition, but also lacks generalization across multiple sessions and users. Thus, the present paper aims for a detailed analysis of an existing EIT dataset acquired with a 16-electrode wrist band as a prerequisite for further improvements of machine learning results on this type of signal. The performed t-SNE analysis confirms a much stronger inter-session and inter-user variance compared to the expected in-class variance. Additionally, we observe a strong drift of signals within a session. To handle these challenging problems, we propose new machine learning architectures based on deep learning, which allow to separate undesired from desired variation and thus significantly improve the classification accuracy. With these new architectures we increased cross-session classification accuracy on 12 gestures from 19.55 to 30.45%. Based on a fundamental data analysis we developed three calibration methods and thus were able to further increase cross-session classification accuracy to 39.01, 55.37, and 56.34%, respectively.",0,0
4054,"Classifying Ruptured Middle Cerebral Artery Aneurysms With a Machine Learning Based, Radiomics-Morphological Model: A Multicentral Study. Radiomics and morphological features were associated with aneurysms rupture. However, the multicentral study of their predictive power for specific-located aneurysms rupture is rare. We aimed to determine robust radiomics features related to middle cerebral artery (MCA) aneurysms rupture and evaluate the additional value of combining morphological and radiomics features in the classification of ruptured MCA aneurysms.",0,0
4055,"Prediction framework for upper body sedentary working behaviour by using deep learning and machine learning techniques. Public health experts and healthcare professionals are gradually identifying sedentary activity as a population-wide, pervasive health risk. The purpose of this paper is to propose a method to identify the changes in posture during sedentary workÂ and to give feedback by analysing the identified posture of the upper body, i.e. hands, shoulder, and head positioning. After capturing the image of the human pose, pre-processing of the image takes place with a bandpass filter, which helps to reduce the noise and morphological operation, which is used to carry out the process of dilation, erosion and opening of an image. To predict the results easily with the use of texture feature extraction, it helps to extract the image's feature. Then, accuracy is predicted by using the deep neural network techniques, to predict the result accurately. After prediction and analysis, the feedback system is developed to alert individuals through the alarm system. The proposed method is formulated by using DNN for prediction in the MATLAB software tool. The results show accuracy, sensitivity and specificity of the prediction using a deep neural network are 97.2%, 88.7% and 99.1%. The proposed method is compared with the existing methods SVM, Random Forest and KNN algorithms. The accuracy, sensitivity and specificity of the existing algorithms are SVM with 77.6%, 57.4 and 97.8%; Random Forest with 80.6%, 63.7% and 97.5%; and KNN with 65.8%, 61.2%, and 95.1%. This concept helps to prevent the impact of sedentary activity on fatal and non-fatal cardiovascular and musculoskeletal diseases, respectively.",0,0
4058,"An adaptive speech signal processing for COVID-19 detection using deep learning approach. Researchers and scientists have been conducting plenty of research on COVID-19 since its outbreak. Healthcare professionals, laboratory technicians, and front-line workers like sanitary workers, data collectors are putting tremendous efforts to avoid the prevalence of the COVID-19 pandemic. Currently, the reverse transcription polymerase chain reaction (RT-PCR) testing strategy determines the COVID-19 virus. This RT-PCR processing is more expensive and induces violation of social distancing rules, and time-consuming. Therefore, this research work introduces generative adversarial network deep learning for quickly detect COVID-19 from speech signals. This proposed system consists of two stages, pre-processing and classification. This work uses the least mean square (LMS) filter algorithm to remove the noise or artifacts from input speech signals. After removing the noise, the proposed generative adversarial network classification method analyses the mel-frequency cepstral coefficients features and classifies the COVID-19 signals and non-COVID-19 signals. The results show a more prominent correlation of MFCCs with various COVID-19 cough and breathing sounds, while the sound is more robust between COVID-19 and non-COVID-19 models. As compared with the existing Artificial Neural Network, Convolutional Neural Network, and Recurrent Neural Network, the proposed GAN method obtains the best result. The precision, recall, accuracy, and F-measure of the proposed GAN are 96.54%, 96.15%, 98.56%, and 0.96, respectively.",0,0
4064,"SARS-Net: COVID-19 detection from chest x-rays by combining graph convolutional network and convolutional neural network. COVID-19 has emerged as one of the deadliest pandemics that has ever crept on humanity. Screening tests are currently the most reliable and accurate steps in detecting severe acute respiratory syndrome coronavirus in a patient, and the most used is RT-PCR testing. Various researchers and early studies implied that visual indicators (abnormalities) in a patient's Chest X-Ray (CXR) or computed tomography (CT) imaging were a valuable characteristic of a COVID-19 patient that can be leveraged to find out virus in a vast population. Motivated by various contributions to open-source community to tackle COVID-19 pandemic, we introduce SARS-Net, a CADx system combining Graph Convolutional Networks and Convolutional Neural Networks for detecting abnormalities in a patient's CXR images for presence of COVID-19 infection in a patient. In this paper, we introduce and evaluate the performance of a custom-made deep learning architecture SARS-Net, to classify and detect the Chest X-ray images for COVID-19 diagnosis. Quantitative analysis shows that the proposed model achieves more accuracy than previously mentioned state-of-the-art methods. It was found that our proposed model achieved an accuracy of 97.60% and a sensitivity of 92.90% on the validation set.",0,0
4065,"Multi-task driven explainable diagnosis of COVID-19 using chest X-ray images. With increasing number of COVID-19 cases globally, all the countries are ramping up the testing numbers. While the RT-PCR kits are available in sufficient quantity in several countries, others are facing challenges with limited availability of testing kits and processing centers in remote areas. This has motivated researchers to find alternate methods of testing which are reliable, easily accessible and faster. Chest X-Ray is one of the modalities that is gaining acceptance as a screening modality. Towards this direction, the paper has two primary contributions. Firstly, we present the COVID-19 Multi-Task Network (COMiT-Net) which is an automated end-to-end network for COVID-19 screening. The proposed network not only predicts whether the CXR has COVID-19 features present or not, it also performs semantic segmentation of the regions of interest to make the model explainable. Secondly, with the help of medical professionals, we manually annotate the lung regions and semantic segmentation of COVID19 symptoms in CXRs taken from the ChestXray-14, CheXpert, and a consolidated COVID-19 dataset. These annotations will be released to the research community. Experiments performed with more than 2500 frontal CXR images show that at 90% specificity, the proposed COMiT-Net yields 96.80% sensitivity.",0,0
4071,"Identification of WHO II/III gliomas by 16 prognostic-related gene signatures using machine learning methods. It is found that the prognosis of gliomas of the same grade has large differences among World Health Organization(WHO) grade II and III in clinical observation. Therefore, a better understanding of the genetics and molecular mechanisms underlying WHO grade II and III gliomas is required, with the aim of developing a classification scheme at the molecular level rather than the conventional pathological morphology level.",0,0
4075,"Raman spectroscopy and machine learning for the classification of breast cancers. Breast cancer is a major health threat for women. The drug responses associated with different breast cancer subtypes have obvious effects on therapeutic outcomes; therefore, the accurate classification of breast cancer subtypes is critical. Breast cancer subtype classification has recently been examined using various methods, and Raman spectroscopy has emerged as an effective technique that can be used for noninvasive breast cancer analysis. However, the accurate and rapid classification of breast cancer subtypes currently requires a great deal of effort and experience with the processing and analysis of Raman spectra data. Here, we adopted Raman spectroscopy and machine learning techniques to simplify and accelerate the process used to distinguish normal from breast cancer cells and classify breast cancer subtypes. Raman spectra were obtained from cultured breast cancer cell lines, and the data were analyzed by two machine learning algorithms: principal component analysis (PCA)-discriminant function analysis (DFA) and PCA-support vector machine (SVM). The accuracies with which these two algorithms were able to distinguish normal breast cells from breast cancer cells were both greater than 97%, and the accuracies of breast cancer subtype classification for both algorithms were both greater than 92%. Moreover, our results showed evidence to support the use of characteristic Raman spectral features as cancer cell biomarkers, such as the intensity of intrinsic Raman bands, which increased in cancer cells. Raman spectroscopy combined with machine learning techniques provides a rapid method for breast cancer analysis able to reveal differences in intracellular compositions and molecular structures among subtypes.",0,0
4076,Machine Learning to Predict Fascial Dehiscence after Exploratory Laparotomy Surgery. Fascial dehiscence following exploratory laparotomy is associated with significant morbidity and increased mortality. Previously published risk prediction models for fascial dehiscence are dated and limit a surgeon's ability to perform reliable risk assessment intraoperatively. We sought to determine if machine learning can predict fascial dehiscence after exploratory laparotomy.,0,0
4077,"A deep CNN model for anomaly detection and localization in wireless capsule endoscopy images. Wireless capsule endoscopy (WCE) is one of the most efficient methods for the examination of gastrointestinal tracts. Computer-aided intelligent diagnostic tools alleviate the challenges faced during manual inspection of long WCE videos. Several approaches have been proposed in the literature for the automatic detection and localization of anomalies in WCE images. Some of them focus on specific anomalies such as bleeding, polyp, lesion, etc. However, relatively fewer generic methods have been proposed to detect all those common anomalies simultaneously. In this paper, a deep convolutional neural network (CNN) based model 'WCENet' is proposed for anomaly detection and localization in WCE images. The model works in two phases. In the first phase, a simple and efficient attention-based CNN classifies an image into one of the four categories: polyp, vascular, inflammatory, or normal. If the image is classified in one of the abnormal categories, it is processed in the second phase for the anomaly localization. Fusion of Grad-CAM++ and a custom SegNet is used for anomalous region segmentation in the abnormal image. WCENet classifier attains accuracy and area under receiver operating characteristic of 98% and 99%. The WCENet segmentation model obtains a frequency weighted intersection over union of 81%, and an average dice score of 56% on the KID dataset. WCENet outperforms nine different state-of-the-art conventional machine learning and deep learning models on the KID dataset. The proposed model demonstrates potential for clinical applications.",0,0
4081,"Aberrant levels of cortical myelin distinguish individuals with depressive disorders from healthy controls. The association between depressive disorders and measures reflecting myelin content is underexplored, despite growing evidence of associations with white matter tract integrity. We characterized the T1w/T2w ratio using the Glasser atlas in 39 UD and 47 HC participants (agesÂ =Â 19-44, 75% female). A logistic elastic net regularized regression with nested cross-validation and a subsequent linear discriminant analysis conducted on held-out samples were used to select brain regions and classify patients vs. healthy controls (HC). True-label model performance was compared against permuted-label model performance. The T1w/T2w ratio distinguished patients from HC with 68% accuracy (pÂ <Â 0.001; sensitivityÂ =Â 63.8%, specificityÂ =Â 71.5%). Brain regions contributing to this classification performance were located in the orbitofrontal cortex, anterior cingulate, extended visual, and auditory cortices, and showed statistically significant differences in the T1w/T2w ratio for patients vs. HC. As the T1w/T2w ratio is thought to characterize cortical myelin, patterns of cortical myelin in these regions may be a biomarker distinguishing individuals with depressive disorders from HC.",0,0
4085,Predicting mortality in SARS-COV-2 (COVID-19) positive patients in the inpatient setting using a novel deep neural network. The nextwave of COVID-19 pandemic is anticipated to be worse than the initial one and will strain the healthcare systems even more during the winter months. Our aim was to develop a novel machine learning-based model to predict mortality using the deep learning Neo-V framework. We hypothesized this novel machine learning approach could be applied to COVID-19 patients to predict mortality successfully with high accuracy.,0,0
4090,Using Machine-Learning for PredictionÂ ofÂ the Response to CardiacÂ Resynchronization Therapy: TheÂ SMART-AV Study. This study aimed to apply machine learning (ML) to develop a prediction model for short-term cardiac resynchronization therapy (CRT) response to identifying CRT candidates for early multidisciplinary CRT heart failure (HF) care.,0,0
4099,"Predicting postoperative surgical site infection with administrative data: a random forests algorithm. Since primary data collection can be time-consuming and expensive, surgical site infections (SSIs) could ideally be monitored using routinely collected administrative data. We derived and internally validated efficient algorithms to identify SSIs within 30â€‰days after surgery with health administrative data, using Machine Learning algorithms.",0,0
4100,"Comparison of domain adaptation techniques for white matter hyperintensity segmentation in brain MR images. Robust automated segmentation of white matter hyperintensities (WMHs) in different datasets (domains) is highly challenging due to differences in acquisition (scanner, sequence), population (WMH amount and location) and limited availability of manual segmentations to train supervised algorithms. In this work we explore various domain adaptation techniques such as transfer learning and domain adversarial learning methods, including domain adversarial neural networks and domain unlearning, to improve the generalisability of our recently proposed triplanar ensemble network, which is our baseline model. We used datasets with variations in intensity profile, lesion characteristics and acquired using different scanners. For the source domain, we considered a dataset consisting of data acquired from 3 different scanners, while the target domain consisted of 2 datasets. We evaluated the domain adaptation techniques on the target domain datasets, and additionally evaluated the performance on the source domain test dataset for the adversarial techniques. For transfer learning, we also studied various training options such as minimal number of unfrozen layers and subjects required for fine-tuning in the target domain. On comparing the performance of different techniques on the target dataset, domain adversarial training of neural network gave the best performance, making the technique promising for robust WMH segmentation.",0,0
4101,"Detection of EEG burst-suppression in neurocritical care patients using an unsupervised machine learning algorithm. The burst suppression pattern in clinical electroencephalographic (EEG) recordings is an important diagnostic tool because of its association with comas of various etiologies, as with hypoxia, drug related intoxication or deep anesthesia. The detection of bursts and the calculation of burst/suppression ratio are often used to monitor the level of anesthesia during treatment of status epilepticus. However, manual counting of bursts is a laborious process open to inter-rater variation and motivates a need for automatic detection.",0,0
4107,"A novel hierarchical machine learning model for hospital-acquired venous thromboembolism risk assessment among multiple-departments. Venous thromboembolism (VTE) is a common vascular disease and potentially fatal complication during hospitalization, and so the early identification of VTE risk is of significant importance. Compared with traditional scale assessments, machine learning methods provide new opportunities for precise early warning of VTE from clinical medical records. This research aimed to propose a two-stage hierarchical machine learning model for VTE risk prediction in patients from multiple departments. First, we built a machine learning prediction model that covered the entire hospital, based on all cohorts and common risk factors. Then, we took the prediction output of the first stage as an initial assessment score and then built specific models for each department. Over the duration of the study, a total of 9213 inpatients, including 1165 VTE-positive samples, were collected from four departments, which were split into developing and test datasets. The proposed model achieved an AUC of 0.879 in the department of oncology, which outperformed the first-stage model (0.730) and the department model (0.787). This was attributed to the fully usage of both the large sample size at the hospital level and variable abundance at the department level. Experimental results show that our model could effectively improve the prediction of hospital-acquired VTE risk before image diagnosis and provide decision support for further nursing and medical intervention.",0,0
4112,"A Machine Learning Methodology for Identification and Triage of Heart Failure Exacerbations. Inadequate at-home management and self-awareness of heart failure (HF) exacerbations are known to be leading causes of the greater than 1 million estimated HF-related hospitalizations in the USA alone. Most current at-home HF management protocols include paper guidelines or exploratory health applications that lack rigor and validation at the level of the individual patient. We report on a novel triage methodology that uses machine learning predictions for real-time detection and assessment of exacerbations. Medical specialist opinions on statistically and clinically comprehensive, simulated patient cases were used to train and validate prediction algorithms. Model performance was assessed by comparison to physician panel consensus in a representative, out-of-sample validation set of 100 vignettes. Algorithm prediction accuracy and safety indicators surpassed all individual specialists in identifying consensus opinion on existence/severity of exacerbations and appropriate treatment response. The algorithms also scored the highest sensitivity, specificity, and PPV when assessing the need for emergency care. Here we develop a machine-learning approach for providing real-time decision support to adults diagnosed with congestive heart failure. The algorithm achieves higher exacerbation and triage classification performance than any individual physician when compared to physician consensus opinion.",1,1
4113,"A proof of concept study for machine learning application to stenosis detection. This proof of concept (PoC) assesses the ability of machine learning (ML) classifiers to predict the presence of a stenosis in a three vessel arterial system consisting of the abdominal aorta bifurcating into the two common iliacs. A virtual patient database (VPD) is created using one-dimensional pulse wave propagation model of haemodynamics. Four different machine learning (ML) methods are used to train and test a series of classifiers-both binary and multiclass-to distinguish between healthy and unhealthy virtual patients (VPs) using different combinations of pressure and flow-rate measurements. It is found that the ML classifiers achieve specificities larger than 80% and sensitivities ranging from 50 to 75%. The most balanced classifier also achieves an area under the receiver operative characteristic curve of 0.75, outperforming approximately 20 methods used in clinical practice, and thus placing the method as moderately accurate. Other important observations from this study are that (i) few measurements can provide similar classification accuracies compared to the case when more/all the measurements are used; (ii) some measurements are more informative than others for classification; and (iii) a modification of standard methods can result in detection of not only the presence of stenosis, but also the stenosed vessel. Graphical Abstract An overview of methodology fo the creation of virtual patients and their classification.",0,0
4114,"Exploring domains, clinical implications and environmental associations of a deep learning marker of biological ageing. Deep Neural Networks (DNN) have been recently developed for the estimation of Biological Age (BA), the hypothetical underlying age of an organism, which can differ from its chronological age (CA). Although promising, these population-specific algorithmsÂ warrant further characterization and validation, since their biological, clinical and environmental correlates remain largely unexplored. Here, an accurate DNN was trained to compute BA based on 36 circulating biomarkers in an Italian population (Nâ€‰=â€‰23,858; ageâ€‰â‰¥â€‰35Â years; 51.7% women). This estimate was heavily influenced by markers of metabolic, heart, kidney and liver function. The resulting Î”age (BA-CA) significantly predicted mortality and hospitalization risk for all and specific causes. Slowed biological aging (Î”ageâ€‰<â€‰0) was associated with higher physical and mental wellbeing, healthy lifestyles (e.g. adherence to Mediterranean diet) and higher socioeconomic status (educational attainment, household income and occupational status), while accelerated aging (Î”ageâ€‰>â€‰0) was associated with smoking and obesity. Together, lifestyles and socioeconomic variables explained ~48% of the total variance in Î”age, potentially suggesting the existence of a genetic basis. These findings validate blood-based biological aging as a marker of public health in adult Italians and provide a robust body of knowledge on its biological architecture, clinical implications and potential environmental influences.",0,0
4117,"Automatic detection of oral cancer in smartphone-based images using deep learning for early diagnosis. Oral cancer is a quite common global health issue. Early diagnosis of cancerous and potentially malignant disorders in the oral cavity would significantly increase the survival rate of oral cancer. Previously reported smartphone-based images detection methods for oral cancer mainly focus on demonstrating the effectiveness of their methodology, yet it still lacks systematic study on how to improve the diagnosis accuracy on oral disease using hand-held smartphone photographic images.",0,0
4119,"The role of deep learning-based survival model in improving survival prediction of patients with glioblastoma. This retrospective study has been conducted to validate the performance of deep learning-based survival models in glioblastoma (GBM) patients alongside the Cox proportional hazards model (CoxPH) and the random survival forest (RSF). Furthermore, the effect of hyperparameters optimization methods on improving the prediction accuracy of deep learning-based survival models was investigated. Of the 305 cases, 260Â GBM patients were included in our analysis based on the following criteria: demographic information (i.e., age, Karnofsky performance score, gender, and race), tumor characteristic (i.e., laterality and location), details of post-surgical treatment (i.e., time to initiate concurrent chemoradiation therapy, standard treatment, and radiotherapy techniques), and last follow-up time as well as the molecular markers (i.e., O-6-methylguanine methyltransferase and isocitrate dehydrogenase 1Â status). Experimental results have demonstrated that age (ElderlyÂ >Â 65: hazard ratio [HR]Â =Â 1.63; 95% confidence interval [CI]: 1.213-2.18; p valueÂ =Â 0.001) and tumors located at multiple lobes ([HR]Â =Â 1.75; 95% [CI]: 1.177-2.61; p valueÂ =Â 0.006) were associated with poorer prognosis. In contrast, age (youngÂ <Â 40: [HR]Â =Â 0.57; 95% [CI]: 0.343-0.96; p valueÂ =Â 0.034) and type of radiotherapy (others include stereotactic and brachytherapy: [HR]Â =Â 0.5; 95%[CI]: 0.266-0.95; p valueÂ =Â 0.035) were significantly related to better prognosis. Furthermore, the proposed deep learning-based survival model (concordance index [c-index]Â =Â 0.823 configured by Bayesian hyperparameter optimization), outperformed the RSF (c-indexÂ =Â 0.728), and the CoxPH model (c-indexÂ =Â 0.713) in the training dataset. Our results show the ability of deep learning in learning a complex association of risk factors. Moreover, the remarkable performance of the deep-learning-based survival model could be promising to support decision-making systems in personalized medicine for patients with GBM.",0,0
4120,"Microwave breast tumor localization using wavelet feature extraction and genetic algorithm-neural network. Ultra-Wide Band (UWB) microwave breast cancer detection is a promising new technology for routine physical examination and home monitoring. The existing microwave imaging algorithms for breast tumor detection are complex and the effect is still not ideal, due to the heterogeneity of breast tissue, skin reflection, and fibroglandular tissue reflection in backscatter signals. This study aims to develop a machine learning method to accurately locate breast tumor.",0,0
4126,"Artificial intelligence manages congenital cataract with individualized prediction and telehealth computing. A challenge of chronic diseases that remains to be solved is how to liberate patients and medical resources from the burdens of long-term monitoring and periodic visits. Precise management based on artificial intelligence (AI) holds great promise; however, a clinical application that fully integrates prediction and telehealth computing has not been achieved, and further efforts are required to validate its real-world benefits. Taking congenital cataract as a representative, we used Bayesian and deep-learning algorithms to create CC-Guardian, an AI agent that incorporates individualized prediction and scheduling, and intelligent telehealth follow-up computing. Our agent exhibits high sensitivity and specificity in both internal and multi-resource validation. We integrate our agent with a web-based smartphone app and prototype a prediction-telehealth cloud platform to support our intelligent follow-up system. We then conduct a retrospective self-controlled test validating that our system not only accurately detects and addresses complications at earlier stages, but also reduces the socioeconomic burdens compared to conventional methods. This study represents a pioneering step in applying AI to achieve real medical benefits and demonstrates a novel strategy for the effective management of chronic diseases.",0,0
4128,"ANFIS-Net for automatic detection of COVID-19. Among the most leading causes of mortality across the globe are infectious diseases which have cost tremendous lives with the latest being coronavirus (COVID-19) that has become the most recent challenging issue. The extreme nature of this infectious virus and its ability to spread without control has made it mandatory to find an efficient auto-diagnosis system to assist the people who work in touch with the patients. As fuzzy logic is considered a powerful technique for modeling vagueness in medical practice, an Adaptive Neuro-Fuzzy Inference System (ANFIS) was proposed in this paper as a key rule for automatic COVID-19 detection from chest X-ray images based on the characteristics derived by texture analysis using gray level co-occurrence matrix (GLCM) technique. Unlike the proposed method, especially deep learning-based approaches, the proposed ANFIS-based method can work on small datasets. The results were promising performance accuracy, and compared with the other state-of-the-art techniques, the proposed method gives the same performance as the deep learning with complex architectures using many backbone.",0,0
4132,Deep learning-based carotid plaque vulnerability classification with multicentre contrast-enhanced ultrasound video: a comparative diagnostic study. The aim of this study was to evaluate the performance of deep learning-based detection and classification of carotid plaque (DL-DCCP) in carotid plaque contrast-enhanced ultrasound (CEUS).,0,0
4134,"Clinical Performance of a Gene-Based Machine Learning Classifier in Assessing Risk of Developing OUD in Subjects Taking Oral Opioids: A Prospective Observational Study. To reduce the incidence of Opioid Use Disorder (OUD), multiple guidelines recommend assessing the risk of OUD prior to prescribing oral opioids. Although subjective risk assessments are available to help classify subjects at risk for OUD, we are aware of no clinically validated objective risk assessment tools. An objective risk assessment based on genetics may help inform shared decision-making prior to prescribing short-duration oral opioids.",0,0
4135,"Elastography ultrasound with machine learning improves the diagnostic performance of traditional ultrasound in predicting kidney fibrosis. Noninvasively predicting kidney tubulointerstitial fibrosis is important because it's closely correlated with the development and prognosis of chronic kidney disease (CKD). Most studies of shear wave elastography (SWE) in CKD were limited to non-linear statistical dependencies and didn't fully consider variables' interactions. Therefore, support vector machine (SVM) of machine learning was used to assess the prediction value of SWE and traditional ultrasound techniques in kidney fibrosis.",0,0
4140,Gene Polymorphisms of the Renin-Angiotensin System and Bleeding Complications of Warfarin: Genetic-Based Machine Learning Models. This study aimed to investigate the effects of genetic variants and haplotypes in the renin-angiotensin system (RAS) on the risk of warfarin-induced bleeding complications at therapeutic international normalized ratios (INRs).,0,0
4159,Explainable Artificial Intelligence for Bias Detection in COVID CT-Scan Classifiers. An application of Explainable Artificial Intelligence Methods for COVID CT-Scan classifiers is presented.,0,0
4164,"Automatic Polyp Segmentation in Colonoscopy Images Using a Modified Deep Convolutional Encoder-Decoder Architecture. Colorectal cancer has become the third most commonly diagnosed form of cancer, and has the second highest fatality rate of cancers worldwide. Currently, optical colonoscopy is the preferred tool of choice for the diagnosis of polyps and to avert colorectal cancer. Colon screening is time-consuming and highly operator dependent. In view of this, a computer-aided diagnosis (CAD) method needs to be developed for the automatic segmentation of polyps in colonoscopy images. This paper proposes a modified SegNet Visual Geometry Group-19 (VGG-19), a form of convolutional neural network, as a CAD method for polyp segmentation. The modifications include skip connections, 5 Ã— 5 convolutional filters, and the concatenation of four dilated convolutions applied in parallel form. The CVC-ClinicDB, CVC-ColonDB, and ETIS-LaribPolypDB databases were used to evaluate the model, and it was found that our proposed polyp segmentation model achieved an accuracy, sensitivity, specificity, precision, mean intersection over union, and dice coefficient of 96.06%, 94.55%, 97.56%, 97.48%, 92.3%, and 95.99%, respectively. These results indicate that our model performs as well as or better than previous schemes in the literature. We believe that this study will offer benefits in terms of the future development of CAD tools for polyp segmentation for colorectal cancer diagnosis and management. In the future, we intend to embed our proposed network into a medical capsule robot for practical usage and try it in a hospital setting with clinicians.",0,0
4166,"Generalized Deep Learning EEG Models for Cross-Participant and Cross-Task Detection of the Vigilance Decrement in Sustained Attention Tasks. Tasks which require sustained attention over a lengthy period of time have been a focal point of cognitive fatigue research for decades, with these tasks including air traffic control, watchkeeping, baggage inspection, and many others. Recent research into physiological markers of mental fatigue indicate that markers exist which extend across all individuals and all types of vigilance tasks. This suggests that it would be possible to build an EEG model which detects these markers and the subsequent vigilance decrement in any task (i.e., a task-generic model) and in any person (i.e., a cross-participant model). However, thus far, no task-generic EEG cross-participant model has been built or tested. In this research, we explored creation and application of a task-generic EEG cross-participant model for detection of the vigilance decrement in an unseen task and unseen individuals. We utilized three different models to investigate this capability: a multi-layer perceptron neural network (MLPNN) which employed spectral features extracted from the five traditional EEG frequency bands, a temporal convolutional network (TCN), and a TCN autoencoder (TCN-AE), with these two TCN models being time-domain based, i.e., using raw EEG time-series voltage values. The MLPNN and TCN models both achieved accuracy greater than random chance (50%), with the MLPNN performing best with a 7-fold CV balanced accuracy of 64% (95% CI: 0.59, 0.69) and validation accuracies greater than random chance for 9 of the 14 participants. This finding demonstrates that it is possible to classify a vigilance decrement using EEG, even with EEG from an unseen individual and unseen task.",0,0
4182,"Classification of Ataxic Gait. Gait disorders accompany a number of neurological and musculoskeletal disorders that significantly reduce the quality of life. Motion sensors enable high-quality modelling of gait stereotypes. However, they produce large volumes of data, the evaluation of which is a challenge. In this publication, we compare different data reduction methods and classification of reduced data for use in clinical practice. The best accuracy achieved between a group of healthy individuals and patients with ataxic gait extracted from the records of 43 participants (23 ataxic, 20 healthy), forming 418 segments of straight gait pattern, is 98% by random forest classifier preprocessed by t-distributed stochastic neighbour embedding.",0,0
4184,"A Tri-Stage Wrapper-Filter Feature Selection Framework for Disease Classification. In machine learning and data science, feature selection is considered as a crucial step of data preprocessing. When we directly apply the raw data for classification or clustering purposes, sometimes we observe that the learning algorithms do not perform well. One possible reason for this is the presence of redundant, noisy, and non-informative features or attributes in the datasets. Hence, feature selection methods are used to identify the subset of relevant features that can maximize the model performance. Moreover, due to reduction in feature dimension, both training time and storage required by the model can be reduced as well. In this paper, we present a tri-stage wrapper-filter-based feature selection framework for the purpose of medical report-based disease detection. In the first stage, an ensemble was formed by four filter methods-Mutual Information, ReliefF, Chi Square, and Xvariance-and then each feature from the union set was assessed by three classification algorithms-support vector machine, naÃ¯ve Bayes, and <i>k</i>-nearest neighbors-and an average accuracy was calculated. The features with higher accuracy were selected to obtain a preliminary subset of optimal features. In the second stage, Pearson correlation was used to discard highly correlated features. In these two stages, XGBoost classification algorithm was applied to obtain the most contributing features that, in turn, provide the best optimal subset. Then, in the final stage, we fed the obtained feature subset to a meta-heuristic algorithm, called whale optimization algorithm, in order to further reduce the feature set and to achieve higher accuracy. We evaluated the proposed feature selection framework on four publicly available disease datasets taken from the UCI machine learning repository, namely, arrhythmia, leukemia, DLBCL, and prostate cancer. Our obtained results confirm that the proposed method can perform better than many state-of-the-art methods and can detect important features as well. Less features ensure less medical tests for correct diagnosis, thus saving both time and cost.",0,0
4185,"Deep Learning for Classifying Physical Activities from Accelerometer Data. Physical inactivity increases the risk of many adverse health conditions, including the world's major non-communicable diseases, such as coronary heart disease, type 2 diabetes, and breast and colon cancers, shortening life expectancy. There are minimal medical care and personal trainers' methods to monitor a patient's actual physical activity types. To improve activity monitoring, we propose an artificial-intelligence-based approach to classify physical movement activity patterns. In more detail, we employ two deep learning (DL) methods, namely a deep feed-forward neural network (DNN) and a deep recurrent neural network (RNN) for this purpose. We evaluate the two models on two physical movement datasets collected from several volunteers who carried tri-axial accelerometer sensors. The first dataset is from the UCI machine learning repository, which contains 14 different activities-of-daily-life (ADL) and is collected from 16 volunteers who carried a single wrist-worn tri-axial accelerometer. The second dataset includes ten other ADLs and is gathered from eight volunteers who placed the sensors on their hips. Our experiment results show that the RNN model provides accurate performance compared to the state-of-the-art methods in classifying the fundamental movement patterns with an overall accuracy of 84.89% and an overall F1-score of 82.56%. The results indicate that our method provides the medical doctors and trainers a promising way to track and understand a patient's physical activities precisely for better treatment.",0,0
4187,"Deep Neural Network-Based Respiratory Pathology Classification Using Cough Sounds. Intelligent systems are transforming the world, as well as our healthcare system. We propose a deep learning-based cough sound classification model that can distinguish between children with healthy versus pathological coughs such as asthma, upper respiratory tract infection (URTI), and lower respiratory tract infection (LRTI). To train a deep neural network model, we collected a new dataset of cough sounds, labelled with a clinician's diagnosis. The chosen model is a bidirectional long-short-term memory network (BiLSTM) based on Mel-Frequency Cepstral Coefficients (MFCCs) features. The resulting trained model when trained for classifying two classes of coughs-healthy or pathology (in general or belonging to a specific respiratory pathology)-reaches accuracy exceeding 84% when classifying the cough to the label provided by the physicians' diagnosis. To classify the subject's respiratory pathology condition, results of multiple cough epochs per subject were combined. The resulting prediction accuracy exceeds 91% for all three respiratory pathologies. However, when the model is trained to classify and discriminate among four classes of coughs, overall accuracy dropped: one class of pathological coughs is often misclassified as the other. However, if one considers the healthy cough classified as healthy and pathological cough classified to have some kind of pathology, then the overall accuracy of the four-class model is above 84%. A longitudinal study of MFCC feature space when comparing pathological and recovered coughs collected from the same subjects revealed the fact that pathological coughs, irrespective of the underlying conditions, occupy the same feature space making it harder to differentiate only using MFCC features.",0,0
4188,"A Blanket Accommodative Sleep Posture Classification System Using an Infrared Depth Camera: A Deep Learning Approach with Synthetic Augmentation of Blanket Conditions. Surveillance of sleeping posture is essential for bed-ridden patients or individuals at-risk of falling out of bed. Existing sleep posture monitoring and classification systems may not be able to accommodate the covering of a blanket, which represents a barrier to conducting pragmatic studies. The objective of this study was to develop an unobtrusive sleep posture classification that could accommodate the use of a blanket. The system uses an infrared depth camera for data acquisition and a convolutional neural network to classify sleeping postures. We recruited 66 participants (40 men and 26 women) to perform seven major sleeping postures (supine, prone (head left and right), log (left and right) and fetal (left and right)) under four blanket conditions (thick, medium, thin, and no blanket). Data augmentation was conducted by affine transformation and data fusion, generating additional blanket conditions with the original dataset. Coarse-grained (four-posture) and fine-grained (seven-posture) classifiers were trained using two fully connected network layers. For the coarse classification, the log and fetal postures were merged into a side-lying class and the prone class (head left and right) was pooled. The results show a drop of overall F1-score by 8.2% when switching to the fine-grained classifier. In addition, compared to no blanket, a thick blanket reduced the overall F1-scores by 3.5% and 8.9% for the coarse- and fine-grained classifiers, respectively; meanwhile, the lowest performance was seen in classifying the log (right) posture under a thick blanket, with an F1-score of 72.0%. In conclusion, we developed a system that can classify seven types of common sleeping postures under blankets and achieved an F1-score of 88.9%.",0,0
4189,"Computer-Aided Diagnosis Algorithm for Classification of Malignant Melanoma Using Deep Neural Networks. Malignant melanoma accounts for about 1-3% of all malignancies in the West, especially in the United States. More than 9000 people die each year. In general, it is difficult to characterize a skin lesion from a photograph. In this paper, we propose a deep learning-based computer-aided diagnostic algorithm for the classification of malignant melanoma and benign skin tumors from RGB channel skin images. The proposed deep learning model constitutes a tumor lesion segmentation model and a classification model of malignant melanoma. First, U-Net was used to classify skin lesions in dermoscopy images. We implement an algorithm to classify malignant melanoma and benign tumors using skin lesion images and expert labeling results from convolutional neural networks. The U-Net model achieved a dice similarity coefficient of 81.1% compared to the expert labeling results. The classification accuracy of malignant melanoma reached 80.06%. As a result, the proposed AI algorithm is expected to be utilized as a computer-aided diagnostic algorithm to help early detection of malignant melanoma.",0,0
4191,"Lead Reconstruction Using Artificial Neural Networks for Ambulatory ECG Acquisition. One of the most powerful techniques to diagnose cardiovascular diseases is to analyze the electrocardiogram (ECG). To increase diagnostic sensitivity, the ECG might need to be acquired using an ambulatory system, as symptoms may occur during a patient's daily life. In this paper, we propose using an ambulatory ECG (aECG) recording device with a low number of leads and then estimating the views that would have been obtained with a standard ECG location, reconstructing the complete Standard 12-Lead System, the most widely used system for diagnosis by cardiologists. Four approaches have been explored, including Linear Regression with ECG segmentation and Artificial Neural Networks (ANN). The best reconstruction algorithm is based on ANN, which reconstructs the actual ECG signal with high precision, as the results bring a high accuracy (RMS Error < 13 Î¼V and CC > 99.7%) for the set of patients analyzed in this paper. This study supports the hypothesis that it is possible to reconstruct the Standard 12-Lead System using an aECG recording device with less leads.",0,0
4204,"Pulmonary COVID-19: Learning Spatiotemporal Features Combining CNN and LSTM Networks for Lung Ultrasound Video Classification. Deep Learning is a very active and important area for building Computer-Aided Diagnosis (CAD) applications. This work aims to present a hybrid model to classify lung ultrasound (LUS) videos captured by convex transducers to diagnose COVID-19. A Convolutional Neural Network (CNN) performed the extraction of spatial features, and the temporal dependence was learned using a Long Short-Term Memory (LSTM). Different types of convolutional architectures were used for feature extraction. The hybrid model (CNN-LSTM) hyperparameters were optimized using the Optuna framework. The best hybrid model was composed of an Xception pre-trained on ImageNet and an LSTM containing 512 units, configured with a dropout rate of 0.4, two fully connected layers containing 1024 neurons each, and a sequence of 20 frames in the input layer (20Ã—2018). The model presented an average accuracy of 93% and sensitivity of 97% for COVID-19, outperforming models based purely on spatial approaches. Furthermore, feature extraction using transfer learning with models pre-trained on ImageNet provided comparable results to models pre-trained on LUS images. The results corroborate with other studies showing that this model for LUS classification can be an important tool in the fight against COVID-19 and other lung diseases.",0,0
4205,"Estimation of Knee Joint Angle Using Textile Capacitive Sensor and Artificial Neural Network Implementing with Three Shoe Types at Two Gait Speeds: A Preliminary Investigation. The lower limb joints might be affected by different shoe types and gait speeds. Monitoring joint angles might require skill and proper technique to obtain accurate data for analysis. We aimed to estimate the knee joint angle using a textile capacitive sensor and artificial neural network (ANN) implementing with three shoe types at two gait speeds. We developed a textile capacitive sensor with a simple structure design and less costly placing in insole shoes to measure the foot plantar pressure for building the deep learning models. The smartphone was used to video during walking at each condition, and Kinovea was applied to calibrate the knee joint angle. Six ANN models were created; three shoe-based ANN models, two speed-based ANN models, and one ANN model that used datasets from all experiment conditions to build a model. All ANN models at comfortable and fast gait provided a high correlation efficiency (0.75 to 0.97) with a mean relative error lower than 15% implement for three testing shoes. And compare the ANN with A convolution neural network contributes a similar result in predict the knee joint angle. A textile capacitive sensor is reliable for measuring foot plantar pressure, which could be used with the ANN algorithm to predict the knee joint angle even using high heel shoes.",0,0
4207,"Recognizing Physical Activities for Spinal Cord Injury Rehabilitation Using Wearable Sensors. The research area of activity recognition is fast growing with diverse applications. However, advances in this field have not yet been used to monitor the rehabilitation of individuals with spinal cord injury. Noteworthily, relying on patient surveys to assess adherence can undermine the outcomes of rehabilitation. Therefore, this paper presents and implements a systematic activity recognition method to recognize physical activities applied by subjects during rehabilitation for spinal cord injury. In the method, raw sensor data are divided into fragments using a dynamic segmentation technique, providing higher recognition performance compared to the sliding window, which is a commonly used approach. To develop the method and build a predictive model, a machine learning approach was adopted. The proposed method was evaluated on a dataset obtained from a single wrist-worn accelerometer. The results demonstrated the effectiveness of the proposed method in recognizing all of the activities that were examined, and it achieved an overall accuracy of 96.86%.",0,0
4213,"Deep Convolutional Neural Network Regularization for Alcoholism Detection Using EEG Signals. Alcoholism is attributed to regular or excessive drinking of alcohol and leads to the disturbance of the neuronal system in the human brain. This results in certain malfunctioning of neurons that can be detected by an electroencephalogram (EEG) using several electrodes on a human skull at appropriate positions. It is of great interest to be able to classify an EEG activity as that of a normal person or an alcoholic person using data from the minimum possible electrodes (or channels). Due to the complex nature of EEG signals, accurate classification of alcoholism using only a small dataset is a challenging task. Artificial neural networks, specifically convolutional neural networks (CNNs), provide efficient and accurate results in various pattern-based classification problems. In this work, we apply CNN on raw EEG data and demonstrate how we achieved 98% average accuracy by optimizing a baseline CNN model and outperforming its results in a range of performance evaluation metrics on the University of California at Irvine Machine Learning (UCI-ML) EEG dataset. This article explains the stepwise improvement of the baseline model using the dropout, batch normalization, and kernel regularization techniques and provides a comparison of the two models that can be beneficial for aspiring practitioners who aim to develop similar classification models in CNN. A performance comparison is also provided with other approaches using the same dataset.",0,0
4214,"An Automated CAD System for Accurate Grading of Uveitis Using Optical Coherence Tomography Images. Uveitis is one of the leading causes of severe vision loss that can lead to blindness worldwide. Clinical records show that early and accurate detection of vitreous inflammation can potentially reduce the blindness rate. In this paper, a novel framework is proposed for automatic quantification of the vitreous on optical coherence tomography (OCT) with particular application for use in the grading of vitreous inflammation. The proposed pipeline consists of two stages, vitreous region segmentation followed by a neural network classifier. In the first stage, the vitreous region is automatically segmented using a U-net convolutional neural network (U-CNN). For the input of U-CNN, we utilized three novel image descriptors to account for the visual appearance similarity of the vitreous region and other tissues. Namely, we developed an adaptive appearance-based approach that utilizes a prior shape information, which consisted of a labeled dataset of the manually segmented images. This image descriptor is adaptively updated during segmentation and is integrated with the original greyscale image and a distance map image descriptor to construct an input fused image for the U-net segmentation stage. In the second stage, a fully connected neural network (FCNN) is proposed as a classifier to assess the vitreous inflammation severity. To achieve this task, a novel discriminatory feature of the segmented vitreous region is extracted. Namely, the signal intensities of the vitreous are represented by a cumulative distribution function (CDF). The constructed CDFs are then used to train and test the FCNN classifier for grading (grade from 0 to 3). The performance of the proposed pipeline is evaluated on a dataset of 200 OCT images. Our segmentation approach documented a higher performance than related methods, as evidenced by the Dice coefficient of 0.988 Â± 0.01 and Hausdorff distance of 0.0003 mm Â± 0.001 mm. On the other hand, the FCNN classification is evidenced by its average accuracy of 86%, which supports the benefits of the proposed pipeline as an aid for early and objective diagnosis of uvea inflammation.",0,0
4218,Predicting Fatigue in Long Duration Mountain Events with a Single Sensor and Deep Learning Model. To determine whether an AI model and single sensor measuring acceleration and ECG could model cognitive and physical fatigue for a self-paced trail run.,0,0
4219,"A Clinically Interpretable Computer-Vision Based Method for Quantifying Gait in Parkinson's Disease. Gait is a core motor function and is impaired in numerous neurological diseases, including Parkinson's disease (PD). Treatment changes in PD are frequently driven by gait assessments in the clinic, commonly rated as part of the Movement Disorder Society (MDS) Unified PD Rating Scale (UPDRS) assessment (item 3.10). We proposed and evaluated a novel approach for estimating severity of gait impairment in Parkinson's disease using a computer vision-based methodology. The system we developed can be used to obtain an estimate for a rating to catch potential errors, or to gain an initial rating in the absence of a trained clinician-for example, during remote home assessments. Videos (n=729) were collected as part of routine MDS-UPDRS gait assessments of Parkinson's patients, and a deep learning library was used to extract body key-point coordinates for each frame. Data were recorded at five clinical sites using commercially available mobile phones or tablets, and had an associated severity rating from a trained clinician. Six features were calculated from time-series signals of the extracted key-points. These features characterized key aspects of the movement including speed (step frequency, estimated using a novel Gamma-Poisson Bayesian model), arm swing, postural control and smoothness (or roughness) of movement. An ordinal random forest classification model (with one class for each of the possible ratings) was trained and evaluated using 10-fold cross validation. Step frequency point estimates from the Bayesian model were highly correlated with manually labelled step frequencies of 606 video clips showing patients walking towards or away from the camera (Pearson's r=0.80, p<0.001). Our classifier achieved a balanced accuracy of 50% (chance = 25%). Estimated UPDRS ratings were within one of the clinicians' ratings in 95% of cases. There was a significant correlation between clinician labels and model estimates (Spearman's Ï=0.52, p<0.001). We show how the interpretability of the feature values could be used by clinicians to support their decision-making and provide insight into the model's objective UPDRS rating estimation. The severity of gait impairment in Parkinson's disease can be estimated using a single patient video, recorded using a consumer mobile device and within standard clinical settings; i.e., videos were recorded in various hospital hallways and offices rather than gait laboratories. This approach can support clinicians during routine assessments by providing an objective rating (or second opinion), and has the potential to be used for remote home assessments, which would allow for more frequent monitoring.",1,0
4224,"Ensemble of Deep Learning Models for Sleep Apnea Detection: An Experimental Study. Sleep Apnea is a breathing disorder occurring during sleep. Older people suffer most from this disease. In-time diagnosis of apnea is needed which can be observed by the application of a proper health monitoring system. In this work, we focus on Obstructive Sleep Apnea (OSA) detection from the Electrocardiogram (ECG) signals obtained through the body sensors. Our work mainly consists of an experimental study of different ensemble techniques applied on three deep learning models-two Convolutional Neural Network (CNN) based models, and a combination of CNN and Long Short-Term Memory (LSTM) models, which were previously proposed in the OSA detection domain. We have chosen four ensemble techniques-majority voting, sum rule and Choquet integral based fuzzy fusion and trainable ensemble using Multi-Layer Perceptron (MLP) for our case study. All the experiments are conducted on the benchmark PhysioNet Apnea-ECG Database. Finally, we have achieved highest OSA detection accuracy of 85.58% using the MLP based ensemble approach. Our best result is also able to surpass many of state-of-the-art methods.",0,0
4229,"Environmental Noise Classification with Inception-Dense Blocks for Hearing Aids. Hearing aids are increasingly essential for people with hearing loss. For this purpose, environmental noise estimation and classification are some of the required technologies. However, some noise classifiers utilize multiple audio features, which cause intense computation. In addition, such noise classifiers employ inputs of different time lengths, which may affect classification performance. Thus, this paper proposes a model architecture for noise classification, and performs experiments with three different audio segment time lengths. The proposed model attains fewer floating-point operations and parameters by utilizing the log-scaled mel-spectrogram as an input feature. The proposed models are evaluated with classification accuracy, computational complexity, trainable parameters, and inference time on the UrbanSound8k dataset and HANS dataset. The experimental results showed that the proposed model outperforms other models on two datasets. Furthermore, compared with other models, the proposed model reduces model complexity and inference time while maintaining classification accuracy. As a result, the proposed noise classification for hearing aids offers less computational complexity without compromising performance.",0,0
4236,"Fusion Learning for sEMG Recognition of Multiple Upper-Limb Rehabilitation Movements. Surface electromyogram (sEMG) signals have been used in human motion intention recognition, which has significant application prospects in the fields of rehabilitation medicine and cognitive science. However, some valuable dynamic information on upper-limb motions is lost in the process of feature extraction for sEMG signals, and there exists the fact that only a small variety of rehabilitation movements can be distinguished, and the classification accuracy is easily affected. To solve these dilemmas, first, a multiscale time-frequency information fusion representation method (MTFIFR) is proposed to obtain the time-frequency features of multichannel sEMG signals. Then, this paper designs the multiple feature fusion network (MFFN), which aims at strengthening the ability of feature extraction. Finally, a deep belief network (DBN) was introduced as the classification model of the MFFN to boost the generalization performance for more types of upper-limb movements. In the experiments, 12 kinds of upper-limb rehabilitation actions were recognized utilizing four sEMG sensors. The maximum identification accuracy was 86.10% and the average classification accuracy of the proposed MFFN was 73.49%, indicating that the time-frequency representation approach combined with the MFFN is superior to the traditional machine learning and convolutional neural network.",0,0
4237,"Automatic Quantification of Anterior Lamina Cribrosa Structures in Optical Coherence Tomography Using a Two-Stage CNN Framework. In this study, we propose a new intelligent system to automatically quantify the morphological parameters of the lamina cribrosa (LC) of the optical coherence tomography (OCT), including depth, curve depth, and curve index from OCT images. The proposed system consisted of a two-stage deep learning (DL) model, which was composed of the detection and the segmentation models as well as a quantification process with a post-processing scheme. The models were used to solve the class imbalance problem and obtain Bruch's membrane opening (BMO) as well as anterior LC information. The detection model was implemented by using YOLOv3 to acquire the BMO and LC position information. The Attention U-Net segmentation model is used to compute accurate locations of the BMO and LC curve information. In addition, post-processing is applied using polynomial regression to attain the anterior LC curve boundary information. Finally, the numerical values of morphological parameters are quantified from BMO and LC curve information using an image processing algorithm. The average precision values in the detection performances of BMO and LC information were 99.92% and 99.18%, respectively, which is very accurate. A highly correlated performance of R<sup>2</sup> = 0.96 between the predicted and ground-truth values was obtained, which was very close to 1 and satisfied the quantification results. The proposed system was performed accurately by fully automatic quantification of BMO and LC morphological parameters using a DL model.",0,0
4238,"Classification and Visualisation of Normal and Abnormal Radiographs; A Comparison between Eleven Convolutional Neural Network Architectures. This paper investigates the classification of radiographic images with eleven convolutional neural network (CNN) architectures (<i>GoogleNet, VGG-19, AlexNet, SqueezeNet, ResNet-18, Inception-v3, ResNet-50, VGG-16, ResNet-101, DenseNet-201 and Inception-ResNet-v2</i>). The CNNs were used to classify a series of wrist radiographs from the Stanford Musculoskeletal Radiographs (MURA) dataset into two classes-normal and abnormal. The architectures were compared for different hyper-parameters against accuracy and Cohen's kappa coefficient. The best two results were then explored with data augmentation. Without the use of augmentation, the best results were provided by Inception-ResNet-v2 (Mean accuracy = 0.723, Mean kappa = 0.506). These were significantly improved with augmentation to Inception-ResNet-v2 (Mean accuracy = 0.857, Mean kappa = 0.703). Finally, Class Activation Mapping was applied to interpret activation of the network against the location of an anomaly in the radiographs.",0,0
4242,"Binary Sensors-Based Privacy-Preserved Activity Recognition of Elderly Living Alone Using an RNN. The recent growth of the elderly population has led to the requirement for constant home monitoring as solitary living becomes popular. This protects older people who live alone from unwanted instances such as falling or deterioration caused by some diseases. However, although wearable devices and camera-based systems can provide relatively precise information about human motion, they invade the privacy of the elderly. One way to detect the abnormal behavior of elderly residents under the condition of maintaining privacy is to equip the resident's house with an Internet of Things system based on a non-invasive binary motion sensor array. We propose to concatenate external features (<i>previous activity</i> and <i>begin time-stamp</i>) along with extracted features with a bi-directional long short-term memory (Bi-LSTM) neural network to recognize the activities of daily living with a higher accuracy. The concatenated features are classified by a fully connected neural network (FCNN). The proposed model was evaluated on open dataset from the Center for Advanced Studies in Adaptive Systems (CASAS) at Washington State University. The experimental results show that the proposed method outperformed state-of-the-art models with a margin of more than 6.25% of the <i>F</i><sub>1</sub> score on the same dataset.",0,0
4246,"Transfer Learning Approach for Classification of Histopathology Whole Slide Images. The classification of whole slide images (WSIs) provides physicians with an accurate analysis of diseases and also helps them to treat patients effectively. The classification can be linked to further detailed analysis and diagnosis. Deep learning (DL) has made significant advances in the medical industry, including the use of magnetic resonance imaging (MRI) scans, computerized tomography (CT) scans, and electrocardiograms (ECGs) to detect life-threatening diseases, including heart disease, cancer, and brain tumors. However, more advancement in the field of pathology is needed, but the main hurdle causing the slow progress is the shortage of large-labeled datasets of histopathology images to train the models. The Kimia Path24 dataset was particularly created for the classification and retrieval of histopathology images. It contains 23,916 histopathology patches with 24 tissue texture classes. A transfer learning-based framework is proposed and evaluated on two famous DL models, Inception-V3 and VGG-16. To improve the productivity of Inception-V3 and VGG-16, we used their pre-trained weights and concatenated these with an image vector, which is used as input for the training of the same architecture. Experiments show that the proposed innovation improves the accuracy of both famous models. The patch-to-scan accuracy of VGG-16 is improved from 0.65 to 0.77, and for the Inception-V3, it is improved from 0.74 to 0.79.",0,0
4252,"Prediction of Myoelectric Biomarkers in Post-Stroke Gait. Electromyography (EMG) is sensitive to neuromuscular changes resulting from ischemic stroke and is considered a potential predictive tool of post-stroke gait and rehabilitation management. This study aimed to evaluate the potential myoelectric biomarkers for the classification of stroke-impaired muscular activity of the stroke patient group and the muscular activity of the control healthy adult group. We also proposed an EMG-based gait monitoring system consisting of a portable EMG device, cloud-based data processing, data analytics, and a health advisor service. This system was investigated with 48 stroke patients (mean age 70.6 years, 65% male) admitted into the emergency unit of a hospital and 75 healthy elderly volunteers (mean age 76.3 years, 32% male). EMG was recorded during walking using the portable device at two muscle positions: the bicep femoris muscle and the lateral gastrocnemius muscle of both lower limbs. The statistical result showed that the mean power frequency (MNF), median power frequency (MDF), peak power frequency (PKF), and mean power (MNP) of the stroke group differed significantly from those of the healthy control group. In the machine learning analysis, the neural network model showed the highest classification performance (precision: 88%, specificity: 89%, accuracy: 80%) using the training dataset and highest classification performance (precision: 72%, specificity: 74%, accuracy: 65%) using the testing dataset. This study will be helpful to understand stroke-impaired gait changes and decide post-stroke rehabilitation.",0,0
4254,"Classification of Bladder Emptying Patterns by LSTM Neural Network Trained Using Acoustic Signatures. (1) Background: Non-invasive uroflowmetry is used in clinical practice for diagnosing lower urinary tract symptoms (LUTS) and the health status of a patient. To establish a smart system for measuring the flowrate during urination without any temporospatial constraints for patients with a urinary disorder, the acoustic signatures from the uroflow of patients being treated for LUTS at a tertiary hospital were utilized. (2) Methods: Uroflowmetry data were collected for construction and verification of a long short-term memory (LSTM) deep-learning algorithm. The initial sample size comprised 34 patients; 27 patients were included in the final analysis. Uroflow sounds generated from flow impacts on a structure were analyzed by loudness and roughness parameters. (3) Results: A similar signal pattern to the clinical urological measurements was observed and applied for health diagnosis. (4) Conclusions: Consistent flowrate values were obtained by applying the uroflow sound samples from the randomly selected patients to the constructed model for validation. The flowrate predicted using the acoustic signature accurately demonstrated actual physical characteristics. This could be used for developing a new smart flowmetry device applicable in everyday life with minimal constraints from settings and enable remote diagnosis of urinary system diseases by objective continuous measurements of bladder emptying function.",0,0
4256,"Neovascularization Detection and Localization in Fundus Images Using Deep Learning. Proliferative Diabetic Retinopathy (PDR) is a severe retinal disease that threatens diabetic patients. It is characterized by neovascularization in the retina and the optic disk. PDR clinical features contain highly intense retinal neovascularization and fibrous spreads, leading to visual distortion if not controlled. Different image processing techniques have been proposed to detect and diagnose neovascularization from fundus images. Recently, deep learning methods are getting popular in neovascularization detection due to artificial intelligence advancement in biomedical image processing. This paper presents a semantic segmentation convolutional neural network architecture for neovascularization detection. First, image pre-processing steps were applied to enhance the fundus images. Then, the images were divided into small patches, forming a training set, a validation set, and a testing set. A semantic segmentation convolutional neural network was designed and trained to detect the neovascularization regions on the images. Finally, the network was tested using the testing set for performance evaluation. The proposed model is entirely automated in detecting and localizing neovascularization lesions, which is not possible with previously published methods. Evaluation results showed that the model could achieve accuracy, sensitivity, specificity, precision, Jaccard similarity, and Dice similarity of 0.9948, 0.8772, 0.9976, 0.8696, 0.7643, and 0.8466, respectively. We demonstrated that this model could outperform other convolutional neural network models in neovascularization detection.",0,0
4262,"Computer-Aided Colon Polyp Detection on High Resolution Colonoscopy Using Transfer Learning Techniques. Colonoscopies reduce the incidence of colorectal cancer through early recognition and resecting of the colon polyps. However, the colon polyp miss detection rate is as high as 26% in conventional colonoscopy. The search for methods to decrease the polyp miss rate is nowadays a paramount task. A number of algorithms or systems have been developed to enhance polyp detection, but few are suitable for real-time detection or classification due to their limited computational ability. Recent studies indicate that the automated colon polyp detection system is developing at an astonishing speed. Real-time detection with classification is still a yet to be explored field. Newer image pattern recognition algorithms with convolutional neuro-network (CNN) transfer learning has shed light on this topic. We proposed a study using real-time colonoscopies with the CNN transfer learning approach. Several multi-class classifiers were trained and mAP ranged from 38% to 49%. Based on an Inception v2 model, a detector adopting a Faster R-CNN was trained. The mAP of the detector was 77%, which was an improvement of 35% compared to the same type of multi-class classifier. Therefore, our results indicated that the polyp detection model could attain a high accuracy, but the polyp type classification still leaves room for improvement.",0,0
4265,"Steady-State Visual Evoked Potential Classification Using Complex Valued Convolutional Neural Networks. The steady-state visual evoked potential (SSVEP), which is a kind of event-related potential in electroencephalograms (EEGs), has been applied to brain-computer interfaces (BCIs). SSVEP-based BCIs currently perform the best in terms of information transfer rate (ITR) among various BCI implementation methods. Canonical component analysis (CCA) or spectrum estimation, such as the Fourier transform, and their extensions have been used to extract features of SSVEPs. However, these signal extraction methods have a limitation in the available stimulation frequency; thus, the number of commands is limited. In this paper, we propose a complex valued convolutional neural network (CVCNN) to overcome the limitation of SSVEP-based BCIs. The experimental results demonstrate that the proposed method overcomes the limitation of the stimulation frequency, and it outperforms conventional SSVEP feature extraction methods.",0,0
4268,"Cascaded Deep Learning Neural Network for Automated Liver Steatosis Diagnosis Using Ultrasound Images. Diagnosing liver steatosis is an essential precaution for detecting hepatocirrhosis and liver cancer in the early stages. However, automatic diagnosis of liver steatosis from ultrasound (US) images remains challenging due to poor visual quality from various origins, such as speckle noise and blurring. In this paper, we propose a fully automated liver steatosis prediction model using three deep learning neural networks. As a result, liver steatosis can be automatically detected with high accuracy and precision. First, transfer learning is used for semantically segmenting the liver and kidney (L-K) on parasagittal US images, and then cropping the L-K area from the original US images. The second neural network also involves semantic segmentation by checking the presence of a ring that is typically located around the kidney and cropping of the L-K area from the original US images. These cropped L-K areas are inputted to the final neural network, SteatosisNet, in order to grade the severity of fatty liver disease. The experimental results demonstrate that the proposed model can predict fatty liver disease with the sensitivity of 99.78%, specificity of 100%, PPV of 100%, NPV of 99.83%, and diagnostic accuracy of 99.91%, which is comparable to the common results annotated by medical experts.",0,0
4269,"Automatic Detection of Short-Term Atrial Fibrillation Segments Based on Frequency Slice Wavelet Transform and Machine Learning Techniques. Atrial fibrillation (AF) is the most frequently encountered cardiac arrhythmia and is often associated with other cardiovascular and cerebrovascular diseases, such as ischemic heart disease, chronic heart failure, and stroke. Automatic detection of AF by analyzing electrocardiogram (ECG) signals has an important application value. Using the contaminated and actual ECG signals, it is not enough to only analyze the atrial activity of disappeared P wave and appeared F wave in the TQ segment. Moreover, the best analysis method is to combine nonlinear features analyzing ventricular activity based on the detection of R peak. In this paper, to utilize the information of the P-QRS-T waveform generated by atrial and ventricular activity, frequency slice wavelet transform (FSWT) is adopted to conduct time-frequency analysis on short-term ECG segments from the MIT-BIH Atrial Fibrillation Database. The two-dimensional time-frequency matrices are obtained. Furthermore, an average sliding window is used to convert the two-dimensional time-frequency matrices to the one-dimensional feature vectors, which are classified using five machine learning (ML) techniques. The experimental results show that the classification performance of the Gaussian-kernel support vector machine (GKSVM) based on the Bayesian optimizer is better. The accuracy of the training set and validation set are 100% and 93.4%. The accuracy, sensitivity, and specificity of the test set without training are 98.15%, 96.43%, and 100%, respectively. Compared with previous research results, our proposed FSWT-GKSVM model shows stability and robustness, and it could achieve the purpose of automatic detection of AF.",0,0
4273,"Digital Biomarkers of Physical Frailty and Frailty Phenotypes Using Sensor-Based Physical Activity and Machine Learning. Remote monitoring of physical frailty is important to personalize care for slowing down the frailty process and/or for the healthy recovery of older adults following acute or chronic stressors. Taking the Fried frailty criteria as a reference to determine physical frailty and frailty phenotypes (slowness, weakness, exhaustion, inactivity), this study aimed to explore the benefit of machine learning to determine the least number of digital biomarkers of physical frailty measurable from a pendant sensor during activities of daily living. Two hundred and fifty-nine older adults were classified into robust or pre-frail/frail groups based on the physical frailty assessments by the Fried frailty criteria. All participants wore a pendant sensor at the sternum level for 48 h. Of seventeen sensor-derived features extracted from a pendant sensor, fourteen significant features were used for machine learning based on logistic regression modeling and a recursive feature elimination technique incorporating bootstrapping. The combination of percentage time standing, percentage time walking, walking cadence, and longest walking bout were identified as optimal digital biomarkers of physical frailty and frailty phenotypes. These findings suggest that a combination of sensor-measured exhaustion, inactivity, and speed have potential to screen and monitor people for physical frailty and frailty phenotypes.",0,0
4275,"Detection of Diabetic Eye Disease from Retinal Images Using a Deep Learning Based CenterNet Model. Diabetic retinopathy (DR) is an eye disease that alters the blood vessels of a person suffering from diabetes. Diabetic macular edema (DME) occurs when DR affects the macula, which causes fluid accumulation in the macula. Efficient screening systems require experts to manually analyze images to recognize diseases. However, due to the challenging nature of the screening method and lack of trained human resources, devising effective screening-oriented treatment is an expensive task. Automated systems are trying to cope with these challenges; however, these methods do not generalize well to multiple diseases and real-world scenarios. To solve the aforementioned issues, we propose a new method comprising two main steps. The first involves dataset preparation and feature extraction and the other relates to improving a custom deep learning based CenterNet model trained for eye disease classification. Initially, we generate annotations for suspected samples to locate the precise region of interest, while the other part of the proposed solution trains the Center Net model over annotated images. Specifically, we use DenseNet-100 as a feature extraction method on which the one-stage detector, CenterNet, is employed to localize and classify the disease lesions. We evaluated our method over challenging datasets, namely, APTOS-2019 and IDRiD, and attained average accuracy of 97.93% and 98.10%, respectively. We also performed cross-dataset validation with benchmark EYEPACS and Diaretdb1 datasets. Both qualitative and quantitative results demonstrate that our proposed approach outperforms state-of-the-art methods due to more effective localization power of CenterNet, as it can easily recognize small lesions and deal with over-fitted training data. Our proposed framework is proficient in correctly locating and classifying disease lesions. In comparison to existing DR and DME classification approaches, our method can extract representative key points from low-intensity and noisy images and accurately classify them. Hence our approach can play an important role in automated detection and recognition of DR and DME lesions.",0,0
4278,"Using Absorption Models for Insulin and Carbohydrates and Deep Leaning to Improve Glucose Level Predictions. Diabetes is a chronic disease caused by the inability of the pancreas to produce insulin or problems in the body to use it efficiently. It is one of the fastest growing health challenges affecting more than 400 million people worldwide, according to the World Health Organization. Intensive research is being carried out on artificial intelligence methods to help people with diabetes to optimize the way in which they use insulin, carbohydrate intakes, or physical activity. By predicting upcoming levels of blood glucose concentrations, preventive actions can be taken. Previous research studies using machine learning methods for blood glucose level predictions have mainly focused on the machine learning model used. Little attention has been given to the pre-processing of insulin and carbohydrate signals in order to mimic the human absorption processes. In this manuscript, a recurrent neural network (RNN) based model for predicting upcoming blood glucose levels in people with type 1 diabetes is combined with several carbohydrate and insulin absorption curves in order to optimize the prediction results. The proposed method is applied to data from real patients suffering type 1 diabetes mellitus (T1DM). The achieved results are encouraging, obtaining accuracy levels around 0.510 mmol/L (9.2 mg/dl) in the best scenario.",0,0
4279,"Daily Human Activity Recognition Using Non-Intrusive Sensors. In recent years, Artificial Intelligence Technologies (AIT) have been developed to improve the quality of life of the elderly and their safety in the home. This work focuses on developing a system capable of recognising the most usual activities in the daily life of an elderly person in real-time to enable a specialist to monitor the habits of this person, such as taking medication or eating the correct meals of the day. To this end, a prediction model has been developed based on recurrent neural networks, specifically on bidirectional LSTM networks, to obtain in real-time the activity being carried out by the individuals in their homes, based on the information provided by a set of different sensors installed at each person's home. The prediction model developed in this paper provides a 95.42% accuracy rate, improving the results of similar models currently in use. In order to obtain a reliable model with a high accuracy rate, a series of processing and filtering processes have been carried out on the data, such as a method based on a sliding window or a stacking and re-ordering algorithm, that are subsequently used to train the neural network, obtained from the public database CASAS.",0,0
4281,"Identification of Autism Subtypes Based on Wavelet Coherence of BOLD FMRI Signals Using Convolutional Neural Network. The functional connectivity (FC) patterns of resting-state functional magnetic resonance imaging (rs-fMRI) play an essential role in the development of autism spectrum disorders (ASD) classification models. There are available methods in literature that have used FC patterns as inputs for binary classification models, but the results barely reach an accuracy of 80%. Additionally, the generalizability across multiple sites of the models has not been investigated. Due to the lack of ASD subtypes identification model, the multi-class classification is proposed in the present study. This study aims to develop automated identification of autism spectrum disorder (ASD) subtypes using convolutional neural networks (CNN) using dynamic FC as its inputs. The rs-fMRI dataset used in this study consists of 144 individuals from 8 independent sites, labeled based on three ASD subtypes, namely autistic disorder (ASD), Asperger's disorder (APD), and pervasive developmental disorder not otherwise specified (PDD-NOS). The blood-oxygen-level-dependent (BOLD) signals from 116 brain nodes of automated anatomical labeling (AAL) atlas are used, where the top-ranked node is determined based on one-way analysis of variance (ANOVA) of the power spectral density (PSD) values. Based on the statistical analysis of the PSD values of 3-level ASD and normal control (NC), putamen_R is obtained as the top-ranked node and used for the wavelet coherence computation. With good resolution in time and frequency domain, scalograms of wavelet coherence between the top-ranked node and the rest of the nodes are used as dynamic FC feature input to the convolutional neural networks (CNN). The dynamic FC patterns of wavelet coherence scalogram represent phase synchronization between the pairs of BOLD signals. Classification algorithms are developed using CNN and the wavelet coherence scalograms for binary and multi-class identification were trained and tested using cross-validation and leave-one-out techniques. Results of binary classification (ASD vs. NC) and multi-class classification (ASD vs. APD vs. PDD-NOS vs. NC) yielded, respectively, 89.8% accuracy and 82.1% macro-average accuracy, respectively. Findings from this study have illustrated the good potential of wavelet coherence technique in representing dynamic FC between brain nodes and open possibilities for its application in computer aided diagnosis of other neuropsychiatric disorders, such as depression or schizophrenia.",0,0
4282,"Intention Prediction and Human Health Condition Detection in Reaching Tasks with Machine Learning Techniques. Detecting human motion and predicting human intentions by analyzing body signals are challenging but fundamental steps for the implementation of applications presenting human-robot interaction in different contexts, such as robotic rehabilitation in clinical environments, or collaborative robots in industrial fields. Machine learning techniques (MLT) can face the limit of small data amounts, typical of this kind of applications. This paper studies the illustrative case of the reaching movement in 10 healthy subjects and 21 post-stroke patients, comparing the performance of linear discriminant analysis (LDA) and random forest (RF) in: (i) predicting the subject's intention of moving towards a specific direction among a set of possible choices, (ii) detecting if the subject is moving according to a healthy or pathological pattern, and in the case of discriminating the damage location (left or right hemisphere). Data were captured with wearable electromagnetic sensors, and a sub-section of the acquired signals was required for the analyses. The possibility of detecting with which arm (left or right hand) the motion was performed, and the sensitivity of the MLT to variations in the length of the signal sub-section were also evaluated. LDA and RF prediction accuracies were compared: Accuracy improves when only healthy subjects or longer signals portions are considered up to 11% and at least 10%, respectively. RF reveals better estimation performance both as intention predictor (on average 59.91% versus the 62.19% of LDA), and health condition detector (over 90% in all the tests).",0,0
4284,"The impact of training sample size on deep learning-based organ auto-segmentation for head-and-neck patients. To investigate the impact of training sample size on the performance of deep learning-based organ auto-segmentation for head-and-neck cancer patients, a total of 1160 patients with head-and-neck cancer who received radiotherapy were enrolled in this study. Patient planning CT images and regions of interest (ROIs) delineation, including the brainstem, spinal cord, eyes, lenses, optic nerves, temporal lobes, parotids, larynx and body, were collected. An evaluation dataset with 200 patients were randomly selected and combined with Dice similarity index to evaluate the model performances. Eleven training datasets with different sample sizes were randomly selected from the remaining 960 patients to form auto-segmentation models. All models used the same data augmentation methods, network structures and training hyperparameters. A performance estimation model of the training sample size based on the inverse power law function was established. Different performance change patterns were found for different organs. Six organs had the best performance with 800 training samples and others achieved their best performance with 600 training samples or 400 samples. The benefit of increasing the size of the training dataset gradually decreased. Compared to the best performance, optic nerves and lenses reached 95% of their best effect at 200, and the other organs reached 95% of their best effect at 40. For the fitting effect of the inverse power law function, the fitted root mean square errors of all ROIs were less than 0.03 (left eye: 0.024, others: <0.01), and the<i>R</i>square of all ROIs except for the body was greater than 0.5. The sample size has a significant impact on the performance of deep learning-based auto-segmentation. The relationship between sample size and performance depends on the inherent characteristics of the organ. In some cases, relatively small samples can achieve satisfactory performance.",0,0
4293,"DeepAtrophy: Teaching a neural network to detect progressive changes in longitudinal MRI of the hippocampal region in Alzheimer's disease. Measures of change in hippocampal volume derived from longitudinal MRI are a well-studied biomarker of disease progression in Alzheimer's disease (AD) and are used in clinical trials to track therapeutic efficacy of disease-modifying treatments. However, longitudinal MRI change measures based on deformable registration can be confounded by MRI artifacts, resulting in over-estimation or underestimation of hippocampal atrophy. For example, the deformation-based-morphometry method ALOHA (Das etÂ al., 2012) finds an increase in hippocampal volume in a substantial proportion of longitudinal scan pairs from the Alzheimer's Disease Neuroimaging Initiative (ADNI) study, unexpected, given that the hippocampal gray matter is lost with age and disease progression. We propose an alternative approach to quantify disease progression in the hippocampal region: to train a deep learning network (called DeepAtrophy) to infer temporal information from longitudinal scan pairs. The underlying assumption is that by learning to derive time-related information from scan pairs, the network implicitly learns to detect progressive changes that are related to aging and disease progression. Our network is trained using two categorical loss functions: one that measures the network's ability to correctly order two scans from the same subject, input in arbitrary order; and another that measures the ability to correctly infer the ratio of inter-scan intervals between two pairs of same-subject input scans. When applied to longitudinal MRI scan pairs from subjects unseen during training, DeepAtrophy achieves greater accuracy in scan temporal ordering and interscan interval inference tasks than ALOHA (88.5% vs. 75.5% and 81.1% vs. 75.0%, respectively). A scalar measure of time-related change in a subject level derived from DeepAtrophy is then examined as a biomarker of disease progression in the context of AD clinical trials. We find that this measure performs on par with ALOHA in discriminating groups of individuals at different stages of the AD continuum. Overall, our results suggest that using deep learning to infer temporal information from longitudinal MRI of the hippocampal region has good potential as a biomarker of disease progression, and hints that combining this approach with conventional deformation-based morphometry algorithms may lead to improved biomarkers in the future.",0,0
4297,"Evaluating a Machine Learning Tool for the Classification of Pathological Uptake in Whole-Body PSMA-PET-CT Scans. The importance of machine learning (ML) in the clinical environment increases constantly. Differentiation of pathological from physiological tracer-uptake in positron emission tomography/computed tomography (PET/CT) images is considered time-consuming and attention intensive, hence crucial for diagnosis and treatment planning. This study aimed at comparing and validating supervised ML algorithms to classify pathological uptake in prostate cancer (PC) patients based on prostate-specific membrane antigen (PSMA)-PET/CT. Retrospective analysis of <sup>68</sup>Ga-PSMA-PET/CTs of 72 PC patients resulted in a total of 77 radiomics features from 2452 manually delineated hotspots for training and labeled pathological (1629) or physiological (823) as ground truth (GT). As the held-out test dataset, 331 hotspots (path.:128, phys.: 203) were delineated in 15 other patients. Three ML classifiers were trained and ranked to assess classification performance. As a result, a high overall average performance (area under the curve (AUC) of 0.98) was achieved, especially to detect pathological uptake (0.97 mean sensitivity). However, there is still room for improvement to detect physiological uptake (0.82 mean specificity), especially for glands. The ML algorithm applied to manually delineated lesions predicts hotspot labels with high accuracy on unseen data and may be an important tool to assist in clinical diagnosis.",0,0
4298,"Combination of Radiomics and Machine Learning with Diffusion-Weighted MR Imaging for Clinical Outcome Prognostication in Cervical Cancer. To explore the potential of Radiomics alone and in combination with a diffusion-weighted derived quantitative parameter, namely the apparent diffusion co-efficient (ADC), using supervised classification algorithms in the prediction of outcomes and prognosis.",0,0
4299,"Machine Learning Consensus Clustering of Hospitalized Patients with Admission Hyponatremia. The objective of this study was to characterize patients with hyponatremia at hospital admission into clusters using an unsupervised machine learning approach, and to evaluate the short- and long-term mortality risk among these distinct clusters.",0,0
4300,"COVID-19 Mortality Prediction From Deep Learning in a Large Multistate Electronic Health Record and Laboratory Information System Data Set: Algorithm Development and Validation. COVID-19 is caused by the SARS-CoV-2 virus and has strikingly heterogeneous clinical manifestations, with most individuals contracting mild disease but a substantial minority experiencing fulminant cardiopulmonary symptoms or death. The clinical covariates and the laboratory tests performed on a patient provide robust statistics to guide clinical treatment. Deep learning approaches on a data set of this nature enable patient stratification and provide methods to guide clinical treatment.",0,0
4308,"Patterns of high-risk drinking among medical students: A web-based survey with machine learning. Prior studies have found increased rates of alcohol consumption among physicians and medical students. The present study aims to build machine learning (ML) models to identify patterns of high-risk drinking (HRD), including alcohol use disorder, within this population.",0,0
4311,"Validation of an Instrumented Hammer for Rhinoplasty Osteotomies: A Cadaveric Study. <b>Background:</b> Osteotomies during rhinoplasty are usually based on surgeon's proprioception to determine the number, energy, and trajectory of impacts. <b>Objective:</b> The first objective was to detect the occurrence of fractures. The second objective was to determine when the thicker frontal bone was encountered by the osteotome. <b>Materials and Methods:</b> An instrumented hammer was used to measure the impact force during lateral osteotomies on nine human anatomic specimens. A prediction algorithm was developed using machine learning techniques, to detect the occurrence of fractures, and the proximity of the osteotome to the frontal bone. <b>Results:</b> The algorithm was able to predict the occurrence of fractures and the proximity to the frontal bone with a prediction rate of 83%, 91%, and 93% when allowing for an error of 0, 1, and 2 impacts, respectively. The location of the osteotome in the frontal bone was predicted with an error of 7.7%. <b>Conclusion:</b> An osteotomy hammer measuring the impact force when performing lateral osteotomies can predict the occurrence of fractures and the proximity to the frontal bone, providing the surgeon with instant feedback.",0,0
4314,"Automated description of the mandible shape by deep learning. The shape of the mandible has been analyzed in a variety of fields, whether to diagnose conditions like osteoporosis or osteomyelitis, in forensics, to estimate biological information such as age, gender, and race or in orthognathic surgery. Although the methods employed produce encouraging results, most rely on the dry bone analyses or complex imaging techniques that, ultimately, hamper sample collection and, as a consequence, the development of large-scale studies. Thus, we proposed an objective, repeatable, and fully automatic approach to provide a quantitative description of the mandible in orthopantomographies (OPGs).",0,0
4315,"An efficient multi-path 3D convolutional neural network for false-positive reduction of pulmonary nodule detection. Considering that false-positive and true pulmonary nodules are highly similar in shapes and sizes between lung computed tomography scans, we develop and evaluate a false-positive nodules reduction method applied to the computer-aided diagnosis system.",0,0
4317,Deep learning radiomic nomogram to predict recurrence in soft tissue sarcoma: a multi-institutional study. To evaluate the performance of a deep learning radiomic nomogram (DLRN) model at predicting tumor relapse in patients with soft tissue sarcomas (STS) who underwent surgical resection.,0,0
4318,"Development and Assessment of an Interpretable Machine Learning Triage Tool for Estimating Mortality After Emergency Admissions. Triage in the emergency department (ED) is a complex clinical judgment based on the tacit understanding of the patient's likelihood of survival, availability of medical resources, and local practices. Although a scoring tool could be valuable in risk stratification, currently available scores have demonstrated limitations.",0,0
4324,"A Machine Learning Approach to Passively Informed Prediction of Mental Health Risk in People with Diabetes: Retrospective Case-Control Analysis. Proactive detection of mental health needs among people with diabetes mellitus could facilitate early intervention, improve overall health and quality of life, and reduce individual and societal health and economic burdens. Passive sensing and ecological momentary assessment are relatively newer methods that may be leveraged for such proactive detection.",0,0
4325,Predicting Kidney Graft Survival Using Machine Learning Methods: Prediction Model Development and Feature Significance Analysis Study. Kidney transplantation is the optimal treatment for patients with end-stage renal disease. Short- and long-term kidney graft survival is influenced by a number of donor and recipient factors. Predicting the success of kidney transplantation is important for optimizing kidney allocation.,0,0
4328,"Skin cancer detection from dermoscopic images using deep learning and fuzzy k-means clustering. Melanoma skin cancer is the most life-threatening and fatal disease among the family of skin cancer diseases. Modern technological developments and research methodologies made it possible to detect and identify this kind of skin cancer more effectively; however, the automated localization and segmentation of skin lesion at earlier stages is still a challenging task due to the low contrast between melanoma moles and skin portion and a higher level of color similarity between melanoma-affected and -nonaffected areas. In this paper, we present a fully automated method for segmenting the skin melanoma at its earliest stage by employing a deep-learning-based approach, namely faster region-based convolutional neural networks (RCNN) along with fuzzy k-means clustering (FKM). Several clinical images are utilized to test the presented method so that it may help the dermatologist in diagnosing this life-threatening disease at its earliest stage. The presented method first preprocesses the dataset images to remove the noise and illumination problems and enhance the visual information before applying the faster-RCNN to obtain the feature vector of fixed length. After that, FKM has been employed to segment the melanoma-affected portion of skin with variable size and boundaries. The performance of the presented method is evaluated on the three standard datasets, namely ISBI-2016, ISIC-2017, and PH2, and the results show that the presented method outperforms the state-of-the-art approaches. The presented method attains an average accuracy of 95.40, 93.1, and 95.6% on the ISIC-2016, ISIC-2017, and PH2 datasets, respectively, which is showing its robustness to skin lesion recognition and segmentation.",0,0
4331,"Machine learning model development for quantitative analysis of CT heterogeneity in canine hepatic masses may predict histologic malignancy. Tumor heterogeneity is a well-established marker of biologically aggressive neoplastic processes and is associated with local recurrence and distant metastasis. Quantitative analysis of CT textural features is an indirect measure of tumor heterogeneity and therefore may help predict malignant disease. The purpose of this retrospective, secondary analysis study was to quantitatively evaluate CT heterogeneity in dogs with histologically confirmed liver masses to build a predictive model for malignancy. Forty dogs with liver tumors and corresponding histopathologic evaluation from a previous prospective study were included. Triphasic image acquisition was standardized across dogs and whole liver and liver mass were contoured on each precontrast and delayed postcontrast dataset. First-order and second-order indices were extracted from contoured regions. Univariate analysis identified potentially significant indices that were subsequently used for top-down model construction. Multiple quadratic discriminatory models were constructed and tested, including individual models using both postcontrast and precontrast whole liver or liver mass volumes. The best performing model utilized the CT features voxel volume and uniformity from postcontrast mass contours; this model had an accuracy of 0.90, sensitivity of 0.67, specificity of 1.0, positive predictive value of 1.0, negative predictive value of 0.88, and precision of 1.0. Heterogeneity indices extracted from delayed postcontrast CT hepatic mass contours were more informative about tumor type compared to indices from whole liver contours, or from precontrast hepatic mass and whole liver contours. Results demonstrate that CT radiomic feature analysis may hold clinical utility as a noninvasive method of predicting hepatic malignancy and may influence diagnostic or therapeutic approaches.",0,0
4333,"Hybrid deep learning model for risk prediction of fracture in patients with diabetes and osteoporosis. The fracture risk of patients with diabetes is higher than those of patients without diabetes due to hyperglycemia, usage of diabetes drugs, changes in insulin levels, and excretion, and this risk begins as early as adolescence. Many factors including demographic data (such as age, height, weight, and gender), medical history (such as smoking, drinking, and menopause), and examination (such as bone mineral density, blood routine, and urine routine) may be related to bone metabolism in patients with diabetes. However, most of the existing methods are qualitative assessments and do not consider the interactions of the physiological factors of humans. In addition, the fracture risk of patients with diabetes and osteoporosis has not been further studied previously. In this paper, a hybrid model combining XGBoost with deep neural network is used to predict the fracture risk of patients with diabetes and osteoporosis, and investigate the effect of patients' physiological factors on fracture risk. A total of 147 raw input features are considered in our model. The presented model is compared with several benchmarks based on various metrics to prove its effectiveness. Moreover, the top 18 influencing factors of fracture risks of patients with diabetes are determined.",0,0
4334,"Validation of a Whole Heart Segmentation from Computed Tomography Imaging Using a Deep-Learning Approach. The aim of this study is to develop an automated deep-learning-based whole heart segmentation of ECG-gated computed tomography data. After 21 exclusions, CT acquired before transcatheter aortic valve implantation in 71 patients were reviewed and randomly split in a training (nâ€‰=â€‰55 patients), validation (nâ€‰=â€‰8 patients), and a test set (nâ€‰=â€‰8 patients). A fully automatic deep-learning method combining two convolutional neural networks performed segmentation of 10 cardiovascular structures, which was compared with the manually segmented reference by the Dice index. Correlations and agreement between myocardial volumes and mass were assessed. The algorithm demonstrated high accuracy (Dice scoreâ€‰=â€‰0.920; interquartile range: 0.906-0.925) and a low computing time (13.4Â s, range 11.9-14.9). Correlations and agreement of volumes and mass were satisfactory for most structures. Six of ten structures were well segmented. Deep-learning-based method allowed automated WHS from ECG-gated CT data with a high accuracy. Challenges remain to improve right-sided structures segmentation and achieve daily clinical application.",0,0
4341,"Artificial intelligence and colon capsule endoscopy: automatic detection of blood in colon capsule endoscopy using a convolutional neural network. Colon capsule endoscopy (CCE) is a minimally invasive alternative to conventional colonoscopy. Most studies on CCE focus on colorectal neoplasia detection. The development of automated tools may address some of the limitations of this diagnostic tool and widen its indications for different clinical settings. We developed an artificial intelligence model based on a convolutional neural network (CNN) for the automatic detection of blood content in CCE images. Training and validation datasets were constructed for the development and testing of the CNN. The CNN detected blood with a sensitivity, specificity, and positive and negative predictive values of 99.8â€Š%, 93.2â€Š%, 93.8â€Š%, and 99.8â€Š%, respectively. The area under the receiver operating characteristic curve for blood detection was 1.00. We developed a deep learning algorithm capable of accurately detecting blood or hematic residues within the lumen of the colon based on colon CCE images.",0,0
4343,"Deep Fractional Max Pooling Neural Network for COVID-19 Recognition. <b>Aim:</b> Coronavirus disease 2019 (COVID-19) is a form of disease triggered by a new strain of coronavirus. This paper proposes a novel model termed ""deep fractional max pooling neural network (DFMPNN)"" to diagnose COVID-19 more efficiently. <b>Methods:</b> This 12-layer DFMPNN replaces max pooling (MP) and average pooling (AP) in ordinary neural networks with the help of a novel pooling method called ""fractional max-pooling"" (FMP). In addition, multiple-way data augmentation (DA) is employed to reduce overfitting. Model averaging (MA) is used to reduce randomness. <b>Results:</b> We ran our algorithm on a four-category dataset that contained COVID-19, community-acquired pneumonia, secondary pulmonary tuberculosis (SPT), and healthy control (HC). The 10 runs on the test set show that the micro-averaged F1 (MAF) score of our DFMPNN is 95.88%. <b>Discussions:</b> This proposed DFMPNN is superior to 10 state-of-the-art models. Besides, FMP outperforms traditional MP, AP, and L2-norm pooling (L2P).",0,0
4344,"Fecal Bacteria as Non-Invasive Biomarkers for Colorectal Adenocarcinoma. Colorectal adenocarcinoma (CRC) ranks one of the five most lethal malignant tumors both in China and worldwide. Early diagnosis and treatment of CRC could substantially increase the survival rate. Emerging evidence has revealed the importance of gut microbiome on CRC, thus fecal microbial community could be termed as a potential screen for non-invasive diagnosis. Importantly, few numbers of bacteria genus as non-invasive biomarkers with high sensitivity and specificity causing less cost would be benefitted more in clinical compared with the whole microbial community analysis. Here we analyzed the gut microbiome between CRC patients and healthy people using 16s rRNA sequencing showing the divergence of microbial composition between case and control. Furthermore, ExtraTrees classifier was performed for the classification of CRC gut microbiome and heathy control, and 13 bacteria were screened as biomarkers for CRC. In addition, 13 biomarkers including 12 bacteria genera and FOBT showed an outstanding sensitivity and specificity for discrimination of CRC patients from healthy controls. This method could be used as a non-invasive method for CRC early diagnosis.",0,0
4354,"Evaluation of the Effectiveness of Artificial Intelligence Chest CT Lung Nodule Detection Based on Deep Learning. Lung cancer is one of the most malignant tumors. If it can be detected early and treated actively, it can effectively improve a patient's survival rate. Therefore, early diagnosis of lung cancer is very important. Early-stage lung cancer usually appears as a solitary lung nodule on medical imaging. It usually appears as a round or nearly round dense shadow in the chest radiograph. It is difficult to distinguish lung nodules and lung soft tissues with the naked eye. Therefore, this article proposes a deep learning-based artificial intelligence chest CT lung nodule detection performance evaluation study, aiming to evaluate the value of chest CT imaging technology in the detection of noncalcified nodules and provide help for the detection and treatment of lung cancer. In this article, the Lung Medical Imaging Database Consortium (LIDC) was selected to obtain 536 usable cases based on inclusion criteria; 80 cases were selected for examination, artificial intelligence software, radiologists, and thoracic imaging specialists. Using 80 pulmonary nodules detection in each case, the pathological type of pulmonary nodules, nonlime tuberculous test results, detection sensitivity, false negative rate, false positive rate, and CT findings were individually analyzed, and the detection efficiency software of artificial intelligence was evaluated. Experiments have proved that the sensitivity of artificial intelligence software to detect noncalcified nodules in the pleural, peripheral, central, and hilar areas is higher than that of radiologists, indicating that the method proposed in this article has achieved good detection results. It has a better nodule detection sensitivity than a radiologist, reducing the complexity of the detection process.",1,1
4356,"A New Optimal Diagnosis System for Coronavirus (COVID-19) Diagnosis Based on Archimedes Optimization Algorithm on Chest X-Ray Images. The new coronavirus, COVID-19, has affected people all over the world. Coronaviruses are a large group of viruses that can infect animals and humans and cause respiratory distress; these discomforts may be as mild as a cold or as severe as pneumonia. Correct detection of this disease can help to avoid its spreading increasingly. In this paper, a new CAD-based approach is suggested for the optimal diagnosis of this disease from chest X-ray images. The proposed method starts with a min-max normalization to scale all data into a normal scale, and then, histogram equalization is performed to improve the quality of the image before main processing. Afterward, 18 different features are extracted from the image. To decrease the method difficulty, the minimum features are selected based on a metaheuristic called Archimedes optimization algorithm (AOA). The model is then implemented on three datasets, and its results are compared with four other state-of-the-art methods. The final results indicated that the proposed method with 86% accuracy and 96% precision has the highest balance between accuracy and reliability with the compared methods as a diagnostic system for COVID-19.",0,0
4358,"A Method for Optimal Detection of Lung Cancer Based on Deep Learning Optimized by Marine Predators Algorithm. Lung cancer is the uncontrolled growth of cells in the lung that are made up of two spongy organs located in the chest. These cells may penetrate outside the lungs in a process called metastasis and spread to tissues and organs in the body. In this paper, using image processing, deep learning, and metaheuristic, an optimal methodology is proposed for early detection of this cancer. Here, we design a new convolutional neural network for this purpose. Marine predators algorithm is also used for optimal arrangement and better network accuracy. The method finally applied to RIDER dataset, and the results are compared with some pretrained deep networks, including CNN ResNet-18, GoogLeNet, AlexNet, and VGG-19. Final results showed higher results of the proposed method toward the compared techniques. The results showed that the proposed MPA-based method with 93.4% accuracy, 98.4% sensitivity, and 97.1% specificity provides the highest efficiency with the least error (1.6) toward the other state of the art methods.",0,0
4363,"Radiomics-based machine learning differentiates ""ground-glass"" opacities due to COVID-19 from acute non-COVID-19 lung disease. Ground-glass opacities (GGOs) are a non-specific high-resolution computed tomography (HRCT) finding tipically observed in early Coronavirus disesase 19 (COVID-19) pneumonia. However, GGOs are also seen in other acute lung diseases, thus making challenging the differential diagnosis. To this aim, we investigated the performance of a radiomics-based machine learning method to discriminate GGOs due to COVID-19 from those due to other acute lung diseases. Two sets of patients were included: a first set of 28 patients (COVID) diagnosed with COVID-19 infection confirmed by real-time polymerase chain reaction (RT-PCR) between March and April 2020 having (a) baseline HRCT at hospital admission and (b) predominant GGOs pattern on HRCT; a second set of 30 patients (nCOVID) showing (a) predominant GGOs pattern on HRCT performed between August 2019 and April 2020 and (b) availability of final diagnosis. Two readers independently segmented GGOs on HRCTs using a semi-automated approach, and radiomics features were extracted using a standard open source software (PyRadiomics). Partial least square (PLS) regression was used as the multivariate machine-learning algorithm. A leave-one-out nested cross-validation was implemented. PLS Î²-weights of radiomics features, including the 5% features with the largest Î²-weights in magnitude (top 5%), were obtained. The diagnostic performance of the radiomics model was assessed through receiver operating characteristic (ROC) analysis. The Youden's test assessed sensitivity and specificity of the classification. A null hypothesis probability threshold of 5% was chosen (pâ€‰<â€‰0.05). The predictive model delivered an AUC of 0.868 (Youden's indexâ€‰=â€‰0.68, sensitivityâ€‰=â€‰93%, specificity 75%, pâ€‰=â€‰4.2â€‰Ã—â€‰10<sup>-7</sup>). Of the seven features included in the top 5% features, five were texture-related. A radiomics-based machine learning signature showed the potential to accurately differentiate GGOs due to COVID-19 pneumonia from those due to other acute lung diseases. Most of the discriminant radiomics features were texture-related. This approach may assist clinician to adopt the appropriate management early, while improving the triage of patients.",0,0
4365,"Explainable machine-learning predictions for complications after pediatric congenital heart surgery. The quality of treatment and prognosis after pediatric congenital heart surgery remains unsatisfactory. A reliable prediction model for postoperative complications of congenital heart surgery patients is essential to enable prompt initiation of therapy and improve the quality of prognosis. Here, we develop an interpretable machine-learning-based model that integrates patient demographics, surgery-specific features and intraoperative blood pressure data for accurately predicting complications after pediatric congenital heart surgery. We used blood pressure variability and the k-means algorithm combined with a smoothed formulation of dynamic time wrapping to extract features from time-series data. In addition, SHAP framework was used to provide explanations of the prediction. Our model achieved the best performance both in binary and multi-label classification compared with other consensus-based risk models. In addition, this explainable model explains why a prediction was made to help improve the clinical understanding of complication risk and generate actionable knowledge in practice. The combination of model performance and interpretability is easy for clinicians to trust and provide insight into how they should respond before the condition worsens after pediatric congenital heart surgery.",0,0
4373,"Tuberculosis detection from chest x-rays for triaging in a high tuberculosis-burden setting: an evaluation of five artificial intelligence algorithms. Artificial intelligence (AI) algorithms can be trained to recognise tuberculosis-related abnormalities on chest radiographs. Various AI algorithms are available commercially, yet there is little impartial evidence on how their performance compares with each other and with radiologists. We aimed to evaluate five commercial AI algorithms for triaging tuberculosis using a large dataset that had not previously been used to train any AI algorithms.",1,1
4378,"Identifying novel transcript biomarkers for hepatocellular carcinoma (HCC) using RNA-Seq datasets and machine learning. Hepatocellular carcinoma (HCC) is one of the leading causes of cancer death in the world owing to limitations in its prognosis. The current prognosis approaches include radiological examination and detection of serum biomarkers, however, both have limited efficiency and are ineffective in early prognosis. Due to such limitations, we propose to use RNA-Seq data for evaluating putative higher accuracy biomarkers at the transcript level that could help in early prognosis.",0,0
4386,"Quantification of the Immune Content in Neuroblastoma: Deep Learning and Topological Data Analysis in Digital Pathology. We introduce here a novel machine learning (ML) framework to address the issue of the quantitative assessment of the immune content in neuroblastoma (NB) specimens. First, the EUNet, a U-Net with an EfficientNet encoder, is trained to detect lymphocytes on tissue digital slides stained with the CD3 T-cell marker. The training set consists of 3782 images extracted from an original collection of 54 whole slide images (WSIs), manually annotated for a total of 73,751 lymphocytes. Resampling strategies, data augmentation, and transfer learning approaches are adopted to warrant reproducibility and to reduce the risk of overfitting and selection bias. Topological data analysis (TDA) is then used to define activation maps from different layers of the neural network at different stages of the training process, described by persistence diagrams (PD) and Betti curves. TDA is further integrated with the uniform manifold approximation and projection (UMAP) dimensionality reduction and the hierarchical density-based spatial clustering of applications with noise (HDBSCAN) algorithm for clustering, by the deep features, the relevant subgroups and structures, across different levels of the neural network. Finally, the recent TwoNN approach is leveraged to study the variation of the intrinsic dimensionality of the U-Net model. As the main task, the proposed pipeline is employed to evaluate the density of lymphocytes over the whole tissue area of the WSIs. The model achieves good results with mean absolute error 3.1 on test set, showing significant agreement between densities estimated by our EUNet model and by trained pathologists, thus indicating the potentialities of a promising new strategy in the quantification of the immune content in NB specimens. Moreover, the UMAP algorithm unveiled interesting patterns compatible with pathological characteristics, also highlighting novel insights into the dynamics of the intrinsic dataset dimensionality at different stages of the training process. All the experiments were run on the Microsoft Azure cloud platform.",0,0
4391,"Machine Learning Models for Sarcopenia Identification Based on Radiomic Features of Muscles in Computed Tomography. The diagnosis of sarcopenia requires accurate muscle quantification. As an alternative to manual muscle mass measurement through computed tomography (CT), artificial intelligence can be leveraged for the automation of these measurements. Although generally difficult to identify with the naked eye, the radiomic features in CT images are informative. In this study, the radiomic features were extracted from L3 CT images of the entire muscle area and partial areas of the erector spinae collected from non-small cell lung carcinoma (NSCLC) patients. The first-order statistics and gray-level co-occurrence, gray-level size zone, gray-level run length, neighboring gray-tone difference, and gray-level dependence matrices were the radiomic features analyzed. The identification performances of the following machine learning models were evaluated: logistic regression, support vector machine (SVM), random forest, and extreme gradient boosting (XGB). Sex, coarseness, skewness, and cluster prominence were selected as the relevant features effectively identifying sarcopenia. The XGB model demonstrated the best performance for the entire muscle, whereas the SVM was the worst-performing model. Overall, the models demonstrated improved performance for the entire muscle compared to the erector spinae. Although further validation is required, the radiomic features presented here could become reliable indicators for quantifying the phenomena observed in the muscles of NSCLC patients, thus facilitating the diagnosis of sarcopenia.",0,0
4394,"A Clinical Decision Web to Predict ICU Admission or Death for Patients Hospitalised with COVID-19 Using Machine Learning Algorithms. The purpose of the study was to build a predictive model for estimating the risk of ICU admission or mortality among patients hospitalized with COVID-19 and provide a user-friendly tool to assist clinicians in the decision-making process. The study cohort comprised 3623 patients with confirmed COVID-19 who were hospitalized in the SALUD hospital network of Aragon (Spain), which includes 23 hospitals, between February 2020 and January 2021, a period that includes several pandemic waves. Up to 165 variables were analysed, including demographics, comorbidity, chronic drugs, vital signs, and laboratory data. To build the predictive models, different techniques and machine learning (ML) algorithms were explored: multilayer perceptron, random forest, and extreme gradient boosting (XGBoost). A reduction dimensionality procedure was used to minimize the features to 20, ensuring feasible use of the tool in practice. Our model was validated both internally and externally. We also assessed its calibration and provide an analysis of the optimal cut-off points depending on the metric to be optimized. The best performing algorithm was XGBoost. The final model achieved good discrimination for the external validation set (AUC = 0.821, 95% CI 0.787-0.854) and accurate calibration (slope = 1, intercept = -0.12). A cut-off of 0.4 provides a sensitivity and specificity of 0.71 and 0.78, respectively. In conclusion, we built a risk prediction model from a large amount of data from several pandemic waves, which had good calibration and discrimination ability. We also created a user-friendly web application that can aid rapid decision-making in clinical practice.",0,0
4395,"Prediction Models of Early Childhood Caries Based on Machine Learning Algorithms. In this study, we developed machine learning-based prediction models for early childhood caries and compared their performances with the traditional regression model. We analyzed the data of 4195 children aged 1-5 years from the Korea National Health and Nutrition Examination Survey data (2007-2018). Moreover, we developed prediction models using the XGBoost (version 1.3.1), random forest, and LightGBM (version 3.1.1) algorithms in addition to logistic regression. Two different methods were applied for variable selection, including a regression-based backward elimination and a random forest-based permutation importance classifier. We compared the area under the receiver operating characteristic (AUROC) values and misclassification rates of the different models and observed that all four prediction models had AUROC values ranging between 0.774 and 0.785. Furthermore, no significant difference was observed between the AUROC values of the four models. Based on the results, we can confirm that both traditional logistic regression and ML-based models can show favorable performance and can be used to predict early childhood caries, identify ECC high-risk groups, and implement active preventive treatments. However, further research is essential to improving the performance of the prediction model using recent methods, such as deep learning.",0,0
4398,"Estimated Artificial Neural Network Modeling of Maximal Oxygen Uptake Based on Multistage 10-m Shuttle Run Test in Healthy Adults. We aimed to develop an artificial neural network (ANN) model to estimate the maximal oxygen uptake (VO<sub>2</sub>max) based on a multistage 10 m shuttle run test (SRT) in healthy adults. For ANN-based VO<sub>2</sub>max estimation, 118 healthy Korean adults (59 men and 59 women) in their twenties and fifties (38.3 Â± 11.8 years, men aged 37.8 Â± 12.1 years, and women aged 38.8 Â± 11.6 years) participated in this study; data included age, sex, blood pressure (systolic blood pressure (SBP), diastolic blood pressure (DBP)), waist circumference, hip circumference, waist-to-hip ratio (WHR), body composition (weight, height, body mass index (BMI), percent skeletal muscle, and percent body), 10 m SRT parameters (number of round trips and final speed), and VO<sub>2</sub>max by graded exercise test (GXT) using a treadmill. The best estimation results (R<sup>2</sup> = 0.8206, adjusted R<sup>2</sup> = 0.7010, root mean square error; RMSE = 3.1301) were obtained in case 3 (using age, sex, height, weight, BMI, waist circumference, hip circumference, WHR, SBP, DBP, number of round trips in 10 m SRT, and final speed in 10 m SRT), while the worst results (R<sup>2</sup> = 0.7765, adjusted R<sup>2</sup> = 0.7206, RMSE = 3.494) were obtained for case 1 (using age, sex, height, weight, BMI, number of round trips in 10 m SRT, and final speed in 10 m SRT). The estimation results of case 2 (using age, sex, height, weight, BMI, waist circumference, hip circumference, WHR, number of round trips in 10 m SRT, and final speed in 10 m SRT) were lower (R<sup>2</sup> = 0.7909, adjusted R<sup>2</sup> = 0.7072, RMSE = 3.3798) than those of case 3 and higher than those of case 1. However, all cases showed high performance (R<sup>2</sup>) in the estimation results. This brief report developed an ANN-based estimation model to predict the VO<sub>2</sub>max of healthy adults, and the model's performance was confirmed to be excellent.",0,0
4415,"Screening of Mood Symptoms Using MMPI-2-RF Scales: An Application of Machine Learning Techniques. (1) Background: The MMPI-2-RF is the most widely used and most researched test among the tools for assessing psychopathology, and previous studies have established its validity. Mood disorders are the most common mental disorders worldwide; they present difficulties in early detection, go undiagnosed in many cases, and have a poor prognosis. (2) Methods: We analyzed a total of 8645 participants. We used the PHQ-9 to evaluate depressive symptoms and the MDQ to evaluate hypomanic symptoms. We used the 10 MMPI-2 Restructured Form scales and 23 Specific Problems scales for the MMPI-2-RF as predictors. We performed machine learning analysis using the k-nearest neighbor classification, linear discriminant analysis, and random forest classification. (3) Results: Through the machine learning technique, depressive symptoms were predicted with an AUC of 0.634-0.767, and the corresponding value range for hypomanic symptoms was 0.770-0.840. When using RCd to predict depressive symptoms, the AUC was 0.807, but this value was 0.840 when using linear discriminant classification. When predicting hypomanic symptoms with RC9, the AUC was 0.704, but this value was 0.767 when using the linear discriminant method. (4) Conclusions: Using machine learning analysis, we defined that participants' mood symptoms could be classified and predicted better than when using the Restructured Clinical scales.",0,0
4416,"Automatic Diagnosis of Bipolar Disorder Using Optical Coherence Tomography Data and Artificial Intelligence. The aim of this study is to explore an objective approach that aids the diagnosis of bipolar disorder (BD), based on optical coherence tomography (OCT) data which are analyzed using artificial intelligence.",0,0
4418,"Automatic Meningioma Segmentation and Grading Prediction: A Hybrid Deep-Learning Method. The purpose of this study was to determine whether a deep-learning-based assessment system could facilitate preoperative grading of meningioma. This was a retrospective study conducted at two institutions covering 643 patients. The system, designed with a cascade network structure, was developed using deep-learning technology for automatic tumor detection, visual assessment, and grading prediction. Specifically, a modified U-Net convolutional neural network was first established to segment tumor images. Subsequently, the segmentations were introduced into rendering algorithms for spatial reconstruction and another DenseNet convolutional neural network for grading prediction. The trained models were integrated as a system, and the robustness was tested based on its performance on an external dataset from the second institution involving different magnetic resonance imaging platforms. The results showed that the segment model represented a noteworthy performance with dice coefficients of 0.920 Â± 0.009 in the validation group. With accurate segmented tumor images, the rendering model delicately reconstructed the tumor body and clearly displayed the important intracranial vessels. The DenseNet model also achieved high accuracy with an area under the curve of 0.918 Â± 0.006 and accuracy of 0.901 Â± 0.039 when classifying tumors into low-grade and high-grade meningiomas. Moreover, the system exhibited good performance on the external validation dataset.",0,0
4419,"Progression-Free Survival Prediction in Patients with Nasopharyngeal Carcinoma after Intensity-Modulated Radiotherapy: Machine Learning vs. Traditional Statistics. The Cox proportional hazards (CPH) model is the most commonly used statistical method for nasopharyngeal carcinoma (NPC) prognostication. Recently, machine learning (ML) models are increasingly adopted for this purpose. However, only a few studies have compared the performances between CPH and ML models. This study aimed at comparing CPH with two state-of-the-art ML algorithms, namely, conditional survival forest (CSF) and DeepSurv for disease progression prediction in NPC.",0,0
4421,"Application of Machine Learning for Predicting Anastomotic Leakage in Patients with Gastric Adenocarcinoma Who Received Total or Proximal Gastrectomy. Anastomotic leakage is a life-threatening complication in patients with gastric adenocarcinoma who received total or proximal gastrectomy, and there is still no model accurately predicting anastomotic leakage. In this study, we aim to develop a high-performance machine learning tool to predict anastomotic leakage in patients with gastric adenocarcinoma received total or proximal gastrectomy. A total of 1660 cases of gastric adenocarcinoma patients who received total or proximal gastrectomy in a large academic hospital from 1 January 2010 to 31 December 2019 were investigated, and these patients were randomly divided into training and testing sets at a ratio of 8:2. Four machine learning models, such as logistic regression, random forest, support vector machine, and XGBoost, were employed, and 24 clinical preoperative and intraoperative variables were included to develop the predictive model. Regarding the area under the receiver operating characteristic curve (AUC), sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy, random forest had a favorable performance with an AUC of 0.89, a sensitivity of 81.8% and specificity of 82.2% in the testing set. Moreover, we built a web app based on random forest model to achieve real-time predictions for guiding surgeons' intraoperative decision making.",0,0
4422,"High BMI1 Expression with Low CD8+ and CD4+ T Cell Activity Could Promote Breast Cancer Cell Survival: A Machine Learning Approach. BMI1 is known to play a key role in the regulation of stem cell self-renewal in both endogenous and cancer stem cells. High BMI1 expression has been associated with poor prognosis in a variety of human tumors. The aim of this study was to reveal the correlations of BMI1 with survival rates, genetic alterations, and immune activities, and to validate the results using machine learning. We investigated the survival rates according to BMI1 expression in 389 and 789 breast cancer patients from Kangbuk Samsung Medical Center (KBSMC) and The Cancer Genome Atlas, respectively. We performed gene set enrichment analysis (GSEA) with pathway-based network analysis, investigated the immune response, and performed in vitro drug screening assays. The survival prediction model was evaluated through a gradient boosting machine (GBM) approach incorporating BMI1. High BMI1 expression was correlated with poor survival in patients with breast cancer. In GSEA and in in silico flow cytometry, high BMI1 expression was associated with factors indicating a weak immune response, such as decreased CD8+ T cell and CD4+ T cell counts. In pathway-based network analysis, BMI1 was directly linked to transcriptional regulation and indirectly linked to inflammatory response pathways, etc. The GBM model incorporating BMI1 showed improved prognostic performance compared with the model without BMI1. We identified telomerase inhibitor IX, a drug with potent activity against breast cancer cell lines with high BMI1 expression. We suggest that high BMI1 expression could be a therapeutic target in breast cancer. These results could contribute to the design of future experimental research and drug development programs for breast cancer.",0,0
4423,"Predicting 1-Year Mortality after Hip Fracture Surgery: An Evaluation of Multiple Machine Learning Approaches. Postoperative death within 1 year following hip fracture surgery is reported to be up to 27%. In the current study, we benchmarked the predictive precision and accuracy of the algorithms support vector machine (SVM), naÃ¯ve Bayes classifier (NB), and random forest classifier (RF) against logistic regression (LR) in predicting 1-year postoperative mortality in hip fracture patients as well as assessed the relative importance of the variables included in the LR model. All adult patients who underwent primary emergency hip fracture surgery in Sweden, between 1 January 2008 and 31 December 2017 were included in the study. Patients with pathological fractures and non-operatively managed hip fractures, as well as those who died within 30 days after surgery, were excluded from the analysis. A LR model with an elastic net regularization were fitted and compared to NB, SVM, and RF. The relative importance of the variables in the LR model was then evaluated using the permutation importance. The LR model including all the variables demonstrated an acceptable predictive ability on both the training and test datasets for predicting one-year postoperative mortality (Area under the curve (AUC) = 0.74 and 0.74 respectively). NB, SVM, and RF tended to over-predict the mortality, particularly NB and SVM algorithms. In contrast, LR only over-predicted mortality when the predicted probability of mortality was larger than 0.7. The LR algorithm outperformed the other three algorithms in predicting 1-year postoperative mortality in hip fracture patients. The most important predictors of 1-year mortality were the presence of a metastatic carcinoma, American Society of Anesthesiologists(ASA) classification, sex, Charlson Comorbidity Index (CCI) â‰¤ 4, age, dementia, congestive heart failure, hypertension, surgery using pins/screws, and chronic kidney disease.",0,0
4424,Deep Learning Algorithm for Management of Diabetes Mellitus via Electrocardiogram-Based Glycated Hemoglobin (ECG-HbA1c): A Retrospective Cohort Study. glycated hemoglobin (HbA1c) provides information on diabetes mellitus (DM) management. Electrocardiography (ECG) is a noninvasive test of cardiac activity that has been determined to be related to DM and its complications. This study developed a deep learning model (DLM) to estimate HbA1c via ECG.,0,0
4425,"Machine Learning Approaches to Predict In-Hospital Mortality among Neonates with Clinically Suspected Sepsis in the Neonatal Intensive Care Unit. preterm and critically ill neonates often experience clinically suspected sepsis during their prolonged hospitalization in the neonatal intensive care unit (NICU), which can be the initial sign of final adverse outcomes. Therefore, we aimed to utilize machine learning approaches to predict neonatal in-hospital mortality through data-driven learning.",0,0
4434,"Multimodal Early Alzheimer's Detection, a Genetic Algorithm Approach with Support Vector Machines. Alzheimer's disease (AD) is a neurodegenerative disease that mainly affects older adults. Currently, AD is associated with certain hypometabolic biomarkers, beta-amyloid peptides, hyperphosphorylated tau protein, and changes in brain morphology. Accurate diagnosis of AD, as well as mild cognitive impairment (MCI) (prodromal stage of AD), is essential for early care of the disease. As a result, machine learning techniques have been used in recent years for the diagnosis of AD. In this research, we propose a novel methodology to generate a multivariate model that combines different types of features for the detection of AD. In order to obtain a robust biomarker, ADNI baseline data, clinical and neuropsychological assessments (1024 features) of 106 patients were used. The data were normalized, and a genetic algorithm was implemented for the selection of the most significant features. Subsequently, for the development and validation of the multivariate classification model, a support vector machine model was created, and a five-fold cross-validation with an AUC of 87.63% was used to measure model performance. Lastly, an independent blind test of our final model, using 20 patients not considered during the model construction, yielded an AUC of 100%.",0,0
4436,"Machine Learning to Predict the Progression of Bone Mass Loss Associated with Personal Characteristics and a Metabolic Syndrome Scoring Index. A relationship exists between metabolic syndrome (MetS) and human bone health; however, whether the combination of demographic, lifestyle, and socioeconomic factors that are associated with MetS development also simultaneously affects bone density remains unclear. Using a machine learning approach, the current study aimed to estimate the usefulness of predicting bone mass loss using these potentially related factors. The present study included a sample of 23,497 adults who routinely visited a health screening center at a large health center at least once during each of three 3-year stages (i.e., 2006-2008, 2009-2011, and 2012-2014). The demographic, socioeconomic, lifestyle characteristics, body mass index (BMI), and MetS scoring index recorded during the first 3-year stage were used to predict the subsequent occurrence of osteopenia using a non-concurrence design. A concurrent prediction was also performed using the features recorded from the same 3-year stage as the predicted outcome. Machine learning algorithms, including logistic regression (LR), support vector machine (SVM), random forest (RF), and extreme gradient boosting (XGBoost), were applied to build predictive models using a unique feature set. The area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, precision, and F1 score were used to evaluate the predictive performances of the models. The XGBoost model presented the best predictive performance among the non-concurrence models. This study suggests that the ensemble learning model with a MetS severity score can be used to predict the progression of osteopenia. The inclusion of an individual's features into a predictive model over time is suggested for future studies.",0,0
4437,"Signal and Texture Features from T2 Maps for the Prediction of Mild Cognitive Impairment to Alzheimer's Disease Progression. Early detection of Alzheimer's disease (AD) is crucial to preserve cognitive functions and provide the opportunity for patients to enter clinical trials. In recent years, some studies have reported that features related to the signal and texture of MRI images can be an effective biomarker of AD. To test these claims, a study was conducted using T2 maps, a sequence not previously studied, of 40 patients with mild cognitive impairment (MCI) from the Alzheimer's Disease Neuroimaging Initiative database, who either progressed to AD (18) or remained stable (22). From these maps, the mean value and absolute difference of 37 signal and texture imaging features for 40 contralateral pairs of regions were measured. We used seven machine learning methods to analyze whether, by adding these imaging features to the neuropsychological studies currently used for diagnosis, we could more accurately identify patients who will progress to AD. The predictive models improved with the addition of signal and texture features. Additionally, features related to the signal and texture of the images were much more relevant than volumetric ones. Our results suggest that contralateral signal and texture features should be further investigated as potential biomarkers for the prediction of AD.",0,0
4441,"Comparison of Deep Learning Models for Cervical Vertebral Maturation Stage Classification on Lateral Cephalometric Radiographs. The purpose of this study is to evaluate and compare the performance of six state-of-the-art convolutional neural network (CNN)-based deep learning models for cervical vertebral maturation (CVM) on lateral cephalometric radiographs, and implement visualization of CVM classification for each model using gradient-weighted class activation map (Grad-CAM) technology. A total of 600 lateral cephalometric radiographs obtained from patients aged 6-19 years between 2013 and 2020 in Pusan National University Dental Hospital were used in this study. ResNet-18, MobileNet-v2, ResNet-50, ResNet-101, Inception-v3, and Inception-ResNet-v2 were tested to determine the optimal pre-trained network architecture. Multi-class classification metrics, accuracy, recall, precision, F1-score, and area under the curve (AUC) values from the receiver operating characteristic (ROC) curve were used to evaluate the performance of the models. All deep learning models demonstrated more than 90% accuracy, with Inception-ResNet-v2 performing the best, relatively. In addition, visualizing each deep learning model using Grad-CAM led to a primary focus on the cervical vertebrae and surrounding structures. The use of these deep learning models in clinical practice will facilitate dental practitioners in making accurate diagnoses and treatment plans.",0,0
4442,Automatic Segmentation of Pancreatic Tumors Using Deep Learning on a Video Image of Contrast-Enhanced Endoscopic Ultrasound. Contrast-enhanced endoscopic ultrasound (CE-EUS) is useful for the differentiation of pancreatic tumors. Using deep learning for the segmentation and classification of pancreatic tumors might further improve the diagnostic capability of CE-EUS.,0,0
4443,"Gallbladder Polyp Classification in Ultrasound Images Using an Ensemble Convolutional Neural Network Model. Differential diagnosis of true gallbladder polyps remains a challenging task. This study aimed to differentiate true polyps in ultrasound images using deep learning, especially gallbladder polyps less than 20 mm in size, where clinical distinction is necessary. A total of 501 patients with gallbladder polyp pathology confirmed through cholecystectomy were enrolled from two tertiary hospitals. Abdominal ultrasound images of gallbladder polyps from these patients were analyzed using an ensemble model combining three convolutional neural network (CNN) models and a 5-fold cross-validation. True polyp diagnosis with the ensemble model that learned only using ultrasonography images achieved an area under receiver operating characteristic curve (AUC) of 0.8960 and accuracy of 83.63%. After adding patient age and polyp size information, the diagnostic performance of the ensemble model improved, with a high specificity of 88.35%, AUC of 0.9082, and accuracy of 87.61%, outperforming the individual CNN models constituting the ensemble model. In the subgroup analysis, the ensemble model showed the best performance with AUC of 0.9131 for polyps larger than 10 mm. Our proposed ensemble model that combines three CNN models classifies gallbladder polyps of less than 20 mm in ultrasonography images with high accuracy and can be useful for avoiding unnecessary cholecystectomy with high specificity.",0,0
4446,Supervised Machine Learning Approach to Identify Early Predictors of Poor Outcome in Patients with COVID-19 Presenting to a Large Quaternary Care Hospital in New York City. The progression of clinical manifestations in patients with coronavirus disease 2019 (COVID-19) highlights the need to account for symptom duration at the time of hospital presentation in decision-making algorithms.,0,0
4451,Prediction Model for Tumor Budding Status Using the Radiomic Features of F-18 Fluorodeoxyglucose Positron Emission Tomography/Computed Tomography in Cervical Cancer. To compare the radiomic features of F-18 fluorodeoxyglucose positron emission tomography/computed tomography (<sup>18</sup>F-FDG PET/CT) and intratumoral heterogeneity according to tumor budding (TB) status and to develop a prediction model for the TB status using the radiomic feature of <sup>18</sup>F-FDG PET/CT in patients with cervical cancer.,0,0
4453,"Deep Learning Analysis of In Vivo Hyperspectral Images for Automated Intraoperative Nerve Detection. Nerves are critical structures that may be difficult to recognize during surgery. Inadvertent nerve injuries can have catastrophic consequences for the patient and lead to life-long pain and a reduced quality of life. Hyperspectral imaging (HSI) is a non-invasive technique combining photography with spectroscopy, allowing non-invasive intraoperative biological tissue property quantification. We show, for the first time, that HSI combined with deep learning allows nerves and other tissue types to be automatically recognized in in vivo hyperspectral images. An animal model was used, and eight anesthetized pigs underwent neck midline incisions, exposing several structures (nerve, artery, vein, muscle, fat, skin). State-of-the-art machine learning models were trained to recognize these tissue types in HSI data. The best model was a convolutional neural network (CNN), achieving an overall average sensitivity of 0.91 and a specificity of 1.0, validated with leave-one-patient-out cross-validation. For the nerve, the CNN achieved an average sensitivity of 0.76 and a specificity of 0.99. In conclusion, HSI combined with a CNN model is suitable for in vivo nerve recognition.",0,0
4454,"Computer-Aided Detection (CADe) System with Optical Coherent Tomography for Melanin Morphology Quantification in Melasma Patients. Dark skin-type individuals have a greater tendency to have pigmentary disorders, among which melasma is especially refractory to treat and often recurs. Objective measurement of melanin amount helps evaluate the treatment response of pigmentary disorders. However, naked-eye evaluation is subjective to weariness and bias. We used a cellular resolution full-field optical coherence tomography (FF-OCT) to assess melanin features of melasma lesions and perilesional skin on the cheeks of eight Asian patients. A computer-aided detection (CADe) system is proposed to mark and quantify melanin. This system combines spatial compounding-based denoising convolutional neural networks (SC-DnCNN), and through image processing techniques, various types of melanin features, including area, distribution, intensity, and shape, can be extracted. Through evaluations of the image differences between the lesion and perilesional skin, a distribution-based feature of confetti melanin without layering, two distribution-based features of confetti melanin in stratum spinosum, and a distribution-based feature of grain melanin at the dermal-epidermal junction, statistically significant findings were achieved (<i>p</i>-values = 0.0402, 0.0032, 0.0312, and 0.0426, respectively). FF-OCT enables the real-time observation of melanin features, and the CADe system with SC-DnCNN was a precise and objective tool with which to interpret the area, distribution, intensity, and shape of melanin on FF-OCT images.",0,0
4455,"Residual-Shuffle Network with Spatial Pyramid Pooling Module for COVID-19 Screening. Since the start of the COVID-19 pandemic at the end of 2019, more than 170 million patients have been infected with the virus that has resulted in more than 3.8 million deaths all over the world. This disease is easily spreadable from one person to another even with minimal contact, even more for the latest mutations that are more deadly than its predecessor. Hence, COVID-19 needs to be diagnosed as early as possible to minimize the risk of spreading among the community. However, the laboratory results on the approved diagnosis method by the World Health Organization, the reverse transcription-polymerase chain reaction test, takes around a day to be processed, where a longer period is observed in the developing countries. Therefore, a fast screening method that is based on existing facilities should be developed to complement this diagnosis test, so that a suspected patient can be isolated in a quarantine center. In line with this motivation, deep learning techniques were explored to provide an automated COVID-19 screening system based on X-ray imaging. This imaging modality is chosen because of its low-cost procedures that are widely available even in many small clinics. A new convolutional neural network (CNN) model is proposed instead of utilizing pre-trained networks of the existing models. The proposed network, Residual-Shuffle-Net, comprises four stacks of the residual-shuffle unit followed by a spatial pyramid pooling (SPP) unit. The architecture of the residual-shuffle unit follows an hourglass design with reduced convolution filter size in the middle layer, where a shuffle operation is performed right after the split branches have been concatenated back. Shuffle operation forces the network to learn multiple sets of features relationship across various channels instead of a set of global features. The SPP unit, which is placed at the end of the network, allows the model to learn multi-scale features that are crucial to distinguish between the COVID-19 and other types of pneumonia cases. The proposed network is benchmarked with 12 other state-of-the-art CNN models that have been designed and tuned specially for COVID-19 detection. The experimental results show that the Residual-Shuffle-Net produced the best performance in terms of accuracy and specificity metrics with 0.97390 and 0.98695, respectively. The model is also considered as a lightweight model with slightly more than 2 million parameters, which makes it suitable for mobile-based applications. For future work, an attention mechanism can be integrated to target certain regions of interest in the X-ray images that are deemed to be more informative for COVID-19 diagnosis.",0,0
4456,"An Artificial Intelligence-Enabled Pipeline for Medical Domain: Malaysian Breast Cancer Survivorship Cohort as a Case Study. Automated artificial intelligence (AI) systems enable the integration of different types of data from various sources for clinical decision-making. The aim of this study is to propose a pipeline to develop a fully automated clinician-friendly AI-enabled database platform for breast cancer survival prediction. A case study of breast cancer survival cohort from the University Malaya Medical Centre was used to develop and evaluate the pipeline. A relational database and a fully automated system were developed by integrating the database with analytical modules (machine learning, automated scoring for quality of life, and interactive visualization). The developed pipeline, <i>i</i>Survive has helped in enhancing data management as well as to visualize important prognostic variables and survival rates. The embedded automated scoring module demonstrated quality of life of patients whereas the interactive visualizations could be used by clinicians to facilitate communication with patients. The pipeline proposed in this study is a one-stop center to manage data, to automate analytics using machine learning, to automate scoring and to produce explainable interactive visuals to enhance clinician-patient communication along the survivorship period to modify behaviours that relate to prognosis. The pipeline proposed can be modelled on any disease not limited to breast cancer.",0,0
4457,"Feasibility and Implementation of a Deep Learning MR Reconstruction for TSE Sequences in Musculoskeletal Imaging. Magnetic Resonance Imaging (MRI) of the musculoskeletal system is one of the most common examinations in clinical routine. The application of Deep Learning (DL) reconstruction for MRI is increasingly gaining attention due to its potential to improve the image quality and reduce the acquisition time simultaneously. However, the technology has not yet been implemented in clinical routine for turbo spin echo (TSE) sequences in musculoskeletal imaging. The aim of this study was therefore to assess the technical feasibility and evaluate the image quality. Sixty examinations of knee, hip, ankle, shoulder, hand, and lumbar spine in healthy volunteers at 3 T were included in this prospective, internal-review-board-approved study. Conventional (TSE<sub>S</sub>) and DL-based TSE sequences (TSE<sub>DL</sub>) were compared regarding image quality, anatomical structures, and diagnostic confidence. Overall image quality was rated to be excellent, with a significant improvement in edge sharpness and reduced noise compared to TSE<sub>S</sub> (<i>p</i> < 0.001). No difference was found concerning the extent of artifacts, the delineation of anatomical structures, and the diagnostic confidence comparing TSE<sub>S</sub> and TSE<sub>DL</sub> (<i>p</i> > 0.05). Therefore, DL image reconstruction for TSE sequences in MSK imaging is feasible, enabling a remarkable time saving (up to 75%), whilst maintaining excellent image quality and diagnostic confidence.",0,0
4458,"Transfer Learning for the Detection and Diagnosis of Types of Pneumonia including Pneumonia Induced by COVID-19 from Chest X-ray Images. Accurate early diagnosis of COVID-19 viral pneumonia, primarily in asymptomatic people, is essential to reduce the spread of the disease, the burden on healthcare capacity, and the overall death rate. It is essential to design affordable and accessible solutions to distinguish pneumonia caused by COVID-19 from other types of pneumonia. In this work, we propose a reliable approach based on deep transfer learning that requires few computations and converges faster. Experimental results demonstrate that our proposed framework for transfer learning is a potential and effective approach to detect and diagnose types of pneumonia from chest X-ray images with a test accuracy of 94.0%.",0,0
4459,"Automated Mesiodens Classification System Using Deep Learning on Panoramic Radiographs of Children. In this study, we aimed to develop and evaluate the performance of deep-learning models that automatically classify mesiodens in primary or mixed dentition panoramic radiographs. Panoramic radiographs of 550 patients with mesiodens and 550 patients without mesiodens were used. Primary or mixed dentition patients were included. SqueezeNet, ResNet-18, ResNet-101, and Inception-ResNet-V2 were each used to create deep-learning models. The accuracy, precision, recall, and F1 score of ResNet-101 and Inception-ResNet-V2 were higher than 90%. SqueezeNet exhibited relatively inferior results. In addition, we attempted to visualize the models using a class activation map. In images with mesiodens, the deep-learning models focused on the actual locations of the mesiodens in many cases. Deep-learning technologies may help clinicians with insufficient clinical experience in more accurate and faster diagnosis.",0,0
4463,"iPMI: Machine Learning-Aided Identification of Parametrial Invasion in Women with Early-Stage Cervical Cancer. Radical hysterectomy is a recommended treatment for early-stage cervical cancer. However, the procedure is associated with significant morbidities resulting from the removal of the parametrium. Parametrial cancer invasion (PMI) is found in a minority of patients but the efficient system used to predict it is lacking. In this study, we develop a novel machine learning (ML)-based predictive model based on a random forest model (called iPMI) for the practical identification of PMI in women. Data of 1112 stage IA-IIA cervical cancer patients who underwent primary surgery were collected and considered as the training dataset, while data from an independent cohort of 116 consecutive patients were used as the independent test dataset. Based on these datasets, iPMI-Econ was then developed by using basic clinicopathological data available prior to surgery, while iPMI-Power was also introduced by adding pelvic node metastasis and uterine corpus invasion to the iPMI-Econ. Both 10-fold cross-validations and independent test results showed that iPMI-Power outperformed other well-known ML classifiers (e.g., logistic regression, decision tree, k-nearest neighbor, multi-layer perceptron, naive Bayes, support vector machine, and extreme gradient boosting). Upon comparison, it was found that iPMI-Power was effective and had a superior performance to other well-known ML classifiers in predicting PMI. It is anticipated that the proposed iPMI may serve as a cost-effective and rapid approach to guide important clinical decision-making.",0,0
4464,"Brain Hemorrhage Classification in CT Scan Images Using Minimalist Machine Learning. Over time, a myriad of applications have been generated for pattern classification algorithms. Several case studies include parametric classifiers such as the Multi-Layer Perceptron (MLP) classifier, which is one of the most widely used today. Others use non-parametric classifiers, Support Vector Machine (SVM), K-Nearest Neighbors (K-NN), NaÃ¯ve Bayes (NB), Adaboost, and Random Forest (RF). However, there is still little work directed toward a new trend in Artificial Intelligence (AI), which is known as eXplainable Artificial Intelligence (X-AI). This new trend seeks to make Machine Learning (ML) algorithms increasingly simple and easy to understand for users. Therefore, following this new wave of knowledge, in this work, the authors develop a new pattern classification methodology, based on the implementation of the novel Minimalist Machine Learning (MML) paradigm and a higher relevance attribute selection algorithm, which we call <i>dMeans</i>. We examine and compare the performance of this methodology with MLP, NB, KNN, SVM, Adaboost, and RF classifiers to perform the task of classification of Computed Tomography (CT) brain images. These grayscale images have an area of 128 Ã— 128 pixels, and there are two classes available in the dataset: CT without Hemorrhage and CT with Intra-Ventricular Hemorrhage (IVH), which were classified using the Leave-One-Out Cross-Validation method. Most of the models tested by Leave-One-Out Cross-Validation performed between 50% and 75% accuracy, while sensitivity and sensitivity ranged between 58% and 86%. The experiments performed using our methodology matched the best classifier observed with 86.50% accuracy, and they outperformed all state-of-the-art algorithms in specificity with 91.60%. This performance is achieved hand in hand with simple and practical methods, which go hand in hand with this trend of generating easily explainable algorithms.",0,0
4465,"Automated Arrhythmia Detection Based on RR Intervals. Abnormal heart rhythms, also known as arrhythmias, can be life-threatening. AFIB and AFL are examples of arrhythmia that affect a growing number of patients. This paper describes a method that can support clinicians during arrhythmia diagnosis. We propose a deep learning algorithm to discriminate AFIB, AFL, and NSR RR interval signals. The algorithm was designed with data from 4051 subjects. With 10-fold cross-validation, the algorithm achieved the following results: ACC = 99.98%, SEN = 100.00%, and SPE = 99.94%. These results are significant because they show that it is possible to automate arrhythmia detection in RR interval signals. Such a detection method makes economic sense because RR interval signals are cost-effective to measure, communicate, and process. Having such a cost-effective solution might lead to widespread long-term monitoring, which can help detecting arrhythmia earlier. Detection can lead to treatment, which improves outcomes for patients.",0,0
4466,"A Promising Approach: Artificial Intelligence Applied to Small Intestinal Bacterial Overgrowth (SIBO) Diagnosis Using Cluster Analysis. Small intestinal bacterial overgrowth (SIBO) is characterized by abnormal and excessive amounts of bacteria in the small intestine. Since symptoms and lab tests are non-specific, the diagnosis of SIBO is highly dependent on breath testing. There is a lack of a universally accepted cut-off point for breath testing to diagnose SIBO, and the dilemma of defining ""SIBO patients"" has made it more difficult to explore the gold standard for SIBO diagnosis. How to validate the gold standard for breath testing without defining ""SIBO patients"" has become an imperious demand in clinic. Breath-testing datasets from 1071 patients were collected from Xiangya Hospital in the past 3 years and analyzed with an artificial intelligence method using cluster analysis. K-means and DBSCAN algorithms were applied to the dataset after the clustering tendency was confirmed with Hopkins Statistic. Satisfying the clustering effect was evaluated with a Silhouette score, and patterns of each group were described. Advantages of artificial intelligence application in adaptive breath-testing diagnosis criteria with SIBO were discussed from the aspects of high dimensional analysis, and data-driven and regional specific dietary influence. This research work implied a promising application of artificial intelligence for SIBO diagnosis, which would benefit clinical practice and scientific research.",0,0
4467,"Alzheimer's Disease and Frontotemporal Dementia: A Robust Classification Method of EEG Signals and a Comparison of Validation Methods. Dementia is the clinical syndrome characterized by progressive loss of cognitive and emotional abilities to a degree severe enough to interfere with daily functioning. Alzheimer's disease (AD) is the most common neurogenerative disorder, making up 50-70% of total dementia cases. Another dementia type is frontotemporal dementia (FTD), which is associated with circumscribed degeneration of the prefrontal and anterior temporal cortex and mainly affects personality and social skills. With the rapid advancement in electroencephalogram (EEG) sensors, the EEG has become a suitable, accurate, and highly sensitive biomarker for the identification of neuronal and cognitive dynamics in most cases of dementia, such as AD and FTD, through EEG signal analysis and processing techniques. In this study, six supervised machine-learning techniques were compared on categorizing processed EEG signals of AD and FTD cases, to provide an insight for future methods on early dementia diagnosis. K-fold cross validation and leave-one-patient-out cross validation were also compared as validation methods to evaluate their performance for this classification problem. The proposed methodology accuracy scores were 78.5% for AD detection with decision trees and 86.3% for FTD detection with random forests.",0,0
4468,"Predicting Depression in Community Dwellers Using a Machine Learning Algorithm. Depression is one of the leading causes of disability worldwide. Given the socioeconomic burden of depression, appropriate depression screening for community dwellers is necessary. We used data from the 2014 and 2016 Korea National Health and Nutrition Examination Surveys. The 2014 dataset was used as a training set, whereas the 2016 dataset was used as the hold-out test set. The synthetic minority oversampling technique (SMOTE) was used to control for class imbalances between the depression and non-depression groups in the 2014 dataset. The least absolute shrinkage and selection operator (LASSO) was used for feature reduction and classifiers in the final model. Data obtained from 9488 participants were used for the machine learning process. The depression group had poorer socioeconomic, health, functional, and biological measures than the non-depression group. From the initial 37 variables, 13 were selected using LASSO. All performance measures were calculated based on the raw 2016 dataset without the SMOTE. The area under the receiver operating characteristic curve and overall accuracy in the hold-out test set were 0.903 and 0.828, respectively. Perceived stress had the strongest influence on the classifying model for depression. LASSO can be practically applied for depression screening of community dwellers with a few variables. Future studies are needed to develop a more efficient and accurate classification model for depression.",0,0
4470,"Combining Deep Learning and Graph-Theoretic Brain Features to Detect Posttraumatic Stress Disorder at the Individual Level. Previous studies using resting-state functional MRI (rs-fMRI) have revealed alterations in graphical metrics in groups of individuals with posttraumatic stress disorder (PTSD). To explore the ability of graph measures to diagnose PTSD and capture its essential features in individual patients, we used a deep learning (DL) model based on a graph-theoretic approach to discriminate PTSD from trauma-exposed non-PTSD at the individual level and to identify its most discriminant features. Our study was performed on rs-fMRI data from 91 individuals with PTSD and 126 trauma-exposed non-PTSD patients. To evaluate our DL method, we used the traditional support vector machine (SVM) classifier as a reference. Our results showed that the proposed DL model allowed single-subject discrimination of PTSD and trauma-exposed non-PTSD individuals with higher accuracy (average: 80%) than the traditional SVM (average: 57.7%). The top 10 DL features were identified within the default mode, central executive, and salience networks; the first two of these networks were also identified in the SVM classification. We also found that nodal efficiency in the left fusiform gyrus was negatively correlated with the Clinician Administered PTSD Scale score. These findings demonstrate that DL based on graphical features is a promising method for assisting in the diagnosis of PTSD.",0,0
4471,"Diagnostic Performance of Artificial Intelligence-Based Computer-Aided Diagnosis for Breast Microcalcification on Mammography. The present study evaluated the diagnostic performance of artificial intelligence-based computer-aided diagnosis (AI-CAD) compared to that of dedicated breast radiologists in characterizing suspicious microcalcification on mammography. We retrospectively analyzed 435 unilateral mammographies from 420 patients (286 benign; 149 malignant) undergoing biopsy for suspicious microcalcification from June 2003 to November 2019. Commercial AI-CAD was applied to the mammography images, and malignancy scores were calculated. Diagnostic performance was compared between radiologists and AI-CAD using the area under the receiving operator characteristics curve (AUC). The AUCs of radiologists and AI-CAD were not significantly different (0.722 vs. 0.745, <i>p</i> = 0.393). The AUCs of the adjusted category were 0.726, 0.744, and 0.756 with cutoffs of 2%, 10%, and 38.03% for AI-CAD, respectively, which were all significantly higher than those for radiologists alone (all <i>p</i> < 0.05). None of the 27 cases downgraded to category 3 with a cutoff of 2% were confirmed as malignant on pathological analysis, suggesting that unnecessary biopsies could be avoided. Our findings suggest that the diagnostic performance of AI-CAD in characterizing suspicious microcalcification on mammography was similar to that of the radiologists, indicating that it may aid in making clinical decisions regarding the treatment of breast microcalcification.",1,1
4472,"COVLIAS 1.0: Lung Segmentation in COVID-19 Computed Tomography Scans Using Hybrid Deep Learning Artificial Intelligence Models. COVID-19 lung segmentation using Computed Tomography (CT) scans is important for the diagnosis of lung severity. The process of automated lung segmentation is challenging due to (a) CT radiation dosage and (b) ground-glass opacities caused by COVID-19. The lung segmentation methodologies proposed in 2020 were semi- or automated but not reliable, accurate, and user-friendly. The proposed study presents a COVID Lung Image Analysis System (COVLIAS 1.0, AtheroPointâ„¢, Roseville, CA, USA) consisting of hybrid deep learning (HDL) models for lung segmentation.",0,0
4477,"Colon Tissues Classification and Localization in Whole Slide Images Using Deep Learning. Colorectal cancer is one of the leading causes of cancer-related death worldwide. The early diagnosis of colon cancer not only reduces mortality but also reduces the burden related to the treatment strategies such as chemotherapy and/or radiotherapy. However, when the microscopic examination of the suspected colon tissue sample is carried out, it becomes a tedious and time-consuming job for the pathologists to find the abnormality in the tissue. In addition, there may be interobserver variability that might lead to conflict in the final diagnosis. As a result, there is a crucial need of developing an intelligent automated method that can learn from the patterns themselves and assist the pathologist in making a faster, accurate, and consistent decision for determining the normal and abnormal region in the colorectal tissues. Moreover, the intelligent method should be able to localize the abnormal region in the whole slide image (WSI), which will make it easier for the pathologists to focus on only the region of interest making the task of tissue examination faster and lesser time-consuming. As a result, artificial intelligence (AI)-based classification and localization models are proposed for determining and localizing the abnormal regions in WSI. The proposed models achieved F-score of 0.97, area under curve (AUC) 0.97 with pretrained Inception-v3 model, and F-score of 0.99 and AUC 0.99 with customized Inception-ResNet-v2 Type 5 (IR-v2 Type 5) model.",0,0
4480,"Automated Adenoid Hypertrophy Assessment with Lateral Cephalometry in Children Based on Artificial Intelligence. Adenoid hypertrophy may lead to pediatric obstructive sleep apnea and mouth breathing. The routine screening of adenoid hypertrophy in dental practice is helpful for preventing relevant craniofacial and systemic consequences. The purpose of this study was to develop an automated assessment tool for adenoid hypertrophy based on artificial intelligence. A clinical dataset containing 581 lateral cephalograms was used to train the convolutional neural network (CNN). According to Fujioka's method for adenoid hypertrophy assessment, the regions of interest were defined with four keypoint landmarks. The adenoid ratio based on the four landmarks was used for adenoid hypertrophy assessment. Another dataset consisting of 160 patients' lateral cephalograms were used for evaluating the performance of the network. Diagnostic performance was evaluated with statistical analysis. The developed system exhibited high sensitivity (0.906, 95% confidence interval [CI]: 0.750-0.980), specificity (0.938, 95% CI: 0.881-0.973) and accuracy (0.919, 95% CI: 0.877-0.961) for adenoid hypertrophy assessment. The area under the receiver operating characteristic curve was 0.987 (95% CI: 0.974-1.000). These results indicated the proposed assessment system is able to assess AH accurately. The CNN-incorporated system showed high accuracy and stability in the detection of adenoid hypertrophy from children' lateral cephalograms, implying the feasibility of automated adenoid hypertrophy screening utilizing a deep neural network model.",0,0
4481,Testing a Deep Learning Algorithm for Detection of Diabetic Retinopathy in a Spanish Diabetic Population and with MESSIDOR Database. The aim of the present study was to test our deep learning algorithm (DLA) by reading the retinographies.,0,0
4483,"Machine Learning Approaches to Identify Patient Comorbidities and Symptoms That Increased Risk of Mortality in COVID-19. Providing appropriate care for people suffering from COVID-19, the disease caused by the pandemic SARS-CoV-2 virus, is a significant global challenge. Many individuals who become infected may have pre-existing conditions that may interact with COVID-19 to increase symptom severity and mortality risk. COVID-19 patient comorbidities are likely to be informative regarding the individual risk of severe illness and mortality. Determining the degree to which comorbidities are associated with severe symptoms and mortality would thus greatly assist in COVID-19 care planning and provision. To assess this we performed a meta-analysis of published global literature, and machine learning predictive analysis using an aggregated COVID-19 global dataset. Our meta-analysis suggested that chronic obstructive pulmonary disease (COPD), cerebrovascular disease (CEVD), cardiovascular disease (CVD), type 2 diabetes, malignancy, and hypertension as most significantly associated with COVID-19 severity in the current published literature. Machine learning classification using novel aggregated cohort data similarly found COPD, CVD, CKD, type 2 diabetes, malignancy, and hypertension, as well as asthma, as the most significant features for classifying those deceased versus those who survived COVID-19. While age and gender were the most significant predictors of mortality, in terms of symptom-comorbidity combinations, it was observed that Pneumonia-Hypertension, Pneumonia-Diabetes, and Acute Respiratory Distress Syndrome (ARDS)-Hypertension showed the most significant associations with COVID-19 mortality. These results highlight the patient cohorts most likely to be at risk of COVID-19-related severe morbidity and mortality, which have implications for prioritization of hospital resources.",0,0
4484,"Automated Characterization of Cyclic Alternating Pattern Using Wavelet-Based Features and Ensemble Learning Techniques with EEG Signals. Sleep is highly essential for maintaining metabolism of the body and mental balance for increased productivity and concentration. Often, sleep is analyzed using macrostructure sleep stages which alone cannot provide information about the functional structure and stability of sleep. The cyclic alternating pattern (CAP) is a physiological recurring electroencephalogram (EEG) activity occurring in the brain during sleep and captures microstructure of the sleep and can be used to identify sleep instability. The CAP can also be associated with various sleep-related pathologies, and can be useful in identifying various sleep disorders. Conventionally, sleep is analyzed using polysomnogram (PSG) in various sleep laboratories by trained physicians and medical practitioners. However, PSG-based manual sleep analysis by trained medical practitioners is onerous, tedious and unfavourable for patients. Hence, a computerized, simple and patient convenient system is highly desirable for monitoring and analysis of sleep. In this study, we have proposed a system for automated identification of CAP phase-A and phase-B. To accomplish the task, we have utilized the openly accessible CAP sleep database. The study is performed using two single-channel EEG modalities and their combination. The model is developed using EEG signals of healthy subjects as well as patients suffering from six different sleep disorders namely nocturnal frontal lobe epilepsy (NFLE), sleep-disordered breathing (SDB), narcolepsy, periodic leg movement disorder (PLM), insomnia and rapid eye movement behavior disorder (RBD) subjects. An optimal orthogonal wavelet filter bank is used to perform the wavelet decomposition and subsequently, entropy and Hjorth parameters are extracted from the decomposed coefficients. The extracted features have been applied to different machine learning algorithms. The best performance is obtained using ensemble of bagged tress (EBagT) classifier. The proposed method has obtained the average classification accuracy of 84%, 83%, 81%, 78%, 77%, 76% and 72% for NFLE, healthy, SDB, narcolepsy, PLM, insomnia and RBD subjects, respectively in discriminating phases A and B using a balanced database. Our developed model yielded an average accuracy of 78% when all 77 subjects including healthy and sleep disordered patients are considered. Our proposed system can assist the sleep specialists in an automated and efficient analysis of sleep using sleep microstructure.",0,0
4486,"Microbiome of Saliva and Plaque in Children According to Age and Dental Caries Experience. Dental caries are one of the chronic diseases caused by organic acids made from oral microbes. However, there was a lack of knowledge about the oral microbiome of Korean children. The aim of this study was to analyze the metagenome data of the oral microbiome obtained from Korean children and to discover bacteria highly related to dental caries with machine learning models. Saliva and plaque samples from 120 Korean children aged below 12 years were collected. Bacterial composition was identified using Illumina HiSeq sequencing based on the V3-V4 hypervariable region of the 16S rRNA gene. Ten major genera accounted for approximately 70% of the samples on average, including <i>Streptococcus</i>, <i>Neisseria</i>, <i>Corynebacterium</i>, and <i>Fusobacterium</i>. Differential abundant analyses revealed that <i>Scardovia wiggsiae</i> and <i>Leptotrichia wadei</i> were enriched in the caries samples, while <i>Neisseria oralis</i> was abundant in the non-caries samples of children aged below 6 years. The caries and non-caries samples of children aged 6-12 years were enriched in <i>Streptococcus mutans</i> and <i>Corynebacterium durum</i>, respectively. The machine learning models based on these differentially enriched taxa showed accuracies of up to 83%. These results confirmed significant alterations in the oral microbiome according to dental caries and age, and these differences can be used as diagnostic biomarkers.",0,0
4489,"Forecasting COVID-19 Severity by Intelligent Optical Fingerprinting of Blood Samples. Forecasting COVID-19 disease severity is key to supporting clinical decision making and assisting resource allocation, particularly in intensive care units (ICUs). Here, we investigated the utility of time- and frequency-related features of the backscattered signal of serum patient samples to predict COVID-19 disease severity immediately after diagnosis. ICU admission was the primary outcome used to define disease severity. We developed a stacking ensemble machine learning model including the backscattered signal features (optical fingerprint), patient comorbidities, and age (AUROC = 0.80), which significantly outperformed the predictive value of clinical and laboratory variables available at hospital admission (AUROC = 0.71). The information derived from patient optical fingerprints was not strongly correlated with any clinical/laboratory variable, suggesting that optical fingerprinting brings unique information for COVID-19 severity risk assessment. Optical fingerprinting is a label-free, real-time, and low-cost technology that can be easily integrated as a front-line tool to facilitate the triage and clinical management of COVID-19 patients.",0,0
4508,"EEG-Based Emotion Recognition by Exploiting Fused Network Entropy Measures of Complex Networks across Subjects. It is well known that there may be significant individual differences in physiological signal patterns for emotional responses. Emotion recognition based on electroencephalogram (EEG) signals is still a challenging task in the context of developing an individual-independent recognition method. In our paper, from the perspective of spatial topology and temporal information of brain emotional patterns in an EEG, we exploit complex networks to characterize EEG signals to effectively extract EEG information for emotion recognition. First, we exploit visibility graphs to construct complex networks from EEG signals. Then, two kinds of network entropy measures (nodal degree entropy and clustering coefficient entropy) are calculated. By applying the AUC method, the effective features are input into the SVM classifier to perform emotion recognition across subjects. The experiment results showed that, for the EEG signals of 62 channels, the features of 18 channels selected by AUC were significant (<i>p</i> < 0.005). For the classification of positive and negative emotions, the average recognition rate was 87.26%; for the classification of positive, negative, and neutral emotions, the average recognition rate was 68.44%. Our method improves mean accuracy by an average of 2.28% compared with other existing methods. Our results fully demonstrate that a more accurate recognition of emotional EEG signals can be achieved relative to the available relevant studies, indicating that our method can provide more generalizability in practical use.",0,0
4512,"Application of Structural Entropy and Spatial Filling Factor in Colonoscopy Image Classification. For finding colorectal polyps the standard method relies on the techniques and devices of colonoscopy and the medical expertise of the gastroenterologist. In case of images acquired through colonoscopes the automatic segmentation of the polyps from their environment (i.e., from the bowel wall) is an essential task within computer aided diagnosis system development. As the number of the publicly available polyp images in various databases is still rather limited, it is important to develop metaheuristic methods, such as fuzzy inference methods, along with the deep learning algorithms to improve and validate detection and classification techniques. In the present manuscript firstly a fuzzy rule set is generated and validated. The former process is based on a statistical approach and makes use of histograms of the antecedents. Secondly, a method for selecting relevant antecedent variables is presented. The selection is based on the comparision of the histograms computed from the measured values for the training set. Then the inclusion of the RÃ©nyi-entropy-based structural entropy and the spatial filling factor into the set of input variables is proposed and assessed. The beneficial effect of including the mentioned structural entropy of the entropies from the hue and saturation (H and S) colour channels resulted in 65% true positive and 60% true negative rate of the classification for an advantageously selected set of antecedents when working with HSV images.",0,0
4513,"Effect of Patient Clinical Variables in Osteoporosis Classification Using Hip X-rays in Deep Learning Analysis. <i>Background and Objectives</i>: A few deep learning studies have reported that combining image features with patient variables enhanced identification accuracy compared with image-only models. However, previous studies have not statistically reported the additional effect of patient variables on the image-only models. This study aimed to statistically evaluate the osteoporosis identification ability of deep learning by combining hip radiographs with patient variables. <i>Materials and</i><i>Methods</i>: We collected a dataset containing 1699 images from patients who underwent skeletal-bone-mineral density measurements and hip radiography at a general hospital from 2014 to 2021. Osteoporosis was assessed from hip radiographs using convolutional neural network (CNN) models (ResNet18, 34, 50, 101, and 152). We also investigated ensemble models with patient clinical variables added to each CNN. Accuracy, precision, recall, specificity, F1 score, and area under the curve (AUC) were calculated as performance metrics. Furthermore, we statistically compared the accuracy of the image-only model with that of an ensemble model that included images plus patient factors, including effect size for each performance metric. <i>Results</i>: All metrics were improved in the ResNet34 ensemble model compared with the image-only model. The AUC score in the ensemble model was significantly improved compared with the image-only model (difference 0.004; 95% CI 0.002-0.0007; <i>p</i> = 0.0004, effect size: 0.871). <i>Conclusions</i>: This study revealed the additional effect of patient variables in identification of osteoporosis using deep CNNs with hip radiographs. Our results provided evidence that the patient variables had additive synergistic effects on the image in osteoporosis identification.",0,0
4514,"Neuroinflammation and Alzheimer's Disease: A Machine Learning Approach to CSF Proteomics. In Alzheimer's disease (AD), the contribution of pathophysiological mechanisms other than amyloidosis and tauopathy is now widely recognized, although not clearly quantifiable by means of fluid biomarkers. We aimed to identify quantifiable protein biomarkers reflecting neuroinflammation in AD using multiplex proximity extension assay (PEA) testing. Cerebrospinal fluid (CSF) samples from patients with mild cognitive impairment due to AD (AD-MCI) and from controls, i.e., patients with other neurological diseases (OND), were analyzed with the Olink Inflammation PEA biomarker panel. A machine-learning approach was then used to identify biomarkers discriminating AD-MCI (<i>n</i>: 34) from OND (<i>n</i>: 25). On univariate analysis, SIRT2, HGF, MMP-10, and CXCL5 showed high discriminatory performance (AUC 0.809, <i>p</i> = 5.2 Ã— 10<sup>-4</sup>, AUC 0.802, <i>p</i> = 6.4 Ã— 10<sup>-4</sup>, AUC 0.793, <i>p</i> = 3.2 Ã— 10<sup>-3</sup>, AUC 0.761, <i>p</i> = 2.3 Ã— 10<sup>-3</sup>, respectively), with higher CSF levels in AD-MCI patients as compared to controls. These same proteins were the best contributors to the penalized logistic regression model discriminating AD-MCI from controls (AUC of the model 0.906, <i>p</i> = 2.97 Ã— 10<sup>-7</sup>). The biological processes regulated by these proteins include astrocyte and microglia activation, amyloid, and tau misfolding modulation, and blood-brain barrier dysfunction. Using a high-throughput multiplex CSF analysis coupled with a machine-learning statistical approach, we identified novel biomarkers reflecting neuroinflammation in AD. Studies confirming these results by means of different assays are needed to validate PEA as a multiplex technique for CSF analysis and biomarker discovery in the field of neurological diseases.",0,0
4517,"Increased Pace of Aging in COVID-Related Mortality. Identifying prognostic biomarkers and risk stratification for COVID-19 patients is a challenging necessity. One of the core survival factors is patient age. However, chronological age is often severely biased due to dormant conditions and existing comorbidities. In this retrospective cohort study, we analyzed the data from 5315 COVID-19 patients (1689 lethal cases) admitted to 11 public hospitals in New York City from 1 March 2020 to 1 December. We calculated patients' pace of aging with BloodAge-a deep learning aging clock trained on clinical blood tests. We further constructed survival models to explore the prognostic value of biological age compared to that of chronological age. A COVID-19 score was developed to support a practical patient stratification in a clinical setting. Lethal COVID-19 cases had higher predicted age, compared to non-lethal cases (Î” = 0.8-1.6 years). Increased pace of aging was a significant risk factor of COVID-related mortality (hazard ratio = 1.026 per year, 95% CI = 1.001-1.052). According to our logistic regression model, the pace of aging had a greater impact (adjusted odds ratio = 1.09 Â± 0.00, per year) than chronological age (1.04 Â± 0.00, per year) on the lethal infection outcome. Our results show that a biological age measure, derived from routine clinical blood tests, adds predictive power to COVID-19 survival models.",0,0
4526,"Diagnosis of Wilson Disease and Its Phenotypes by Using Artificial Intelligence. WD is caused by <i>ATP7B</i> variants disrupting copper efflux resulting in excessive copper accumulation mainly in liver and brain. The diagnosis of WD is challenged by its variable clinical course, onset, morbidity, and <i>ATP7B</i> variant type. Currently it is diagnosed by a combination of clinical symptoms/signs, aberrant copper metabolism parameters (e.g., low ceruloplasmin serum levels and high urinary and hepatic copper concentrations), and genetic evidence of <i>ATP7B</i> mutations when available. As early diagnosis and treatment are key to favorable outcomes, it is critical to identify subjects before the onset of overtly detrimental clinical manifestations. To this end, we sought to improve WD diagnosis using artificial neural network algorithms (part of artificial intelligence) by integrating available clinical and molecular parameters. Surprisingly, WD diagnosis was based on plasma levels of glutamate, asparagine, taurine, and Fischer's ratio. As these amino acids are linked to the urea-Krebs' cycles, our study not only underscores the central role of hepatic mitochondria in WD pathology but also that most WD patients have underlying hepatic dysfunction. Our study provides novel evidence that artificial intelligence utilized for integrated analysis for WD may result in earlier diagnosis and mechanistically relevant treatments for patients with WD.",0,0
4533,"Using Machine Learning Algorithms for Identifying Gait Parameters Suitable to Evaluate Subtle Changes in Gait in People with Multiple Sclerosis. In multiple sclerosis (MS), gait impairment is one of the most prominent symptoms. For a sensitive assessment of pathological gait patterns, a comprehensive analysis and processing of several gait analysis systems is necessary. The objective of this work was to determine the best diagnostic gait system (DIERS pedogait, GAITRite system, and Mobility Lab) using six machine learning algorithms for the differentiation between people with multiple sclerosis (pwMS) and healthy controls, between pwMS with and without fatigue and between pwMS with mild and moderate impairment. The data of the three gait systems were assessed on 54 pwMS and 38 healthy controls. Gaussian Naive Bayes, Decision Tree, k-Nearest Neighbor, and Support Vector Machines (SVM) with linear, radial basis function (rbf) and polynomial kernel were applied for the detection of subtle walking changes. The best performance for a healthy-sick classification was achieved on the DIERS data with a SVM rbf kernel (Îº = 0.49 Â± 0.11). For differentiating between pwMS with mild and moderate disability, the GAITRite data with the SVM linear kernel (Îº = 0.61 Â± 0.06) showed the best performance. This study demonstrates that machine learning methods are suitable for identifying pathologic gait patterns in early MS.",0,0
4534,"Utility of a Short Neuropsychological Protocol for Detecting HIV-Associated Neurocognitive Disorders in Patients with Asymptomatic HIV-1 Infection. Human Immunodeficiency Virus type 1 (HIV-1) infection is a chronic disease that affects ~40 million people worldwide. HIV-associated neurocognitive disorders (HAND) are common in individuals with HIV-1 Infection, and represent a recent public health problem. Here we evaluate the performance of a recently proposed short protocol for detecting HAND by studying 60 individuals with HIV-1-Infection and 60 seronegative controls from a Caribbean community in Barranquilla, Colombia. The short evaluation protocol used significant neuropsychological tests from a previous study of asymptomatic HIV-1 infected patients and a group of seronegative controls. Brief screening instruments, i.e., the Mini-mental State Examination (MMSE) and the International HIV Dementia Scale (IHDS), were also applied. Using machine-learning techniques, we derived predictive models of HAND status, and evaluated their performance with the ROC curves. The proposed short protocol performs exceptionally well yielding sensitivity, specificity, and overall prediction values >90%, and better predictive capacity than that of the MMSE and IHDS. Community-specific cut-off values for HAND diagnosis, based on the MMSE and IHDS, make this protocol suitable for HAND screening in individuals from this Caribbean community. This study shows the effectivity of a recently proposed short protocol to detect HAND in individuals with asymptomatic HIV-1-Infection. The application of community-specific cut-off values for HAND diagnosis in the clinical setting may improve HAND screening accuracy and facilitate patients' treatment and follow-up. Further studies are needed to assess the performance of this protocol in other Latin American populations.",0,0
4536,"Unsupervised Machine Learning to Identify Separable Clinical Alzheimer's Disease Sub-Populations. Heterogeneity among Alzheimer's disease (AD) patients confounds clinical trial patient selection and therapeutic efficacy evaluation. This work defines separable AD clinical sub-populations using unsupervised machine learning. Clustering (t-SNE followed by k-means) of patient features and association rule mining (ARM) was performed on the ADNIMERGE dataset from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Patient sociodemographics, brain imaging, biomarkers, cognitive tests, and medication usage were included for analysis. Four AD clinical sub-populations were identified using between-cluster mean fold changes [cognitive performance, brain volume]: cluster-1 represented least severe disease [+17.3, +13.3]; cluster-0 [-4.6, +3.8] and cluster-3 [+10.8, -4.9] represented mid-severity sub-populations; cluster-2 represented most severe disease [-18.4, -8.4]. ARM assessed frequently occurring pharmacologic substances within the 4 sub-populations. No drug class was associated with the least severe AD (cluster-1), likely due to lesser antecedent disease. Anti-hyperlipidemia drugs associated with cluster-0 (mid-severity, higher volume). Interestingly, antioxidants vitamin C and E associated with cluster-3 (mid-severity, higher cognition). Anti-depressants like Zoloft associated with most severe disease (cluster-2). Vitamin D is protective for AD, but ARM identified significant underutilization across all AD sub-populations. Identification and feature characterization of four distinct AD sub-population ""clusters"" using standard clinical features enhances future clinical trial selection criteria and cross-study comparative analysis.",0,0
4537,"Raman Spectroscopy and Machine Learning for IDH Genotyping of Unprocessed Glioma Biopsies. Isocitrate dehydrogenase (IDH) mutational status is pivotal in the management of gliomas. Patients with IDH-mutated (IDH-MUT) tumors have a better prognosis and benefit more from extended surgical resection than IDH wild-type (IDH-WT). Raman spectroscopy (RS) is a minimally invasive optical technique with great potential for intraoperative diagnosis. We evaluated the RS's ability to characterize the IDH mutational status onto unprocessed glioma biopsies. We extracted 2073 Raman spectra from thirty-eight unprocessed samples. The classification performance was assessed using the eXtreme Gradient Boosted trees (XGB) and Support Vector Machine with Radial Basis Function kernel (RBF-SVM). Measured Raman spectra displayed differences between IDH-MUT and IDH-WT tumor tissue. From the 103 Raman shifts screened as input features, the cross-validation loop identified 52 shifts with the highest performance in the distinction of the two groups. Raman analysis showed differences in spectral features of lipids, collagen, DNA and cholesterol/phospholipids. We were able to distinguish between IDH-MUT and IDH-WT tumors with an accuracy and precision of 87%. RS is a valuable and accurate tool for characterizing the mutational status of IDH mutation in unprocessed glioma samples. This study improves RS knowledge for future personalized surgical strategy or in situ target therapies for glioma tumors.",0,0
4539,"Developing an Agnostic Risk Prediction Model for Early AKI Detection in Cancer Patients. Acute kidney injury (AKI) is a common complication among oncology patients associated with lower remission rates and higher mortality. To reduce the impact of this condition, we aimed to predict AKI earlier than existing tools, to allow clinical intervention before occurrence. We trained a random forest model on 597,403 routinely collected blood test results from 48,865 patients undergoing cancer treatment at The Christie NHS Foundation Trust between January 2017 and May 2020, to identify AKI events upcoming in the next 30 days. AKI risk levels were assigned to upcoming AKI events and tested through a prospective analysis between June and August 2020. The trained model gave an AUROC of 0.881 (95% CI 0.878-0.883), when assessing predictions per blood test for AKI occurrences within 30 days. Assigning risk levels and testing the model through prospective validation from the 1st June to the 31st August identified 73.8% of patients with an AKI event before at least one AKI occurrence, 61.2% of AKI occurrences. Our results suggest that around 60% of AKI occurrences experienced by patients undergoing cancer treatment could be identified using routinely collected blood results, allowing clinical remedial action to be taken and disruption to treatment by AKI to be minimised.",0,0
4540,"Clinical Categorization Algorithm (CLICAL) and Machine Learning Approach (SRF-CLICAL) to Predict Clinical Benefit to Immunotherapy in Metastatic Melanoma Patients: Real-World Evidence from the Istituto Nazionale Tumori IRCCS Fondazione Pascale, Napoli, Italy. The real-life application of immune checkpoint inhibitors (ICIs) may yield different outcomes compared to the benefit presented in clinical trials. For this reason, there is a need to define the group of patients that may benefit from treatment. We retrospectively investigated 578 metastatic melanoma patients treated with ICIs at the Istituto Nazionale Tumori IRCCS Fondazione ""G. Pascale"" of Napoli, Italy (INT-NA). To compare patients' clinical variables (i.e., age, lactate dehydrogenase (LDH), neutrophil-lymphocyte ratio (NLR), eosinophil, BRAF status, previous treatment) and their predictive and prognostic power in a comprehensive, non-hierarchical manner, a clinical categorization algorithm (CLICAL) was defined and validated by the application of a machine learning algorithm-survival random forest (SRF-CLICAL). The comprehensive analysis of the clinical parameters by log risk-based algorithms resulted in predictive signatures that could identify groups of patients with great benefit or not, regardless of the ICI received. From a real-life retrospective analysis of metastatic melanoma patients, we generated and validated an algorithm based on machine learning that could assist with the clinical decision of whether or not to apply ICI therapy by defining five signatures of predictability with 95% accuracy.",0,0
4541,"Blood-Based Multi-Cancer Detection Using a Novel Variant Calling Assay (DEEPGEN<sup>TM</sup>): Early Clinical Results. This is an early clinical analysis of the DEEPGENTM platform for cancer detection. Newly diagnosed cancer patients and individuals with no known malignancy were included in a prospective open-label case-controlled study (NCT03517332). Plasma cfDNA that was extracted from peripheral blood was sequenced and data were processed using machine-learning algorithms to derive cancer prediction scores. A total of 260 cancer patients and 415 controls were included in the study. Overall, sensitivity for all cancers was 57% (95% CI: 52, 64) at 95% specificity, and 43% (95% CI: 37, 49) at 99% specificity. With 51% sensitivity and 95% specificity for all stage 1 cancers, the stage-specific sensitivities trended to improve with higher stages. Early results from this preliminary clinical, prospective evaluation of the DEEPGENTM liquid biopsy platform suggests the platform offers a clinically relevant ability to differentiate individuals with and without known cancer, even at early stages of cancer.",0,0
4542,"Deep Learning Analysis of CT Images Reveals High-Grade Pathological Features to Predict Survival in Lung Adenocarcinoma. We aimed to develop a deep learning (DL) model for predicting high-grade patterns in lung adenocarcinomas (ADC) and to assess the prognostic performance of model in advanced lung cancer patients who underwent neoadjuvant or definitive concurrent chemoradiation therapy (CCRT). We included 275 patients with 290 early lung ADCs from an ongoing prospective clinical trial in the training dataset, which we split into internal-training and internal-validation datasets. We constructed a diagnostic DL model of high-grade patterns of lung ADC considering both morphologic view of the tumor and context view of the area surrounding the tumor (MC3DN; morphologic-view context-view 3D network). Validation was performed on an independent dataset of 417 patients with advanced non-small cell lung cancer who underwent neoadjuvant or definitive CCRT. The area under the curve value of the DL model was 0.8 for the prediction of high-grade histologic patterns such as micropapillary and solid patterns (MPSol). When our model was applied to the validation set, a high probability of MPSol was associated with worse overall survival (probability of MPSol >0.5 vs. <0.5; 5-year OS rate 56.1% vs. 70.7%), indicating that our model could predict the clinical outcomes of advanced lung cancer patients. The subgroup with a high probability of MPSol estimated by the DL model showed a 1.76-fold higher risk of death (HR 1.76, 95% CI 1.16-2.68). Our DL model can be useful in estimating high-grade histologic patterns in lung ADCs and predicting clinical outcomes of patients with advanced lung cancer who underwent neoadjuvant or definitive CCRT.",0,0
4543,"Enhancement of Radiosurgical Treatment Outcome Prediction Using MRI Radiomics in Patients with Non-Small Cell Lung Cancer Brain Metastases. The diagnosis of brain metastasis (BM) is commonly observed in non-small cell lung cancer (NSCLC) with poor outcomes. Accordingly, developing an approach to early predict BM response to Gamma Knife radiosurgery (GKRS) may benefit the patient treatment and monitoring. A total of 237 NSCLC patients with BMs (for survival prediction) and 256 patients with 976 BMs (for prediction of local tumor control) treated with GKRS were retrospectively analyzed. All the survival data were recorded without censoring, and the status of local tumor control was determined by comparing the last MRI follow-up in patients' lives with the pre-GKRS MRI. Overall 1763 radiomic features were extracted from pre-radiosurgical magnetic resonance images. Three prediction models were constructed, using (1) clinical data, (2) radiomic features, and (3) clinical and radiomic features. Support vector machines with a 30% hold-out validation approach were constructed. For treatment outcome predictions, the models derived from both the clinical and radiomics data achieved the best results. For local tumor control, the combined model achieved an area under the curve (AUC) of 0.95, an accuracy of 90%, a sensitivity of 91%, and a specificity of 89%. For patient survival, the combined model achieved an AUC of 0.81, an accuracy of 77%, a sensitivity of 78%, and a specificity of 80%. The pre-radiosurgical radiomics data enhanced the performance of local tumor control and survival prediction models in NSCLC patients with BMs treated with GRKS. An outcome prediction model based on radiomics combined with clinical features may guide therapy in these patients.",0,0
4544,"New Approaches in Characterization of Lesions Dissemination in DLBCL Patients on Baseline PET/CT. Dissemination, expressed recently by the largest Euclidian distance between lymphoma sites (SDmax), appeared a promising risk factor in DLBCL patients. We investigated alternative distance metrics to characterize the robustness of the dissemination information. In 290 patients from the REMARC trial (NCT01122472), the Euclidean (Euc), Manhattan (Man), and Tchebychev (Tch) distances between the furthest lesions, firstly based on the centroid of each lesion and then directly from the two most distant tumor voxels and the Travelling Salesman Problem distance (TSP) were calculated. For PFS, the areas under the ROC curves were between 0.63 and 0.64, and between 0.62 and 0.65 for OS. Patients with high SDmax whatever the method of calculation or high SD_TSP had a significantly poorer outcome than patients with low SDmax or SD_TSP (<i>p</i> < 0.001 for both PFS and OS), with significance maintained in Ann Arbor advanced-stage patients. In multivariate analysis with total metabolic tumor volume and ECOG, each distance feature had an independent prognostic value for PFS. For OS, only SDmax_Tch, SDmax_Euc _Vox, and SDmax_Man _Vox reached significance. The spread of DLBCL lesions measured by the largest distance between lymphoma sites is a strong independent prognostic factor and could be measured directly from tumor voxels, allowing its development in the area of the deep learning segmentation methods.",0,0
4545,"<i>USP19</i> and <i>RPL23</i> as Candidate Prognostic Markers for Advanced-Stage High-Grade Serous Ovarian Carcinoma. Ovarian cancer is one of the leading causes of deaths among patients with gynecological malignancies worldwide. In order to identify prognostic markers for ovarian cancer, we performed RNA-sequencing and analyzed the transcriptome data from 51 patients who received conventional therapies for high-grade serous ovarian carcinoma (HGSC). Patients with early-stage (I or II) HGSC exhibited higher immune gene expression than patients with advanced stage (III or IV) HGSC. In order to predict the prognosis of patients with HGSC, we created machine learning-based models and identified <i>USP19</i> and <i>RPL23</i> as candidate prognostic markers. Specifically, patients with lower <i>USP19</i> mRNA levels and those with higher <i>RPL23</i> mRNA levels had worse prognoses. This model was then used to analyze the data of patients with HGSC hosted on The Cancer Genome Atlas; this analysis validated the prognostic abilities of these two genes with respect to patient survival. Taken together, the transcriptome profiles of <i>USP19</i> and <i>RPL23</i> determined using a machine-learning model could serve as prognostic markers for patients with HGSC receiving conventional therapy.",0,0
4557,"Uncovering Barriers to Screening for Distress in Patients With Cancer via Machine Learning. Psychologic distress and manifest mental disorders are overlooked in 30-50% of patients with cancer. Accordingly, international cancer treatment guidelines recommend routine screening for distress in order to provide psychologic support to those in need. Yet, institutional and patient-related factors continue to hinder implementation.",0,0
4558,"Convolutional neural network in proteomics and metabolomics for determination of comorbidity between cancer and schizophrenia. The association between cancer risk and schizophrenia is widely debated. Despite many epidemiological studies, there is still no strong evidence regarding the molecular basis for the comorbidity between these two pathological conditions. The vast majority of assays have been performed using clinical records of schizophrenic patients or those undergoing cancer treatment and monitored for sufficient time to find shared features between the considered conditions. We performed mass spectrometry-based proteomic and metabolomic investigations of patients with different cancer phenotypes (breast, ovarian, renal, and prostate) and patients with schizophrenia. The resulting vast quantity of proteomic and metabolomic data were then processed using systems biology and one-dimensional (1D) convolutional neural network (1DCNN) machine learning approaches. Traditional systematic approaches permit the segregation of schizophrenia and cancer phenotypes on the level of biological processes, while 1DCNN recognized ""signatures"" that could segregate distinct cancer phenotypes and schizophrenia at the comorbidity level. The designed network efficiently discriminated unrelated pathologies with a model accuracy of 0.90 and different subtypes of oncophenotypes with an accuracy of 0.94. The proposed strategy integrates systematic analysis of identified compounds and application of 1DCNN model for unidentified ones to reveal the similarity between distinct phenotypes.",0,0
4559,"Less is more: Detecting clinical deterioration in the hospital with machine learning using only age, heart rate, and respiratory rate. We sought to develop a machine learning analytic (eCART Lite) for predicting clinical deterioration using only age, heart rate, and respiratory data, which can be pulled in real time from patient monitors and updated continuously without need for additional inputs or cumbersome electronic health record integrations.",0,0
4560,"Staged reflexive artificial intelligence driven testing algorithms for early diagnosis of pituitary disorders. Sellar masses (SM) frequently present with insidious hormonal dysfunction. We previously showed that, by utilizing a combined reflex/reflecting approach involving a laboratory clinician (LC) on common endocrine test results requested by non-specialists, and subsequently adding further warranted tests, previously undiagnosed pituitary disorders can be identified. However, manually employing these strategies by an LC is not feasible for wider screening of pituitary disorders.",0,0
4562,"Multi- class classification of breast cancer abnormalities using Deep Convolutional Neural Network (CNN). The real cause of breast cancer is very challenging to determine and therefore early detection of the disease is necessary for reducing the death rate due to risks of breast cancer. Early detection of cancer boosts increasing the survival chance up to 8%. Primarily, breast images emanating from mammograms, X-Rays or MRI are analyzed by radiologists to detect abnormalities. However, even experienced radiologists face problems in identifying features like micro-calcifications, lumps and masses, leading to high false positive and high false negative. Recent advancement in image processing and deep learning create some hopes in devising more enhanced applications that can be used for the early detection of breast cancer. In this work, we have developed a Deep Convolutional Neural Network (CNN) to segment and classify the various types of breast abnormalities, such as calcifications, masses, asymmetry and carcinomas, unlike existing research work, which mainly classified the cancer into benign and malignant, leading to improved disease management. Firstly, a transfer learning was carried out on our dataset using the pre-trained model ResNet50. Along similar lines, we have developed an enhanced deep learning model, in which learning rate is considered as one of the most important attributes while training the neural network. The learning rate is set adaptively in our proposed model based on changes in error curves during the learning process involved. The proposed deep learning model has achieved a performance of 88% in the classification of these four types of breast cancer abnormalities such as, masses, calcifications, carcinomas and asymmetry mammograms.",0,0
4563,"A comparison of prediction approaches for identifying prodromal Parkinson disease. Identifying people with Parkinson disease during the prodromal period, including via algorithms in administrative claims data, is an important research and clinical priority. We sought to improve upon an existing penalized logistic regression model, based on diagnosis and procedure codes, by adding prescription medication data or using machine learning. Using Medicare Part D beneficiaries age 66-90 from a population-based case-control study of incident Parkinson disease, we fit a penalized logistic regression both with and without Part D data. We also built a predictive algorithm using a random forest classifier for comparison. In a combined approach, we introduced the probability of Parkinson disease from the random forest, as a predictor in the penalized regression model. We calculated the receiver operator characteristic area under the curve (AUC) for each model. All models performed well, with AUCs ranging from 0.824 (simplest model) to 0.835 (combined approach). We conclude that medication data and random forests improve Parkinson disease prediction, but are not essential.",0,0
4567,"Automatic subject-specific spatiotemporal feature selection for subject-independent affective BCI. The dimensionality of the spatially distributed channels and the temporal resolution of electroencephalogram (EEG) based brain-computer interfaces (BCI) undermine emotion recognition models. Thus, prior to modeling such data, as the final stage of the learning pipeline, adequate preprocessing, transforming, and extracting temporal (i.e., time-series signals) and spatial (i.e., electrode channels) features are essential phases to recognize underlying human emotions. Conventionally, inter-subject variations are dealt with by avoiding the sources of variation (e.g., outliers) or turning the problem into a subject-deponent. We address this issue by preserving and learning from individual particularities in response to affective stimuli. This paper investigates and proposes a subject-independent emotion recognition framework that mitigates the subject-to-subject variability in such systems. Using an unsupervised feature selection algorithm, we reduce the feature space that is extracted from time-series signals. For the spatial features, we propose a subject-specific unsupervised learning algorithm that learns from inter-channel co-activation online. We tested this framework on real EEG benchmarks, namely DEAP, MAHNOB-HCI, and DREAMER. We train and test the selection outcomes using nested cross-validation and a support vector machine (SVM). We compared our results with the state-of-the-art subject-independent algorithms. Our results show an enhanced performance by accurately classifying human affection (i.e., based on valence and arousal) by 16%-27% compared to other studies. This work not only outperforms other subject-independent studies reported in the literature but also proposes an online analysis solution to affection recognition.",0,0
4582,Obstructive sleep apnea predicts 10-year cardiovascular disease related mortality in the Sleep Heart Health Study: a machine learning approach. Obstructive sleep apnea (OSA) is considered to be an important risk factor for the development of cardiovascular disease (CVD). This study aimed to develop and evaluate a machine learning approach with a set of features for assessing the 10-year CVD mortality risk of the OSA population.,0,0
4585,"Factors affecting creatine phosphokinase elevation during daptomycin therapy using a combination of machine learning and conventional methods. Musculoskeletal toxicity is a typical side effect of daptomycin (DAP). However, the risk factors have not been well established. Here, we aimed to identify independent factors affecting DAP-induced musculoskeletal toxicity using a combination of machine learning and conventional statistical methods.",0,0
4586,"Dysregulated Alanine as a Potential Predictive Marker of Glioma-An Insight from Untargeted HRMAS-NMR and Machine Learning Data. Metabolic alterations play a crucial role in glioma development and progression and can be detected even before the appearance of the fatal phenotype. We have compared the circulating metabolic fingerprints of glioma patients versus healthy controls, for the first time, in a quest to identify a panel of small, dysregulated metabolites with potential to serve as a predictive and/or diagnostic marker in the clinical settings. High-resolution magic angle spinning nuclear magnetic resonance spectroscopy (HRMAS-NMR) was used for untargeted metabolomics and data acquisition followed by a machine learning (ML) approach for the analyses of large metabolic datasets. Cross-validation of ML predicted NMR spectral features was done by statistical methods (Wilcoxon-test) using JMP-pro16 software. Alanine was identified as the most critical metabolite with potential to detect glioma with precision of 1.0, recall of 0.96, and F1 measure of 0.98. The top 10 metabolites identified for glioma detection included alanine, glutamine, valine, methionine, N-acetylaspartate (NAA), Î³-aminobutyric acid (GABA), serine, Î±-glucose, lactate, and arginine. We achieved 100% accuracy for the detection of glioma using ML algorithms, extra tree classifier, and random forest, and 98% accuracy with logistic regression. Classification of glioma in low and high grades was done with 86% accuracy using logistic regression model, and with 83% and 79% accuracy using extra tree classifier and random forest, respectively. The predictive accuracy of our ML model is superior to any of the previously reported algorithms, used in tissue- or liquid biopsy-based metabolic studies. The identified top metabolites can be targeted to develop early diagnostic methods as well as to plan personalized treatment strategies.",0,0
4590,"A Study of One-Class Classification Algorithms for Wearable Fall Sensors. In recent years, the popularity of wearable devices has fostered the investigation of automatic fall detection systems based on the analysis of the signals captured by transportable inertial sensors. Due to the complexity and variety of human movements, the detection algorithms that offer the best performance when discriminating falls from conventional Activities of Daily Living (ADLs) are those built on machine learning and deep learning mechanisms. In this regard, supervised machine learning binary classification methods have been massively employed by the related literature. However, the learning phase of these algorithms requires mobility patterns caused by falls, which are very difficult to obtain in realistic application scenarios. An interesting alternative is offered by One-Class Classifiers (OCCs), which can be exclusively trained and configured with movement traces of a single type (ADLs). In this paper, a systematic study of the performance of various typical OCCs (for diverse sets of input features and hyperparameters) is performed when applied to nine public repositories of falls and ADLs. The results show the potentials of these classifiers, which are capable of achieving performance metrics very similar to those of supervised algorithms (with values for the specificity and the sensitivity higher than 95%). However, the study warns of the need to have a wide variety of types of ADLs when training OCCs, since activities with a high degree of mobility can significantly increase the frequency of false alarms (ADLs identified as falls) if not considered in the data subsets used for training.",0,0
4591,"Atrial Fibrillation Prediction from Critically Ill Sepsis Patients. Sepsis is defined by life-threatening organ dysfunction during infection and is the leading cause of death in hospitals. During sepsis, there is a high risk that new onset of atrial fibrillation (AF) can occur, which is associated with significant morbidity and mortality. Consequently, early prediction of AF during sepsis would allow testing of interventions in the intensive care unit (ICU) to prevent AF and its severe complications. In this paper, we present a novel automated AF prediction algorithm for critically ill sepsis patients using electrocardiogram (ECG) signals. From the heart rate signal collected from 5-min ECG, feature extraction is performed using the traditional time, frequency, and nonlinear domain methods. Moreover, variable frequency complex demodulation and tunable Q-factor wavelet-transform-based time-frequency methods are applied to extract novel features from the heart rate signal. Using a selected feature subset, several machine learning classifiers, including support vector machine (SVM) and random forest (RF), were trained using only the 2001 Computers in Cardiology data set. For testing the proposed method, 50 critically ill ICU subjects from the Medical Information Mart for Intensive Care (MIMIC) III database were used in this study. Using distinct and independent testing data from MIMIC III, the SVM achieved 80% sensitivity, 100% specificity, 90% accuracy, 100% positive predictive value, and 83.33% negative predictive value for predicting AF immediately prior to the onset of AF, while the RF achieved 88% AF prediction accuracy. When we analyzed how much in advance we can predict AF events in critically ill sepsis patients, the algorithm achieved 80% accuracy for predicting AF events 10 min early. Our algorithm outperformed a state-of-the-art method for predicting AF in ICU patients, further demonstrating the efficacy of our proposed method. The annotations of patients' AF transition information will be made publicly available for other investigators. Our algorithm to predict AF onset is applicable for any ECG modality including patch electrodes and wearables, including Holter, loop recorder, and implantable devices.",0,0
4593,"A Machine Learning Approach to Predict Stress Hormones and Inflammatory Markers Using Illness Perception and Quality of Life in Breast Cancer Patients. Psychosocial factors have become central concepts in oncology research. However, their role in the prognosis of the disease is not yet well established. Studies on this subject report contradictory findings. We examine if illness perception and quality of life reports measured at baseline could predict the stress hormones and inflammatory markers in breast cancer survivors, one year later. We use statistics and machine learning methods to analyze our data and find the best prediction model. Patients with stage I to III breast cancer (N = 70) were assessed twice, at baseline and one year later, and completed scales assessing quality of life and illness perception. Blood and urine samples were obtained to measure stress hormones (cortisol and adrenocorticotropic hormone (ACTH) and inflammatory markers (c-reactive protein (CRP), erythrocyte sedimentation rate (ESR) and fibrinogen). Family quality of life is a strong predictor for ACTH. Women who perceive their illness as being more chronic at baseline have higher ESR and fibrinogen values one year later. The artificial intelligence (AI) data analysis yields the highest prediction score of 81.2% for the ACTH stress hormone, and 70% for the inflammatory marker ESR. A chronic timeline, illness control, health and family quality of life were important features associated with the best predictive results.",0,0
4594,Prediction of Recurrence in Pyogenic Vertebral Osteomyelitis by Artificial Neural Network Using Time-series Data of C-Reactive Protein: A Retrospective Cohort Study of 704 Patients. A retrospective cohort study.,0,0
4597,"Classification of Children With Autism and Typical Development Using Eye-Tracking Data From Face-to-Face Conversations: Machine Learning Model Development and Performance Evaluation. Previous studies have shown promising results in identifying individuals with autism spectrum disorder (ASD) by applying machine learning (ML) to eye-tracking data collected while participants viewed varying images (ie, pictures, videos, and web pages). Although gaze behavior is known to differ between face-to-face interaction and image-viewing tasks, no study has investigated whether eye-tracking data from face-to-face conversations can also accurately identify individuals with ASD.",0,0
4604,"Microscopic segmentation and classification of COVID-19 infection with ensemble convolutional neural network. The detection of biological RNA from sputum has a comparatively poor positive rate in the initial/early stages of discovering COVID-19, as per the World Health Organization. It has a different morphological structure as compared to healthy images, manifested by computer tomography (CT). COVID-19 diagnosis at an early stage can aid in the timely cure of patients, lowering the mortality rate. In this reported research, three-phase model is proposed for COVID-19 detection. In Phase I, noise is removed from CT images using a denoise convolutional neural network (DnCNN). In the Phase II, the actual lesion region is segmented from the enhanced CT images by using deeplabv3 and ResNet-18. In Phase III, segmented images are passed to the stack sparse autoencoder (SSAE) deep learning model having two stack auto-encoders (SAE) with the selected hidden layers. The designed SSAE model is based on both SAE and softmax layers for COVID19 classification. The proposed method is evaluated on actual patient data of Pakistan Ordinance Factories and other public benchmark data sets with different scanners/mediums. The proposed method achieved global segmentation accuracy of 0.96 and 0.97 for classification.",0,0
4607,"Intelligible Models for HealthCare: Predicting the Probability of 6-Month Unfavorable Outcome in Patients with Ischemic Stroke. Early prediction of unfavorable outcome after ischemic stroke is significant for clinical management. Machine learning as a novel computational modeling technique could help clinicians to address the challenge. We aim to investigate the applicability of machine learning models for individualized prediction in ischemic stroke patients and demonstrate the utility of various model-agnostic explanation techniques for machine learning predictions. A total of 499 consecutive patients with Unfavorable [modified Rankin Scale (mRS) score 3-6, nâ€‰=â€‰140] and favorable (mRS score 0-2, nâ€‰=â€‰359) outcome after 6-month from ischemic stroke were enrolled in this study. Four machine learning models, including Random Forest [RF], eXtreme Gradient Boosting [XGBoost], Adaptive Boosting [Adaboost] and Support Vector Machine [SVM] were performed with the area-under-the-curve (AUC): (90.20â€‰Â±â€‰0.22)%, (86.91â€‰Â±â€‰1.05)%, (86.49â€‰Â±â€‰2.35)%, (81.89â€‰Â±â€‰2.40)%, respectively. Three global interpretability techniques (Feature Importance shows the contribution of selected features, Partial Dependence Plot aims to visualize the average effect of a feature on the predicted probability of unfavorable outcome, Feature Interaction detects the change in the prediction that occurs by varying the features after considering the individual feature effects) and one local interpretability technique (Shapley Value indicates the probability of unfavorable outcome of different instances) have been applied to present the interpretability techniques via visualization. Thereby, the current study is important for better understanding intelligible healthcare analytics via explanations for the prediction of local and global levels, and potentially reduction of the mortality of patients with ischemic stroke by assisting clinicians in the decision-making process.",0,0
4609,"Predicting the onset of breast cancer using mammogram imaging data with irregular boundary. With mammography being the primary breast cancer screening strategy, it is essential to make full use of the mammogram imaging data to better identify women who are at higher and lower than average risk. Our primary goal in this study is to extract mammogram-based features that augment the well-established breast cancer risk factors to improve prediction accuracy. In this article, we propose a supervised functional principal component analysis (sFPCA) over triangulations method for extracting features that are ordered by the magnitude of association with the failure time outcome. The proposed method accommodates the irregular boundary issue posed by the breast area within the mammogram imaging data with flexible bivariate splines over triangulations. We also provide an eigenvalue decomposition algorithm that is computationally efficient. Compared to the conventional unsupervised FPCA method, the proposed method results in a lower Brier Score and higher area under the ROC curve (AUC) in simulation studies. We apply our method to data from the Joanne Knight Breast Health Cohort at Siteman Cancer Center. Our approach not only obtains the best prediction performance comparing to unsupervised FPCA and benchmark models but also reveals important risk patterns within the mammogram images. This demonstrates the importance of utilizing additional supervised image-based features to clarify breast cancer risk.",0,0
4612,"Self-Learning Network-based segmentation for real-time brain M.R. images through HARIS. In recent years in medical imaging technology, the advancement for medical diagnosis, the initial assessment of the ailment, and the abnormality have become challenging for radiologists. Magnetic resonance imaging is one such predominant technology used extensively for the initial evaluation of ailments. The primary goal is to mechanizean approach that can accurately assess the damaged region of the human brain throughan automated segmentation process that requires minimal training and can learn by itself from the previous experimental outcomes. It is computationally more efficient than other supervised learning strategies such as CNN deep learning models. As a result, the process of investigation and statistical analysis of the abnormality would be made much more comfortable and convenient. The proposed approach's performance seems to be much better compared to its counterparts, with an accuracy of 77% with minimal training of the model. Furthermore, the performance of the proposed training model is evaluated through various performance evaluation metrics like sensitivity, specificity, the Jaccard Similarity Index, and the Matthews correlation coefficient, where the proposed model is productive with minimal training.",0,0
4615,"Modeling a deep transfer learning framework for the classification of COVID-19 radiology dataset. Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-Coronavirus-2 or SARS-CoV-2), which came into existence in 2019, is a viral pandemic that caused coronavirus disease 2019 (COVID-19) illnesses and death. Research showed that relentless efforts had been made to improve key performance indicators for detection, isolation, and early treatment. This paper used Deep Transfer Learning Model (DTL) for the classification of a real-life COVID-19 dataset of chest X-ray images in both binary (COVID-19 or Normal) and three-class (COVID-19, Viral-Pneumonia or Normal) classification scenarios. Four experiments were performed where fine-tuned VGG-16 and VGG-19 Convolutional Neural Networks (CNNs) with DTL were trained on both binary and three-class datasets that contain X-ray images. The system was trained with an X-ray image dataset for the detection of COVID-19. The fine-tuned VGG-16 and VGG-19 DTL were modelled by employing a batch size of 10 in 40 epochs, Adam optimizer for weight updates, and categorical cross-entropy loss function. The results showed that the fine-tuned VGG-16 and VGG-19 models produced an accuracy of 99.23% and 98.00%, respectively, in the binary task. In contrast, in the multiclass (three-class) task, the fine-tuned VGG-16 and VGG-19 DTL models produced an accuracy of 93.85% and 92.92%, respectively. Moreover, the fine-tuned VGG-16 and VGG-19 models have MCC of 0.98 and 0.96 respectively in the binary classification, and 0.91 and 0.89 for multiclass classification. These results showed strong positive correlations between the models' predictions and the true labels. In the two classification tasks (binary and three-class), it was observed that the fine-tuned VGG-16 DTL model had stronger positive correlations in the MCC metric than the fine-tuned VGG-19 DTL model. The VGG-16 DTL model has a Kappa value of 0.98 as against 0.96 for the VGG-19 DTL model in the binary classification task, while in the three-class classification problem, the VGG-16 DTL model has a Kappa value of 0.91 as against 0.89 for the VGG-19 DTL model. This result is in agreement with the trend observed in the MCC metric. Hence, it was discovered that the VGG-16 based DTL model classified COVID-19 better than the VGG-19 based DTL model. Using the best performing fine-tuned VGG-16 DTL model, tests were carried out on 470 unlabeled image dataset, which was not used in the model training and validation processes. The test accuracy obtained for the model was 98%. The proposed models provided accurate diagnostics for both the binary and multiclass classifications, outperforming other existing models in the literature in terms of accuracy, as shown in this work.",0,0
4617,"Detection of COVID-19 from chest x-ray images using transfer learning. <b>Purpose:</b> The objective of this study is to develop and evaluate a fully automated, deep learning-based method for detection of COVID-19 infection from chest x-ray images. <b>Approach:</b> The proposed model was developed by replacing the final classifier layer in DenseNet201 with a new network consisting of global averaging layer, batch normalization layer, a dense layer with ReLU activation, and a final classification layer. Then, we performed an end-to-end training using the initial pretrained weights on all the layers. Our model was trained using a total of 8644 images with 4000 images each in normal and pneumonia cases and 644 in COVID-19 cases representing a large real dataset. The proposed method was evaluated based on accuracy, sensitivity, specificity, ROC curve, and <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>F</mi> <mn>1</mn></mrow> </math> -score using a test dataset comprising 1729 images (129 COVID-19, 800 normal, and 800 pneumonia). As a benchmark, we also compared the results of our method with those of seven state-of-the-art pretrained models and with a lightweight CNN architecture designed from scratch. <b>Results:</b> The proposed model based on DenseNet201 was able to achieve an accuracy of 94% in detecting COVID-19 and an overall accuracy of 92.19%. The model was able to achieve an AUC of 0.99 for COVID-19, 0.97 for normal, and 0.97 for pneumonia. The model was able to outperform alternative models in terms of overall accuracy, sensitivity, and specificity. <b>Conclusions:</b> Our proposed automated diagnostic model yielded an accuracy of 94% in the initial screening of COVID-19 patients and an overall accuracy of 92.19% using chest x-ray images.",0,0
4622,"Adaptive Attention Convolutional Neural Network for Liver Tumor Segmentation. Accurate segmentation of liver and liver tumors is critical for radiotherapy. Liver tumor segmentation, however, remains a difficult and relevant problem in the field of medical image processing because of the various factors like complex and variable location, size, and shape of liver tumors, low contrast between tumors and normal tissues, and blurred or difficult-to-define lesion boundaries. In this paper, we proposed a neural network (S-Net) that can incorporate attention mechanisms to end-to-end segmentation of liver tumors from CT images.",0,0
4626,"Artificial intelligence-assisted identification and quantification of osteoclasts. Quantification of osteoclasts to assess bone resorption is a time-consuming and tedious process. Since the inception of bone histomorphometry and manual counting of osteoclasts using bright-field microscopy, several approaches have been proposed to accelerate the counting process using both free and commercially available software. However, most of the present alternatives depend on manual or semi-automatic color segmentation and do not take advantage of artificial intelligence (AI). The present study directly compare estimates of osteoclast-covered surfaces (Oc.S/BS) obtained by the conventional manual method using a bright-field microscope to that obtained by a new AI-assisted method. We present a detailed step-by-step guide for the AI-based method. Tibiae from Wistar rats were either enzymatically stained for TRAP or immunostained for cathepsin K to identify osteoclasts. We found that estimation of Oc.S/BS by the new AI-assisted method was considerably less time-consuming, while still providing similar results to the conventional manual method. In addition, the retrainable AI-module used in the present study allows for fully automated overnight batch processing of multiple annotated sections.â€¢Bone histomorphometryâ€¢AI-assisted osteoclast identificationâ€¢TRAP and cathepsin K.",0,0
4632,"Classification Framework for Healthy Hairs and Alopecia Areata: A Machine Learning (ML) Approach. Alopecia areata is defined as an autoimmune disorder that results in hair loss. The latest worldwide statistics have exhibited that alopecia areata has a prevalence of 1 in 1000 and has an incidence of 2%. Machine learning techniques have demonstrated potential in different areas of dermatology and may play a significant role in classifying alopecia areata for better prediction and diagnosis. We propose a framework pertaining to the classification of healthy hairs and alopecia areata. We used 200 images of healthy hairs from the Figaro1k dataset and 68 hair images of alopecia areata from the Dermnet dataset to undergo image preprocessing including enhancement and segmentation. This was followed by feature extraction including texture, shape, and color. Two classification techniques, i.e., support vector machine (SVM) and <i>k</i>-nearest neighbor (KNN), are then applied to train a machine learning model with 70% of the images. The remaining image set was used for the testing phase. With a 10-fold cross-validation, the reported accuracies of SVM and KNN are 91.4% and 88.9%, respectively. Paired sample <i>T</i>-test showed significant differences between the two accuracies with a <i>p</i> < 0.001. SVM generated higher accuracy (91.4%) as compared to KNN (88.9%). The findings of our study demonstrate potential for better prediction in the field of dermatology.",0,0
4638,"Machine learning model to predict hypotension after starting continuous renal replacement therapy. Hypotension after starting continuous renal replacement therapy (CRRT) is associated with worse outcomes compared with normotension, but it is difficult to predict because several factors have interactive and complex effects on the risk. The present study applied machine learning algorithms to develop models to predict hypotension after initiating CRRT. Among 2349 adult patients who started CRRT due to acute kidney injury, 70% and 30% were randomly assigned into the training and testing sets, respectively. Hypotension was defined as a reduction in mean arterial pressure (MAP)â€‰â‰¥â€‰20Â mmHg from the initial value within 6Â h. The area under the receiver operating characteristic curves (AUROCs) in machine learning models, such as support vector machine (SVM), deep neural network (DNN), light gradient boosting machine (LGBM), and extreme gradient boosting machine (XGB) were compared with those in disease-severity scores such as the Sequential Organ Failure Assessment and Acute Physiology and Chronic Health Evaluation II. The XGB model showed the highest AUROC (0.828 [0.796-0.861]), and the DNN and LGBM models followed with AUROCs of 0.822 (0.789-0.856) and 0.813 (0.780-0.847), respectively; all machine learning AUROC values were higher than those obtained from disease-severity scores (AUROCsâ€‰<â€‰0.6). Although other definitions of hypotension were used such as a reduction of MAPâ€‰â‰¥â€‰30Â mmHg or a reduction occurring within 1Â h, the AUROCs of machine learning models were higher than those of disease-severity scores. Machine learning models successfully predict hypotension after starting CRRT and can serve as the basis of systems to predict hypotension before starting CRRT.",0,1
4639,"Respiratory sound classification for crackles, wheezes, and rhonchi in the clinical field using deep learning. Auscultation has been essential part of the physical examination; this is non-invasive, real-time, and very informative. Detection of abnormal respiratory sounds with a stethoscope is important in diagnosing respiratory diseases and providing first aid. However, accurate interpretation of respiratory sounds requires clinician's considerable expertise, so trainees such as interns and residents sometimes misidentify respiratory sounds. To overcome such limitations, we tried to develop an automated classification of breath sounds. We utilized deep learning convolutional neural network (CNN) to categorize 1918 respiratory sounds (normal, crackles, wheezes, rhonchi) recorded in the clinical setting. We developed the predictive model for respiratory sound classification combining pretrained image feature extractor of series, respiratory sound, and CNN classifier. It detected abnormal sounds with an accuracy of 86.5% and the area under the ROC curve (AUC) of 0.93. It further classified abnormal lung sounds into crackles, wheezes, or rhonchi with an overall accuracy of 85.7% and a mean AUC of 0.92. On the other hand, as a result of respiratory sound classification by different groups showed varying degree in terms of accuracy; the overall accuracies were 60.3% for medical students, 53.4% for interns, 68.8% for residents, and 80.1% for fellows. Our deep learning-based classification would be able to complement the inaccuracies of clinicians' auscultation, and it may aid in the rapid diagnosis and appropriate treatment of respiratory diseases.",0,0
4642,"Early prognosis of respiratory virus shedding in humans. This paper addresses the development of predictive models for distinguishing pre-symptomatic infections from uninfected individuals. Our machine learning experiments are conducted on publicly available challenge studies that collected whole-blood transcriptomics data from individuals infected with HRV, RSV, H1N1, and H3N2. We address the problem of identifying discriminatory biomarkers between controls and eventual shedders in the first 32 h post-infection. Our exploratory analysis shows that the most discriminatory biomarkers exhibit a strong dependence on time over the course of the human response to infection. We visualize the feature sets to provide evidence of the rapid evolution of the gene expression profiles. To quantify this observation, we partition the data in the first 32 h into four equal time windows of 8 h each and identify all discriminatory biomarkers using sparsity-promoting classifiers and Iterated Feature Removal. We then perform a comparative machine learning classification analysis using linear support vector machines, artificial neural networks and Centroid-Encoder. We present a range of experiments on different groupings of the diseases to demonstrate the robustness of the resulting models.",0,0
4645,"Deep neural network-estimated electrocardiographic age as a mortality predictor. The electrocardiogram (ECG) is the most commonly used exam for the evaluation of cardiovascular diseases. Here we propose that the age predicted by artificial intelligence (AI) from the raw ECG (ECG-age) can be a measure of cardiovascular health. A deep neural network is trained to predict a patient's age from the 12-lead ECG in the CODE study cohort (nâ€‰=â€‰1,558,415 patients). On a 15% hold-out split, patients with ECG-age more than 8 years greater than the chronological age have a higher mortality rate (hazard ratio (HR) 1.79, pâ€‰<â€‰0.001), whereas those with ECG-age more than 8 years smaller, have a lower mortality rate (HR 0.78, pâ€‰<â€‰0.001). Similar results are obtained in the external cohorts ELSA-Brasil (nâ€‰=â€‰14,236) and SaMi-Trop (nâ€‰=â€‰1,631). Moreover, even for apparent normal ECGs, the predicted ECG-age gap from the chronological age remains a statistically significant risk predictor. These results show that the AI-enabled analysis of the ECG can add prognostic information.",0,0
4646,Lens Opacities Classification System III-based artificial intelligence program for automatic cataract grading. To establish and validate an artificial intelligence (AI)-assisted automatic cataract grading program based on the Lens Opacities Classification System III (LOCSIII).,0,0
4647,"Emergency medicine patient wait time multivariable prediction models: a multicentre derivation and validation study. Patients, families and community members would like emergency department wait time visibility. This would improve patient journeys through emergency medicine. The study objective was to derive, internally and externally validate machine learning models to predict emergency patient wait times that are applicable to a wide variety of emergency departments.",0,0
4648,"Robust biomarker discovery for hepatocellular carcinoma from high-throughput data by multiple feature selection methods. Hepatocellular carcinoma (HCC) is one of the most common cancers. The discovery of specific genes severing as biomarkers is of paramount significance for cancer diagnosis and prognosis. The high-throughput omics data generated by the cancer genome atlas (TCGA) consortium provides a valuable resource for the discovery of HCC biomarker genes. Numerous methods have been proposed to select cancer biomarkers. However, these methods have not investigated the robustness of identification with different feature selection techniques.",0,0
4652,"Decoding attempted phantom hand movements from ipsilateral sensorimotor areas after amputation. <i>Objective.</i>The sensorimotor cortex is often selected as target in the development of a Brain-Computer Interface, as activation patterns from this region can be robustly decoded to discriminate between different movements the user executes. Up until recently, such BCIs were primarily based on activity in the contralateral hemisphere, where decoding movements still works even years after denervation. However, there is increasing evidence for a role of the sensorimotor cortex in controlling the ipsilateral body. The aim of this study is to investigate the effects of denervation on the movement representation on the ipsilateral sensorimotor cortex.<i>Approach.</i>Eight subjects with acquired above-elbow arm amputation and nine controls performed a task in which they made (or attempted to make with their phantom hand) six different gestures from the American Manual Alphabet. Brain activity was measured using 7T functional MRI, and a classifier was trained to discriminate between activation patterns on four different regions of interest (ROIs) on the ipsilateral sensorimotor cortex.<i>Main results.</i>Classification scores showed that decoding was possible and significantly better than chance level for both the phantom and intact hands from all ROIs. Decoding both the left (intact) and right (phantom) hand from the same hemisphere was also possible with above-chance level classification score.<i>Significance.</i>The possibility to decode both hands from the same hemisphere, even years after denervation, indicates that implantation of motor-electrodes for BCI control possibly need only cover a single hemisphere, making surgery less invasive, and increasing options for people with lateralized damage to motor cortex like after stroke.",0,0
4653,"Machine Learning for personalised stress detection: Inter-individual variability of EEG-ECG markers for acute-stress response. Stress appears as a response for a broad variety of physiological stimuli. It does vary among individuals in amplitude, phase and frequency. Thus, the necessity for personalised diagnosis is key to prevent stress-related diseases. In order to evaluate stress levels, a multi-sensing system is proposed based on non-invasive EEG and ECG signals. A target population of 24 individuals which age range between 18-23 years old are intentionally exposed to control-induced stress tests while EEG and ECG are simultaneously recorded. The acquired signals are processed by using semisupevised Machine Learning techniques as those provide a patient-specific approach due to key characteristics such as adaptiveness and robustness. In here, a stress metric is proposed that jointly with each individual medical history provide mechanisms to prevent and avoid possible chronic-health issues for individuals whom are more sensitive to stressors. Finally, supervised learning techniques are used to classify the obtained featured clusters to evaluate specific and general subject models in order to pave the way for real time stress monitoring.",0,0
4655,"Autistic spectrum traits detection and early screening: A machine learning based eye movement study. Autism spectrum disorders (ASD) are pervasive neurodevelopmental disorders and generally accompanied by social disorders, verbal or nonverbal communication defects, inability to concentrate and other negative symptoms that affect the autistic person's normal life. However, traditional screening methods are time-consuming and public health resources are limited.",0,0
4658,A multi-task deep-learning system for assessment of diabetic macular ischemia on optical coherence tomography angiography images. We aimed to develop and test a deep-learning (DL) system to perform image quality and diabetic macular ischemia (DMI) assessment on OCTA images.,0,0
4671,The Added Value of Computer-Aided Diagnosis System in Differential Diagnosis of Breast Lesions by Radiologists With Different Experience. To evaluate the value of computer-aided diagnosis system S-Detect (based on deep learning algorithm) in distinguishing benign and malignant breast masses and reducing unnecessary biopsy based on the experience of radiologists.,1,1
4677,"Versatile anomaly detection method for medical images with semi-supervised flow-based generative models. Radiologists interpret many medical images and clinical practice demands timely interpretation, resulting in a heavy workload. To reduce the workload, here we formulate and validate a method that can handle different types of medical image and can detect virtually all types of lesion in a medical image. For the first time, we show that two flow-based deep generative (FDG) models can predict the logarithm posterior probability in a semi-supervised approach.",0,0
4679,"A deep learning-machine learning fusion approach for the classification of benign, malignant, and intermediate bone tumors. To build and validate deep learning and machine learning fusion models to classify benign, malignant, and intermediate bone tumors based on patient clinical characteristics and conventional radiographs of the lesion.",0,0
4689,"Diagnostic performance of endoscopic ultrasound-artificial intelligence using deep learning analysis of gallbladder polypoid lesions. Endoscopic ultrasound (EUS) is the most accurate diagnostic modality for polypoid lesions of the gallbladder (GB), but is limited by subjective interpretation. Deep learning-based artificial intelligence (AI) algorithms are under development. We evaluated the diagnostic performance of AI in differentiating polypoid lesions using EUS images.",0,0
4693,"Deep Learning-Based Algorithm for the Detection and Characterization of MRI Safety of Cardiac Implantable Electronic Devices on Chest Radiographs. With the recent development of various MRI-conditional cardiac implantable electronic devices (CIEDs), the accurate identification and characterization of CIEDs have become critical when performing MRI in patients with CIEDs. We aimed to develop and evaluate a deep learning-based algorithm (DLA) that performs the detection and characterization of parameters, including MRI safety, of CIEDs on chest radiograph (CR) in a single step and compare its performance with other related algorithms that were recently developed.",0,0
4694,Deep Learning Algorithm for Simultaneous Noise Reduction and Edge Sharpening in Low-Dose CT Images: A Pilot Study Using Lumbar Spine CT. The purpose of this study was to assess whether a deep learning (DL) algorithm could enable simultaneous noise reduction and edge sharpening in low-dose lumbar spine CT.,0,0
4700,"Artificial image objects for classification of schizophrenia with GWAS-selected SNVs and convolutional neural network. In this article, we propose a new approach to analyze large genomics data. We considered individual genetic variants as pixels in an image and transformed a collection of variants into an artificial image object (AIO), which could be classified as a regular image by CNN algorithms. Using schizophrenia as a case study, we demonstrate the principles and their applications with 3 datasets. With 4,096 SNVs, the CNN models achieved an accuracy of 0.678Â Â± 0.007 and an AUC of 0.738Â Â± 0.008 for the diagnosis phenotype. With 44,100 SNVs, the models achieved class-specific accuracies of 0.806Â Â± 0.032 and 0.820Â Â± 0.049, and AUCs of 0.930Â Â± 0.017 and 0.867Â Â± 0.040 for the bottom and top classes stratified by the patient's polygenic risk scores. These results suggest that, once transformed to images, large genomics data can be analyzed effectively with image classification algorithms.",0,0
4710,Development of a machine learning model to predict the risk of late cardiogenic shock in patients with ST-segment elevation myocardial infarction. The in-hospital mortality of patients with ST-segment elevation myocardial infarction (STEMI) increases to more than 50% following a cardiogenic shock (CS) event. This study highlights the need to consider the risk of delayed calculation in developing in-hospital CS risk models. This report compared the performances of multiple machine learning models and established a late-CS risk nomogram for STEMI patients.,0,0
4711,"Value of artificial intelligence model based on unenhanced computed tomography of urinary tract for preoperative prediction of calcium oxalate monohydrate stones <i>in vivo</i>. Urolithiasis is a global disease with a high incidence and recurrence rate, and stone composition is closely related to the choice of treatment and preventive measures. Calcium oxalate monohydrate (COM) is the most common in clinical practice, which is hard and difficult to fragment. Preoperative identification of its components and selection of effective surgical methods can reduce the risk of patients having a second operation. Methods that can be used for stone composition analysis include infrared spectroscopy, X-ray diffraction, and polarized light microscopy, but they are all performed on stone specimens <i>in vitro</i> after surgery. This study aimed to design and develop an artificial intelligence (AI) model based on unenhanced computed tomography (CT) images of the urinary tract, and to investigate the predictive ability of the model for COM stones <i>in vivo</i> preoperatively, so as to provide surgeons with more accurate diagnostic information.",0,0
4719,"Predicting the risk of rupture for vertebral aneurysm based on geometric features of blood vessels. A significant proportion of the adult population worldwide suffers from cerebral aneurysms. If left untreated, aneurysms may rupture and lead to fatal massive internal bleeding. On the other hand, treatment of aneurysms also involve significant risks. It is desirable, therefore, to have an objective tool that can be used to predict the risk of rupture and assist in surgical decision for operating on the aneurysms. Currently, such decisions are made mostly based on medical expertise of the healthcare team. In this paper, we investigate the possibility of using machine learning algorithms to predict rupture risk of vertebral artery fusiform aneurysms based on geometric features of the blood vessels surrounding but excluding the aneurysm. For each of the aneurysm images (12 ruptured and 25 unruptured), the vessel is segmented into distal and proximal parts by cross-sectional area and 382 non-aneurysm-related geometric features extracted. The decision tree model using two of the features (standard deviation of eccentricity of proximal vessel, and diameter at the distal endpoint) achieved 83.8% classification accuracy. Additionally, with support vector machine and logistic regression, we also achieved 83.8% accuracy with another set of two features (ratio of mean curvature between distal and proximal parts, and diameter at the distal endpoint). Combining the aforementioned three features with integration of curvature of proximal vessel and also ratio of mean cross-sectional area between distal and proximal parts, these models achieve an impressive 94.6% accuracy. These results strongly suggest the usefulness of geometric features in predicting the risk of rupture.",0,0
4720,"<i>Meta</i>Cancer: A deep learning-based pan-cancer metastasis prediction model developed using multi-omics data. Predicting metastasis in the early stages means that clinicians have more time to adjust a treatment regimen to target the primary and metastasized cancer. In this regard, several computational approaches are being developed to identify metastasis early. However, most of the approaches focus on changes on one genomic level only, and they are not being developed from a pan-cancer perspective. Thus, we here present a deep learning (DL)-based model, <i>Meta</i>Cancer, that differentiates pan-cancer metastasis status based on three heterogeneous data layers. In particular, we built the DL-based model using 400 patients' data that includes RNA sequencing (RNA-Seq), microRNA sequencing (microRNA-Seq), and DNA methylation data from The Cancer Genome Atlas (TCGA). We quantitatively assess the proposed convolutional variational autoencoder (CVAE) and alternative feature extraction methods. We further show that integrating mRNA, microRNA, and DNA methylation data as features improves our model's performance compared to when we used mRNA data only. In addition, we show that the mRNA-related features make a more significant contribution when attempting to distinguish the primary tumors from metastatic ones computationally. Lastly, we show that our DL model significantly outperformed a machine learning (ML) ensemble method based on various metrics.",0,0
4722,"Non-invasive multi-channel deep learning convolutional neural networks for localization and classification of common hepatic lesions. Machine learning techniques, especially convolutional neural networks (CNN), have revolutionized the spectrum of computer vision tasks with a primary focus on supervised and labelled image datasets. We aimed to assess a novel method to segment the liver from the abdomen computed tomography (CT) image using the CNN network, and to train a unique method to locate and classify liver lesion pre-histological findings using multi-channel deep learning CNN (MDL-CNN).",0,0
4727,"Development of a lupus nephritis suboptimal response prediction tool using renal histopathological and clinical laboratory variables at the time of diagnosis. Lupus nephritis (LN) is an immune complex-mediated glomerular and tubulointerstitial disease in patients with SLE. Prediction of outcomes at the onset of LN diagnosis can guide decisions regarding intensity of monitoring and therapy for treatment success. Currently, no machine learning model of outcomes exists. Several outcomes modelling works have used univariate or linear modelling but were limited by the disease heterogeneity. We hypothesised that a combination of renal pathology results and routine clinical laboratory data could be used to develop and to cross-validate a clinically meaningful machine learning early decision support tool that predicts LN outcomes at approximately 1 year.",0,0
4730,"SMDI: An Index for Measuring Subgingival Microbial Dysbiosis. An intuitive, clinically relevant index of microbial dysbiosis as a summary statistic of subgingival microbiome profiles is needed. Here, we describe a subgingival microbial dysbiosis index (SMDI) based on machine learning analysis of published periodontitis/health 16S microbiome data. The raw sequencing data, split into training and test sets, were quality filtered, taxonomically assigned to the species level, and centered log-ratio transformed. The training data set was subject to random forest analysis to identify discriminating species (DS) between periodontitis and health. DS lists, compiled by various ""Gini"" importance score cutoffs, were used to compute the SMDI for samples in the training and test data sets as the mean centered log-ratio abundance of periodontitis-associated species subtracted by that of health-associated ones. Diagnostic accuracy was assessed with receiver operating characteristic analysis. An SMDI based on 49 DS provided the highest accuracy with areas under the curve of 0.96 and 0.92 in the training and test data sets, respectively, and ranged from -6 (most normobiotic) to 5 (most dysbiotic) with a value around zero discriminating most of the periodontitis and healthy samples. The top periodontitis-associated DS were <i>Treponema denticola, Mogibacterium timidum, Fretibacterium</i> spp., and <i>Tannerella forsythia</i>, while <i>Actinomyces naeslundii</i> and <i>Streptococcus sanguinis</i> were the top health-associated DS. The index was highly reproducible by hypervariable region. Applying the index to additional test data sets in which nitrate had been used to modulate the microbiome demonstrated that nitrate has dysbiosis-lowering properties in vitro and in vivo. Finally, 3 genera (<i>Treponema, Fretibacterium</i>, and <i>Actinomyces</i>) were identified that could be used for calculation of a simplified SMDI with comparable accuracy. In conclusion, we have developed a nonbiased, reproducible, and easy-to-interpret index that can be used to identify patients/sites at risk of periodontitis, to assess the microbial response to treatment, and, importantly, as a quantitative tool in microbiome modulation studies.",0,0
4734,Are there different gait profiles in patients with advanced knee osteoarthritis? A machine learning approach. Determine whether knee kinematics features analyzed using machine-learning algorithms can identify different gait profiles in knee OA patients.,0,0
4738,"Early prediction of central line associated bloodstream infection using machine learning. Central line-associated bloodstream infections (CLABSIs) are associated with significant morbidity, mortality, and increased healthcare costs. Despite the high prevalence of CLABSIs in the U.S., there are currently no tools to stratify a patient's risk of developing an infection as the result of central line placement. To this end, we have developed and validated a machine learning algorithm (MLA) that can predict a patient's likelihood of developing CLABSI using only electronic health record data in order to provide clinical decision support.",0,0
4741,"Multi-parameter-based radiological diagnosis of Chiari Malformation using Machine Learning Technology. The known primary radiological diagnosis of Chiari Malformation-I (CM-I) is based on the degree of tonsillar herniation (TH) below the Foramen Magnum (FM). However, recent data also shows the association of such malformation with smaller posterior cranial fossa (PCF) volume and the anatomical issues regarding the Odontoid. This study presents the achieved result regarding some detected potential radiological findings that may aid CM-I diagnosis using several machine learning (ML) algorithms.",0,0
4746,"Real-Time Activity Recognition With Instantaneous Characteristic Features of Thigh Kinematics. Current supervised learning or deep learning-based activity recognition classifiers can achieve high accuracy in recognizing locomotion activities. Most available techniques use a high-dimensional space of features, e.g., combinations of EMG, kinematics and kinetics, and transformations over those signals. The associated classification rules are therefore complex; the machine tries to understand the human, but the human does not understand the machine. This paper presents an activity recognition system that uses signals from a thigh-mounted IMU and a force sensitive resistor to classify transitions between sitting, walking, stair ascending, and stair descending. The system uses the thigh's orientation and velocity with foot contact information at specific moments within a given activity as the features to classify transitions to other activities. We call these Instantaneous Characteristic Features (ICFs). Because these ICFs are biomechanically intuitive, they are easy for the user to understand and thus control the activity transitions of wearable robots. We assessed our classification algorithm offline using an existing dataset with 10 able-bodied subjects and online with another 10 able-bodied subjects wearing a real-time system. The offline study analyzed the effect of subject-dependency and ramp inclinations. The real-time classification accuracy was evaluated before and after training the subjects on the ICFs. The real-time system achieved overall pre-subject-training and post-subject-training error rates of 0.59% Â± 0.24% and 0.56% Â± 0.20%, respectively. We also evaluated the feasibility of our ICFs for amputee ambulation by analyzing a public dataset with the open-source bionic leg. The simplicity of these classification rules demonstrates a new paradigm for activity recognition where the human can understand the machine and vice-versa.",0,0
4747,"A Dual-Modal Approach Using Electromyography and Sonomyography Improves Prediction of Dynamic Ankle Movement: A Case Study. For decades, surface electromyography (sEMG) has been a popular non-invasive bio-sensing technology for predicting human joint motion. However, cross-talk, interference from adjacent muscles, and its inability to measure deeply located muscles limit its performance in predicting joint motion. Recently, ultrasound (US) imaging has been proposed as an alternative non-invasive technology to predict joint movement due to its high signal-to-noise ratio, direct visualization of targeted tissue, and ability to access deep-seated muscles. This paper proposes a dual-modal approach that combines US imaging and sEMG for predicting volitional dynamic ankle dorsiflexion movement. Three feature sets: 1) a uni-modal set with four sEMG features, 2) a uni-modal set with four US imaging features, and 3) a dual-modal set with four dominant sEMG and US imaging features, together with measured ankle dorsiflexion angles, were used to train multiple machine learning regression models. The experimental results from a seated posture and five walking trials at different speeds, ranging from 0.50 m/s to 1.50 m/s, showed that the dual-modal set significantly reduced the prediction root mean square errors (RMSEs). Compared to the uni-modal sEMG feature set, the dual-modal set reduced RMSEs by up to 47.84% for the seated posture and up to 77.72% for the walking trials. Similarly, when compared to the US imaging feature set, the dual-modal set reduced RMSEs by up to 53.95% for the seated posture and up to 58.39% for the walking trials. The findings show that potentially the dual-modal sensing approach can be used as a superior sensing modality to predict human intent of a continuous motion and implemented for volitional control of clinical rehabilitative and assistive devices.",0,0
4751,"Characterizing Swallows From People With Neurodegenerative Diseases Using High-Resolution Cervical Auscultation Signals and Temporal and Spatial Swallow Kinematic Measurements. Purpose The prevalence of dysphagia in patients with neurodegenerative diseases (ND) is alarmingly high and frequently results in morbidity and accelerated mortality due to subsequent adverse events (e.g., aspiration pneumonia). Swallowing in patients with ND should be continuously monitored due to the progressive disease nature. Access to instrumental swallow evaluations can be challenging, and limited studies have quantified changes in temporal/spatial swallow kinematic measures in patients with ND. High-resolution cervical auscultation (HRCA), a dysphagia screening method, has accurately differentiated between safe and unsafe swallows, identified swallow kinematic events (e.g., laryngeal vestibule closure [LVC]), and classified swallows between healthy adults and patients with ND. This study aimed to (a) compare temporal/spatial swallow kinematic measures between patients with ND and healthy adults and (b) investigate HRCA's ability to annotate swallow kinematic events in patients with ND. We hypothesized there would be significant differences in temporal/spatial swallow measurements between groups and that HRCA would accurately annotate swallow kinematic events in patients with ND. Method Participants underwent videofluoroscopic swallowing studies with concurrent HRCA. We used linear mixed models to compare temporal/spatial swallow measurements (<i>n</i> = 170 ND patient swallows, <i>n</i> = 171 healthy adult swallows) and deep learning machine-learning algorithms to annotate specific temporal and spatial kinematic events in swallows from patients with ND. Results Differences (<i>p</i> < .05) were found between groups for several temporal and spatial swallow kinematic measures. HRCA signal features were used as input to machine-learning algorithms and annotated upper esophageal sphincter (UES) opening, UES closure, LVC, laryngeal vestibule reopening, and hyoid bone displacement with 66.25%, 85%, 68.18%, 70.45%, and 44.6% accuracy, respectively, compared to human judges' measurements. Conclusion This study demonstrates HRCA's potential in characterizing swallow function in patients with ND and other patient populations.",0,0
4758,Prediction of the occurrence of calcium oxalate kidney stones based on clinical and gut microbiota characteristics. To predict the occurrence of calcium oxalate kidney stones based on clinical and gut microbiota characteristics.,0,0
4759,Automatic Localization of the Scleral Spur Using Deep Learning and Ultrasound Biomicroscopy. The purpose of this study was to develop a convolutional neural network (CNN) for automated localization of the scleral spur in ultrasound biomicroscopy (UBM) images of open-angle eyes.,0,0
4761,"Machine learning powered tools for automated analysis of muscle sympathetic nerve activity recordings. Automated analysis and quantification of physiological signals in clinical practice and medical research can reduce manual labor, increase efficiency, and provide more objective, reproducible results. To build a novel platform for the analysis of muscle sympathetic nerve activity (MSNA), we employed state-of-the-art data processing and machine learning applications. Data processing methods for integrated MSNA recordings were developed to evaluate signals regarding the overall quality of the signal, the validity of individual signal peaks regarding the potential to be MSNA bursts and the timing of their occurrence. An overall probability score was derived from this flexible platform to evaluate each individual signal peak automatically. Overall, three deep neural networks were designed and trained to validate individual signal peaks randomly sampled from recordings representing only electrical noise and valid microneurography recordings. A novel data processing method for the whole signal was developed to differentiate between periods of valid MSNA signal recordings and periods in which the signal was not available or lost due to involuntary movement of the recording electrode. A probabilistic model for timing of the signal bursts was implemented as part of the system. Machine Learning algorithms and data processing tools were implemented to replicate the complex decision-making process of manual MSNA analysis. Validation of manual MSNA analysis including intra- and inter-rater validity and a comparison with automated MSNA tools is required. The developed toolbox for automated MSNA analysis can be extended in a flexible way to include algorithms based on other datasets.",0,0
4764,Risk Stratification of Early-Stage Cervical Cancer with Intermediate-Risk Factors: Model Development and Validation Based on Machine Learning Algorithm. Adjuvant therapy for patients with cervical cancer (CC) with intermediate-risk factors remains controversial. The objectives of the present study are to assess the prognoses of patients with early-stage CC with pathological intermediate-risk factors and to provide a reference for adjuvant therapy choice.,0,0
4766,"Development and Qualification of a Machine Learning Algorithm for Automated Hair Counting. Determining the amount of hair on the scalp has always been an important metric of patient satisfaction for hair growth and hair retention technologies. While simple in concept, this measurement is a difficult, resource intensive task for the dermatologist and the research scientist. Specifically, counting and measuring hair in phototrichogram images is very time consuming and labor intensive. Due to cost, often only a fraction of available images is manually analyzed. There is a need for an automated method that can significantly increase speed and throughput while reducing the cost of counting and measuring hair in phototrichogram images.",0,0
4772,"Automatic Diagnosis of Alzheimer's Disease and Mild Cognitive Impairment Based on CNNâ€‰+â€‰SVM Networks with End-to-End Training. Alzheimer's disease (AD) is an irreversible neurodegenerative disease, and, at present, once it has been diagnosed, there is no effective curative treatment. Accurate and early diagnosis of Alzheimer's disease is crucial for improving the condition of patients since effective preventive measures can be taken in advance to delay the onset time of the disease. <sup>18</sup>F-Fluorodeoxyglucose positron emission tomography (<sup>18</sup>F-FDG PETâ€‰:â€‰PET) is an effective biomarker of the symptom of AD and has been used as medical imaging data for diagnosing AD. Mild cognitive impairment (MCI) is regarded as an early symptom of AD, and it has been shown that MCI also has a certain biomedical correlation with PET. In this paper, we explore how to use 3D PET images to realize the effective recognition of MCI and thus achieve the early prediction of AD. This problem is then taken as the classification of three categories of PET images, including MCI, AD, and NC (normal controls). In order to get better classification performance, a novel network model is proposed in the paper based on 3D convolution neural networks (CNN) and support vector machines (SVM) by utilizing both the excellent abilities of CNN in feature extraction and SVM in classification. In order to make full use of the optimal property of SVM in solving binary classification problems, the three-category classification problem is divided into three binary classifications, and each binary classification is being realized with a CNNâ€‰+â€‰SVM network. Then, the outputs of the three CNNâ€‰+â€‰SVM networks are fused into a final three-category classification result. An end-to-end learning algorithm is developed to train the CNNâ€‰+â€‰SVM networks, and a decision fusion algorithm is exploited to realize the fusion of the outputs of three CNNâ€‰+â€‰SVM networks. Experimental results obtained in the work with comparative analyses confirm the effectiveness of the proposed method.",0,0
4773,"The Contribution of White Matter Diffusion and Cortical Perfusion Pathology to Vascular Cognitive Impairment: A Multimode Imaging-Based Machine Learning Study. Widespread impairments in white matter and cerebrovascular integrity have been consistently implicated in the pathophysiology of patients with small vessel disease (SVD). However, the neural circuit mechanisms that underlie the developing progress of clinical cognitive symptoms remain largely elusive. Here, we conducted cross-modal MRI scanning including diffusion tensor imaging and arterial spin labeling in a cohort of 113 patients with SVD, which included 74 patients with vascular mild cognitive impairment (vMCI) and 39 patients without vMCI symptoms, and hence developed multimode imaging-based machine learning models to identify markers that discriminated SVD subtypes. Diffusion and perfusion features, respectively, extracted from individual white matter and gray matter regions were used to train three sets of classifiers in a nested 10-fold fashion: diffusion-based, perfusion-based, and combined diffusion-perfusion-based classifiers. We found that the diffusion-perfusion combined classifier achieved the highest accuracy of 72.57% with leave-one-out cross-validation, with the diffusion features largely spanning the capsular lateral pathway of the cholinergic tracts, and the perfusion features mainly distributed in the frontal-subcortical-limbic areas. Furthermore, diffusion-based features within vMCI group were associated with performance on executive function tests. We demonstrated the superior accuracy of using diffusion-perfusion combined multimode imaging features for classifying vMCI subtype out of a cohort of patients with SVD. Disruption of white matter integrity might play a critical role in the progression of cognitive impairment in patients with SVD, while malregulation of coritcal perfusion needs further study.",0,0
4776,"Low-count whole-body PET with deep learning in a multicenter and externally validated study. More widespread use of positron emission tomography (PET) imaging is limited by its high cost and radiation dose. Reductions in PET scan time or radiotracer dosage typically degrade diagnostic image quality (DIQ). Deep-learning-based reconstruction may improve DIQ, but such methods have not been clinically evaluated in a realistic multicenter, multivendor environment. In this study, we evaluated the performance and generalizability of a deep-learning-based image-quality enhancement algorithm applied to fourfold reduced-count whole-body PET in a realistic clinical oncologic imaging environment with multiple blinded readers, institutions, and scanner types. We demonstrate that the low-count-enhanced scans were noninferior to the standard scans in DIQ (pâ€‰<â€‰0.05) and overall diagnostic confidence (pâ€‰<â€‰0.001) independent of the underlying PET scanner used. Lesion detection for the low-count-enhanced scans had a high patient-level sensitivity of 0.94 (0.83-0.99) and specificity of 0.98 (0.95-0.99). Interscan kappa agreement of 0.85 was comparable to intrareader (0.88) and pairwise inter-reader agreements (maximum of 0.72). SUV quantification was comparable in the reference regions and lesions (lowest p-value=0.59) and had high correlation (lowest CCCâ€‰=â€‰0.94). Thus, we demonstrated that deep learning can be used to restore diagnostic image quality and maintain SUV accuracy for fourfold reduced-count PET scans, with interscan variations in lesion depiction, lower than intra- and interreader variations. This method generalized to an external validation set of clinical patients from multiple institutions and scanner types. Overall, this method may enable either dose or exam-duration reduction, increasing safety and lowering the cost of PET imaging.",1,1
4777,"A novel CT scoring method predicts the prognosis of interstitial lung disease associated with anti-MDA5 positive dermatomyositis. Anti-melanoma differentiation-associated gene 5-positive dermatomyositis-associated interstitial lung disease (MDA5<sup>+</sup> DM-ILD) is a life-threatening disease. This study aimed to develop a novel pulmonary CT visual scoring method for assessing the prognosis of the disease, and an artificial intelligence (AI) algorithm-based analysis and an idiopathic pulmonary fibrosis (IPF)-based scoring were conducted as comparators. A retrospective cohort of hospitalized patients with MDA5<sup>+</sup> DM-ILD was analyzed. Since most fatalities occur within the first half year of the disease course, the primary outcome was the six-month all-cause mortality since the time of admission. A ground glass opacity (GGO) and consolidation-weighted CT visual scoring model for MDA5<sup>+</sup> DM-ILD, namely 'MDA5 score', was then developed with C-index values of 0.80 (95%CI 0.75-0.86) in the derivation dataset (nâ€‰=â€‰116) and 0.84 (95%CI 0.71-0.97) in the validation dataset (nâ€‰=â€‰57), respectively. While, the AI algorithm-based analysis, namely 'AI score', yielded C-index 0.78 (95%CI 0.72-0.84) for the derivation dataset and 0.77 (95%CI 0.64-0.90) for the validation dataset. These findings suggest that the newly derived 'MDA5 score' may serve as an applicable prognostic predictor for MDA5<sup>+</sup> DM-ILD and facilitate further clinical trial design. The AI based CT quantitative analysis provided a promising solution for ILD evaluation.",0,0
4778,"Identification of markers that distinguish adipose tissue and glucose and insulin metabolism using a multi-modal machine learning approach. The study of metabolomics has improved our knowledge of the biology behind type 2 diabetes and its related metabolic physiology. We aimed to investigate markers of adipose tissue morphology, as well as insulin and glucose metabolism in 53 non-obese male individuals. The participants underwent extensive clinical, biochemical and magnetic resonance imaging phenotyping, and we also investigated non-targeted serum metabolites. We used a multi-modal machine learning approach to evaluate which serum metabolomic compounds predicted markers of glucose and insulin metabolism, adipose tissue morphology and distribution. Fasting glucose was associated with metabolites of intracellular insulin action and beta-cell dysfunction, namely cysteine-s-sulphate and n-acetylgarginine, whereas fasting insulin was predicted by myristoleoylcarnitine, propionylcarnitine and other metabolites of beta-oxidation of fatty acids. OGTT-glucose levels at 30Â min were predicted by 7-Hoca, a microbiota derived metabolite, as well as eugenol, a fatty acid. Both insulin clamp and HOMA-IR were predicted by metabolites involved in beta-oxidation of fatty acids and biodegradation of triacylglycerol, namely tartrate and 3-phosphoglycerate, as well as pyruvate, xanthine and liver fat. OGTT glucose area under curve (AUC) and OGTT insulin AUC, was associated with bile acid metabolites, subcutaneous adipocyte cell size, liver fat and fatty chain acids and derivates, such as isovalerylcarnitine. Finally, subcutaneous adipocyte size was associated with long chain fatty acids, markers of sphingolipid metabolism, increasing liver fat and dopamine-sulfate 1. Ectopic liver fat was predicted by methylmalonate, adipocyte cell size, glutathione derived metabolites and fatty chain acids. Ectopic heart fat was predicted visceral fat, gamma-glutamyl tyrosine and 2-acetamidophenol sulfate. Adipocyte cell size, age, alpha-tocopherol and blood pressure were associated with visceral fat. We identified several biomarkers associated with adipose tissue pathophysiology and insulin and glucose metabolism using a multi-modal machine learning approach. Our approach demonstrated the relative importance of serum metabolites and they outperformed traditional clinical and biochemical variables for most endpoints.",0,0
4779,"A real-world demonstration of machine learning generalizability in the detection of intracranial hemorrhage on head computerized tomography. Machine learning (ML) holds great promise in transforming healthcare. While published studies have shown the utility of ML models in interpreting medical imaging examinations, these are often evaluated under laboratory settings. The importance of real world evaluation is best illustrated by case studies that have documented successes and failures in the translation of these models into clinical environments. A key prerequisite for the clinical adoption of these technologies is demonstrating generalizable ML model performance under real world circumstances. The purpose of this study was to demonstrate that ML model generalizability is achievable in medical imaging with the detection of intracranial hemorrhage (ICH) on non-contrast computed tomography (CT) scans serving as the use case. An ML model was trained using 21,784 scans from the RSNA Intracranial Hemorrhage CT dataset while generalizability was evaluated using an external validation dataset obtained from our busy trauma and neurosurgical center. This real world external validation dataset consisted of every unenhanced head CT scan (nâ€‰=â€‰5965) performed in our emergency department in 2019 without exclusion. The model demonstrated an AUC of 98.4%, sensitivity of 98.8%, and specificity of 98.0%, on the test dataset. On external validation, the model demonstrated an AUC of 95.4%, sensitivity of 91.3%, and specificity of 94.1%. Evaluating the ML model using a real world external validation dataset that is temporally and geographically distinct from the training dataset indicates that ML generalizability is achievable in medical imaging applications.",0,0
4780,Baseline clinical characteristics of predicted structural and pain progressors in the IMI-APPROACH knee OA cohort. To describe the relations between baseline clinical characteristics of the Applied Public-Private Research enabling OsteoArthritis Clinical Headway (IMI-APPROACH) participants and their predicted probabilities for knee osteoarthritis (OA) structural (S) progression and/or pain (P) progression.,0,0
4781,"Development of a machine learning-based real-time location system to streamline acute endovascular intervention in acute stroke: a proof-of-concept study. Delivery of acute stroke endovascular intervention can be challenging because it requires complex coordination of patient and staff across many different locations. In this proof-of-concept paper we (a) examine whether WiFi fingerprinting is a feasible machine learning (ML)-based real-time location system (RTLS) technology that can provide accurate real-time location information within a hospital setting, and (b) hypothesize its potential application in streamlining acute stroke endovascular intervention.",0,0
4785,"Wide & Deep neural network model for patch aggregation in CNN-based prostate cancer detection systems. Prostate cancer (PCa) is one of the most commonly diagnosed cancer and one of the leading causes of death among men, with almost 1.41 million new cases and around 375,000 deaths in 2020. Artificial Intelligence algorithms have had a huge impact on medical image analysis, including digital histopathology, where Convolutional Neural Networks (CNNs) are used to provide a fast and accurate diagnosis, supporting experts in this task. To perform an automatic diagnosis, prostate tissue samples are first digitized into gigapixel-resolution whole-slide images. Due to the size of these images, neural networks cannot use them as input and, therefore, small subimages called patches are extracted and predicted, obtaining a patch-level classification. In this work, a novel patch aggregation method based on a custom Wide & Deep neural network model is presented, which performs a slide-level classification using the patch-level classes obtained from a CNN. The malignant tissue ratio, a 10-bin malignant probability histogram, the least squares regression line of the histogram, and the number of malignant connected components are used by the proposed model to perform the classification. An accuracy of 94.24% and a sensitivity of 98.87% were achieved, proving that the proposed system could aid pathologists by speeding up the screening process and, thus, contribute to the fight against PCa.",0,0
4788,"Evolutionary warning system for COVID-19 severity: Colony predation algorithm enhanced extreme learning machine. Coronavirus Disease 2019 (COVID-19) was distributed globally at the end of December 2019 due to severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). Early diagnosis and successful COVID-19 assessment are missing, clinical care is ineffective, and deaths are high. In this study, we investigate whether the level of biochemical indicators helps to discriminate and classify the severity of the COVID-19 using the machine learning method. This research creates an efficient intelligence method for the diagnosis of COVID-19 from the perspective of biochemical indexes. The framework is proposed by integrating an enhanced new stochastic called the colony predation algorithm (CPA) with a kernel extreme learning machine (KELM), abbreviated as ECPA-KELM. The core feature of the approach is the ECPA algorithm which incorporates the two main operators that have been abstained from the grey wolf optimizer and moth-flame optimizer to improve and restore the CPA research functions and are simultaneously used to optimize the parameters and to select features for KELM. The ECPA output is checked thoroughly using IEEE CEC2017 benchmark to verify the capacity of the proposed methodology. Finally, in the diagnosis of COVID-19 using biochemical indexes, the designed ECPA-KELM model and other competing KELM models based on other optimization are used. Checking statistical results will display improved predictive properties for all metrics and higher stability. ECPA-KELM can also be used to discriminate and classify the severity of the COVID-19 as a possible computer-aided method and provide effective early warning for the treatment and diagnosis of COVID-19.",0,0
4797,Application of deep learning to identify COVID-19 infection in posteroanterior chest X-rays. The objective of this study was to assess seven configurations of six convolutional deep neural network architectures for classification of chest X-rays (CXRs) as COVID-19 positive or negative.,0,0
4798,"Dosiomics-based prediction of radiation-induced hypothyroidism in nasopharyngeal carcinoma patients. To predict the incidence of radiation-induced hypothyroidism (RHT) in nasopharyngeal carcinoma (NPC) patients, dosiomics features based prediction models were established.",0,0
4800,"Deep learning for cranioplasty in clinical practice: Going from synthetic to real patient data. Correct virtual reconstruction of a defective skull is a prerequisite for successful cranioplasty and its automatization has the potential for accelerating and standardizing the clinical workflow. This work provides a deep learning-based method for the reconstruction of a skull shape and cranial implant design on clinical data of patients indicated for cranioplasty. The method is based on a cascade of multi-branch volumetric CNNs that enables simultaneous training on two different types of cranioplasty ground-truth data: the skull patch, which represents the exact shape of the missing part of the original skull, and which can be easily created artificially from healthy skulls, and expert-designed cranial implant shapes that are much harder to acquire. The proposed method reaches an average surface distance of the reconstructed skull patches of 0.67Â mm on a clinical test set of 75 defective skulls. It also achieves a 12% reduction of a newly proposed defect border Gaussian curvature error metric, compared to a baseline model trained on synthetic data only. Additionally, it produces directly 3D printable cranial implant shapes with a Dice coefficient 0.88 and a surface error of 0.65Â mm. The outputs of the proposed skull reconstruction method reach good quality and can be considered for use in semi- or fully automatic clinical cranial implant design workflows.",0,0
4801,"Automatic segmentation of corneal deposits from corneal stromal dystrophy images via deep learning. Granular dystrophy is the most common stromal dystrophy. To perform automated segmentation of corneal stromal deposits, we trained and tested a deep learning (DL) algorithm from patients with corneal stromal dystrophy and compared its performance with human segmentation.",1,1
4803,"AIFNet: Automatic vascular function estimation for perfusion analysis using deep learning. Perfusion imaging is crucial in acute ischemic stroke for quantifying the salvageable penumbra and irreversibly damaged core lesions. As such, it helps clinicians to decide on the optimal reperfusion treatment. In perfusion CT imaging, deconvolution methods are used to obtain clinically interpretable perfusion parameters that allow identifying brain tissue abnormalities. Deconvolution methods require the selection of two reference vascular functions as inputs to the model: the arterial input function (AIF) and the venous output function, with the AIF as the most critical model input. When manually performed, the vascular function selection is time demanding, suffers from poor reproducibility and is subject to the professionals' experience. This leads to potentially unreliable quantification of the penumbra and core lesions and, hence, might harm the treatment decision process. In this work we automatize the perfusion analysis with AIFNet, a fully automatic and end-to-end trainable deep learning approach for estimating the vascular functions. Unlike previous methods using clustering or segmentation techniques to select vascular voxels, AIFNet is directly optimized at the vascular function estimation, which allows to better recognise the time-curve profiles. Validation on the public ISLES18 stroke database shows that AIFNet almost reaches inter-rater performance for the vascular function estimation and, subsequently, for the parameter maps and core lesion quantification obtained through deconvolution. We conclude that AIFNet has potential for clinical transfer and could be incorporated in perfusion deconvolution software.",0,0
4804,"COVID-19 lung infection segmentation with a novel two-stage cross-domain transfer learning framework. With the global outbreak of COVID-19 in early 2020, rapid diagnosis of COVID-19 has become the urgent need to control the spread of the epidemic. In clinical settings, lung infection segmentation from computed tomography (CT) images can provide vital information for the quantification and diagnosis of COVID-19. However, accurate infection segmentation is a challenging task due to (i) the low boundary contrast between infections and the surroundings, (ii) large variations of infection regions, and, most importantly, (iii) the shortage of large-scale annotated data. To address these issues, we propose a novel two-stage cross-domain transfer learning framework for the accurate segmentation of COVID-19 lung infections from CT images. Our framework consists of two major technical innovations, including an effective infection segmentation deep learning model, called nCoVSegNet, and a novel two-stage transfer learning strategy. Specifically, our nCoVSegNetÂ conducts effective infection segmentation by taking advantage of attention-aware feature fusion and large receptive fields, aiming to resolve the issues related to low boundary contrast and large infection variations. To alleviate the shortage of the data, the nCoVSegNetÂ is pre-trained using a two-stage cross-domain transfer learning strategy, which makes full use of the knowledge from natural images (i.e., ImageNet) and medical images (i.e., LIDC-IDRI) to boost the final training on CT images with COVID-19 infections. Extensive experiments demonstrate that our framework achieves superior segmentation accuracy and outperforms the cutting-edge models, both quantitatively and qualitatively.",0,0
4813,"Automatic feature extraction and fusion recognition of motor imagery EEG using multilevel multiscale CNN. A motor imagery EEG (MI-EEG) signal is often selected as the driving signal in an active brain computer interface (BCI) system, and it has been a popular field to recognize MI-EEG images via convolutional neural network (CNN), which poses a potential problem for maintaining the integrity of the time-frequency-space information in MI-EEG images and exploring the feature fusion mechanism in the CNN. However, information is excessively compressed in the present MI-EEG image, and the sequential CNN is unfavorable for the comprehensive utilization of local features. In this paper, a multidimensional MI-EEG imaging method is proposed, which is based on time-frequency analysis and the Clough-Tocher (CT) interpolation algorithm. The time-frequency matrix of each electrode is generated via continuous wavelet transform (WT), and the relevant section of frequency is extracted and divided into nine submatrices, the longitudinal sums and lengths of which are calculated along the directions of frequency and time successively to produce a 3 Ã— 3 feature matrix for each electrode. Then, feature matrix of each electrode is interpolated to coincide with their corresponding coordinates, thereby yielding a WT-based multidimensional image, called WTMI. Meanwhile, a multilevel and multiscale feature fusion convolutional neural network (MLMSFFCNN) is designed for WTMI, which has dense information, low signal-to-noise ratio, and strong spatial distribution. Extensive experiments are conducted on the BCI Competition IV 2a and 2b datasets, and accuracies of 92.95% and 97.03% are yielded based on 10-fold cross-validation, respectively, which exceed those of the state-of-the-art imaging methods. The kappa values and p values demonstrate that our method has lower class skew and error costs. The experimental results demonstrate that WTMI can fully represent the time-frequency-space features of MI-EEG and that MLMSFFCNN is beneficial for improving the collection of multiscale features and the fusion recognition of general and abstract features for WTMI.",0,0
4815,"A new strategy for canine visceral leishmaniasis diagnosis based on FTIR spectroscopy and machine learning. Visceral leishmaniasis is a neglected disease caused by protozoan parasites of the genus Leishmania. The successful control of the disease depends on its accurate and early diagnosis, which is usually made by combining clinical symptoms with laboratory tests such as serological, parasitological, and molecular tests. However, early diagnosis based on serological tests may exhibit low accuracy due to lack of specificity caused by cross-reactivities with other pathogens, and sensitivity issues related, among other reasons, to disease stage, leading to misdiagnosis. In this study was investigated the use of mid-infrared spectroscopy and multivariate analysis to perform a fast, accurate, and easy canine visceral leishmaniasis diagnosis. Canine blood sera of 20 noninfected, 20 Leishmania infantum, and eight Trypanosoma evansi infected dogs were studied. The data demonstrate that principal component analysis with machine learning algorithms achieved an overall accuracy above 85% in the diagnosis.",0,0
4816,Contrast-Enhanced Ultrasound for Differentiation Between Poorly Differentiated Hepatocellular Carcinoma and Intrahepatic Cholangiocarcinoma. To evaluate the diagnostic performance of LR-5 for diagnosing poorly differentiated hepatocellular carcinoma (p-HCC). To build a contrast-enhanced ultrasound (CEUS) signature for improving the differential diagnostic performance between p-HCC and intrahepatic cholangiocarcinoma (ICC).,0,0
4828,"A fast, resource efficient, and reliable rule-based system for COVID-19 symptom identification. With COVID-19, there was a need for a rapidly scalable annotation system that facilitated real-time integration with clinical decision support systems (CDS). Current annotation systems suffer from a high-resource utilization and poor scalability limiting real-world integration with CDS. A potential solution to mitigate these issues is to use the rule-based gazetteer developed at our institution.",0,0
4829,"Detecting diabetic retinopathy through machine learning on electronic health record data from an urban, safety net healthcare system. Clinical guidelines recommend annual eye examinations to detect diabetic retinopathy (DR) in patients with diabetes. However, timely DR detection remains a problem in medically underserved and under-resourced settings in the United States. Machine learning that identifies patients with latent/undiagnosed DR could help to address this problem.",0,0
4832,"Lung nodule malignancy classification with weakly supervised explanation generation. <b>Purpose</b>: Explainable AI aims to build systems that not only give high performance but also are able to provide insights that drive the decision making. However, deriving this explanation is often dependent on fully annotated (class label and local annotation) data, which are not readily available in the medical domain. <b>Approach</b>: This paper addresses the above-mentioned aspects and presents an innovative approach to classifying a lung nodule in a CT volume as malignant or benign, and generating a morphologically meaningful explanation for the decision in the form of attributes such as nodule margin, sphericity, and spiculation. A deep learning architecture that is trained using a multi-phase training regime is proposed. The nodule class label (benign/malignant) is learned with full supervision and is guided by semantic attributes that are learned in a weakly supervised manner. <b>Results</b>: Results of an extensive evaluation of the proposed system on the LIDC-IDRI dataset show good performance compared with state-of-the-art, fully supervised methods. The proposed model is able to label nodules (after full supervision) with an accuracy of 89.1% and an area under curve of 0.91 and to provide eight attributes scores as an explanation, which is learned from a much smaller training set. The proposed system's potential to be integrated with a sub-optimal nodule detection system was also tested, and our system handled 95% of false positive or random regions in the input well by labeling them as benign, which underscores its robustness. <b>Conclusions</b>: The proposed approach offers a way to address computer-aided diagnosis system design under the constraint of sparse availability of fully annotated images.",0,0
4834,"A New Method for Syndrome Classification of Non-Small-Cell Lung Cancer Based on Data of Tongue and Pulse with Machine Learning. To explore the data characteristics of tongue and pulse of non-small-cell lung cancer with Qi deficiency syndrome and Yin deficiency syndrome, establish syndrome classification model based on data of tongue and pulse by using machine learning methods, and evaluate the feasibility of syndrome classification based on data of tongue and pulse.",0,0
4836,"Semi-supervised generative adversarial networks for closed-angle detection on anterior segment optical coherence tomography images: an empirical study with a small training dataset. Semi-supervised learning algorithms can leverage an unlabeled dataset when labeling is limited or expensive to obtain. In the current study, we developed and evaluated a semi-supervised generative adversarial networks (GANs) model that detects closed-angle on anterior segment optical coherence tomography (AS-OCT) images using a small labeled dataset.",0,0
4837,"Computer-aided diagnostic system based on deep learning for classifying colposcopy images. Colposcopy is widely used to detect cervical cancer, but developing countries lack the experienced colposcopists necessary for accurate diagnosis. Artificial intelligence (AI) is being widely used in computer-aided diagnosis (CAD) systems. In this study, we developed and validated a CAD model based on deep learning to classify cervical lesions on colposcopy images.",0,0
4838,"Machine Learning Augmented Echocardiography for Diastolic Function Assessment. Cardiac diastolic dysfunction is prevalent and is a diagnostic criterion for heart failure with preserved ejection fraction-a burgeoning global health issue. As gold-standard invasive haemodynamic assessment of diastolic function is not routinely performed, clinical guidelines advise using echocardiography measures to determine the grade of diastolic function. However, the current process has suboptimal accuracy, regular indeterminate classifications and is susceptible to confounding from comorbidities. Advances in artificial intelligence in recent years have created revolutionary ways to evaluate and integrate large quantities of cardiology data. Imaging is an area of particular strength for the sub-field of machine-learning, with evidence that trained algorithms can accurately discern cardiac structures, reliably estimate chamber volumes, and output systolic function metrics from echocardiographic images. In this review, we present the emerging field of machine-learning based echocardiographic diastolic function assessment. We summarise how machine-learning has made use of diastolic parameters to accurately differentiate pathology, to identify novel phenotypes within diastolic disease, and to grade diastolic function. Perspectives are given about how these innovations could be used to augment clinical practice, whilst areas for future investigation are identified.",0,0
4839,"Early Prediction of Left Ventricular Reverse Remodeling in First-Diagnosed Idiopathic Dilated Cardiomyopathy: A Comparison of Linear Model, Random Forest, and Extreme Gradient Boosting. <b>Introduction:</b> Left ventricular reverse remodeling (LVRR) is associated with decreased cardiovascular mortality and improved cardiac survival and also crucial for therapeutic options. However, there is a lack of an early prediction model of LVRR in first-diagnosed dilated cardiomyopathy. <b>Methods:</b> This single-center study included 104 patients with idiopathic DCM. We defined LVRR as an absolute increase in left ventricular ejection fraction (LVEF) from >10% to a final value >35% and a decrease in left ventricular end-diastolic diameter (LVDd) >10%. Analysis features included demographic characteristics, comorbidities, physical sign, biochemistry data, echocardiography, electrocardiogram, Holter monitoring, and medication. Logistic regression, random forests, and extreme gradient boosting (XGBoost) were, respectively, implemented in a 10-fold cross-validated model to discriminate LVRR and non-LVRR, with receiver operating characteristic (ROC) curves and calibration plot for performance evaluation. <b>Results:</b> LVRR occurred in 47 (45.2%) patients after optimal medical treatment. Cystatin C, right ventricular end-diastolic dimension, high-density lipoprotein cholesterol (HDL-C), left atrial dimension, left ventricular posterior wall dimension, systolic blood pressure, severe mitral regurgitation, eGFR, and NYHA classification were included in XGBoost, which reached higher AU-ROC compared with logistic regression (AU-ROC, 0.8205 vs. 0.5909, <i>p</i> = 0.0119). Ablation analysis revealed that cystatin C, right ventricular end-diastolic dimension, and HDL-C made the largest contributions to the model. <b>Conclusion:</b> Tree-based models like XGBoost were able to early differentiate LVRR and non-LVRR in patients with first-diagnosed DCM before drug therapy, facilitating disease management and invasive therapy selection. A multicenter prospective study is necessary for further validation. <b>Clinical Trial Registration:</b>http://www.chictr.org.cn/usercenter.aspx (ChiCTR2000034128).",0,0
4843,"Molecular Subtypes of Oral Squamous Cell Carcinoma Based on Immunosuppression Genes Using a Deep Learning Approach. <b>Background:</b> The mechanisms through which immunosuppressed patients bear increased risk and worse survival in oral squamous cell carcinoma (OSCC) are unclear. Here, we used deep learning to investigate the genetic mechanisms underlying immunosuppression in the survival of OSCC patients, especially from the aspect of various survival-related subtypes. <b>Materials and methods:</b> OSCC samples data were obtained from The Cancer Genome Atlas (TCGA), International Cancer Genome Consortium (ICGC), and OSCC-related genetic datasets with survival data in the National Center for Biotechnology Information (NCBI). Immunosuppression genes (ISGs) were obtained from the HisgAtlas and DisGeNET databases. Survival analyses were performed to identify the ISGs with significant prognostic values in OSCC. A deep learning (DL)-based model was established for robustly differentiating the survival subpopulations of OSCC samples. In order to understand the characteristics of the different survival-risk subtypes of OSCC samples, differential expression analysis and functional enrichment analysis were performed. <b>Results:</b> A total of 317 OSCC samples were divided into one inferring cohort (TCGA) and four confirmation cohorts (ICGC set, GSE41613, GSE42743, and GSE75538). Eleven ISGs (i.e., BGLAP, CALCA, CTLA4, CXCL8, FGFR3, HPRT1, IL22, ORMDL3, TLR3, SPHK1, and INHBB) showed prognostic value in OSCC. The DL-based model provided two optimal subgroups of TCGA-OSCC samples with significant differences (<i>p</i> = 4.91E-22) and good model fitness [concordance index (C-index) = 0.77]. The DL model was validated by using four external confirmation cohorts: ICGC cohort (<i>n</i> = 40, C-index = 0.39), GSE41613 dataset (<i>n</i> = 97, C-index = 0.86), GSE42743 dataset (<i>n</i> = 71, C-index = 0.87), and GSE75538 dataset (<i>n</i> = 14, C-index = 0.48). Importantly, subtype Sub1 demonstrated a lower probability of survival and thus a more aggressive nature compared with subtype Sub2. ISGs in subtype Sub1 were enriched in the tumor-infiltrating immune cells-related pathways and cancer progression-related pathways, while those in subtype Sub2 were enriched in the metabolism-related pathways. <b>Conclusion:</b> The two survival subtypes of OSCC identified by deep learning can benefit clinical practitioners to divide immunocompromised patients with oral cancer into two subpopulations and give them target drugs and thus might be helpful for improving the survival of these patients and providing novel therapeutic strategies in the precision medicine area.",0,0
4849,"A Pipeline for Predicting the Treatment Response of Neoadjuvant Chemoradiotherapy for Locally Advanced Rectal Cancer Using Single MRI Modality: Combining Deep Segmentation Network and Radiomics Analysis Based on ""Suspicious Region"". Patients with locally advanced rectal cancer (LARC) who achieve a pathologic complete response (pCR) after neoadjuvant chemoradiotherapy (nCRT) typically have a good prognosis. An early and accurate prediction of the treatment response, i.e., whether a patient achieves pCR, could significantly help doctors make tailored plans for LARC patients. This study proposes a pipeline of pCR prediction using a combination of deep learning and radiomics analysis. Taking into consideration missing pre-nCRT magnetic resonance imaging (MRI), as well as aiming to improve the efficiency for clinical application, the pipeline only included a post-nCRT T2-weighted (T2-w) MRI. Unlike other studies that attempted to carefully find the region of interest (ROI) using a pre-nCRT MRI as a reference, we placed the ROI on a ""suspicious region"", which is a continuous area that has a high possibility to contain a tumor or fibrosis as assessed by radiologists. A deep segmentation network, termed the two-stage rectum-aware U-Net (tsraU-Net), is designed to segment the ROI to substitute for a time-consuming manual delineation. This is followed by a radiomics analysis model based on the ROI to extract the hidden information and predict the pCR status. The data from a total of 275 patients were collected from two hospitals and partitioned into four datasets: Seg-T (N = 88) for training the tsraUNet, Rad-T (N = 107) for building the radiomics model, In-V (N = 46) for internal validation, and Ex-V (N = 34) for external validation. The proposed method achieved an area under the curve (AUC) of 0.829 (95% confidence interval [CI]: 0.821, 0.837) on In-V and 0.815 (95% CI, 0.801, 0.830) on Ex-V. The performance of the method was considerable and stable in two validation sets, indicating that the well-designed pipeline has the potential to be used in real clinical procedures.",0,0
4851,"Robust Prognostic Subtyping of Muscle-Invasive Bladder Cancer Revealed by Deep Learning-Based Multi-Omics Data Integration. Muscle-invasive bladder cancer (MIBC) is the most common urinary system carcinoma associated with poor outcomes. It is necessary to develop a robust classification system for prognostic prediction of MIBC. Recently, increasing omics data at different levels of MIBC were produced, but few integration methods were used to classify MIBC that reflects the patient's prognosis. In this study, we constructed an autoencoder based deep learning framework to integrate multi-omics data of MIBC and clustered samples into two different subgroups with significant overall survival difference (<i>P</i> = 8.11 Ã— 10<sup>-5</sup>). As an independent prognostic factor relative to clinical information, these two subtypes have some significant genomic differences. Remarkably, the subtype of poor prognosis had significant higher frequency of chromosome 3p deletion. Immune decomposition analysis results showed that these two MIBC subtypes had different immune components including macrophages M1, resting NK cells, regulatory T cells, plasma cells, and naÃ¯ve B cells. Hallmark gene set enrichment analysis was performed to investigate the functional character difference between these two MIBC subtypes, which revealed that activated IL-6/JAK/STAT3 signaling, interferon-alpha response, reactive oxygen species pathway, and unfolded protein response were significantly enriched in upregulated genes of high-risk subtype. We constructed MIBC subtyping models based on multi-omics data and single omics data, respectively, and internal and external validation datasets showed the robustness of the prediction model as well as its ability of prognosis (<i>P</i> < 0.05 in all datasets). Finally, through bioinformatics analysis and immunohistochemistry experiments, we found that KRT7 can be used as a biomarker reflecting MIBC risk.",0,0
4852,"Deep transfer learning for COVID-19 detection and infection localization with superpixel based segmentation. The evolution the novel corona virus disease (COVID-19) as a pandemic has inflicted several thousand deaths per day endangering the lives of millions of people across the globe. In addition to thermal scanning mechanisms, chest imaging examinations provide valuable insights to the detection of this virus, diagnosis and prognosis of the infections. Though Chest CT and Chest X-ray imaging are common in the clinical protocols of COVID-19 management, the latter is highly preferred, attributed to its simple image acquisition procedure and mobility of the imaging mechanism. However, Chest X-ray images are found to be less sensitive compared to Chest CT images in detecting infections in the early stages. In this paper, we propose a deep learning based framework to enhance the diagnostic values of these images for improved clinical outcomes. It is realized as a variant of the conventional SqueezeNet classifier with segmentation capabilities, which is trained with deep features extracted from the Chest X-ray images of a standard dataset for binary and multi class classification. The binary classifier achieves an accuracy of 99.53% in the discrimination of COVID-19 and Non COVID-19 images. Similarly, the multi class classifier performs classification of COVID-19, Viral Pneumonia and Normal cases with an accuracy of 99.79%. This model called the COVID-19 Super pixel SqueezNet (COVID-SSNet) performs super pixel segmentation of the activation maps to extract the regions of interest which carry perceptual image features and constructs an overlay of the Chest X-ray images with these regions. The proposed classifier model adds significant value to the Chest X-rays for an integral examination of the image features and the image regions influencing the classifier decisions to expedite the COVID-19 treatment regimen.",0,0
4854,"A Novel Artificial Intelligence-assisted Risk Assessment Model for Preventing Complications in Esthetic Surgery. Prevention of complications to reduce morbidity and mortality, and improve patient satisfaction is of paramount importance to plastic surgeons. This study aimed to evaluate the predictive risk factors for complications and to validate a novel risk assessment model, using artificial intelligence.",0,0
4856,Clinicopathological models for predicting lymph node metastasis in patients with early-stage lung adenocarcinoma: the application of machine learning algorithms. Lymph node metastasis (LNM) status can be a critical decisive factor for clinical management of lung cancer. Accurately evaluating the risk of LNM during or after the surgery can be helpful for making clinical decisions. This study aims to incorporate clinicopathological characteristics to develop reliable machine learning (ML)-based models for predicting LNM in patients with early-stage lung adenocarcinoma.,0,0
4857,"An algorithm for Parkinson's disease speech classification based on isolated words analysis. Automatic assessment of speech impairment is a cutting edge topic in Parkinson's disease (PD). Language disorders are known to occur several years earlier than typical motor symptoms, thus speech analysis may contribute to the early diagnosis of the disease. Moreover, the remote monitoring of dysphonia could allow achieving an effective follow-up of PD clinical condition, possibly performed in the home environment.",0,0
4859,The Role of Deep Learning-Based Echocardiography in the Diagnosis and Evaluation of the Effects of Routine Anti-Heart-Failure Western Medicines in Elderly Patients with Acute Left Heart Failure. The role of deep learning-based echocardiography in the diagnosis and evaluation of the effects of routine anti-heart-failure Western medicines was investigated in elderly patients with acute left heart failure (ALHF).,0,0
4863,"Computer-aided detection of COVID-19 from CT scans using an ensemble of CNNs and KSVM classifier. Corona Virus Disease-2019 (COVID-19) is a global pandemic which is spreading briskly across the globe. The gold standard for the diagnosis of COVID-19 is viral nucleic acid detection with real-time polymerase chain reaction (RT-PCR). However, the sensitivity of RT-PCR in the diagnosis of early-stage COVID-19 is less. Recent research works have shown that computed tomography (CT) scans of the chest are effective for the early diagnosis of COVID-19. Convolutional neural networks (CNNs) are proven successful for diagnosing various lung diseases from CT scans. CNNs are composed of multiple layers which represent a hierarchy of features at each level. CNNs require a big number of labeled instances for training from scratch. In medical imaging tasks like the detection of COVID-19 where there is a difficulty in acquiring a large number of labeled CT scans, pre-trained CNNs trained on a huge number of natural images can be employed for extracting features. Feature representation of each CNN varies and an ensemble of features generated from various pre-trained CNNs can increase the diagnosis capability significantly. In this paper, features extracted from an ensemble of 5 different CNNs (MobilenetV2, Shufflenet, Xception, Darknet53 and EfficientnetB0) in combination with kernel support vector machine is used for the diagnosis of COVID-19 from CT scans. The method was tested using a public dataset and it attained an area under the receiver operating characteristic curve of 0.963, accuracy of 0.916, kappa score of 0.8305, F-score of 0.91, sensitivity of 0.917 and positive predictive value of 0.904 in the prediction of COVID-19.",0,0
4865,Radiomics Analysis Based on Automatic Image Segmentation of DCE-MRI for Predicting Triple-Negative and Nontriple-Negative Breast Cancer. To investigate whether quantitative radiomics features extracted from dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) could be used to differentiate triple-negative breast cancer (TNBC) and nontriple-negative breast cancer (non-TNBC).,0,0
4866,"Identification of Nephrogenic Therapeutic Biomarkers of Wilms Tumor Using Machine Learning. Wilms tumor is the most common renal malignancy in children, with a survival rate of more than 90%; however, treatment outcomes for certain patient subgroups, such as those with bilateral and recurrent diseases, remain significantly below this survival rate. Therefore, it remains essential to identify new biomarkers and develop effective therapeutic strategies. Based on the Therapeutically Applicable Research to Generate Effective Treatments and Gene Expression Omnibus RNA microarray datasets, we have identified eight differentially expressed genes in Wilms tumors as renal-specific in 33 randomly selected adult tumors. The risk model, constructed using survival forest and multivariate Cox regression, can effectively predict the prognosis; the risk score is an independent prognostic factor in Wilms tumor. Gene set enrichment analysis showed that most of the signature genes were involved in regulating human development-related pathways. At the same time, patients in the high-risk group exhibited more sensitive immunological and chemotherapeutic properties than those in the low-risk group. These results provide new insights into personalized and precise Wilms tumor treatment strategies.",0,0
4868,"Design of Deep Learning Model for Task-Evoked fMRI Data Classification. Machine learning methods have been successfully applied to neuroimaging signals, one of which is to decode specific task states from functional magnetic resonance imaging (fMRI) data. In this paper, we propose a model that simultaneously utilizes characteristics of both spatial and temporal sequential information of fMRI data with deep neural networks to classify the fMRI task states. We designed a convolution network module and a recurrent network module to extract the spatial and temporal features of fMRI data, respectively. In particular, we also add the attention mechanism to the recurrent network module, which more effectively highlights the brain activation state at the moment of reaction. We evaluated the model using task-evoked fMRI data from the Human Connectome Project (HCP) dataset, the classification accuracy got 94.31%, and the experimental results have shown that the model can effectively distinguish the brain states under different task stimuli.",0,0
4869,"Optimal Diagnosis of COVID-19 Based on Convolutional Neural Network and Red Fox Optimization Algorithm. SARS-CoV-2 is a specific type of Coronavirus that was firstly reported in China in December 2019 and is the causative agent of coronavirus disease 2019 (COVID-19). In March 2020, this disease spread to different parts of the world causing a global pandemic. Although this disease is still increasing exponentially day by day, early diagnosis of this disease is very important to reduce the death rate and to reduce the prevalence of this pandemic. Since there are sometimes human errors by physicians in the diagnosis of this disease, using computer-aided diagnostic systems can be helpful to get more accurate results. In this paper, chest X-ray images have been examined using a new pipeline machine vision-based system to provide more accurate results. In the proposed method, after preprocessing the input X-ray images, the region of interest has been segmented. Then, a combined gray-level cooccurrence matrix (GLCM) and Discrete Wavelet Transform (DWT) features have been extracted from the processed images. Finally, an improved version of Convolutional Neural Network (CNN) based on the Red Fox Optimization algorithm is employed for the classification of the images based on the features. The proposed method is validated by performing to three datasets and its results are compared with some state-of-the-art methods. The final results show that the suggested method has proper efficiency toward the others for the diagnosis of COVID-19.",0,0
4874,"Genetic Mechanism Revealed of Age-Related Macular Degeneration Based on Fusion of Statistics and Machine Learning Method. Age-related macular degeneration (AMD) is the most common cause of irreversible vision loss in the developed world which affects the quality of life for millions of elderly individuals worldwide. Genome-wide association studies (GWAS) have identified genetic variants at 34 loci contributing to AMD. To better understand the disease pathogenesis and identify causal genes for AMD, we applied random walk (RW) and support vector machine (SVM) to identify AMD-related genes based on gene interaction relationship and significance of genes. Our model achieved 0.927 of area under the curve (AUC), and 65 novel genes have been identified as AMD-related genes. To verify our results, a statistics method called summary data-based Mendelian randomization (SMR) has been implemented to integrate GWAS data and transcriptome data to verify AMD susceptibility-related genes. We found 45 genes are related to AMD by SMR. Among these genes, 37 genes overlap with those found by SVM-RW. Finally, we revealed the biological process of genetic mutations leading to changes in gene expression leading to AMD. Our results reveal the genetic pathogenic factors and related mechanisms of AMD.",0,0
4880,"Predicting MCI to AD Conversation Using Integrated sMRI and rs-fMRI: Machine Learning and Graph Theory Approach. Graph theory and machine learning have been shown to be effective ways of classifying different stages of Alzheimer's disease (AD). Most previous studies have only focused on inter-subject classification with single-mode neuroimaging data. However, whether this classification can truly reflect the changes in the structure and function of the brain region in disease progression remains unverified. In the current study, we aimed to evaluate the classification framework, which combines structural Magnetic Resonance Imaging (sMRI) and resting-state functional Magnetic Resonance Imaging (rs-fMRI) metrics, to distinguish mild cognitive impairment non-converters (MCInc)/AD from MCI converters (MCIc) by using graph theory and machine learning.",0,0
4882,"Identifying Individuals With Mild Cognitive Impairment Using Working Memory-Induced Intra-Subject Variability of Resting-State EEGs. Individuals with mild cognitive impairment (MCI) are at high risk of developing into dementia (e. g., Alzheimer's disease, AD). A reliable and effective approach for early detection of MCI has become a critical challenge. Although compared with other costly or risky lab tests, electroencephalogram (EEG) seems to be an ideal alternative measure for early detection of MCI, searching for valid EEG features for classification between healthy controls (HCs) and individuals with MCI remains to be largely unexplored. Here, we design a novel feature extraction framework and propose that the spectral-power-based task-induced intra-subject variability extracted by this framework can be an encouraging candidate EEG feature for the early detection of MCI. In this framework, we extracted the task-induced intra-subject spectral power variability of resting-state EEGs (as measured by a between-run similarity) before and after participants performing cognitively exhausted working memory tasks as the candidate feature. The results from 74 participants (23 individuals with AD, 24 individuals with MCI, 27 HC) showed that the between-run similarity over the frontal and central scalp regions in the HC group is higher than that in the AD or MCI group. Furthermore, using a feature selection scheme and a support vector machine (SVM) classifier, the between-run similarity showed encouraging leave-one-participant-out cross-validation (LOPO-CV) classification performance for the classification between the MCI and HC (80.39%) groups and between the AD vs. HC groups (78%), and its classification performance is superior to other widely-used features such as spectral powers, coherence, and the complexity estimated by Katz's method extracted from single-run resting-state EEGs (a common approach in previous studies). The results based on LOPO-CV, therefore, suggest that the spectral-power-based task-induced intra-subject EEG variability extracted by the proposed feature extraction framework has the potential to serve as a neurophysiological feature for the early detection of MCI in individuals.",0,0
4886,"Hybrid intelligent model for classifying chest X-ray images of COVID-19 patients using genetic algorithm and neutrosophic logic. The highly spreading virus, COVID-19, created a huge need for an accurate and speedy diagnosis method. The famous RT-PCR test is costly and not available for many suspected cases. This article proposes a neurotrophic model to diagnose COVID-19 patients based on their chest X-ray images. The proposed model has five main phases. First, the speeded up robust features (SURF) method is applied to each X-ray image to extract robust invariant features. Second, three sampling algorithms are applied to treat imbalanced dataset. Third, the neutrosophic rule-based classification system is proposed to generate a set of rules based on the three neutrosophic values < T; I; F>, the degrees of truth, indeterminacy falsity. Fourth, a genetic algorithm is applied to select the optimal neutrosophic rules to improve the classification performance. Fifth, in this phase, the classification-based neutrosophic logic is proposed. The testing rule matrix is constructed with no class label, and the goal of this phase is to determine the class label for each testing rule using intersection percentage between testing and training rules. The proposed model is referred to as GNRCS. It is compared with six state-of-the-art classifiers such as multilayer perceptron (MLP), support vector machines (SVM), linear discriminant analysis (LDA), decision tree (DT), naive Bayes (NB), and random forest classifiers (RFC) with quality measures of accuracy, precision, sensitivity, specificity, and F1-score. The results show that the proposed model is powerful for COVID-19 recognition with high specificity and high sensitivity and less computational complexity. Therefore, the proposed GNRCS model could be used for real-time automatic early recognition of COVID-19.",0,0
4887,"Region of interest-based predictive algorithm for subretinal hemorrhage detection using faster R-CNN. Macular edema (ME) is an essential sort of macular issue caused due to the storing of fluid underneath the macula. Age-related Macular Degeneration (AMD) and diabetic macular edema (DME) are the two customary visual contaminations that can lead to fragmentary or complete vision loss. This paper proposes a deep learning-based predictive algorithm that can be used to detect the presence of a Subretinal hemorrhage. Region Convolutional Neural Network (R-CNN) and faster R-CNN are used to develop the predictive algorithm that can improve the classification accuracy. This method initially detects the presence of Subretinal hemorrhage, and it then segments the Region of Interest (ROI) by a semantic segmentation process. The segmented ROI is applied to a predictive algorithm which is derived from the Fast Region Convolutional Neural Network algorithm, that can categorize the Subretinal hemorrhage as responsive or non-responsive. The dataset, provided by a medical institution, comprised of optical coherence tomography (OCT) images of both pre- and post-treatment images, was used for training the proposed Faster Region Convolutional Neural Network (Faster R-CNN). We also used the Kaggle dataset for performance comparison with the traditional methods that are derived from the convolutional neural network (CNN) algorithm. The evaluation results using the Kaggle dataset and the hospital images provide an average sensitivity, selectivity, and accuracy of 85.3%, 89.64%, and 93.48% respectively. Further, the proposed method provides a time complexity in testing as 2.64s, which is less than the traditional schemes like CNN, R-CNN, and Fast R-CNN.",0,0
4893,"[Object Detection Model Utilizing Deep Learning to Identify Retained Surgical Gauze in the Body on Postoperative Radiography: Phantom Study]. Foreign bodies such as a surgical gauze can be retained in the body after surgery and in some cases cannot be detected by postoperative radiography. The aim of this study was to develop an object detection model capable of postsurgical detection of retained gauze in the body. The object detection model used deep learning using abdominal radiographs, and a phantom study was performed to evaluate the ability of the model to automatically detect retained surgical gauze.",0,0
4894,"[A Study on Radiation Dermatitis Grading Support System Based on Deep Learning by Hybrid Generation Method]. Radiation dermatitis is one of the most common adverse events in patients undergoing radiotherapy. However, the objective evaluation of this condition is difficult to provide because the clinical evaluation of radiation dermatitis is made by visual assessment based on Common Terminology Criteria for Adverse Events (CTCAE). Therefore, we created a radiation dermatitis grading support system (RDGS) using a deep convolutional neural network (DCNN) and then evaluated the effectiveness of the RDGS.",0,0
4897,"Using a Convolutional Neural Network to Predict Remission of Diabetes After Gastric Bypass Surgery: Machine Learning Study From the Scandinavian Obesity Surgery Register. Prediction of diabetes remission is an important topic in the evaluation of patients with type 2 diabetes (T2D) before bariatric surgery. Several high-quality predictive indices are available, but artificial intelligence algorithms offer the potential for higher predictive capability.",0,0
4899,Comparison and development of advanced machine learning tools to predict nonalcoholic fatty liver disease: An extended study. Nonalcoholic fatty liver disease (NAFLD) is a public health challenge and significant cause of morbidity and mortality worldwide. Early identification is crucial for disease intervention. We recently proposed a nomogram-based NAFLD prediction model from a large population cohort. We aimed to explore machine learning tools in predicting NAFLD.,0,0
4909,"Discriminative deep learning based benignity/malignancy diagnosis of dermatologic ultrasound skin lesions with pretrained artificial intelligence architecture. Deep-learning algorithms (DLAs) have been used in artificial intelligence aided ultrasonography diagnosis of thyroid and breast lesions. However, its use has not been described in the case of dermatologic ultrasound lesions. Our purpose was to train a DLA to discriminate benign form malignant lesions in dermatologic ultrasound images.",0,0
4910,"Seeing under the cover with a 3D U-Net: point cloud-based weight estimation of covered patients. Body weight is a crucial parameter for patient-specific treatments, particularly in the context of proper drug dosage. Contactless weight estimation from visual sensor data constitutes a promising approach to overcome challenges arising in emergency situations. Machine learning-based methods have recently been shown to perform accurate weight estimation from point cloud data. The proposed methods, however, are designed for controlled conditions in terms of visibility and position of the patient, which limits their practical applicability. In this work, we aim to decouple accurate weight estimation from such specific conditions by predicting the weight of covered patients from voxelized point cloud data.",0,0
4911,"Machine learning with neuroimaging data to identify autism spectrum disorder: a systematic review and meta-analysis. AutismÂ Spectrum Disorder (ASD) is diagnosed through observation or interview assessments, which is time-consuming, subjective, and with questionable validity and reliability. Thus, we aimed to evaluate the role of machine learning (ML) with neuroimaging data to provide a reliable classification of ASD.",0,0
4913,"Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza. Respiratory virus infections are significant causes of morbidity and mortality, and may induce host metabolite alterations by infecting respiratory epithelial cells. We investigated the use of liquid chromatography quadrupole time-of-flight mass spectrometry (LC/Q-TOF) combined with machine learning for the diagnosis of influenza infection.",0,0
4915,"Data-driven prediction of decannulation probability and timing in patients with severe acquired brain injury. From a rehabilitation perspective, removal of tracheostomy in patients with severe acquired brain injuries (sABI) is a crucial step. Predictive parameters for a successful decannulation are currently still a focus of the research for sABI patients, especially for those presenting a disorder of consciousness. For this reason, we adopted a data-driven approach predicting decannulation probability and timing using ensemble learning models in patients in intensive rehabilitation units.",0,0
4919,Development of a machine learning algorithm for predicting in-hospital and 1-year mortality after traumatic spinal cord injury. Current prognostic tools such as the Injury Severity Score (ISS) that predict mortality following trauma do not adequately consider the unique characteristics of traumatic spinal cord injury (tSCI).,0,0
4920,"Deep Learning Algorithm Predicts Angiographic Coronary Artery Disease in Stable Patients Using Only a Standard 12-lead Electrocardiogram. Current electrocardiogram analysis algorithms cannot predict the presence of coronary artery disease (CAD), especially in stable patients. This study assessed the ability of an artificial intelligence algorithm (ECGio) to predict the presence, location, and severity of coronary artery lesions in an unselected stable patient population.",0,0
4922,"Detection of hypertrophic cardiomyopathy by an artificial intelligence electrocardiogram in children and adolescents. There is no established screening approach for hypertrophic cardiomyopathy (HCM). We recently developed an artificial intelligence (AI) model for the detection of HCM based on the 12â€‘lead electrocardiogram (AI-ECG) in adults. Here, we aimed to validate this approach of ECG-based HCM detection in pediatric patients (ageÂ â‰¤Â 18Â years).",0,0
4924,"Reducing the heterogeneity in hepatocellular carcinoma. A cluster analysis based on clinical variables in patients treated at a quaternary care hospital. Even though the term hepatocellular carcinoma designates the most common type of primary liver cancer, the disease has a high level of heterogeneity due to its etiology, geographic variation, behavior, and association with specific genetic alterations. The aim of the present study was to establish, through a cluster analysis, the clinical characteristics that enable homogeneous conglomerates to be defined.",0,0
4929,"Deep learning assisted quantitative assessment of histopathological markers of Alzheimer's disease and cerebral amyloid angiopathy. Traditionally, analysis of neuropathological markers in neurodegenerative diseases has relied on visual assessments of stained sections. Resulting semiquantitative scores often vary between individual raters and research centers, limiting statistical approaches. To overcome these issues, we have developed six deep learning-based models, that identify some of the most characteristic markers of Alzheimer's disease (AD) and cerebral amyloid angiopathy (CAA). The deep learning-based models are trained to differentially detect parenchymal amyloid Î² (AÎ²)-plaques, vascular AÎ²-deposition, iron and calcium deposition, reactive astrocytes, microglia, as well as fibrin extravasation. The models were trained on digitized histopathological slides from brains of patients with AD and CAA, using a workflow that allows neuropathology experts to train convolutional neural networks (CNNs) on a cloud-based graphical interface. Validation of all models indicated a very good to excellent performance compared to three independent expert human raters. Furthermore, the AÎ² and iron models were consistent with previously acquired semiquantitative scores in the same dataset and allowed the use of more complex statistical approaches. For example, linear mixed effects models could be used to confirm the previously described relationship between leptomeningeal CAA severity and cortical iron accumulation. A similar approach enabled us to explore the association between neuroinflammation and disparate AÎ² pathologies. The presented workflow is easy for researchers with pathological expertise to implement and is customizable for additional histopathological markers. The implementation of deep learning-assisted analyses of histopathological slides is likely to promote standardization of the assessment of neuropathological markers across research centers, which will allow specific pathophysiological questions in neurodegenerative disease to be addressed in a harmonized way and on a larger scale.",1,1
4933,"Interobserver variability between experienced and inexperienced observers in the histopathological analysis of Wilms tumors: a pilot study for future algorithmic approach. Histopathological classification of Wilms tumors determines treatment regimen. Machine learning has been shown to contribute to histopathological classification in various malignancies but requires large numbers of manually annotated images and thus specific pathological knowledge. This study aimed to assess whether trained, inexperienced observers could contribute to reliable annotation of Wilms tumor components for classification performed by machine learning.",1,1
4939,"Supervised machine learning for the assessment of Chronic Kidney Disease advancement. Chronic Kidney Disease (CKD) is a condition characterized by a progressive loss of kidney function over time caused by many diseases. The most effective weapons against CKD are early diagnosis and treatment, which in most of the cases can only postpone the onset of complete kidney failure. The CKD grading system is classified based on the estimated Glomerular Filtration Rate (eGFR), and it helps to stratify patients for risk, follow up and management planning. This study aims to effectively predict how soon a CKD patient will need to be dialyzed, thus allowing personalized care and strategic planning of treatment.",0,0
4940,"Automatic creation of annotations for chest radiographs based on the positional information extracted from radiographic image reports. In this study, we tried to create a machine-learning method that detects disease lesions from chest X-ray (CXR) images using a data set annotated with extracted CXR reports information. We set the nodule as the target disease lesion. Manually annotating nodules is costly in terms of time. Therefore, we used the report information to automatically produce training data for the object detection task.",0,0
4945,"Influenza and anosmia: Important prediction factors for severity and death of COVID-19. Objectives To investigate the factors related to the severity and mo rtality of COVID-19 using big data-machine learning techniques. Methods This study included 8070 patients in South Korea diagnosed with COVID-19 between January and July 2020, and whose data were available from the National-Health-Insurance-Service. Results Machine-learning algorithms were performed to evaluate the effects of comorbidities on severity and mortality of COVID-19. The most common comorbidities of COVID-19 were pulmonary inflammation followed by hypertension. The model that best predicted severity was a neural network (AUC: 85.06%). The most important variable for predicting severity in the neural network model was a history of influenza (relative importance: 0.083). The model that best predicted mortality was the logistic regression elastic net (EN) model (AUC: 93.86%). The most important variables for mortality in the EN model were age (coefficient: 2.136) and anosmia (coefficient: -1.438). Conclusions In COVID-19 patients, influenza was found to be a major adverse factor in addition to old age and male. In addition, anosmia was found to be a major factor associated with lower severity and mortality. Therefore, in the current situation where there is no adequate COVID-19 treatment at present, examining the patient's history of influenza vaccination and anosmia in addition to age and sex will be an important indicator for predicting the severity and mortality of COVID-19 patients.",0,0
4949,Fully automated detection of prostate transition zone tumors on T2-weighted and apparent diffusion coefficient (ADC) map MR images using U-Net ensemble. Accurate detection of transition zone (TZ) prostate cancer (PCa) on magnetic resonance imaging (MRI) remains challenging using clinical subjective assessment due to overlap between PCa and benign prostatic hyperplasia (BPH). The objective of this paper is to describe a deep-learning-based framework for fully automated detection of PCa in the TZ using T2-weighted (T2W) and apparent diffusion coefficient (ADC) map MR images.,0,0
4950,Generating pseudo-computerized tomography (P-CT) scan images from magnetic resonance imaging (MRI) images using machine learning algorithms based on fuzzy theory for radiotherapy treatment planning. The substitution of computerized tomography (CT) with magnetic resonance imaging (MRI) has been investigated for external radiotherapy treatment planning. The present study aims to use pseudo-CT (P-CT) images created by MRI images to calculate the dose distribution for facilitating the treatment planning process.,0,0
4951,"Pattern of cerebellar grey matter loss associated with ataxia severity in spinocerebellar ataxias type 3: a multi-voxel pattern analysis. Spinocerebellar ataxias type 3 (SCA3) patients are clinically characterized by progressive cerebellar ataxia combined with degeneration of the cerebellum. Previous neuroimaging studies have indicated ataxia severity associated with cerebellar atrophy using univariate methods. However, whether cerebellar atrophy patterns can be used to quantitatively predict ataxia severity in SCA3 patients at the individual level remains largely unexplored. In this study, a group of 66 SCA3 patients and 58 healthy controls were included. Disease duration and ataxia assessment, including theÂ Scale for the Assessment and Rating of Ataxia (SARA) and the International Cooperative Ataxia Rating Scale (ICARS), were collected for SCA3 patients. The high-resolution T1-weighted MRI was obtained, and cerebellar grey matter (GM) was extracted using a spatially unbiased infratentorial template toolbox for all participants. We investigated the association between the pattern of cerebellar grey matter (GM) loss and ataxia assessment in SCA3 by using a multivariate machine learning technique. We found that the application of RVR allowed quantitative prediction of both SARA scores (leave-one-subject-out cross-validation: correlationâ€‰=â€‰0.56, p-valueâ€‰=â€‰0.001; mean squared error (MSE)â€‰=â€‰20.51, p-valueâ€‰=â€‰0.001; ten-fold cross-validation: correlationâ€‰=â€‰0.52, p-valueâ€‰=â€‰0.001; MSEâ€‰=â€‰21.00, p-valueâ€‰=â€‰0.001) and ICARS score (leave-one-subject-out cross-validation: correlationâ€‰=â€‰0.59, p-valueâ€‰=â€‰0.001; MSEâ€‰=â€‰139.69, p-valueâ€‰=â€‰0.001; ten-fold cross-validation: correlationâ€‰=â€‰0.57, p-valueâ€‰=â€‰0.001; MSEâ€‰=â€‰145.371, p-valueâ€‰=â€‰0.001) with statistically significant accuracy. These results provide proof-of-concept that ataxia severity in SCA3 patients can be predicted by the alteration pattern of cerebellar GM using multi-voxel pattern analysis.",0,0
4952,"Fuzzy segmentation and black widow-based optimal SVM for skin disease classification. The skin, which has seven layers, is the main human organ and external barrier. According to the World Health Organization (WHO), skin cancer is the fourth leading cause of non-fatal disease risk. In medicinal fields, skin disease classification is a major challenging issue due to inaccurate outputs, overfitting, larger computational cost, and so on. We presented a novel approach of support vector machine-based black widow optimization (SVM-BWO) for skin disease classification. Five different kinds of skin disease images are taken such as psoriasis, paederus, herpes, melanoma, and benign with healthy images which are chosen for this work. The pre-processing step is handled to remove the noises from the original input images. Thereafter, the novel fuzzy set segmentation algorithm subsequently segments the skin lesion region. From this, the color, gray-level co-occurrence matrix texture, and shape features are extracted for further process. Skin disease is classified with the usage of the SVM-BWO algorithm. The implementation works are handled in MATLAB-2018a, thereby the dataset images were collected from ISIC-2018 datasets. Experimentally, various kinds of performance analyses with state-of-the-art techniques are performed. Anyway, the proposed methodology outperforms better classification accuracy of 92% than other methods. Workflow diagram of the proposed methodology.",0,0
4953,Molecular subtyping of diffuse gliomas using magnetic resonance imaging: comparison and correlation between radiomics and deep learning. The molecular subtyping of diffuse gliomas is important. The aim of this study was to establish predictive models based on preoperative multiparametric MRI.,0,0
4957,"Accelerating Prediction of Malignant Cerebral Edema After Ischemic Stroke with Automated Image Analysis and Explainable Neural Networks. Malignant cerebral edema is a devastating complication of stroke, resulting in deterioration and death if hemicraniectomy is not performed prior to herniation. Current approaches for predicting this relatively rare complication often require advanced imaging and still suffer from suboptimal performance. We performed a pilot study to evaluate whether neural networks incorporating data extracted from routine computed tomography (CT) imaging could enhance prediction of edema in a large diverse stroke cohort.",0,0
4961,"Detection and characterization of lung cancer using cell-free DNA fragmentomes. Non-invasive approaches for cell-free DNA (cfDNA) assessment provide an opportunity for cancer detection and intervention. Here, we use a machine learning model for detecting tumor-derived cfDNA through genome-wide analyses of cfDNA fragmentation in a prospective study of 365 individuals at risk for lung cancer. We validate the cancer detection model using an independent cohort of 385 non-cancer individuals and 46 lung cancer patients. Combining fragmentation features, clinical risk factors, and CEA levels, followed by CT imaging, detected 94% of patients with cancer across stages and subtypes, including 91% of stage I/II and 96% of stage III/IV, at 80% specificity. Genome-wide fragmentation profiles across ~13,000 ASCL1 transcription factor binding sites distinguished individuals with small cell lung cancer from those with non-small cell lung cancer with high accuracy (AUCâ€‰=â€‰0.98). A higher fragmentation score represented an independent prognostic indicator of survival. This approachÂ provides a facile avenueÂ for non-invasive detection of lung cancer.",0,0
4966,Automated emergent large vessel occlusion detection by artificial intelligence improves stroke workflow in a hub and spoke stroke system of care. Emergent large vessel occlusion (ELVO) acute ischemic stroke is a time-sensitive disease.,0,0
4969,Development and validation of deep learning classifiers to detect Epstein-Barr virus and microsatellite instability status in gastric cancer: a retrospective multicentre cohort study. Response to immunotherapy in gastric cancer is associated with microsatellite instability (or mismatch repair deficiency) and Epstein-Barr virus (EBV) positivity. We therefore aimed to develop and validate deep learning-based classifiers to detect microsatellite instability and EBV status from routine histology slides.,0,0
4973,"Individualized diagnosis of major depressive disorder via multivariate pattern analysis of thalamic sMRI features. Magnetic resonance imaging (MRI) studies have found thalamic abnormalities in major depressive disorder (MDD). Although there are significant differences in the structure and function of the thalamus between MDD patients and healthy controls (HCs) at the group level, it is not clear whether the structural and functional features of the thalamus are suitable for use as diagnostic prediction aids at the individual level. Here, we were to test the predictive value of gray matter density (GMD), gray matter volume (GMV), amplitude of low-frequency fluctuations (ALFF), and fractional amplitude of low-frequency fluctuations (fALFF) in the thalamus using multivariate pattern analysis (MVPA).",0,0
4976,"Assessment of Axillary Lymph Nodes for Metastasis on Ultrasound Using Artificial Intelligence. The purpose of this study was to evaluate an artificial intelligence (AI) system for the classification of axillary lymph nodes on ultrasound compared to radiologists. Ultrasound images of 317 axillary lymph nodes from patients referred for ultrasound guided fine needle aspiration or core needle biopsy and corresponding pathology findings were collected. Lymph nodes were classified into benign and malignant groups with histopathological result serving as the reference. Google Cloud AutoML Vision (Mountain View, CA) was used for AI image classification. Three experienced radiologists also classified the images and gave a level of suspicion score (1-5). To test the accuracy of AI, an external testing dataset of 64 images from 64 independent patients was evaluated by three AI models and the three readers. The diagnostic performance of AI and the humans were then quantified using receiver operating characteristics curves. In the complete set of 317 images, AutoML achieved a sensitivity of 77.1%, positive predictive value (PPV) of 77.1%, and an area under the precision recall curve of 0.78, while the three radiologists showed a sensitivity of 87.8%â€‰Â±â€‰8.5%, specificity of 50.3%â€‰Â±â€‰16.4%, PPV of 61.1%â€‰Â±â€‰5.4%, negative predictive value (NPV) of 84.1%â€‰Â±â€‰6.6%, and accuracy of 67.7%â€‰Â±â€‰5.7%. In the three external independent test sets, AI and human readers achieved sensitivity of 74.0%â€‰Â±â€‰0.14% versus 89.9%â€‰Â±â€‰0.06% (<i>p</i>â€‰=â€‰.25), specificity of 64.4%â€‰Â±â€‰0.11% versus 50.1â€‰Â±â€‰0.20% (<i>p</i>â€‰=â€‰.22), PPV of 68.3%â€‰Â±â€‰0.04% versus 65.4â€‰Â±â€‰0.07% (<i>p</i>â€‰=â€‰.50), NPV of 72.6%â€‰Â±â€‰0.11% versus 82.1%â€‰Â±â€‰0.08% (<i>p</i>â€‰=â€‰.33), and accuracy of 69.5%â€‰Â±â€‰0.06% versus 70.1%â€‰Â±â€‰0.07% (<i>p</i>â€‰=â€‰.90), respectively. These preliminary results indicate AI has comparable performance to trained radiologists and could be used to predict the presence of metastasis in ultrasound images of axillary lymph nodes.",1,1
4977,"Caries Detection on Intraoral Images Using Artificial Intelligence. Although visual examination (VE) is the preferred method for caries detection, the analysis of intraoral digital photographs in machine-readable form can be considered equivalent to VE. While photographic images are rarely used in clinical practice for diagnostic purposes, they are the fundamental requirement for automated image analysis when using artificial intelligence (AI) methods. Considering that AI has not been used for automatic caries detection on intraoral images so far, this diagnostic study aimed to develop a deep learning approach with convolutional neural networks (CNNs) for caries detection and categorization (test method) and to compare the diagnostic performance with respect to expert standards. The study material consisted of 2,417 anonymized photographs from permanent teeth with 1,317 occlusal and 1,100 smooth surfaces. All the images were evaluated into the following categories: caries free, noncavitated caries lesion, or caries-related cavitation. Each expert diagnosis served as a reference standard for cyclic training and repeated evaluation of the AI methods. The CNN was trained using image augmentation and transfer learning. Before training, the entire image set was divided into a training and test set. Validation was conducted by selecting 25%, 50%, 75%, and 100% of the available images from the training set. The statistical analysis included calculations of the sensitivity (SE), specificity (SP), and area under the receiver operating characteristic (ROC) curve (AUC). The CNN was able to correctly detect caries in 92.5% of cases when all test images were considered (SE, 89.6; SP, 94.3; AUC, 0.964). If the threshold of caries-related cavitation was chosen, 93.3% of all tooth surfaces were correctly classified (SE, 95.7; SP, 81.5; AUC, 0.955). It can be concluded that it was possible to achieve more than 90% agreement in caries detection using the AI method with standardized, single-tooth photographs. Nevertheless, the current approach needs further improvement.",0,0
4983,"EEG Channel Correlation Based Model for Emotion Recognition. Emotion recognition using Artificial Intelligence (AI) is a fundamental prerequisite to improve Human-Computer Interaction (HCI). Recognizing emotion from Electroencephalogram (EEG) has been globally accepted in many applications such as intelligent thinking, decision-making, social communication, feeling detection, affective computing, etc. Nevertheless, due to having too low amplitude variation related to time on EEG signal, the proper recognition of emotion from this signal has become too challenging. Usually, considerable effort is required to identify the proper feature or feature set for an effective feature-based emotion recognition system. To extenuate the manual human effort of feature extraction, we proposed a deep machine-learning-based model with Convolutional Neural Network (CNN). At first, the one-dimensional EEG data were converted to Pearson's Correlation Coefficient (PCC) featured images of channel correlation of EEG sub-bands. Then the images were fed into the CNN model to recognize emotion. Two protocols were conducted, namely, protocol-1 to identify two levels and protocol-2 to recognize three levels of valence and arousal that demonstrate emotion. We investigated that only the upper triangular portion of the PCC featured images reduced the computational complexity and size of memory without hampering the model accuracy. The maximum accuracy of 78.22% on valence and 74.92% on arousal were obtained using the internationally authorized DEAP dataset.",0,0
4984,"External Validation and Recalibration of the CURB-65 and PSI for Predicting 30-Day Mortality and Critical Care Intervention in Multiethnic Patients with COVID-19. To validate and recalibrate the CURB-65 and pneumonia severity index (PSI) in predicting 30-day mortality and critical care intervention (CCI) in a multiethnic population with COVID-19, along with evaluating both models in predicting CCI.",0,0
4987,"Development and validation of a simple web-based tool for early prediction of COVID-19-associated death in kidney transplant recipients. This analysis, using data from the Brazilian kidney transplant (KT) COVID-19 study, seeks to develop a prediction score to assist in COVID-19 risk stratification in KT recipients. In this study, 1379 patients (35 sites) were enrolled, and a machine learning approach was used to fit models in a derivation cohort. A reduced Elastic Net model was selected, and the accuracy to predict the 28-day fatality after the COVID-19 diagnosis, assessed by the area under the ROC curve (AUC-ROC), was confirmed in a validation cohort. The better calibration values were used to build the applicable ImAgeS score. The 28-day fatality rate was 17% (nÂ =Â 235), which was associated with increasing age, hypertension and cardiovascular disease, higher body mass index, dyspnea, and use of mycophenolate acid or azathioprine. Higher kidney graft function, longer time of symptoms until COVID-19 diagnosis, presence of anosmia or coryza, and use of mTOR inhibitor were associated with reduced risk of death. The coefficients of the best model were used to build the predictive score, which achieved an AUC-ROC of 0.767 (95% CI 0.698-0.834) in the validation cohort. In conclusion, the easily applicable predictive model could assist health care practitioners in identifying non-hospitalized kidney transplant patients that may require more intensive monitoring. Trial registration: ClinicalTrials.gov NCT04494776.",0,0
4989,"Use of an artificial intelligence-based rule extraction approach to predict an emergency cesarean section. One of the major problems with artificial intelligence (AI) is that it is generally known as a ""black box"". Therefore, the present study aimed to construct an emergency cesarean section (CS) prediction system using an AI-based rule extraction approach as a ""white box"" to detect the cause for the emergency CS.",0,0
4994,"Estimating the conditional probability of developing human papilloma virus related oropharyngeal cancer by combining machine learning and inverse Bayesian modelling. The epidemic increase in the incidence of Human Papilloma Virus (HPV) related Oropharyngeal Squamous Cell Carcinomas (OPSCCs) in several countries worldwide represents a significant public health concern. Although gender neutral HPV vaccination programmes are expected to cause a reduction in the incidence rates of OPSCCs, these effects will not be evident in the foreseeable future. Secondary prevention strategies are currently not feasible due to an incomplete understanding of the natural history of oral HPV infections in OPSCCs. The key parameters that govern natural history models remain largely ill-defined for HPV related OPSCCs and cannot be easily inferred from experimental data. Mathematical models have been used to estimate some of these ill-defined parameters in cervical cancer, another HPV related cancer leading to successful implementation of cancer prevention strategies. We outline a ""double-Bayesian"" mathematical modelling approach, whereby, a Bayesian machine learning model first estimates the probability of an individual having an oral HPV infection, given OPSCC and other covariate information. The model is then inverted using Bayes' theorem to reverse the probability relationship. We use data from the Surveillance, Epidemiology, and End Results (SEER) cancer registry, SEER Head and Neck with HPV Database and the National Health and Nutrition Examination Surveys (NHANES), representing the adult population in the United States to derive our model. The model contains 8,106 OPSCC patients of which 73.0% had an oral HPV infection. When stratified by age, sex, marital status and race/ethnicity, the model estimated a higher conditional probability for developing OPSCCs given an oral HPV infection in non-Hispanic White males and females compared to other races/ethnicities. The proposed Bayesian model represents a proof-of-concept of a natural history model of HPV driven OPSCCs and outlines a strategy for estimating the conditional probability of an individual's risk of developing OPSCC following an oral HPV infection.",0,0
4995,"Improving Non-invasive Aspiration Detection with Auxiliary Classifier Wasserstein Generative Adversarial Networks. Aspiration is a serious complication of swallowing disorders. Adequate detection of aspiration is essential in dysphagia management and treatment. High-resolution cervical auscultation has been increasingly considered as a promising noninvasive swallowing screening tool and has inspired automatic diagnosis with advanced algorithms. The performance of such algorithms relies heavily on the amount of training data. However, the practical collection of cervical auscultation signal is an expensive and time-consuming process because of the clinical settings and trained experts needed for acquisition and interpretations. Furthermore, the relatively infrequent incidence of severe airway invasion during swallowing studies constrains the performance of machine learning models. Here, we produced supplementary training exemplars for desired class by capturing the underlying distribution of original cervical auscultation signal features using auxiliary classifier Wasserstein generative adversarial networks. A 10-fold subject cross-validation was conducted on 2079 sets of 36-dimensional signal features collected from 189 patients undergoing swallowing examinations. The proposed data augmentation outperforms basic data sampling, cost-sensitive learning and other generative models with significant enhancement. This demonstrates the remarkable potential of proposed network in improving classification performance using cervical auscultation signals and paves the way of developing accurate noninvasive swallowing evaluation in dysphagia care.",0,0
4996,"Exploiting Shared Knowledge from Non-COVID Lesions for Annotation-Efficient COVID-19 CT Lung Infection Segmentation. The novel Coronavirus disease (COVID-19) is a highly contagious virus and has spread all over the world, posing an extremely serious threat to all countries. Automatic lung infection segmentation from computed tomography (CT) plays an important role in the quantitative analysis of COVID-19. However, the major challenge lies in the inadequacy of annotated COVID-19 datasets. Currently, there are several public non-COVID lung lesion segmentation datasets, providing the potential for generalizing useful information to the related COVID-19 segmentation task. In this paper, we propose a novel relation-driven collaborative learning model to exploit shared knowledge from non-COVID lesions for annotation-efficient COVID-19 CT lung infection segmentation. The model consists of a general encoder to capture general lung lesion features based on multiple non-COVID lesions, and a target encoder to focus on task-specific features based on COVID-19 infections. Features extracted from the two parallel encoders are concatenated for the subsequent decoder part. We develop a collaborative learning scheme to regularize feature-level relation consistency of given input and encourage the model to learn more general and discriminative representation of COVID-19 infections. Extensive experiments demonstrate that trained with limited COVID-19 data, exploiting shared knowledge from non-COVID lesions can further improve state-of-the-art performance with up to 3.0% in dice similarity coefficient and 4.2% in normalized surface dice. In addition, experimental results on large scale 2D dataset with CT slices show that our method significantly outperforms cutting-edge segmentation methods on all evaluation metrics. Our proposed method promotes new insights into annotation-efficient deep learning for COVID-19 infection segmentation and illustrates strong potential for real-world applications in the global fight against COVID-19 in the absence of sufficient high-quality annotations.",0,0
4999,Combining computed tomography and biologically effective dose in radiomics and deep learning improves prediction of tumor response to robotic lung stereotactic body radiation therapy. The aim of this study is to improve the performance of machine learning (ML) models in predicting response of non-small cell lung cancer (NSCLC) to stereotactic body radiation therapy (SBRT) by integrating image features from pre-treatment computed tomography (CT) with features from the biologically effective dose (BED) distribution.,0,0
5004,"Detection of Optic Disc Abnormalities in Color Fundus Photographs Using Deep Learning. To date, deep learning-based detection of optic disc abnormalities in color fundus photographs has mostly been limited to the field of glaucoma. However, many life-threatening systemic and neurological conditions can manifest as optic disc abnormalities. In this study, we aimed to extend the application of deep learning (DL) in optic disc analyses to detect a spectrum of nonglaucomatous optic neuropathies.",0,0
5009,"Strategies for feature extraction from structural brain imaging in lesion-deficit modelling. High-dimensional modelling of post-stroke deficits from structural brain imaging is highly relevant to basic cognitive neuroscience and bears the potential to be translationally used to guide individual rehabilitation measures. One strategy to optimise model performance is well-informed feature selection and representation. However, different feature representation strategies were so far used, and it is not known what strategy is best for modelling purposes. The present study compared the three common main strategies: voxel-wise representation, lesion-anatomical componential feature reduction and region-wise atlas-based feature representation. We used multivariate, machine-learning-based lesion-deficit models to predict post-stroke deficits based on structural lesion data. Support vector regression was tuned by nested cross-validation techniques and tested on held-out validation data to estimate model performance. While we consistently found the numerically best models for lower-dimensional, featurised data and almost always for principal components extracted from lesion maps, our results indicate only minor, non-significant differences between different feature representation styles. Hence, our findings demonstrate the general suitability of all three commonly applied feature representations in lesion-deficit modelling. Likewise, model performance between qualitatively different popular brain atlases was not significantly different. Our findings also highlight potential minor benefits in individual fine-tuning of feature representations and the challenge posed by the high, multifaceted complexity of lesion data, where lesion-anatomical and functional criteria might suggest opposing solutions to feature reduction.",0,0
5018,Using machine learning to improve survival prediction after heart transplantation. This study investigates the use of modern machine learning (ML) techniques to improve prediction of survival after orthotopic heart transplantation (OHT).,0,0
5023,"Automatic Identification of Upper Extremity Rehabilitation Exercise Type and Dose Using Body-Worn Sensors and Machine Learning: A Pilot Study. Prior studies suggest that participation in rehabilitation exercises improves motor function poststroke; however, studies on optimal exercise dose and timing have been limited by the technical challenge of quantifying exercise activities over multiple days.",0,0
5026,"Hospitalization-Associated Disability After Cardiac Surgery in Elderly Patientsã€€- Exploring the Risk Factors Using Machine Learning Algorithms. <b><i>Background:</i></b> Hospitalization-associated disability (HAD) is associated with prolonged functional decline and increased mortality after discharge. Therefore, we examined the incidence and risk factors associated with HAD in elderly patients undergoing cardiac surgery in Japan. <b><i>Methodsâ€„andâ€„Results:</i></b> We retrospectively examined 2,262 elderly patients who underwent elective cardiac surgery at Sakakibara Heart Institute. HAD was defined as a functional decline between time of admission and discharge measured by the Barthel Index. We analyzed clinical characteristics using machine learning algorithms to identify the risk factors associated with HAD. After excluding 203 patients, 2,059 patients remained, of whom 108 (5.2%) developed HAD after cardiac surgery. The risk factors identified were age, serum albumin concentration, estimated glomerular filtration rate, Revised Hasegawa's Dementia Scale, N-terminal pro B-type natriuretic peptide, vital capacity, preoperative Short Physical Performance Battery (SPPB) score, operation times, cardiopulmonary bypass times, ventilator times, length of postoperative intensive care unit stay, and postoperative ambulation start day. The highest incidence of HAD was found in patients with an SPPB score â‰¤9 and in those who started ambulation >6 days after surgery (76.9%). <b><i>Conclusions:</i></b> Several risk factors for HAD are components of frailty, suggesting that preoperative rehabilitation to reduce the risk of HAD is feasible. Furthermore, the association between HAD and a delayed start of ambulation reaffirms the importance of early mobilization and rehabilitation.",0,0
5028,"Using Deep Learning to Identify High-Risk Patients with Heart Failure with Reduced Ejection Fraction. <b>Background:</b> Deep Learning (DL) has not been well-established as a method to identify high-risk patients among patients with heart failure (HF). <b>Objectives:</b> This study aimed to use DL models to predict hospitalizations, worsening HF events, and 30-day and 90-day readmissions in patients with heart failure with reduced ejection fraction (HFrEF). <b>Methods:</b> We analyzed the data of adult HFrEF patients from the IBMÂ® MarketScanÂ® Commercial and Medicare Supplement databases between January 1, 2015 and December 31, 2017. A sequential model architecture based on bi-directional long short-term memory (Bi-LSTM) layers was utilized. For DL models to predict HF hospitalizations and worsening HF events, we utilized two study designs: with and without a buffer window. For comparison, we also tested multiple traditional machine learning models including logistic regression, random forest, and eXtreme Gradient Boosting (XGBoost). Model performance was assessed by area under the curve (AUC) values, precision, and recall on an independent testing dataset. <b>Results:</b> A total of 47â€¯498 HFrEF patients were included; 9427 with at least one HF hospitalization. The best AUCs of DL models without a buffer window in predicting HF hospitalizations and worsening HF events in the total patient cohort were 0.977 and 0.972; with a 7-day buffer window the best AUCs were 0.573 and 0.608, respectively. The best AUCs in predicting 30- and 90-day readmissions in all adult patients were 0.597 and 0.614, respectively. An AUC of 0.861 was attained for prediction of 90-day readmission in patients aged 18-64. For all outcomes assessed, the DL approach outperformed traditional machine learning models. <b>Discussion:</b> The DL approach can automate feature engineering during the model learning, which can increase the clinical applicability and lead to comparable or better model performance. However, the lack of granular clinical data, and sample size and imbalance issues may have limited the model's performance. <b>Conclusions:</b> A DL approach using Bi-LSTM was shown to be a feasible and useful tool to predict HF-related outcomes. This study can help inform the future development and deployment of predictive tools to identify high-risk HFrEF patients and ultimately facilitate targeted interventions in clinical practice.",0,0
5031,Machine Learning to Improve Prognosis Prediction of Early Hepatocellular Carcinoma After Surgical Resection. Improved prognostic prediction is needed to stratify patients with early hepatocellular carcinoma (EHCC) to refine selection of adjuvant therapy. We aimed to develop a machine learning (ML)-based model to predict survival after liver resection for EHCC based on readily available clinical data.,0,0
5035,"Predicting special care during the COVID-19 pandemic: a machine learning approach. More than ever, COVID-19 is putting pressure on health systems worldwide, especially in Brazil. In this study, we propose a method based on statistics and machine learning that uses blood lab exam data from patients to predict whether patients will require special care (hospitalization in regular or special-care units). We also predict the number of days the patients will stay under such care. The two-step procedure developed uses Bayesian Optimisation to select the best model among several candidates. This leads us to final models that achieve 0.94 area under ROC curve performance for the first target and 1.87 root mean squared error for the second target (which is a 77% improvement over the mean baseline)-making our model ready to be deployed as a decision system that could be available for everyone interested. The analytical approach can be used in other diseases and can help to plan hospital resources in other contexts.",0,0
5046,"Using Base-ml to Learn Classification of Common Vestibular Disorders on DizzyReg Registry Data. <b>Background:</b> Multivariable analyses (MVA) and machine learning (ML) applied on large datasets may have a high potential to provide clinical decision support in neuro-otology and reveal further avenues for vestibular research. To this end, we build base-ml, a comprehensive MVA/ML software tool, and applied it to three increasingly difficult clinical objectives in differentiation of common vestibular disorders, using data from a large prospective clinical patient registry (DizzyReg). <b>Methods:</b> Base-ml features a full MVA/ML pipeline for classification of multimodal patient data, comprising tools for data loading and pre-processing; a stringent scheme for nested and stratified cross-validation including hyper-parameter optimization; a set of 11 classifiers, ranging from commonly used algorithms like logistic regression and random forests, to artificial neural network models, including a graph-based deep learning model which we recently proposed; a multi-faceted evaluation of classification metrics; tools from the domain of ""Explainable AI"" that illustrate the input distribution and a statistical analysis of the most important features identified by multiple classifiers. <b>Results:</b> In the first clinical task, classification of the bilateral vestibular failure (<i>N</i> = 66) vs. functional dizziness (<i>N</i> = 346) was possible with a classification accuracy ranging up to 92.5% (Random Forest). In the second task, primary functional dizziness (<i>N</i> = 151) vs. secondary functional dizziness (following an organic vestibular syndrome) (<i>N</i> = 204), was classifiable with an accuracy ranging from 56.5 to 64.2% (k-nearest neighbors/logistic regression). The third task compared four episodic disorders, benign paroxysmal positional vertigo (<i>N</i> = 134), vestibular paroxysmia (<i>N</i> = 49), MeniÃ¨re disease (<i>N</i> = 142) and vestibular migraine (<i>N</i> = 215). Classification accuracy ranged between 25.9 and 50.4% (NaÃ¯ve Bayes/Support Vector Machine). Recent (graph-) deep learning models classified well in all three tasks, but not significantly better than more traditional ML methods. Classifiers reliably identified clinically relevant features as most important toward classification. <b>Conclusion:</b> The three clinical tasks yielded classification results that correlate with the clinical intuition regarding the difficulty of diagnosis. It is favorable to apply an array of MVA/ML algorithms rather than a single one, to avoid under-estimation of classification accuracy. Base-ml provides a systematic benchmarking of classifiers, with a standardized output of MVA/ML performance on clinical tasks. To alleviate re-implementation efforts, we provide base-ml as an open-source tool for the community.",0,0
5054,"Deep learning for early dental caries detection in bitewing radiographs. The early detection of initial dental caries enables preventive treatment, and bitewing radiography is a good diagnostic tool for posterior initial caries. In medical imaging, the utilization of deep learning with convolutional neural networks (CNNs) to process various types of images has been actively researched, with promising performance. In this study, we developed a CNN model using a U-shaped deep CNN (U-Net) for caries detection on bitewing radiographs and investigated whether this model can improve clinicians' performance. The research complied with relevant ethical regulations. In total, 304 bitewing radiographs were used to train the CNN model and 50 radiographs for performance evaluation. The diagnostic performance of the CNN model on the total test dataset was as follows: precision, 63.29%; recall, 65.02%; and F1-score, 64.14%, showing quite accurate performance. When three dentists detected caries using the results of the CNN model as reference data, the overall diagnostic performance of all three clinicians significantly improved, as shown by an increased sensitivity ratio (D1, 85.34%; D1', 92.15%; D2, 85.86%; D2', 93.72%; D3, 69.11%; D3', 79.06%; pâ€‰<â€‰0.05). These increases were especially significant (pâ€‰<â€‰0.05) in the initial and moderate caries subgroups. The deep learning model may help clinicians to diagnose dental caries more accurately.",1,1
5057,"Evaluation of the feasibility of explainable computer-aided detection of cardiomegaly on chest radiographs using deep learning. We examined the feasibility of explainable computer-aided detection of cardiomegaly in routine clinical practice using segmentation-based methods. Overall, 793 retrospectively acquired posterior-anterior (PA) chest X-ray images (CXRs) of 793 patients were used to train deep learning (DL) models for lung and heart segmentation. The training dataset included PA CXRs from two public datasets and in-house PA CXRs. Two fully automated segmentation-based methods using state-of-the-art DL models for lung and heart segmentation were developed. The diagnostic performance was assessed and the reliability of the automatic cardiothoracic ratio (CTR) calculation was determined using the mean absolute error and paired t-test. The effects of thoracic pathological conditions on performance were assessed using subgroup analysis. One thousand PA CXRs of 1000 patients (480 men, 520 women; mean age 63â€‰Â±â€‰23Â years) were included. The CTR values derived from the DL models and diagnostic performance exhibited excellent agreement with reference standards for the whole test dataset. Performance of segmentation-based methods differed based on thoracic conditions. When tested using CXRs with lesions obscuring heart borders, the performance was lower than that for other thoracic pathological findings. Thus, segmentation-based methods using DL could detect cardiomegaly; however, the feasibility of computer-aided detection of cardiomegaly without human intervention was limited.",0,0
5059,"An approach to rapidly assess sepsis through multi-biomarker host response using machine learning algorithm. Sepsis is a life-threatening condition and understanding the disease pathophysiology through the use of host immune response biomarkers is critical for patient stratification. Lack of accurate sepsis endotyping impedes clinicians from making timely decisions alongside insufficiencies in appropriate sepsis management. This work aims to demonstrate the potential feasibility of a data-driven validation model for supporting clinical decisions to predict sepsis host-immune response. Herein, we used a machine learning approach to determine the predictive potential of identifying sepsis host immune response for patient stratification by combining multiple biomarker measurements from a single plasma sample. Results were obtained using the following cytokines and chemokines IL-6, IL-8, IL-10, IP-10 and TRAIL where the test dataset was 70%. Supervised machine learning algorithm naÃ¯ve Bayes and decision tree algorithm showed good accuracy of 96.64% and 94.64%. These promising findings indicate the proposed AI approach could be a valuable testing resource for promoting clinical decision making.",0,0
5060,"A machine learning approach to identify predictive molecular markers for cisplatin chemosensitivity following surgical resection in ovarian cancer. Ovarian cancer is associated with poor prognosis. Platinum resistance contributes significantly to the high rate of tumour recurrence. We aimed to identify a set of molecular markers for predicting platinum sensitivity. A signature predicting cisplatin sensitivity was generated using the Genomics of Drug Sensitivity in Cancer and The Cancer Genome Atlas databases. Four potential biomarkers (CYTH3, GALNT3, S100A14, and ERI1) were identified and optimized for immunohistochemistry (IHC). Validation was performed on a cohort of patients (nâ€‰=â€‰50) treated with surgical resection followed by adjuvant carboplatin. Predictive models were established to predict chemosensitivity. The four biomarkers were also assessed for their ability to prognosticate overall survival in three ovarian cancer microarray expression datasets from The Gene Expression Omnibus. The extreme gradient boosting (XGBoost) algorithm was selected for the final model to validate the accuracy in an independent validation dataset (nâ€‰=â€‰10). CYTH3 and S100A14, followed by nodal stage, were the features with the greatest importance. The four gene signature had comparable prognostication as clinical information for two-year survival. Assessment of tumour biology by means of gene expression can serve as an adjunct for prediction of chemosensitivity and prognostication. Potentially, the assessment of molecular markers alongside clinical information offers a chance to further optimise therapeutic decision making.",0,0
5061,"Predicting prognosis and IDH mutation status for patients with lower-grade gliomas using whole slide images. We developed end-to-end deep learning models using whole slide images of adults diagnosed with diffusely infiltrating, World Health Organization (WHO) grade 2 gliomas to predict prognosis and the mutation status of a somatic biomarker, isocitrate dehydrogenase (IDH) 1/2. The models, which utilize ResNet-18 as a backbone, were developed and validated on 296 patients from The Cancer Genome Atlas (TCGA) database. To account for the small sample size, repeated random train/test splits were performed for hyperparameter tuning, and the out-of-sample predictions were pooled for evaluation. Our models achieved a concordance- (C-) index of 0.715 (95% CI: 0.569, 0.830) for predicting prognosis and an area under the curve (AUC) of 0.667 (0.532, 0.784) for predicting IDH mutations. When combined with additional clinical information, the performance metrics increased to 0.784 (95% CI: 0.655, 0.880) and 0.739 (95% CI: 0.613, 0.856), respectively. When evaluated on the WHO grade 3 gliomas from the TCGA dataset, which were not used for training, our models predicted survival with a C-index of 0.654 (95% CI: 0.537, 0.768) and IDH mutations with an AUC of 0.814 (95% CI: 0.721, 0.897). If validated in a prospective study, our method could potentially assist clinicians in managing and treating patients with diffusely infiltrating gliomas.",0,0
5063,"A deep learning approach to automatic gingivitis screening based on classification and localization in RGB photos. Routine dental visit is the most common approach to detect the gingivitis. However, such diagnosis can sometimes be unavailable due to the limited medical resources in certain areas and costly for low-income populations. This study proposes to screen the existence of gingivitis and its irritants, i.e., dental calculus and soft deposits, from oral photos with a novel Multi-Task Learning convolutional neural network (CNN) model. The study can be meaningful for promoting the public dental health, since it sheds light on a cost-effective and ubiquitous solution for the early detection of dental issues. With 625 patients included in this study, the classification Area Under the Curve (AUC) for detecting gingivitis, dental calculus and soft deposits were 87.11%, 80.11%, and 78.57%, respectively; Meanwhile, according to our experiments, the model can also localize the three types of findings on oral photos with moderate accuracy, which enables the model to explain the screen results. By comparing to general-purpose CNNs, we showed our model significantly outperformed on both classification and localization tasks, which indicates the effectiveness of Multi-Task Learning on dental disease detection. In all, the study shows the potential of deep learning for enabling the screening of dental diseases among large populations.",0,0
5064,"Machine learning approach to dynamic risk modeling of mortality in COVID-19: a UK Biobank study. The COVID-19 pandemic has created an urgent need for robust, scalable monitoring tools supporting stratification of high-risk patients. This research aims to develop and validate prediction models, using the UK Biobank, to estimate COVID-19 mortality risk in confirmed cases. From the 11,245 participants testing positive for COVID-19, we develop a data-driven random forest classification model with excellent performance (AUC: 0.91), using baseline characteristics, pre-existing conditions, symptoms, and vital signs, such that the score could dynamically assess mortality risk with disease deterioration. We also identify several significant novel predictors of COVID-19 mortality with equivalent or greater predictive value than established high-risk comorbidities, such as detailed anthropometrics and prior acute kidney failure, urinary tract infection, and pneumonias. The model design and feature selection enables utility in outpatient settings. Possible applications include supporting individual-level risk profiling and monitoring disease progression across patients with COVID-19 at-scale, especially in hospital-at-home settings.",0,0
5066,Diagnostic performance of an algorithm for automated large vessel occlusion detection on CT angiography. Machine learning algorithms hold the potential to contribute to fast and accurate detection of large vessel occlusion (LVO) in patients with suspected acute ischemic stroke. We assessed the diagnostic performance of an automated LVO detection algorithm on CT angiography (CTA).,0,0
5071,Characterization of Benign and Malignant Pancreatic Lesions with DECT Quantitative Metrics and Radiomics. To compare dual energy CT (DECT) quantitative metrics and radiomics for differentiating benign and malignant pancreatic lesions on contrast enhanced abdomen CT.,0,0
5075,"AIOSA: An approach to the automatic identification of obstructive sleep apnea events based on deep learning. Obstructive Sleep Apnea Syndrome (OSAS) is the most common sleep-related breathing disorder. It is caused by an increased upper airway resistance during sleep, which determines episodes of partial or complete interruption of airflow. The detection and treatment of OSAS is particularly important in patients who suffered a stroke, because the presence of severe OSAS is associated with higher mortality, worse neurological deficits, worse functional outcome after rehabilitation, and a higher likelihood of uncontrolled hypertension. The gold standard test for diagnosing OSAS is polysomnography (PSG). Unfortunately, performing a PSG in an electrically hostile environment, like a stroke unit, on neurologically impaired patients is a difficult task; moreover, the number of strokes per day vastly outnumbers the availability of polysomnographs and dedicated healthcare professionals. Hence, a simple and automated recognition system to identify OSAS cases among acute stroke patients, relying on routinely recorded vital signs, is highly desirable. The vast majority of the work done so far focuses on data recorded in ideal conditions and highly selected patients, and thus it is hardly exploitable in real-life circumstances, where it would be of actual use. In this paper, we propose a novel convolutional deep learning architecture able to effectively reduce the temporal resolution of raw waveform data, like physiological signals, extracting key features that can be used for further processing. We exploit models based on such an architecture to detect OSAS events in stroke unit recordings obtained from the monitoring of unselected patients. Unlike existing approaches, annotations are performed at one-second granularity, allowing physicians to better interpret the model outcome. Results are considered to be satisfactory by the domain experts. Moreover, through tests run on a widely-used public OSAS dataset, we show that the proposed approach outperforms current state-of-the-art solutions.",0,0
5076,"Circumpapillary OCT-focused hybrid learning for glaucoma grading using tailored prototypical neural networks. Glaucoma is one of the leading causes of blindness worldwide and Optical Coherence Tomography (OCT) is the quintessential imaging technique for its detection. Unlike most of the state-of-the-art studies focused on glaucoma detection, in this paper, we propose, for the first time, a novel framework for glaucoma grading using raw circumpapillary B-scans. In particular, we set out a new OCT-based hybrid network which combines hand-driven and deep learning algorithms. An OCT-specific descriptor is proposed to extract hand-crafted features related to the retinal nerve fibre layer (RNFL). In parallel, an innovative CNN is developed using skip-connections to include tailored residual and attention modules to refine the automatic features of the latent space. The proposed architecture is used as a backbone to conduct a novel few-shot learning based on static and dynamic prototypical networks. The k-shot paradigm is redefined giving rise to a supervised end-to-end system which provides substantial improvements discriminating between healthy, early and advanced glaucoma samples. The training and evaluation processes of the dynamic prototypical network are addressed from two fused databases acquired via Heidelberg Spectralis system. Validation and testing results reach a categorical accuracy of 0.9459 and 0.8788 for glaucoma grading, respectively. Besides, the high performance reported by the proposed model for glaucoma detection deserves a special mention. The findings from the class activation maps are directly in line with the clinicians' opinion since the heatmaps pointed out the RNFL as the most relevant structure for glaucoma diagnosis.",0,0
5081,"The Physiological Deep Learner: First application of multitask deep learning to predict hypotension in critically ill patients. Critical care clinicians are trained to analyze simultaneously multiple physiological parameters to predict critical conditions such as hemodynamic instability. We developed the Multi-task Learning Physiological Deep Learner (MTL-PDL), a deep learning algorithm that predicts simultaneously the mean arterial pressure (MAP) and the heart rate (HR). In an external validation dataset, our model exhibited very good calibration: R<sup>2</sup> of 0.747 (95% confidence interval, 0.692 to 0.794) and 0.850 (0.815 to 0.879) for respectively, MAP and HR prediction 60-minutes ahead of time. For acute hypotensive episodes defined as a MAP below 65Â mmHg for 5Â min, our MTL-PDL reached a predictive value of 90% for patients at very high risk (predicted MAP â‰¤ 60Â mmHg) and 2â€° for patients at low risk (predicted MAP >70Â mmHg). Based on its excellent prediction performance, the Physiological Deep Learner has the potential to help the clinician proactively adjust the treatment in order to avoid hypotensive episodes and end-organ hypoperfusion.",0,0
5082,"A progressive deep wavelet cascade classification model for epilepsy detection. Automatic epileptic seizure detection according to EEG recordings is helpful for neurologists to identify an epilepsy occurrence in the initial anti-epileptic treatment. To quickly and accurately detect epilepsy, we proposed a progressive deep wavelet cascade classification model (PDWC) based on the discrete wavelet transform (DWT) and Random Forest (RF). Different from current deep networks, the PDWC mimics the progressive object identification process of human beings with recognition cycles. In every cycle, enhanced wavelet energy features at a specific scale were extracted by DWT and input into a set of cascade RF classifiers to realize one recognition. The recognition accuracy of PDWC is gradually improved by the fusion of classification results produced by multiple recognition cycles. Moreover, the cascade structure of PDWC can be automatically determined by the classification accuracy increment between layers. To verify the performance of the PDWC, we respectively applied five traditional schemes and four deep learning schemes to four public datasets. The results show that the PDWC is not only superior than five traditional schemes, including KNN, Bayes, DT, SVM, and RF, but also better than deep learning methods, i.e. convolutional neural network (CNN), Long Short-Term Memory (LSTM), multi-Grained Cascade Forest (gcForest) and wavelet cascade model (WCM). The mean accuracy of PDWC for all subjects of all datasets reaches to 0.9914. With a flexible structure and less parameters, the PDWC is more suitable for the epilepsy detection of diverse EEG signals.",0,0
5084,"An explainable AI system for automated COVID-19 assessment and lesion categorization from CT-scans. COVID-19 infection caused by SARS-CoV-2 pathogen has been a catastrophic pandemic outbreak all over the world, with exponential increasing of confirmed cases and, unfortunately, deaths. In this work we propose an AI-powered pipeline, based on the deep-learning paradigm, for automated COVID-19 detection and lesion categorization from CT scans. We first propose a new segmentation module aimed at automatically identifying lung parenchyma and lobes. Next, we combine the segmentation network with classification networks for COVID-19 identification and lesion categorization. We compare the model's classification results with those obtained by three expert radiologists on a dataset of 166 CT scans. Results showed a sensitivity of 90.3% and a specificity of 93.5% for COVID-19 detection, at least on par with those yielded by the expert radiologists, and an average lesion categorization accuracy of about 84%. Moreover, a significant role is played by prior lung and lobe segmentation, that allowed us to enhance classification performance by over 6 percent points. The interpretation of the trained AI models reveals that the most significant areas for supporting the decision on COVID-19 identification are consistent with the lesions clinically associated to the virus, i.e., crazy paving, consolidation and ground glass. This means that the artificial models are able to discriminate a positive patient from a negative one (both controls and patients with interstitial pneumonia tested negative to COVID) by evaluating the presence of those lesions into CT scans. Finally, the AI models are integrated into a user-friendly GUI to support AI explainability for radiologists, which is publicly available at http://perceivelab.com/covid-ai. The whole AI system is unique since, to the best of our knowledge, it is the first AI-based software, publicly available, that attempts to explain to radiologists what information is used by AI methods for making decisions and that proactively involves them in the decision loop to further improve the COVID-19 understanding.",1,1
5085,"Fully-channel regional attention network for disease-location recognition with tongue images. Using the deep learning model to realize tongue image-based disease location recognition and focus on solving two problems: 1. The ability of the general convolution network to model detailed regional tongue features is weak; 2. Ignoring the group relationship between convolution channels, which caused the high redundancy of the model.",0,0
5086,"A novel convolutional neural network for reconstructing surface electrocardiograms from intracardiac electrograms and vice versa. We propose a novel convolutional neural network framework for mapping a multivariate input to a multivariate output. In particular, we implement our algorithm within the scope of 12-lead surface electrocardiogram (ECG) reconstruction from intracardiac electrograms (EGM) and vice versa. The goal of performing this task is to allow for improved point-of-care monitoring of patients with an implanted device to treat cardiac pathologies. We will achieve this goal with 12-lead ECG reconstruction and by providing a new diagnostic tool for classifying five different ECG types. The algorithm is evaluated on a dataset retroactively collected from 14 patients. Correlation coefficients calculated between the reconstructed and the actual ECG show that the proposed convolutional neural network model represents an efficient, accurate, and superior way to synthesize a 12-lead ECG when compared to previous methods. We can also achieve the same reconstruction accuracy with only one EGM lead as input. We also tested the model in a non-patient specific way and saw a reasonable correlation coefficient. The model was also executed in the reverse direction to produce EGM signals from a 12-lead ECG and found that the correlation was comparable to the forward direction. Lastly, we analyzed the features learned in the model and determined that the model learns an overcomplete basis of our 12-lead ECG space. We then use this basis of features to create a new diagnostic tool for classifying different ECG arrhythmia's on the MIT-BIH arrhythmia database with an average accuracy of 0.98.",0,0
5091,Quantitative CT for detecting COVIDâ€‘19 pneumonia in suspected cases. Corona Virus Disease 2019 (COVID-19) is currently a worldwide pandemic and has a huge impact on public health and socio-economic development. The purpose of this study is to explore the diagnostic value of the quantitative computed tomography (CT) method by using different threshold segmentation techniques to distinguish between patients with or without COVID-19 pneumonia.,0,0
5103,TN-USMA Net: Triple normalization-based gastrointestinal stromal tumors classification on multicenter EUS images with ultrasound-specific pretraining and meta attention. Accurate quantification of gastrointestinal stromal tumors' (GISTs) risk stratification on multicenter endoscopic ultrasound (EUS) images plays a pivotal role in aiding the surgical decision-making process. This study focuses on automatically classifying higher-risk and lower-risk GISTs in the presence of a multicenter setting and limited data.,0,0
5107,"Exploring the value of pleural fluid biomarkers for complementary pleural effusion disease examination. Pleural fluid biomarkers are beneficial for the complementary diagnosis of pleural effusion etiologies. This study focuses on the multidimensional evaluation of deep learning to investigate the pleural effusion biomarkers value and the diagnostic utility of combining these markers, in distinguishing pleural effusion etiologies.",0,0
5109,"A deep learning algorithm for automatic detection and classification of acute intracranial hemorrhages in head CT scans. Acute Intracranial hemorrhage (ICH) is a life-threatening disease that requires emergency medical attention, which is routinely diagnosed using non-contrast head CT imaging. The diagnostic accuracy of acute ICH on CT varies greatly among radiologists due to the difficulty of interpreting subtle findings and the time pressure associated with the ever-increasing workload. The use of artificial intelligence technology may help automate the process and assist radiologists for more prompt and better decision-making. In this work, we design a deep learning approach that mimics the interpretation process of radiologists, and combines a 2D CNN model and two sequence models to achieve accurate acute ICH detection and subtype classification. Being developed using the extensive 2019-RSNA Brain CT Hemorrhage Challenge dataset with over 25000 CT scans, our deep learning algorithm can accurately classify the acute ICH and its five subtypes with AUCs of 0.988 (ICH), 0.984 (EDH), 0.992 (IPH), 0.996 (IVH), 0.985 (SAH), and 0.983 (SDH), respectively, reaching the accuracy level of expert radiologists. Our method won 1st place among 1345 teams from 75 countries in the RSNA challenge. We have further evaluated our algorithm on two independent external validation datasets with 75 and 491 CT scans, respectively, and our method maintained high AUCs of 0.964 and 0.949 for acute ICH detection. These results have demonstrated the high performance and robust generalization ability of our proposed method, which makes it a useful second-read or triage tool that can facilitate routine clinical applications.",1,1
5110,"Risk profiles for negative and positive COVID-19 hospitalized patients. COVID-19 is a viral infection that affects people differently, where the majority of cases develop mild symptoms, some people require hospitalization, and unfortunately, a small number of patients perish. Hence, identifying risk factors is critical for physicians to make treatment decisions. The purpose of this article is to determine whether unsupervised analysis of risk factors in positive and negative COVID-19 subjects can aid in the identification of a set of reliable and clinically relevant risk profiles. Positive and negative patients hospitalized were randomly selected from the Mexican Open Registry between March and May 2020. Thirteen risk factors, three distinct outcomes, and COVID-19 test results were used to categorize registry patients. As a result, the dataset was reported via 6144 different risk profiles for each age group. The unsupervised learning method is proposed in this study to discover the most prevalent risk profiles. The data was partitioned into discovery (70%) and validation (30%) sets. The discovery set was analyzed using the partition around medoids (PAM) method, and the stable set of risk profiles was estimated using robust consensus clustering. The PAM models' reliability was validated by predicting the risk profile of subjects from the validation set and patients admitted in November 2020. In the validation set, the clinical relevance of the risk profiles was evaluated by determining the prevalence of three patient outcomes: pneumonia diagnosis, ICU admission, or death. Six positive and five negative COVID-19 risk profiles were identified, with significant statistical differences between them. As a result, PAM clustering with consensus mapping is a viable method for discovering unsupervised risk profiles in subjects with severe respiratory health problems.",0,0
5113,"Supervised line attention for tumor attribute classification from pathology reports: Higher performance with less data. We aim to build an accurate machine learning-based system for classifying tumor attributes from cancer pathology reports in the presence of a small amount of annotated data, motivated by the expensive and time-consuming nature of pathology report annotation. An enriched labeling scheme that includes the location of relevant information along with the final label is used along with a corresponding hierarchical method for classifying reports that leverages these enriched annotations.",0,0
5114,"Longitudinal K-means approaches to clustering and analyzing EHR opioid use trajectories for clinical subtypes. Identification of patient subtypes from retrospective Electronic Health Record (EHR) data is fraught with inherent modeling issues, such as missing data and variable length time intervals, and the results obtained are highly dependent on data pre-processing strategies. As we move towards personalized medicine, assessing accurate patient subtypes will be a key factor in creating patient specific treatment plans. Partitioning longitudinal trajectories from irregularly spaced and variable length time intervals is a well-established, but open problem. In this work, we present and compare k-means approaches for subtyping opioid use trajectories from EHR data. We then interpret the resulting subtypes using decision trees, examining how each subtype is influenced by opioid medication features and patient diagnoses, procedures, and demographics. Finally, we discuss how the subtypes can be incorporated in static machine learning models as features in predicting opioid overdose and adverse events. The proposed methods are general, and can be extended to other EHR prescription dosage trajectories.",0,0
5116,A Machine-Learning Algorithm to Predict the Likelihood of Prolonged Opioid Use Following Arthroscopic Hip Surgery. To develop a machine-learning algorithm and clinician-friendly tool predicting the likelihood of prolonged opioid use (>90 days) following hip arthroscopy.,0,0
5118,"Identification of biomarkers for acute leukemia via machine learning-based stemness index. Traditional methods to understand leukemia stem cell (LSC)'s biological characteristics include constructing LSC-like cells and mouse models by transgenic or knock-in methods. However, there are some potential pitfalls in using this method, such as retroviral insertion mutagenesis, non-physiological level gene expression, non-physiological expansion, and difficulty to construct. The mRNAsi index for each sample of the Cancer Genome Atlas (TCGA) could avoid these potential pitfalls by machine learning. In this work, we aimed to construct a network of LSC genes utilizing the mRNAsi. First, mRNAsi value was analyzed with expressions distributions, survival analysis, age, and gender in acute myeloid leukemia (AML) samples. Then, we used the weighted gene co-expression network analysis (WGCNA) to construct modules of stemness genes. The correlation of the LSC genes transcription and interplay among LSC proteins was analyzed. We performed functional and pathway enrichment analysis to annotate stemness genes. Survival analysis further identified prognostic biomarkers by clinical data of TCGA and the Gene Expression Omnibus (GEO) database. We found that the result of mRNAsi overall survival is not significant, which may be due to the heterogeneity of AML in the stage of myeloid differentiation, French-American-British (FAB) classification systems. Enrichment analysis indicated that the stemness genes were biologically clustered as a group and mainly associated with cell cycle and mitosis. Moreover, 10 key genes (SNRNP40, RFC4, RFC5, CDC6, HSPE1, PA2G4, SNAP23P, DARS2, MIS18A, and HPRT1) were screened by survival analysis with the data from TCGA and GEO. Among them, RFC4 and RFC5 were the distinguished biomarkers for their double-validated prognostic value in both databases. Additionally, the expression of RFC4 and RFC5 had the same trend as mRNAsi score in FAB subtypes. In conclusion, our result demonstrated that mRNAsi based LSC-related genes were found to have strong interactions as a cluster. These genes, especially RFC4 and RFC5, could be the therapeutic targets for inhibiting the stemness characteristics of AML. This work is also a comprehensive pipeline for future cancer stem cell studies.",0,0
5124,"Classification of Autism Spectrum Disorder From EEG-Based Functional Brain Connectivity Analysis. Autism is a psychiatric condition that is typically diagnosed with behavioral assessment methods. Recent years have seen a rise in the number of children with autism. Since this could have serious health and socioeconomic consequences, it is imperative to investigate how to develop strategies for an early diagnosis that might pave the way to an adequate intervention. In this study, the phase-based functional brain connectivity derived from electroencephalogram (EEG) in a machine learning framework was used to classify the children with autism and typical children in an experimentally obtained data set of 12 autism spectrum disorder (ASD) and 12 typical children. Specifically, the functional brain connectivity networks have quantitatively been characterized by graph-theoretic parameters computed from three proposed approaches based on a standard phase-locking value, which were used as the features in a machine learning environment. Our study was successfully classified between two groups with approximately 95.8% accuracy, 100% sensitivity, and 92% specificity through the trial-averaged phase-locking value (PLV) approach and cubic support vector machine (SVM). This work has also shown that significant changes in functional brain connectivity in ASD children have been revealed at theta band using the aggregated graph-theoretic features. Therefore, the findings from this study offer insight into the potential use of functional brain connectivity as a tool for classifying ASD children.",0,0
5127,"A machine learning approach to predict extreme inactivity in COPD patients using non-activity-related clinical data. Facilitating the identification of extreme inactivity (EI) has the potential to improve morbidity and mortality in COPD patients. Apart from patients with obvious EI, the identification of a such behavior during a real-life consultation is unreliable. We therefore describe a machine learning algorithm to screen for EI, as actimetry measurements are difficult to implement. Complete datasets for 1409 COPD patients were obtained from COLIBRI-COPD, a database of clinicopathological data submitted by French pulmonologists. Patient- and pulmonologist-reported estimates of PA quantity (daily walking time) and intensity (domestic, recreational, or fitness-directed) were first used to assign patients to one of four PA groups (extremely inactive [EI], overtly active [OA], intermediate [INT], inconclusive [INC]). The algorithm was developed by (i) using data from 80% of patients in the EI and OA groups to identify 'phenotype signatures' of non-PA-related clinical variables most closely associated with EI or OA; (ii) testing its predictive validity using data from the remaining 20% of EI and OA patients; and (iii) applying the algorithm to identify EI patients in the INT and INC groups. The algorithm's overall error for predicting EI status among EI and OA patients was 13.7%, with an area under the receiver operating characteristic curve of 0.84 (95% confidence intervals: 0.75-0.92). Of the 577 patients in the INT/INC groups, 306 (53%) were reclassified as EI by the algorithm. Patient- and physician- reported estimation may underestimate EI in a large proportion of COPD patients. This algorithm may assist physicians in identifying patients in urgent need of interventions to promote PA.",0,0
5133,"Is there a relationship between fall status, cognition and cerebellar lobule volume in patients with multiple sclerosis? In this prospective case control study, relationship of detailed cerebellar volumetric data and cognition in patients with multiple sclerosis considering falling status using 3â€‰D MRI and network analysis were evaluated. Participants consist of 106 adults with relapsing-remitting multiple sclerosis. Scores of Montreal cognitive assessment test, <b>s</b>ymbol digit modality Test, nine-hole peg test, berg balance scale test, timed up and go test, timed 25-foot walk test were worse in faller group than non faller group (<i>p</i>â€‰<â€‰0.05 for all tests). There was no significant difference in terms of cerebellar lobule volumes between groups. But using artificial intelligence (AI) based network analysis, we brought a new perspective to interpreting the relationship between the cerebellum, cognition, gait, and balance. Overall, data from the study suggest a possible relationship between cerebellar volume changes and cognitive dysfunction through connectivity analysis in patients with multiple sclerosis. Further studies are needed to examine this issue by using connectivity analysis.",0,0
5134,"Novel Artificial Intelligence-based Technology for Chest Computed Tomography Analysis of Idiopathic Pulmonary Fibrosis. There is a growing need to accurately estimate the prognosis of idiopathic pulmonary fibrosis (IPF) in clinical practice, given the development of effective drugs for treating IPF.",0,0
5135,"Machine learning approach to measurement of criticism: The core dimension of expressed emotion. Expressed emotion (EE), a measure of the family's emotional climate, is a fundamental measure in caregiving research. A core dimension of EE is the level of criticism expressed by the caregiver to the care recipient, with a high level of criticism a marker of significant distress in the household. The Five-Minute Speech Sample (FMSS), the most commonly used brief measure of EE, requires time-consuming manual processing and scoring by a highly trained expert. In this study, we used natural language processing and supervised machine learning techniques to develop a fully automated framework to evaluate caregiver criticism level based on the verbatim transcript of the FMSS. The success of the machine learning algorithm was established by demonstrating that the classification of maternal caregivers as high versus low EE was consistent with the classification of these 298 maternal caregivers of adult children with schizophrenia using standard manual coding procedures, with area under the receiver operating characteristic curve (AUROC) of 0.76. Evidence of construct validity was established by demonstrating that maternal caregivers of adults with schizophrenia, who were classified as having a high level of criticism had higher levels of caregiver burden, reported that their child had more psychiatric symptoms and behaviors and perceived that their child had greater control over these symptoms and behaviors. Additionally, maternal caregivers who had high levels of criticism reported having a poorer quality of relationship with their child with schizophrenia than maternal caregivers low on criticism. Rapid measurement of criticism facilitates the incorporation of this dimension into research across a broad range of caregiving contexts. (PsycInfo Database Record (c) 2021 APA, all rights reserved).",0,0
5149,Predicting long-term outcomes of ultrasound-guided percutaneous irrigation of calcific tendinopathy with the use of machine learning. To evaluate the performance of two machine learning models in predicting the long-term complete pain resolution in patients undergoing ultrasound-guided percutaneous irrigation of calcific tendinopathy (US-PICT).,0,0
5150,"Sleep apnea and respiratory anomaly detection from a wearable band and oxygen saturation. Sleep-related respiratory abnormalities are typically detected using polysomnography. There is a need in general medicine and critical care for a more convenient method to detect sleep apnea automaticallyÂ from a simple, easy-to-wear device. The objective was to detect abnormal respiration and estimate the Apnea-Hypopnea Index (AHI) automaticallyÂ with a wearable respiratory device with and without SpO<sub>2</sub> signals using a large (nâ€‰=â€‰412) dataset serving as ground truth.",0,0
5163,"Developing Machine Learning Algorithms to Predict Pulmonary Complications After Emergency Gastrointestinal Surgery. <b>Objective:</b> Investigate whether machine learning can predict pulmonary complications (PPCs) after emergency gastrointestinal surgery in patients with acute diffuse peritonitis. <b>Methods:</b> This is a secondary data analysis study. We use five machine learning algorithms (Logistic regression, DecisionTree, GradientBoosting, Xgbc, and gbm) to predict postoperative pulmonary complications. <b>Results:</b> Nine hundred and twenty-six cases were included in this study; 187 cases (20.19%) had PPCs. The five most important variables for the postoperative weight were preoperative albumin, cholesterol on the 3rd day after surgery, albumin on the day of surgery, platelet count on the 1st day after surgery and cholesterol count on the 1st day after surgery for pulmonary complications. In the test group: the logistic regression model shows AUC = 0.808, accuracy = 0.824 and precision = 0.621; Decision tree shows AUC = 0.702, accuracy = 0.795 and precision = 0.486; The GradientBoosting model shows AUC = 0.788, accuracy = 0.827 and precision = 1.000; The Xgbc model shows AUC = 0.784, accuracy = 0.806 and precision = 0.583. The Gbm model shows AUC = 0.814, accuracy = 0.806 and precision = 0.750. <b>Conclusion:</b> Machine learning algorithms can predict patients' PPCs with acute diffuse peritonitis. Moreover, the results of the importance matrix for the Gbdt algorithm model show that albumin, cholesterol, age, and platelets are the main variables that account for the highest pulmonary complication weights.",0,0
5164,"Prediction of Genetic Factors of Hyperthyroidism Based on Gene Interaction Network. The number of hyperthyroidism patients is increasing these years. As a disease that can lead to cardiovascular disease, it brings great potential health risks to humans. Since hyperthyroidism can induce the occurrence of many diseases, studying its genetic factors will promote the early diagnosis and treatment of hyperthyroidism and its related diseases. Previous studies have used genome-wide association analysis (GWAS) to identify genes related to hyperthyroidism. However, these studies only identify significant sites related to the disease from a statistical point of view and ignore the complex regulation relationship between genes. In addition, mutation is not the only genetic factor of causing hyperthyroidism. Identifying hyperthyroidism-related genes from gene interactions would help researchers discover the disease mechanism. In this paper, we purposed a novel machine learning method for identifying hyperthyroidism-related genes based on gene interaction network. The method, which is called ""RW-RVM,"" is a combination of Random Walk (RW) and Relevance Vector Machines (RVM). RW was implemented to encode the gene interaction network. The features of genes were the regulation relationship between genes and non-coding RNAs. Finally, multiple RVMs were applied to identify hyperthyroidism-related genes. The result of 10-cross validation shows that the area under the receiver operating characteristic curve (AUC) of our method reached 0.9, and area under the precision-recall curve (AUPR) was 0.87. Seventy-eight novel genes were found to be related to hyperthyroidism. We investigated two genes of these novel genes with existing literature, which proved the accuracy of our result and method.",0,0
5169,"Maternal Parenting Stress in the Face of Early Regulatory Disorders in Infancy: A Machine Learning Approach to Identify What Matters Most. <b>Objective:</b> Early regulatory disorders (ERD) in infancy are typically associated with high parenting stress (PS). Theoretical and empirical literature suggests a wide range of factors that may contribute to PS related to ERD. The aim of this study was to identify key predictors of maternal PS within a large predictor data set in a sample of <i>N</i> = 135 mothers of infants diagnosed with ERD. <b>Methods:</b> We used machine learning to identify relevant predictors. Maternal PS was assessed with the Parenting Stress Index. The multivariate dataset assessed cross-sectionally consisted of 464 self-reported and clinically rated variables covering mother-reported psychological distress, maternal self-efficacy, parental reflective functioning, socio-demographics, each parent's history of illness, recent significant life events, former miscarriage/abortion, pregnancy, obstetric history, infants' medical history, development, and social environment. Variables were drawn from behavioral diaries on regulatory symptoms and parental co-regulative behavior as well as a clinical interview which was utilized to diagnose ERD and to assess clinically rated regulatory symptoms, quality of parent-infant relationship, organic/biological and psychosocial risks, and social-emotional functioning. <b>Results:</b> The final prediction model identified 11 important variables summing up to the areas maternal self-efficacy, psychological distress (particularly depression and anger-hostility), infant regulatory symptoms (particularly duration of fussing/crying), and age-appropriate physical development. The RMSE (i.e., prediction accuracy) of the final model applied to the test set was 21.72 (<i>R</i> <sup>2</sup> = 0.58). <b>Conclusions:</b> This study suggests that among behavioral, environmental, developmental, parent-infant relationship, and mental health variables, a mother's higher self-efficacy, psychological distress symptoms particularly depression and anger symptoms, symptoms in the child particularly fussing/crying symptoms, and age-inappropriate physical development are associated with higher maternal PS. With these factors identified, clinicians may more efficiently assess a mother's PS related to ERD in a low-risk help-seeking sample.",0,0
5170,"Multi-Joint Angles Estimation of Forearm Motion Using a Regression Model. To improve the life quality of forearm amputees, prosthetic hands with high accuracy, and robustness are necessary. The application of surface electromyography (sEMG) signals to control a prosthetic hand is challenging. In this study, we proposed a time-domain CNN model for the regression prediction of joint angles in three degrees of freedom (3-DOFs, include two wrist joint motion and one finger joint motion), and five-fold cross validation was used to evaluate the correlation coefficient (CC). The CC value results of wrist flexion/extension motion obtained from 10 participants was 0.87-0.92, pronation/supination motion was 0.72-0.95, and hand grip/open motion was 0.75-0.94. We backtracked the fully connected layer weights to create a geometry plot for analyzing the motion pattern to investigate the learning of the proposed model. In order to discuss the daily updateability of the model by transfer learning, we performed a second experiment on five of the participants in another day and conducted transfer learning based on smaller amount of dataset. The CC results improved (wrist flexion/extension was 0.90-0.97, pronation/supination was 0.84-0.96, hand grip/open was 0.85-0.92), suggesting the effectiveness of the transfer learning by incorporating the small amounts of sEMG data acquired in different days. We compared our CNN-based model with four conventional regression models, the result illustrates that proposed model significantly outperforms the four conventional models with and without transfer learning. The offline result suggests the reliability of the proposed model in real-time control in different days, it can be applied for real-time prosthetic control in the future.",0,0
5174,"Cancer-associated fibroblasts are associated with poor prognosis in solid type of lung adenocarcinoma in a machine learning analysis. Cancer-associated fibroblasts (CAFs) participate in critical processes in the tumor microenvironment, such as extracellular matrix remodeling, reciprocal signaling interactions with cancer cells and crosstalk with infiltrating inflammatory cells. However, the relationships between CAFs and survival are not well known in lung cancer. The aim of this study was to reveal the correlations of CAFs with survival rates, genetic alterations and immune activities. This study reviewed the histological features of 517 patients with lung adenocarcinoma from The Cancer Genome Atlas (TCGA) database. We performed gene set enrichment analysis (GSEA), network-based analysis and survival analysis based on CAFs in four histological types of lung adenocarcinoma: acinar, papillary, micropapillary and solid. We found four hallmark gene sets, the epithelial-mesenchymal transition, angiogenesis, hypoxia, and inflammatory response gene sets, that were associated with the presence of CAFs. CAFs were associated with tumor proliferation, elevated memory CD4+T cells and high CD274 (encoding PD-L1) expression. In the pathway analyses, CAFs were related to blood vessel remodeling, matrix organization, negative regulation of apoptosis and transforming growth factor-Î² signaling. In the survival analysis of each histological type, CAFs were associated with poor prognosis in the solid type. These results may contribute to the development of therapeutic strategies against lung adenocarcinoma cases in which CAFs are present.",0,0
5175,"Predicting pediatric anxiety from the temporal pole using neural responses to emotional faces. A prominent cognitive aspect of anxiety is dysregulation of emotional interpretation of facial expressions, associated with neural activity from the amygdala and prefrontal cortex. We report machine learning analysis of fMRI results supporting a key role for a third area, the temporal pole (TP) for childhood anxiety in this context. This finding is based on differential fMRI responses to emotional faces (angry versus fearful faces) in children with one or more of generalized anxiety, separation anxiety, and social phobia (n = 22) compared with matched controls (n = 23). In our machine learning (Adaptive Boosting) model, the right TP distinguished anxious from control children (accuracy = 81%). Involvement of the TP as significant for neurocognitive aspects of pediatric anxiety is a novel finding worthy of further investigation.",0,0
5178,"Reservoir computing with biocompatible organic electrochemical networks for brain-inspired biosignal classification. Early detection of malign patterns in patients' biological signals can save millions of lives. Despite the steady improvement of artificial intelligence-based techniques, the practical clinical application of these methods is mostly constrained to an offline evaluation of the patients' data. Previous studies have identified organic electrochemical devices as ideal candidates for biosignal monitoring. However, their use for pattern recognition in real time was never demonstrated. Here, we produce and characterize brain-inspired networks composed of organic electrochemical transistors and use them for time-series predictions and classification tasks using the reservoir computing approach. To show their potential use for biofluid monitoring and biosignal analysis, we classify four classes of arrhythmic heartbeats with an accuracy of 88%. The results of this study introduce a previously unexplored paradigm for biocompatible computational platforms and may enable development of ultralow-power consumption hardware-based artificial neural networks capable of interacting with body fluids and biological tissues.",0,0
5189,"Multi-class motor imagery EEG classification method with high accuracy and low individual differences based on hybrid neural network. <i>Objective.</i>Most current methods of classifying different patterns for motor imagery EEG signals require complex pre-processing and feature extraction steps, which consume time and lack adaptability, ignoring individual differences in EEG signals. It is essential to improve algorithm performance with the increased classes and diversity of subjects.<i>Approach.</i>This study introduces deep learning method for end-to-end learning to complete the classification of four-class MI tasks, aiming to improve the recognition rate and balance the classification accuracy among different subjects. A new one-dimensional input data representation method is proposed. This representation method can increase the number of samples and ignore the influence of channel correlation. In addition, a cascade network of convolutional neural network and gated recurrent unit is designed to learn time-frequency information from EEG data without extracting features manually, this model can capture the hidden representations related to different MI mode of each people.<i>Main results</i>. Experiments on BCI Competition 2a dataset and actual collected dataset achieve high accuracy near 99.40% and 92.56%, and the standard deviation is 0.34 and 1.35 respectively. Results demonstrate that the proposed method outperforms the advanced methods and baseline models.<i>Significance.</i>Experimental results show that the proposed method improves the accuracy of multi-classification and overcomes the impact of individual differences on classification by training neural network subject-dependent, which promotes the development of actual brain-computer interface systems.",0,0
5193,"Natural language processing for prediction of readmission in posterior lumbar fusion patients: which free-text notes have the most utility? The increasing volume of free-text notes available in electronic health records has created an opportunity for natural language processing (NLP) algorithms to mine this unstructured data in order to detect and predict adverse outcomes. Given the volume and diversity of documentation available in spine surgery, it remains unclear which types of documentation offer the greatest value for prediction of adverse outcomes.",0,0
5194,"Machine learning-enabled multitrust audit of stroke comorbidities using natural language processing. With the increasing adoption of electronic records in the health system, machine learning-enabled techniques offer the opportunity for greater computer-assisted curation of these data for audit and research purposes. In this project, we evaluate the consistency of traditional curation methods used in routine clinical practice against a new machine learning-enabled tool, MedCAT, for the extraction of the stroke comorbidities recorded within the UK's Sentinel Stroke National Audit Programme (SSNAP) initiative.",0,0
5203,"Modeling the Effects of HIV and Aging on Resting-State Networks using Machine Learning. The relationship between HIV infection, the functional organization of the brain, cognitive impairment, and aging remains poorly understood. Understanding disease progression over the lifespan is vital for the care of people living with HIV (PLWH).",0,0
5212,"An analysis about the function of a new artificial intelligence, CAD EYE with the lesion recognition and diagnosis for colorectal polyps in clinical practice. Recently, CAD EYE (Fujifilm, Tokyo, Japan), an artificial intelligence for the lesion recognition (CADe) and the optical diagnosis (CADx) of colorectal polyps, was released. We evaluated the function of CADe and CADx of CAD EYE.",0,0
5214,Quantitative Assessment of Fundus Tessellated Density and Associated Factors in Fundus Images Using Artificial Intelligence. This study aimed to quantitative assess the fundus tessellated density (FTD) and associated factors on the basis of fundus photographs using artificial intelligence.,0,0
5216,Prediction of impacts on liver enzymes from the exposure of low-dose medical radiations through artificial intelligence algorithms. This study aimed to develop artificial intelligence and machine learning-based models to predict alterations in liver enzymes from the exposure of low annual average effective doses in radiology and nuclear medicine personnel of Institute of Nuclear Medicine and Oncology Hospital.,0,0
5217,"Comparison of Machine Learning Methods for Predicting Outcomes After In-Hospital Cardiac Arrest. Prognostication of neurologic status among survivors of in-hospital cardiac arrests remains a challenging task for physicians. Although models such as the Cardiac Arrest Survival Post-Resuscitation In-hospital score are useful for predicting neurologic outcomes, they were developed using traditional statistical techniques. In this study, we derive and compare the performance of several machine learning models with each other and with the Cardiac Arrest Survival Post-Resuscitation In-hospital score for predicting the likelihood of favorable neurologic outcomes among survivors of resuscitation.",0,0
5218,"Fully-Automated Deep Learning Tool for Sarcopenia Assessment on CT: L1 Versus L3 Vertebral Level Muscle Measurements for Opportunistic Prediction of Adverse Clinical Outcomes. <b>Background:</b> Sarcopenia is associated with adverse clinical outcomes. CT-based skeletal muscle measurements for sarcopenia assessment are most commonly performed at the L3 vertebral level. <b>Objective:</b> To compare the utility of fully-automated deep learning CT-based muscle quantitation at the L1 versus L3 levels for predicting future hip fractures and death. <b>Methods:</b> This retrospective study included 9223 asymptomatic adults (mean age, 57Â±8 years; 4071 men, 5152 women) who underwent unenhanced low-dose abdominal CT. A previously validated fully-automated deep learning tool was used to assess muscle for myosteatosis (mean attenuation) and myopenia (cross-sectional area) at the L1 and L3 levels. Performance for predicting hip fractures and death was compared between L1 and L3 measures. Performance for predicting hip fractures and death was also evaluated using established clinical risk scores [FRAX score and Framingham risk score (FRS), respectively]. <b>Results:</b> Median clinical follow-up interval after CT was 8.8 years (interquartile range, 5.1-11.6 years), yielding hip fractures and death in 219 (2.4%) and 549 (6.0%) patients, respectively. L1- and L3-muscle attenuation were not different in 2-year AUC, 5-year AUC, or 10-year AUC for hip fracture (p=.12-.98) or death (p=.19-.95). For hip fracture, 5-year ROC for L1-muscle attenuation, L3-muscle attenuation, and FRAX score were 0.717, 0.709, and 0.710, respectively. For death, 5-year ROC for L1-muscle attenuation, L3-muscle attenuation, and FRS were 0.737, 0.721, and 0.688 respectively. Lowest quartile hazard ratios (HR) for hip fracture were 2.20 (L1 attenuation), 2.45 (L3 attenuation), and 2.53 (FRAX score), and for death were 3.25 (L1 attenuation), 3.58, (L3 attenuation), and 2.82 (FRS). CT-based muscle cross-sectional area measurements at L1 and L3 were less predictive for hip fracture and death (5-year ROC â‰¤0.571; HR â‰¤1.56). <b>Conclusion:</b> Automated CT-based measurements of muscle attenuation for myosteatosis at the L1 level compare favorably with previously-established L3 level measurements and clinical risk scores for predicting hip fractures and death. Assessment for myopenia was less predictive of outcomes at both levels. <b>Clinical Impact:</b> Alternative use of the L1 rather than L3 level for CT-based muscle measurements allows sarcopenia assessment using both chest and abdominal CT scans, greatly increasing the potential yield of opportunistic CT screening.",0,1
5223,"Prediction of hand-wrist maturation stages based on cervical vertebrae images using artificial intelligence. To predict the hand-wrist maturation stages based on the cervical vertebrae (CV) images, and to analyse the accuracy of the proposed algorithms.",0,0
5224,"MRI pulse sequence integration for deep-learning-based brain metastases segmentation. Magnetic resonance (MR) imaging is an essential diagnostic tool in clinical medicine. Recently, a variety of deep-learning methods have been applied to segmentation tasks in medical images, with promising results for computer-aided diagnosis. For MR images, effectively integrating different pulse sequences is important to optimize performance. However, the best way to integrate different pulse sequences remains unclear. In addition, networks trained with a certain subset of pulse sequences as input are unable to perform when given a subset of those pulse sequences. In this study, we evaluate multiple architectural features and characterize their effects in the task of metastasis segmentation while creating a method to robustly train a network to be able to work given any strict subset of the pulse sequences available during training.",0,0
5226,"Toward a machine learning model for a primary diagnosis of Guillain-BarrÃ© syndrome subtypes. Guillain-BarrÃ© Syndrome (GBS) is a neurological disorder affecting people of any age and sex, mainly damaging the peripheral nervous system. GBS is divided into several subtypes, in which only four are the most common, demanding different treatments. Identifying the subtype is an expensive and time-consuming task. Early GBS detection is crucial to save the patient's life and not aggravate the disease. This work aims to provide a primary screening tool for GBS subtypes fast and efficiently without complementary invasive methods, based only on clinical variables prospected in consultation, taken from clinical history, and based on risk factors. We conducted experiments with four classifiers with different approaches, five different filters for feature selection, six wrappers, and One versus All (OvA) classification. For the experiments, we used a data set that includes 129 records of Mexican patients and 26 clinical representative variables. Random Forest filter obtained the best results in each classifier for the diagnosis of the four subtypes, in the same way, this filter with the SVM classifier achieved the best result (0.6840). OvA with SVM classifier reached a balanced accuracy of 0.8884 for the Miller-Fisher (MF) subtype.",0,0
5229,A Deep Learning Approach for Histopathological Diagnosis of Onychomycosis: Not Inferior to Analogue Diagnosis by Histopathologists. Onychomycosis is common. Diagnosis can be confirmed by various methods; a commonly used method is the histological examination of nail clippings. A deep learning system was developed and its diagnostic accuracy compared with that of human experts. A dataset with annotations for fungal elements was used to train an artificial intelligence (AI) model. In a second dataset (n=199) the diagnostic accuracy of the AI was compared with that of dermatopathologists. The results show a non-inferiority of the deep learning system to that of analogue diagnosis (non-inferiority margin 5%) with respect to specificity and the area under the receiver operating characteristic curve (AUC). The AI achieved an AUC of 0.981. One limitation of this system is the need for a large number of training images. The AI had difficulty recognizing spores and confused serum or aggregated bacteria with fungal elements. Use of this deep learning system in dermatopathology routine might help to diagnose onychomycosis more efficiently.,1,1
5231,"Neural Style Transfer as Data Augmentation for Improving COVID-19 Diagnosis Classification. Coronavirus disease 2019 (COVID-19) has accounted for millions ofÂ causalities. While it affects not only individuals but also our collective healthcare and economic systems, testing is insufficient and costly hampering efforts to deal with the pandemic. Chest X-rays are routine radiographic imaging tests that are used for the diagnosis of respiratory conditions such as pneumonia and COVID-19. Convolutional neural networks have shown promise to be effective at classifying X-rays for assisting diagnosis of conditions; however, achieving robust performance demanded in most modern medical applications typically requires a large number of samples. While there exist datasets containing thousands of X-ray images of patients with healthy and pneumonia diagnoses, because COVID-19 is such a recent phenomenon, there are relatively few confirmed COVID-19 positive chest X-rays openly available to the research community. In this paper, we demonstrate the effectiveness of cycle-generative adversarial network, commonly used for neural style transfer, as a way to augment COVID-19 negative X-ray images to look like COVID-19 positive images for increasing the number of COVID-19 positive training samples. The statistical results show an increase in the mean macro <i>f</i>1-score over 21% on a one-tailed <i>t</i> score = 2.68 and <i>p</i> value = 0.01 to accept our alternative hypothesis for an <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>Î±</mi> <mo>=</mo> <mn>0.05</mn></mrow> </math> . We conclude that this approach, when used in conjunction with standard transfer learning techniques, is effective at improving the performance of COVID-19 classifiers for a variety of common convolutional neural networks.",0,0
5233,"Artificial Intelligence-Based Application Provides Accurate Medical Triage Advice When Compared to Consensus Decisions of Healthcare Providers. Accurate medical triage is essential for improving patient outcomes and efficient healthcare delivery. Patients increasingly rely on artificial intelligence (AI)-based applications to access healthcare information, including medical triage advice. We assessed the accuracy of triage decisions provided by an AI-based application. We presented 50 clinical vignettes to the AI-based application, seven emergency medicine providers, and five internal medicine physicians. We compared the triage decisions of the AI-based application to those of the individual providers as well as their consensus decisions. When compared to the human clinicians' consensus triage decisions, the AI-based application performed equal or better than individual human clinicians.",1,1
5235,"A comparison of machine learning classifiers for pediatric epilepsy using resting-state functional MRI latency data. Epilepsy affects 1 in 150 children under the age of 10 and is the most common chronic pediatric neurological condition; poor seizure control can irreversibly disrupt normal brain development. The present study compared the ability of different machine learning algorithms trained with resting-state functional MRI (rfMRI) latency data to detect epilepsy. Preoperative rfMRI and anatomical MRI scans were obtained for 63 patients with epilepsy and 259 healthy controls. The normal distribution of latency z-scores from the epilepsy and healthy control cohorts were analyzed for overlap in 36 seed regions. In these seed regions, overlap between the study cohorts ranged from 0.44-0.58. Machine learning features were extracted from latency z-score maps using principal component analysis. Extreme Gradient Boosting (XGBoost), Support Vector Machines (SVM), and Random Forest algorithms were trained with these features. Area under the receiver operating characteristics curve (AUC), accuracy, sensitivity, specificity and F1-scores were used to evaluate model performance. The XGBoost model outperformed all other models with a test AUC of 0.79, accuracy of 74%, specificity of 73%, and a sensitivity of 77%. The Random Forest model performed comparably to XGBoost across multiple metrics, but it had a test sensitivity of 31%. The SVM model did not perform >70% in any of the test metrics. The XGBoost model had the highest sensitivity and accuracy for the detection of epilepsy. Development of machine learning algorithms trained with rfMRI latency data could provide an adjunctive method for the diagnosis and evaluation of epilepsy with the goal of enabling timely and appropriate care for patients.",0,0
5236,"INTRACRANIAL VESSEL WALL SEGMENTATION FOR ATHEROSCLEROTIC PLAQUE QUANTIFICATION. Intracranial vessel wall segmentation is critical for the quantitative assessment of intracranial atherosclerosis based on magnetic resonance vessel wall imaging. This work further improves on a previous 2D deep learning segmentation network by the utilization of 1) a 2.5D structure to balance network complexity and regularizing geometry continuity; 2) a UNET++ model to achieve structure adaptation; 3) an additional approximated Hausdorff distance (HD) loss into the objective to enhance geometry conformality; and 4) landing in a commonly used morphological measure of plaque burden - the normalized wall index (NWI) - to match the clinical endpoint. The modified network achieved Dice similarity coefficient of 0.9172 Â± 0.0598 and 0.7833 Â± 0.0867, HD of 0.3252 Â± 0.5071 mm and 0.4914 Â± 0.5743 mm, mean surface distance of 0.0940 Â± 0.0781 mm and 0.1408 Â± 0.0917 mm for the lumen and vessel wall, respectively. These results compare favorably to those obtained by the original 2D UNET on all segmentation metrics. Additionally, the proposed segmentation network reduced the mean absolute error in NWI from 0.0732 Â± 0.0294 to 0.0725 Â± 0.0333.",0,0
5239,"Evaluation of focus and deep learning methods for automated image grading and factors influencing image quality in adaptive optics ophthalmoscopy. Adaptive optics flood illumination ophthalmoscopy (AO-FIO) is an established imaging tool in the investigation of retinal diseases. However, the clinical interpretation of AO-FIO images can be challenging due to varied image quality. Therefore, image quality assessment is essential before interpretation. An image assessment tool will also assist further work on improving the image quality, either during acquisition or post processing. In this paper, we describe, validate and compare two automated image quality assessment methods; the energy of Laplacian focus operator (LAPE; not commonly used but easily implemented) and convolutional neural network (CNN; effective but more complex approach). We also evaluate the effects of subject age, axial length, refractive error, fixation stability, disease status and retinal location on AO-FIO image quality. Based on analysis of 10,250 images of 50â€‰Ã—â€‰50Â Î¼m size, at 41 retinal locations, from 50 subjects we demonstrate that CNN slightly outperforms LAPE in image quality assessment. CNN achieves accuracy of 89%, whereas LAPE metric achieves 73% and 80% (for a linear regression and random forest multiclass classifier methods, respectively) compared to ground truth. Furthermore, the retinal location, age and disease are factors that can influence the likelihood of poor image quality.",0,0
5241,"Deep forest model for diagnosing COVID-19 from routine blood tests. The Coronavirus Disease 2019 (COVID-19) global pandemic has threatened the lives of people worldwide and posed considerable challenges. Early and accurate screening of infected people is vital for combating the disease. To help with the limited quantity of swab tests, we propose a machine learning prediction model to accurately diagnose COVID-19 from clinical and/or routine laboratory data. The model exploits a new ensemble-based method called the deep forest (DF), where multiple classifiers in multiple layers are used to encourage diversity and improve performance. The cascade level employs the layer-by-layer processing and is constructed from three different classifiers: extra trees, XGBoost, and LightGBM. The prediction model was trained and evaluated on two publicly available datasets. Experimental results show that the proposed DF model has an accuracy of 99.5%, sensitivity of 95.28%, and specificity of 99.96%. These performance metrics are comparable to other well-established machine learning techniques, and hence DF model can serve as a fast screening tool for COVID-19 patients at places where testing is scarce.",0,0
5243,"Deep learning with convolutional neural network for estimation of the characterisation of coronary plaques: Validation using IB-IVUS. Deep learning approaches have shown high diagnostic performance in image classifications, such as differentiation of malignant tumors and calcified coronary plaque. However, it is unknown whether deep learning is useful for characterizing coronary plaques without the presence of calcification using coronary computed tomography angiography (CCTA). The purpose of this study was to compare the diagnostic performance of deep learning with a convolutional neural network (CNN) with that of radiologists in the estimation of coronary plaques.",1,1
5244,Clinical evaluation of a deep-learning-based computer-aided detection system for the detection of pulmonary nodules in a large teaching hospital. To evaluate a deep-learning-based computer-aided detection (DL-CAD) software system for pulmonary nodule detection on computed tomography (CT) images and assess its added value in the clinical practice of a large teaching hospital.,0,0
5248,"Machine learning identifies ICU outcome predictors in a multicenter COVID-19 cohort. Intensive Care Resources are heavily utilized during the COVID-19 pandemic. However, risk stratification and prediction of SARS-CoV-2 patient clinical outcomes upon ICU admission remain inadequate. This study aimed to develop a machine learning model, based on retrospective & prospective clinical data, to stratify patient risk and predict ICU survival and outcomes.",0,0
5249,"Deep learning method for prediction of patient-specific dose distribution in breast cancer. Patient-specific dose prediction improves the efficiency and quality of radiation treatment planning and reduces the time required to find the optimal plan. In this study, a patient-specific dose prediction model was developed for a left-sided breast clinical case using deep learning, and its performance was compared with that of conventional knowledge-based planning using RapidPlanâ„¢.",0,0
5251,Artificial intelligence and placental DNA methylation: newborn prediction and molecular mechanisms of autism in preterm children. Autism Spectrum Disorder (ASD) represents a heterogeneous group of disorders with a complex genetic and epigenomic etiology. DNA methylation is the most extensively studied epigenomic mechanism and correlates with altered gene expression. Artificial intelligence (AI) is a powerful tool for group segregation and for handling the large volume of data generated in omics experiments.,0,0
5253,"Imaging and artificial intelligence for progression of age-related macular degeneration. Age-related macular degeneration (AMD) is a leading cause of severe vision loss. With our aging population, it may affect 288 million people globally by the year 2040. AMD progresses from an early and intermediate dry form to an advanced one, which manifests as choroidal neovascularization and geographic atrophy. Conversion to AMD-related exudation is known as progression to neovascular AMD, and presence of geographic atrophy is known as progression to advanced dry AMD. AMD progression predictions could enable timely monitoring, earlier detection and treatment, improving vision outcomes. Machine learning approaches, a subset of artificial intelligence applications, applied on imaging data are showing promising results in predicting progression. Extracted biomarkers, specifically from optical coherence tomography scans, are informative in predicting progression events. The purpose of this mini review is to provide an overview about current machine learning applications in artificial intelligence for predicting AMD progression, and describe the various methods, data-input types, and imaging modalities used to identify high-risk patients. With advances in computational capabilities, artificial intelligence applications are likely to transform patient care and management in AMD. External validation studies that improve generalizability to populations and devices, as well as evaluating systems in real-world clinical settings are needed to improve the clinical translations of artificial intelligence AMD applications.",0,0
5256,Suicide prediction among men and women with depression: A population-based study. Accurate identification of persons at risk of suicide is challenging because suicide is a rare outcome with a multifactorial origin. The purpose of this study was to predict suicide among persons with depression using machine learning methods.,0,0
5257,"A novel attention-guided convolutional network for the detection of abnormal cervical cells in cervical cancer screening. Early detection of abnormal cervical cells in cervical cancer screening increases the chances of timely treatment. But manual detection requires experienced pathologists and is time-consuming and error prone. Previously, some methods have been proposed for automated abnormal cervical cell detection, whose performance yet remained debatable. Here, we develop an attention feature pyramid network (AttFPN) for automatic abnormal cervical cell detection in cervical cytology images to assist pathologists to make a more accurate diagnosis. Our proposed method consists of two main components. First, an attention module mimicking the way pathologists reading a cervical cytology image. It learns what features to emphasize or suppress by refining extracted features effectively. Second, a multi-scale region-based feature fusion network guided by clinical knowledge to fuse the refined features for detecting abnormal cervical cells at different scales. The region proposals in the multi-scale network are designed according to the clinical knowledge about size and shape distribution of real abnormal cervical cells. Our method, trained and validated with 7030 annotated cervical cytology images, performs better than the state of art deep learning-based methods. The overall sensitivity, specificity, accuracy, and AUC of an independent testing dataset with 3970 cervical cytology images is 95.83%, 94.81%, 95.08% and 0.991, respectively, which is comparable to that of an experienced pathologist with 10 years of experience. Besides, we further validated our method on an external dataset with 110 cases and 35,013 images from a different organization, the case-level sensitivity, specificity, accuracy, and AUC is 91.30%, 90.62%, 90.91% and 0.934, respectively. Average diagnostic time of our method is 0.04s per image, which is much quicker than the average time of pathologists (14.83s per image). Thus, our AttFPN is effective and efficient in cervical cancer screening, and improvement of clinical workflows for the benefit of potential patients. Our code is available at https://github.com/cl2227619761/TCT_Detection.",1,1
5258,"The role of suicide ideation in assessing near-term suicide risk: A machine learning approach. The majority of suicide attempters do not disclose suicide ideation (SI) prior to making an attempt. When reported, SI is nevertheless associated with increased risk of suicide. This paper implemented machine learning (ML) approaches to assess the degree to which current and lifetime SI affect the predictive validity of the Suicide Crisis Syndrome (SCS), an acute condition indicative of imminent risk, for near-term suicidal behaviors (SB ).",0,0
5259,Large Vessel Occlusion Prediction in the Emergency Department with National Institutes of Health Stroke Scale Components: A Machine Learning Approach. To determine the feasibility of using a machine learning algorithm to screen for large vessel occlusions (LVO) in the Emergency Department (ED).,0,0
5260,"Prediction of COVID Criticality Score with Laboratory, Clinical and CT Images using Hybrid Regression Models. Rapid and precise diagnosis of COVID-19 is very critical in hotspot regions. The main aim of this proposed work is to investigate the baseline, laboratory and CT features of COVID-19 affected patients of two groups (Early and Critical stages). The detection model for COVID-19 is built depending upon the manifestations that define the severity of the disease.",0,0
5263,"Deep Learning for Automated Diabetic Retinopathy Screening Fused With Heterogeneous Data From EHRs Can Lead to Earlier Referral Decisions. Fundus images are typically used as the sole training input for automated diabetic retinopathy (DR) classification. In this study, we considered several well-known DR risk factors and attempted to improve the accuracy of DR screening.",0,0
5264,"Colonoscopy polyp detection and classification: Dataset creation and comparative evaluations. Colorectal cancer (CRC) is one of the most common types of cancer with a high mortality rate. Colonoscopy is the preferred procedure for CRC screening and has proven to be effective in reducing CRC mortality. Thus, a reliable computer-aided polyp detection and classification system can significantly increase the effectiveness of colonoscopy. In this paper, we create an endoscopic dataset collected from various sources and annotate the ground truth of polyp location and classification results with the help of experienced gastroenterologists. The dataset can serve as a benchmark platform to train and evaluate the machine learning models for polyp classification. We have also compared the performance of eight state-of-the-art deep learning-based object detection models. The results demonstrate that deep CNN models are promising in CRC screening. This work can serve as a baseline for future research in polyp detection and classification.",0,0
5266,"Automated detection of superficial fungal infections from microscopic images through a regional convolutional neural network. Direct microscopic examination with potassium hydroxide is generally used as a screening method for diagnosing superficial fungal infections. Although this type of examination is faster than other diagnostic methods, it can still be time-consuming to evaluate a complete sample; additionally, it possesses the disadvantage of inconsistent reliability as the accuracy of the reading may differ depending on the performer's skill. This study aims at detecting hyphae more quickly, conveniently, and consistently through deep learning using images obtained from microscopy used in real-world practice. An object detection convolutional neural network, YOLO v4, was trained on microscopy images with magnifications of 100Ã—, 40Ã—, and (100+40)Ã—. The study was conducted at the Department of Dermatology at Veterans Health Service Medical Center, Seoul, Korea between January 1, 2019 and December 31, 2019, using 3,707 images (1,255 images for training, 1,645 images for testing). The average precision was used to evaluate the accuracy of object detection. Precision recall curve analysis was performed for the hyphal location determination, and receiver operating characteristic curve analysis was performed on the image classification. The F1 score, sensitivity, and specificity values were used as measures of the overall performance. The sensitivity and specificity were, respectively, 95.2% and 100% in the 100Ã— data model, and 99% and 86.6% in the 40Ã— data model; the sensitivity and specificity in the combined (100+40)Ã— data model were 93.2% and 89%, respectively. The performance of our model had high sensitivity and specificity, indicating that hyphae can be detected with reliable accuracy. Thus, our deep learning-based autodetection model can detect hyphae in microscopic images obtained from real-world practice. We aim to develop an automatic hyphae detection system that can be utilized in real-world practice through continuous research.",0,0
5279,"Gender Prediction for a Multiethnic Population via Deep Learning Across Different Retinal Fundus Photograph Fields: Retrospective Cross-sectional Study. Deep learning algorithms have been built for the detection of systemic and eye diseases based on fundus photographs. The retina possesses features that can be affected by gender differences, and the extent to which these features are captured via photography differs depending on the retinal image field.",0,0
5280,"Population-based and Personalized Reference Intervals for Liver and Spleen Volumes in Healthy Individuals and Those with Viral Hepatitis. Background Reference intervals guiding volumetric assessment of the liver and spleen have yet to be established. Purpose To establish population-based and personalized reference intervals for liver volume, spleen volume, and liver-to-spleen volume ratio (LSVR). Materials and Methods This retrospective study consecutively included healthy adult liver donors from 2001 to 2013 (reference group) and from 2014 to 2016 (healthy validation group) and patients with viral hepatitis from 2007 to 2017. Liver volume, spleen volume, and LSVR were measured with CT by using a deep learning algorithm. In the reference group, the reference intervals for the volume indexes were determined by using the population-based (ranges encompassing the central 95% of donors) and personalized (quantile regression modeling of the 2.5th and 97.5th percentiles as a function of age, sex, height, and weight) approaches. The validity of the reference intervals was evaluated in the healthy validation group and the viral hepatitis group. Results The reference and healthy validation groups had 2989 donors (mean age Â± standard deviation, 30 years Â± 9; 1828 men) and 472 donors (mean age, 30 years Â± 9; 334 men), respectively. The viral hepatitis group had 158 patients (mean age, 48 years Â± 12; 95 men). The population-based reference intervals were 824.5-1700.0 cm<sup>3</sup> for liver volume, 81.1-322.0 cm<sup>3</sup> for spleen volume, and 3.96-13.78 for LSVR. Formulae and a web calculator <i>(https://i-pacs.com/calculators)</i> were presented to calculate the personalized reference intervals. In the healthy validation group, both the population-based and personalized reference intervals were used to classify the volume indexes of 94%-96% of the donors as falling within the reference interval. In the viral hepatitis group, when compared with the population-based reference intervals, the personalized reference intervals helped identify more patients with volume indexes outside the reference interval (liver volume, 21.5% [34 of 158] vs 13.3% [21 of 158], <i>P</i> = .01; spleen volume, 29.1% [46 of 158] vs 22.2% [35 of 158], <i>P</i> = .01; LSVR, 35.4% [56 of 158] vs 26.6% [42 of 158], <i>P</i> < .001). Conclusion Reference intervals derived from a deep learning approach in healthy adults may enable evidence-based assessments of liver and spleen volume in clinical practice. Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i> See also the editorial by Ringl in this issue.",0,0
5284,Developing machine learning models to personalize care levels among emergency room patients for hospital admission. To develop prediction models for intensive care unit (ICU) vs non-ICU level-of-care need within 24 hours of inpatient admission for emergency department (ED) patients using electronic health record data.,0,0
5285,"Predicting brain function status changes in critically ill patients via Machine learning. In intensive care units (ICUs), a patient's brain function status can shift from a state of acute brain dysfunction (ABD) to one that is ABD-free and vice versa, which is challenging to forecast and, in turn, hampers the allocation of hospital resources. We aim to develop a machine learning model to predict next-day brain function status changes.",0,0
5288,Bimodal multispectral imaging system with cloud-based machine learning algorithm for real-time screening and detection of oral potentially malignant lesions and biopsy guidance. Screening and early detection of oral potentially malignant lesions (OPMLs) are of great significance in reducing the mortality rates associated with head and neck malignancies. Intra-oral multispectral optical imaging of tissues in conjunction with cloud-based machine learning (CBML) can be used to detect oral precancers at the point-of-care (POC) and guide the clinician to the most malignant site for biopsy.,0,0
5289,Fully Automatic Coronary Calcium Score Software Empowered by Artificial Intelligence Technology: Validation Study Using Three CT Cohorts. This study aimed to validate a deep learning-based fully automatic calcium scoring (coronary artery calcium [CAC]_auto) system using previously published cardiac computed tomography (CT) cohort data with the manually segmented coronary calcium scoring (CAC_hand) system as the reference standard.,1,1
5291,"Machine Learning Approach for Active Vaccine Safety Monitoring. Vaccine safety surveillance is important because it is related to vaccine hesitancy, which affects vaccination rate. To increase confidence in vaccination, the active monitoring of vaccine adverse events is important. For effective active surveillance, we developed and verified a machine learning-based active surveillance system using national claim data.",0,0
5293,"Deep learning-based model for diagnosing Alzheimer's disease and tauopathies. This study aimed to develop a deep learning-based model for differentiating tauopathies, including Alzheimer's disease (AD), progressive supranuclear palsy (PSP), corticobasal degeneration (CBD) and Pick's disease (PiD), based on tau-immunostained digital slide images.",0,0
5296,"Automatic contour segmentation of cervical cancer using artificial intelligence. In cervical cancer treatment, radiation therapy is selected based on the degree of tumor progression, and radiation oncologists are required to delineate tumor contours. To reduce the burden on radiation oncologists, an automatic segmentation of the tumor contours would prove useful. To the best of our knowledge, automatic tumor contour segmentation has rarely been applied to cervical cancer treatment. In this study, diffusion-weighted images (DWI) of 98 patients with cervical cancer were acquired. We trained an automatic tumor contour segmentation model using 2D U-Net and 3D U-Net to investigate the possibility of applying such a model to clinical practice. A total of 98 cases were employed for the training, and they were then predicted by swapping the training and test images. To predict tumor contours, six prediction images were obtained after six training sessions for one case. The six images were then summed and binarized to output a final image through automatic contour segmentation. For the evaluation, the Dice similarity coefficient (DSC) and Hausdorff distance (HD) was applied to analyze the difference between tumor contour delineation by radiation oncologists and the output image. The DSC ranged from 0.13 to 0.93 (median 0.83, mean 0.77). The cases with DSC <0.65 included tumors with a maximum diameterâ€‰<â€‰40Â mm and heterogeneous intracavitary concentration due to necrosis. The HD ranged from 2.7 to 9.6Â mm (median 4.7Â mm). Thus, the study confirmed that the tumor contours of cervical cancer can be automatically segmented with high accuracy.",0,0
5299,"Artificial intelligence MacHIne learning for the detection and treatment of atrial fibrillation guidelines in the emergency department setting (AIM HIGHER): Assessing a machine learning clinical decision support tool to detect and treat non-valvular atrial fibrillation in the emergency department. Advanced machine learning technology provides an opportunity to improve clinical electrocardiogram (ECG) interpretation, allowing non-cardiology clinicians to initiate care for atrial fibrillation (AF). The Lucia Atrial Fibrillation Application (Lucia App) photographs the ECG to determine rhythm detection, calculates CHA2DS2-VASc and HAS-BLED scores, and then provides guideline-recommended anticoagulation. Our purpose was to determine the rate of accurate AF identification and appropriate anticoagulation recommendations in emergency department (ED) patients ultimately diagnosed with AF.",0,0
5301,"Machine learning analysis of non-marital sexual violence in India. Machine learning techniques can explore low prevalence data to offer insight into identification of factors associated with non-marital sexual violence (NMSV). NMSV in India is a health and human rights concern that disproportionately affects adolescents, is under-reported, and not well understood or addressed in the country.",0,0
5306,"Volumetric modulated arc therapy dose prediction and deliverable treatment plan generation for prostate cancer patients using a densely connected deep learning model. Radiation therapy treatment planning is a manual, time-consuming task that might be accelerated using machine learning algorithms. In this study, we aimed to evaluate if a triplet-based deep learning model can predict volumetric modulated arc therapy (VMAT) dose distributions for prostate cancer patients.",0,0
5307,"COVID-Nets: deep CNN architectures for detecting COVID-19 using chest CT scans. In this paper we propose two novel deep convolutional network architectures, CovidResNet and CovidDenseNet, to diagnose COVID-19 based on CT images. The models enable transfer learning between different architectures, which might significantly boost the diagnostic performance. Whereas novel architectures usually suffer from the lack of pretrained weights, our proposed models can be partly initialized with larger baseline models like ResNet50 and DenseNet121, which is attractive because of the abundance of public repositories. The architectures are utilized in a first experimental study on the SARS-CoV-2 CT-scan dataset, which contains 4173 CT images for 210 subjects structured in a subject-wise manner into three different classes. The models differentiate between COVID-19, non-COVID-19 viral pneumonia, and healthy samples. We also investigate their performance under three binary classification scenarios where we distinguish COVID-19 from healthy, COVID-19 from non-COVID-19 viral pneumonia, and non-COVID-19 from healthy, respectively. Our proposed models achieve up to 93.87% accuracy, 99.13% precision, 92.49% sensitivity, 97.73% specificity, 95.70% F1-score, and 96.80% AUC score for binary classification, and up to 83.89% accuracy, 80.36% precision, 82.04% sensitivity, 92.07% specificity, 81.05% F1-score, and 94.20% AUC score for the three-class classification tasks. We also validated our models on the COVID19-CT dataset to differentiate COVID-19 and other non-COVID-19 viral infections, and our CovidDenseNet model achieved the best performance with 81.77% accuracy, 79.05% precision, 84.69% sensitivity, 79.05% specificity, 81.77% F1-score, and 87.50% AUC score. The experimental results reveal the effectiveness of the proposed networks in automated COVID-19 detection where they outperform standard models on the considered datasets while being more efficient.",0,0
5308,"A new smart healthcare framework for real-time heart disease detection based on deep and machine learning. Cardiovascular diseases (CVDs) are the most critical heart diseases. Accurate analytics for real-time heart disease is significant. This paper sought to develop a smart healthcare framework (SHDML) by using deep and machine learning techniques based on optimization stochastic gradient descent (SGD) to predict the presence of heart disease. The SHDML framework consists of two stage, the first stage of SHDML is able to monitor the heart beat rate condition of a patient. The SHDML framework to monitor patients in real-time has been developed using an ATmega32 Microcontroller to determine heartbeat rate per minute pulse rate sensors. The developed SHDML framework is able to broadcast the acquired sensor data to a Firebase Cloud database every 20 seconds. The smart application is infectious in regard to displaying the sensor data. The second stage of SHDML has been used in medical decision support systems to predict and diagnose heart diseases. Deep or machine learning techniques were ported to the smart application to analyze user data and predict CVDs in real-time. Two different methods of deep and machine learning techniques were checked for their performances. The deep and machine learning techniques were trained and tested using widely used open-access dataset. The proposed SHDML framework had very good performance with an accuracy of 0.99, sensitivity of 0.94, specificity of 0.85, and F1-score of 0.87.",0,0
5310,"A Novel, Potentially Universal Machine Learning Algorithm to Predict Complications in Total Knee Arthroplasty. There remains a lack of accurate and validated outcome-prediction models in total knee arthroplasty (TKA). While machine learning (ML) is a powerful predictive tool, determining the proper algorithm to apply across diverse data sets is challenging. AutoPrognosis (AP) is a novel method that uses automated ML framework to incorporate the best performing stages of prognostic modeling into a single well-calibrated algorithm. We aimed to compare various ML methods to AP in predictive performance of complications after TKA.",0,0
5312,"Predicting acute suicidal ideation on Instagram using ensemble machine learning models. Online social networking data (SN) is a contextually and temporally rich data stream that has shown promise in the prediction of suicidal thought and behavior. Despite the clear advantages of this digital medium, predictive modeling of acute suicidal ideation (SI) currently remains underdeveloped. SN data, in conjunction with robust machine learning algorithms, may offer a promising way forward.",0,0
5320,Fundus autofluorescence and optical coherence tomography biomarkers associated with the progression of geographic atrophy secondary to age-related macular degeneration. To investigate the impact of qualitatively graded and deep learning quantified imaging biomarkers on growth of geographic atrophy (GA) secondary to age-related macular degeneration.,0,0
5324,"iCOVID: interpretable deep learning framework for early recovery-time prediction of COVID-19 patients. Most prior studies focused on developing models for the severity or mortality prediction of COVID-19 patients. However, effective models for recovery-time prediction are still lacking. Here, we present a deep learning solution named iCOVID that can successfully predict the recovery-time of COVID-19 patients based on predefined treatment schemes and heterogeneous multimodal patient information collected within 48â€‰hours after admission. Meanwhile, an interpretable mechanism termed FSR is integrated into iCOVID to reveal the features greatly affecting the prediction of each patient. Data from a total of 3008 patients were collected from three hospitals in Wuhan, China, for large-scale verification. The experiments demonstrate that iCOVID can achieve a time-dependent concordance index of 74.9% (95% CI: 73.6-76.3%) and an average day error of 4.4 days (95% CI: 4.2-4.6 days). Our study reveals that treatment schemes, age, symptoms, comorbidities, and biomarkers are highly related to recovery-time predictions.",0,0
5325,"Multi-muscle deep learning segmentation to automate the quantification of muscle fat infiltration in cervical spine conditions. Muscle fat infiltration (MFI) has been widely reported across cervical spine disorders. The quantification of MFI requires time-consuming and rater-dependent manual segmentation techniques. A convolutional neural network (CNN) model was trained to segment seven cervical spine muscle groups (left and right muscles segmented separately, 14 muscles total) from Dixon MRI scans (nâ€‰=â€‰17, 17 scans <â€‰2Â weeks post motor vehicle collision (MVC), and 17 scans 12Â months post MVC). The CNN MFI measures demonstrated high test reliability and accuracy in an independent testing dataset (nâ€‰=â€‰18, 9 scans <â€‰2Â weeks post MVC, andÂ 9 scans 12Â months post MVC). Using the CNN in 84 participants with scans <â€‰2Â weeks post MVC (61 females, 23 males, ageâ€‰=â€‰34.2â€‰Â±â€‰10.7Â years) differences in MFI between the muscle groups and relationships between MFI and sex, age, and body mass index (BMI) were explored. Averaging across all muscles, females had significantly higher MFI than males (pâ€‰=â€‰0.026). The deep cervical muscles demonstrated significantly greater MFI than the more superficial muscles (pâ€‰<â€‰0.001), and only MFI within the deep cervical muscles was moderately correlated to age (râ€‰>â€‰0.300, pâ€‰â‰¤â€‰0.001). CNN's allow for the accurate and rapid, quantitative assessment of the composition of theÂ architecturally complex muscles traversing the cervical spine. Acknowledging the wider reports of MFI in cervical spine disorders and the time required to manually segment the individual muscles, this CNN may have diagnostic, prognostic, and predictive value in disorders of the cervical spine.",0,0
5326,"Comparative analysis of machine learning approaches to classify tumor mutation burden in lung adenocarcinoma using histopathology images. Both histologic subtypes and tumor mutation burden (TMB) represent important biomarkers in lung cancer, with implications for patient prognosis and treatment decisions. Typically, TMB is evaluated by comprehensive genomic profiling but this requires use of finite tissue specimens and costly, time-consuming laboratory processes. Histologic subtype classification represents an established component of lung adenocarcinoma histopathology, but can be challenging and is associated with substantial inter-pathologist variability. Here we developed a deep learning system to both classify histologic patterns in lung adenocarcinoma and predict TMB status using de-identified Hematoxylin and Eosin (H&E) stained whole slide images. We first trained a convolutional neural network to map histologic features across whole slide images of lung cancer resection specimens. On evaluation using an external data source, this model achieved patch-level area under the receiver operating characteristic curve (AUC) of 0.78-0.98 across nine histologic features. We then integrated the output of this model with clinico-demographic data to develop an interpretable model for TMB classification. The resulting end-to-end system was evaluated on 172 held out cases from TCGA, achieving an AUC of 0.71 (95% CI 0.63-0.80). The benefit of using histologic features in predicting TMB is highlighted by the significant improvement this approach offers over using the clinical features alone (AUC of 0.63 [95% CI 0.53-0.72], pâ€‰=â€‰0.002). Furthermore, we found that our histologic subtype-based approach achieved performance similar to that of a weakly supervised approach (AUC of 0.72 [95% CI 0.64-0.80]). Together these results underscore that incorporating histologic patterns in biomarker prediction for lung cancer provides informative signals, and that interpretable approaches utilizing these patterns perform comparably with less interpretable, weakly supervised approaches.",0,0
5327,"Automatic detection of pathological myopia using machine learning. Pathological myopia is a severe case of myopia, i.e., nearsightedness. Pathological myopia is also known as degenerative myopia because it ultimately leads to blindness. In pathological myopia, certain myopia-specific pathologies occur at the eye's posterior i.e., Foster-Fuchs's spot, Cystoid degeneration, Liquefaction, Macular degeneration, Vitreous opacities, Weiss's reflex, Posterior staphyloma, etc. This research is aimed at developing a machine learning (ML) approach for the automatic detection of pathological myopia based on fundus images. A deep learning technique of convolutional neural network (CNN) is employed for this purpose. A CNN model is developed in Spyder. The fundus images are first preprocessed. The preprocessed images are then fed to the designed CNN model. The CNN model automatically extracts the features from the input images and classifies the images i.e., normal image or pathological myopia. The best performing CNN model achieved an AUC score of 0.9845. The best validation loss obtained is 0.1457. The results show that the model can be successfully employed to detect pathological myopia from the fundus images.",0,0
5330,"Predicting incident heart failure in women with machine learning: The Women's Health Initiative Cohort. Heart failure (HF) is a leading cause of cardiac morbidity among women, whose risk factors differ from those in men. We used machine learning approaches to develop risk prediction models for incident HF in a cohort of postmenopausal women from the Women's Health Initiative (WHI).",0,0
5336,Development and validation of a novel blending machine learning model for hospital mortality prediction in ICU patients with Sepsis. Early prediction of hospital mortality is crucial for ICU patients with sepsis. This study aimed to develop a novel blending machine learning (ML) model for hospital mortality prediction in ICU patients with sepsis.,0,0
5338,"Deep learning-based predictive biomarker of pathological complete response to neoadjuvant chemotherapy from histological images in breast cancer. Pathological complete response (pCR) is considered a surrogate endpoint for favorable survival in breast cancer patients treated with neoadjuvant chemotherapy (NAC). Predictive biomarkers of treatment response are crucial for guiding treatment decisions. With the hypothesis that histological information on tumor biopsy images could predict NAC response in breast cancer, we proposed a novel deep learning (DL)-based biomarker that predicts pCR from images of hematoxylin and eosin (H&E)-stained tissue and evaluated its predictive performance.",0,0
5339,"Identification of novel biomarkers in Hunner's interstitial cystitis using the CIBERSORT, an algorithm based on machine learning. Â Hunner's interstitial cystitis (HIC) is a complex disorder characterized by pelvic pain, disrupted urine storage, and Hunner lesions seen on cystoscopy. There are few effective diagnostic biomarkers. In the present study, we used the novel machine learning tool CIBERSORT to measure immune cell subset infiltration and potential novel diagnostic biomarkers for HIC.",0,0
5340,"Symptom clusters among cancer survivors: what can machine learning techniques tell us? Knowledge regarding symptom clusters may inform targeted interventions. The current study investigated symptom clusters among cancer survivors, using machine learning techniques on a large data set.",0,0
5350,"Artificial Inteligence-Based Decision for the Prediction of Cardioembolism in Patients with Chagas Disease and Ischemic Stroke. Chagas disease (CD) and ischemic stroke (IS) have a close, but poorly understood, association. There is paucity of evidence on the ideal secondary prophylaxis and etiological determination, with few cardioembolic patients being identified.",0,0
5351,"Deep Bayesian baseline for segmenting diabetic retinopathy lesions: Advances and challenges. Early diagnosis of retinopathy is essential for preventing retinal complications and visual impairment due to diabetes. For the detection of retinopathy lesions from retinal images, several automatic approaches based on deep neural networks have been developed in the recent years. Most of the proposed methods produce point estimates of pixels belonging to the lesion areas and give no or little information on the uncertainty of method predictions. However, the latter can be essential in the examination of the medical condition of the patient when the goal is early detection of abnormalities. This work extends the recent research with a Bayesian framework by considering the parameters of a convolutional neural network as random variables and utilizing stochastic variational dropout based approximation for uncertainty quantification. The framework includes an extended validation procedure and it allows analyzing lesion segmentation distributions, model calibration and prediction uncertainties. Also the challenges related to the deep probabilistic model and uncertainty quantification are presented. The proposed method achieves area under precision-recall curve of 0.84 for hard exudates, 0.641 for soft exudates, 0.593 for haemorrhages, and 0.484 for microaneurysms on IDRiD dataset.",0,0
5353,"Prediction of obstructive sleep apnea using ensemble of recurrence plot convolutional neural networks (RPCNNs) from polysomnography signals. Obstructive Sleep Apnea (OSA) is a common disorder characterized by periodic cessation of breathing during sleep. OSA affects daily life and poses a severe threat to human health. The standard clinical method for identifying and predicting OSA events is the use of Polysomnography signals. In this paper, a novel scheme based on an ensemble of recurrence plots (RPs) and pre-trained convolutional neural networks (RPCNNs) is proposed to improve the prediction rate of OSA. First, RPs were used to represent the dynamic behavior of single electroencephalogram (EEG) and electrocardiogram (ECG) signals for 60Â s before and during OSA events. Then, using RPs, three prompt CNNs named ResNet-50 were fine-tuned, and their classification results were fused via the Majority Voting (MV) method to produce a final result concerning prediction. Next, the subject-independent Leave-One-Subject-Out Cross-Validation (LOSO-CV) and subject-dependent 10-fold Cross-Validation (10-fold CV) methods were used to validate the prediction rate from signals derived from the University College Dublin Sleep Apnea Database. Finally, the highest achieved average accuracy for the fusion level was 91.74% and 89.45% at the 10-fold CV and LOSO-CV. Additionally, our results outperformed state-of-the-art findings and could be recommended to predict and detect other biomedical signals. As a result, this predictive system can also be used to adjust the air pressure in sleep apnea patients' Automatic Positive Airway Pressure (APAP) devices.",0,0
5354,Use of machine learning method on automatic classification of motor subtype of Parkinson's disease based on multilevel indices of rs-fMRI. This study aimed to develop an automatic classifier to distinguish different motor subtypes of Parkinson's disease (PD) based on multilevel indices of resting-state functional magnetic resonance imaging (rs-fMRI).,0,0
5355,"MommiNet-v2: Mammographic multi-view mass identification networks. Many existing approaches for mammogram analysis are based on single view. Some recent DNN-based multi-view approaches can perform either bilateral or ipsilateral analysis, while in practice, radiologists use both to achieve the best clinical outcome. MommiNet is the first DNN-based tri-view mass identification approach, which can simultaneously perform bilateral and ipsilateral analysis of mammographic images, and in turn, can fully emulate the radiologists' reading practice. In this paper, we present MommiNet-v2, with improved network architecture and performance. Novel high-resolution network (HRNet)-based architectures are proposed to learn the symmetry and geometry constraints, to fully aggregate the information from all views for accurate mass detection. A multi-task learning scheme is adopted to incorporate both Breast Imaging-Reporting and Data System (BI-RADS) and biopsy information to train a mass malignancy classification network. Extensive experiments have been conducted on the public DDSM (Digital Database for Screening Mammography) dataset and our in-house dataset, and state-of-the-art results have been achieved in terms of mass detection accuracy. Satisfactory mass malignancy classification result has also been obtained on our in-house dataset.",0,0
5358,"Inter-database validation of a deep learning approach for automatic sleep scoring. Development of inter-database generalizable sleep staging algorithms represents a challenge due to increased data variability across different datasets. Sharing data between different centers is also a problem due to potential restrictions due to patient privacy protection. In this work, we describe a new deep learning approach for automatic sleep staging, and address its generalization capabilities on a wide range of public sleep staging databases. We also examine the suitability of a novel approach that uses an ensemble of individual local models and evaluate its impact on the resulting inter-database generalization performance.",0,0
5361,"Development and Validation of an Arterial Pressure-Based Cardiac Output Algorithm Using a Convolutional Neural Network: Retrospective Study Based on Prospective Registry Data. Arterial pressure-based cardiac output (APCO) is a less invasive method for estimating cardiac output without concerns about complications from the pulmonary artery catheter (PAC). However, inaccuracies of currently available APCO devices have been reported. Improvements to the algorithm by researchers are impossible, as only a subset of the algorithm has been released.",0,0
5362,Semisupervised Deep Learning Techniques for Predicting Acute Respiratory Distress Syndrome From Time-Series Clinical Data: Model Development and Validation Study. A high number of patients who are hospitalized with COVID-19 develop acute respiratory distress syndrome (ARDS).,0,0
5367,"SpindleU-Net: An Adaptive U-Net Framework for Sleep Spindle Detection in Single-Channel EEG. The sleep spindles in EEG have become one type of biomarker used to assess cognitive abilities and related disorders, and thus their detection is crucial for clinical research. This task, traditionally performed by sleep experts, is time-consuming. Many methods have been proposed to automate this process, yet an increase in performance is still expected. Inspired by the application in image segmentation, we propose a point-wise spindle detection method based on the U-Net framework with an attention module (SpindleU-Net). It maps the sequences of arbitrary-length EEG inputs to those of dense labels of spindle or non-spindle on freely chosen intervals. The attention module that focuses on the salient spindle region allows better performance, and a task-specific loss function is defined to alleviate the problem of imbalanced classification. As a deep learning method, SpindleU-Net outperforms state-of-the-art methods on the widely used benchmark dataset of MASS as well as the DREAMS dataset with a small number of samples. On MASS dataset it achieves average F1 scores of 0.854 and 0.803 according to its consistency with the annotations by two sleep experts respectively. On DREAMS dataset, it shows the average F1 score of 0.739. Its cross-dataset performance is also better compared to other methods, showing the good generalization ability for cross-dataset applications.",0,0
5378,"Evaporation-Induced rGO Coatings for Highly Sensitive and Non-Invasive Diagnosis of Prostate Cancer in the PSA Gray Zone. The prostate-specific antigen (PSA) has been widely used for the early diagnosis of prostate cancer during routine check-ups. However, the low sensitivity of regular PSA tests in the PSA gray zone often means that patients are required to undergo further invasive needle biopsy for the diagnosis of prostate cancer, which may lead to potential overdiagnosis and overtreatment. In this study, a circulating tumor cell (CTC)-chip based on an evaporation-induced reduced graphene oxide (rGO) coating is presented, which enables a highly specific and non-invasive diagnosis of prostate cancer in the PSA gray zone. During the evaporation process of the rGO dispersion, the Marangoni effect induces the self-assembly of a hierarchical micro/nanowrinkled rGO coating, which can capture CTCs after subsequent surface modification of capture agents. Compared to the low diagnostic sensitivity (58.3%) of regular PSA tests, a combination of CTC detection and PSA-based hematological tests via machine-learning analysis can greatly upgrade the diagnostic sensitivity of this disease to 91.7% in clinical trial. Therefore, this study provides a non-invasive alternative with high sensitivity for the diagnosis of prostate cancer in the PSA gray zone.",0,0
5380,"A mechatronics data collection, image processing, and deep learning platform for clinical posture analysis: a technical note. Static and dynamic posture analysis was a critical clinical examination in physiotherapy and rehabilitation. It was a time-consuming task for clinicians, so a semi-automatic method can facilitate this process as well as provide well-documented medical records and strong infrastructure for deep learning scenarios. The current research presents a mechatronics platform for static and real-time dynamic posture analysis, which consisted of hybrid computational modules. Our study was a developmental and applied research according to a system development life cycle. The designed modules are as follows: (1) a mechanical structure includes patient place, 360-degree engine, mirror, laser, distance meter, and cams; (2) a software module includes data collection, electronic medical record, semi-automatic image analysis, annotation, and reporting, and (3) a network to exchange raw data with deep learning server. Patients were informed about the research by their healthcare provider and all data were transformed into a Fourier format, in which the patients remained autonomous without a bit of information. The results show acceptable reliability and validity of the instruments. Also, a telerehabilitation application was designed to cover the patients after diagnosis. We suggest a longer time for data acquisition. It will lead to a more accurate and fully automated dynamic posture analysis. The result of this study suggest that the designed mechatronics device used in conjunction with smartphone application is a valid tool that can be used to obtain reliable measurements.",0,0
5383,Estimating the Severity of Visual Field Damage From Retinal Nerve Fiber Layer Thickness Measurements With Artificial Intelligence. The purpose of this study was to assess the accuracy of artificial neural networks (ANN) in estimating the severity of mean deviation (MD) from peripapillary retinal nerve fiber layer (RNFL) thickness measurements derived from optical coherence tomography (OCT).,0,0
5386,"A Data Set and Deep Learning Algorithm for the Detection of Masses and Architectural Distortions in Digital Breast Tomosynthesis Images. Breast cancer screening is among the most common radiological tasks, with more than 39 million examinations performed each year. While it has been among the most studied medical imaging applications of artificial intelligence, the development and evaluation of algorithms are hindered by the lack of well-annotated, large-scale publicly available data sets.",0,0
5388,"Added value of deep learning-based computer-aided diagnosis and shear wave elastography to b-mode ultrasound for evaluation of breast masses detected by screening ultrasound. Low specificity and operator dependency are the main problems of breast ultrasound (US) screening. We investigated the added value of deep learning-based computer-aided diagnosis (S-Detect) and shear wave elastography (SWE) to B-mode US for evaluation of breast masses detected by screening US.Between February 2018 and June 2019, B-mode US, S-Detect, and SWE were prospectively obtained for 156 screening US-detected breast masses in 146 women before undergoing US-guided biopsy. S-Detect was applied for the representative B-mode US image, and quantitative elasticity was measured for SWE. Breast Imaging Reporting and Data System final assessment category was assigned for the datasets of B-mode US alone, B-mode US plus S-Detect, and B-mode US plus SWE by 3 radiologists with varied experience in breast imaging. Area under the receiver operator characteristics curve (AUC), sensitivity, and specificity for the 3 datasets were compared using Delong's method and McNemar test.Of 156 masses, 10 (6%) were malignant and 146 (94%) were benign. Compared to B-mode US alone, the addition of S-Detect increased the specificity from 8%-9% to 31%-71% and the AUC from 0.541-0.545 to 0.658-0.803 in all radiologists (All Pâ€Š<â€Š.001). The addition of SWE to B-mode US also increased the specificity from 8%-9% to 41%-75% and the AUC from 0.541-0.545 to 0.709-0.823 in all radiologists (All Pâ€Š<â€Š.001). There was no significant loss in sensitivity when either S-Detect or SWE were added to B-mode US.Adding S-Detect or SWE to B-mode US improved the specificity and AUC without loss of sensitivity.",1,1
5390,"A Machine Learning-Based Fall Risk Assessment Model for Inpatients. Falls are one of the most common accidents among inpatients and may result in extended hospitalization and increased medical costs. Constructing a highly accurate fall prediction model could effectively reduce the rate of patient falls, further reducing unnecessary medical costs and patient injury. This study applied data mining techniques on a hospital's electronic medical records database comprising a nursing information system to construct inpatient-fall-prediction models for use during various stages of inpatient care. The inpatient data were collected from 15 inpatient wards. To develop timely and effective fall prediction models for inpatients, we retrieved the data of multiple-time assessment variables at four points during hospitalization. This study used various supervised machine learning algorithms to build classification models. Four supervised learning and two classifier ensemble techniques were selected for model development. The results indicated that Bagging+RF classifiers yielded optimal prediction performance at all four points during hospitalization. This study suggests that nursing personnel should be aware of patients' risk factors based on comprehensive fall risk assessment and provide patients with individualized fall prevention interventions to reduce inpatient fall rates.",0,0
5392,"Hubness weighted svm ensemble for prediction of breast cancer subtypes. Breast cancer is a major disease causing panic among women worldwide. Since gene mutations are the root cause for cancer development, analyzing gene expressions can give more insights into various phenotype of cancer treatments. Breast Cancer subtype prediction from gene expression data can provide more information for cancer treatment decisions.",0,0
5399,Predictive modeling of service discontinuation in transitional age youth with recent behavioral health service use. To develop and test predictive models of discontinuation of behavioral health service use within 12â€‰months in transitional age youth with recent behavioral health service use.,0,0
5405,"Identifying elevated risk for future pain crises in sickle-cell disease using photoplethysmogram patterns measured during sleep: A machine learning approach. Transient increases in peripheral vasoconstriction frequently occur in obstructive sleep apnea and periodic leg movement disorder, both of which are common in sickle cell disease (SCD). These events reduce microvascular blood flow and increase the likelihood of triggering painful vaso-occlusive crises (VOC) that are the hallmark of SCD. We recently reported a significant association between the magnitude of vasoconstriction, inferred from the finger photoplethysmogram (PPG) during sleep, and the frequency of future VOC in 212 children with SCD. In this study, we present an improved predictive model of VOC frequency by employing a two-level stacking machine learning (ML) model that incorporates detailed features extracted from the PPG signals in the same database. The first level contains seven different base ML algorithms predicting each subject's pain category based on the input PPG characteristics and other clinical information, while the second level is a meta model which uses the inputs to the first-level model along with the outputs of the base models to produce the final prediction. Model performance in predicting future VOC was significantly higher than in predicting VOC prior to each sleep study (F1-score of 0.43 vs 0.35, p-value < 0.0001), consistent with our hypothesis of a causal relationship between vasoconstriction and future pain incidence, rather than past pain leading to greater propensity for vasoconstriction. The model also performed much better than our previous conventional statistical model (F1=0.33), as well as all other algorithms that used only the base-models for predicting VOC without the second tier meta model. The modest F1 score of the present predictive model was due in part to the relatively small database with substantial imbalance (176:36) between low-pain and high-pain subjects, as well as other factors not captured by the sleep data alone. This report represents the first attempt ever to use noninvasive finger PPG measurements during sleep and a ML-based approach to predict increased propensity for VOC crises in SCD. The promising results suggest the future possibility of embedding an improved version of this model in a low-cost wearable system to assist clinicians in managing long-term therapy for SCD patients.",0,0
5407,"Machine Learning Identifies Clinical andÂ Genetic Factors Associated With Anthracycline Cardiotoxicity in PediatricÂ Cancer Survivors. Despite known clinical risk factors, predicting anthracycline cardiotoxicity remains challenging.",0,0
5409,"Predicting Future Care Requirements Using Machine Learning for Pediatric Intensive and Routine Care Inpatients. Develop and compare separate prediction models for ICU and non-ICU care for hospitalized children in four future time periods (6-12, 12-18, 18-24, and 24-30 hr) and assess these models in an independent cohort and simulated children's hospital.",0,0
5410,"A deep learning approach for monitoring parietal-dominant Alzheimer's disease in World Trade Center responders at midlife. Little is known about the characteristics and causes of early-onset cognitive impairment. Responders to the 2001 New York World Trade Center disaster represent an ageing population that was recently shown to have an excess prevalence of cognitive impairment. Neuroimaging and molecular data demonstrate that a subgroup of affected responders may have a unique form of parietal-dominant Alzheimer's Disease. Recent neuropsychological testing and artificial intelligence approaches have emerged as methods that can be used to identify and monitor subtypes of cognitive impairment. We utilized data from World Trade Center responders participating in a health monitoring program and applied a deep learning approach to evaluate neuropsychological and neuroimaging data to generate a cortical atrophy risk score. We examined risk factors associated with the prevalence and incidence of high risk for brain atrophy in responders who are now at midlife. Training was conducted in a randomly selected two-thirds sample (<i>N</i>â€‰=â€‰99) enrolled using of the results of a structural neuroimaging study. Testing accuracy was estimated for each training cycle in the remaining third subsample. After training was completed, the scoring methodology that was generated was applied to longitudinal data from 1441 World Trade Center responders. The artificial neural network provided accurate classifications of these responders in both the testing (Area Under the Receiver Operating Curve, 0.91) and validation samples (Area Under the Receiver Operating Curve, 0.87). At baseline and follow-up, responders identified as having a high risk of atrophy (<i>nâ€‰</i>=<i>â€‰</i>378) showed poorer cognitive functioning, most notably in domains that included memory, throughput, and variability as compared to their counterparts at low risk for atrophy (<i>nâ€‰</i>=<i>â€‰</i>1063). Factors associated with atrophy risk included older age [adjusted hazard ratio, 1.045 (95% confidence interval = 1.027-1.065)], increased duration of exposure at the WTC site [adjusted hazard ratio, 2.815 (1.781-4.449)], and a higher prevalence of post-traumatic stress disorder [aHR, 2.072 (1.408-3.050)]. High atrophy risk was associated with an increased risk of all-cause mortality [adjusted risk ratio, 3.19 (1.13-9.00)]. In sum, the high atrophy risk group displayed higher levels of previously identified risk factors and characteristics of cognitive impairment, including advanced age, symptoms of post-traumatic stress disorder, and prolonged duration of exposure to particulate matter. Thus, this study suggests that a high risk of brain atrophy may be accurately monitored using cognitive data.",0,0
5411,"Prediction of response to repetitive transcranial magnetic stimulation in phantom sounds based on individual brain anatomy. Non-invasive brain stimulation can reduce the severity of tinnitus phantom sounds beyond the time of stimulation by inducing regional neuroplastic changes. However, there are no good clinical predictors for treatment outcome. We used machine learning to investigate whether brain anatomy can predict therapeutic outcome. Sixty-one chronic tinnitus patients received repetitive transcranial magnetic stimulation of left dorsolateral prefrontal and temporal cortex. Before repetitive transcranial magnetic stimulation, a structural magnetic resonance image was obtained from all patients. To predict individual treatment response in new subjects, we employed a support vector machine ensemble for individual out-of-sample prediction. In the cross-validation, the support vector machine ensemble based on stratified sub-sampling and feature selection yielded an area under the curve of 0.87 for prediction of therapy success in new, previously unseen subjects. This corresponded to a balanced accuracy of 83.5%, sensitivity of 77.2% and specificity of 87.2%. Investigating the most selected features showed the involvement of the auditory cortex but also revealed a network of non-auditory brain areas. These findings suggest that idiosyncratic brain patterns accurately predict individual responses to repetitive transcranial magnetic stimulation treatment for tinnitus. Our findings may hence pave the way for future investigations into the precision treatment of tinnitus, involving automatic identification of the appropriate treatment method for the individual patient.",0,0
5413,"Conditional-GAN Based Data Augmentation for Deep Learning Task Classifier Improvement Using fNIRS Data. Functional near-infrared spectroscopy (fNIRS) is a neuroimaging technique used for mapping the functioning human cortex. fNIRS can be widely used in population studies due to the technology's economic, non-invasive, and portable nature. fNIRS can be used for task classification, a crucial part of functioning with Brain-Computer Interfaces (BCIs). fNIRS data are multidimensional and complex, making them ideal for deep learning algorithms for classification. Deep Learning classifiers typically need a large amount of data to be appropriately trained without over-fitting. Generative networks can be used in such cases where a substantial amount of data is required. Still, the collection is complex due to various constraints. Conditional Generative Adversarial Networks (CGAN) can generate artificial samples of a specific category to improve the accuracy of the deep learning classifier when the sample size is insufficient. The proposed system uses a CGAN with a CNN classifier to enhance the accuracy through data augmentation. The system can determine whether the subject's task is a Left Finger Tap, Right Finger Tap, or Foot Tap based on the fNIRS data patterns. The authors obtained a task classification accuracy of 96.67% for the CGAN-CNN combination.",0,0
5420,"Machine Learning-based Model for Predicting Postoperative Complications among Patients with Colonic Perforation: A Retrospective study. Surgery for colonic perforation has high morbidity and mortality rates. Predicting complications preoperatively would help improve short-term outcomes; however, no predictive risk stratification model exists to date. Therefore, the current study aimed to determine risk factors for complications after colonic perforation surgery and use machine learning to construct a predictive model.",0,0
5425,"Diagnosis of vertebral column pathologies using concatenated resampling with machine learning algorithms. Medical diagnosis through the classification of biomedical attributes is one of the exponentially growing fields in bioinformatics. Although a large number of approaches have been presented in the past, wide use and superior performance of the machine learning (ML) methods in medical diagnosis necessitates significant consideration for automatic diagnostic methods. This study proposes a novel approach called concatenated resampling (CR) to increase the efficacy of traditional ML algorithms. The performance is analyzed leveraging four ML approaches like tree-based ensemble approaches, and linear machine learning approach for automatic diagnosis of inter-vertebral pathologies with increased. Besides, undersampling, over-sampling, and proposed CR techniques have been applied to unbalanced training dataset to analyze the impact of these techniques on the accuracy of each of the classification model. Extensive experiments have been conducted to make comparisons among different classification models using several metrics including accuracy, precision, recall, and <i>F</i> <sub>1</sub> score. Comparative analysis has been performed on the experimental results to identify the best performing classifier along with the application of the re-sampling technique. The results show that the extra tree classifier achieves an accuracy of 0.99 in association with the proposed CR technique.",0,0
5428,"Ability of Procalcitonin and C-Reactive Protein for Discriminating between Bacterial and Enteroviral Meningitis in Children Using Decision Tree. Bacterial meningitis (BM) is a public health burden in developing countries, including Central Asia. This disease is characterized by a high mortality rate and serious neurological complications. Delay with the start of adequate therapy is associated with an increase in mortality for patients with acute bacterial meningitis. Cerebrospinal fluid culture, as a gold standard in bacterial meningitis diagnosis, is time-consuming with modest sensitivity, and this is unsuitable for timely decision-making. It has been shown that bacterial meningitis differentiation from viral meningitis could be done through different parameters such as clinical signs and symptoms, laboratory values, such as PCR, including blood and cerebrospinal fluid (CSF) analysis. In this study, we proposed the method for distinguishing the bacterial form of meningitis from enteroviral one. The method is based on the machine learning process deriving making decision rules. The proposed fast-and-frugal trees (FFTree) decision tree approach showed an ability to determine procalcitonin and C-reactive protein (CRP) with cut-off values for distinguishing between bacterial and enteroviral meningitis (EVM) in children. Such a method demonstrated 100% sensitivity, 96% specificity, and 98% accuracy in the differentiation of all cases of bacterial meningitis in this study. These findings and proposed method may be useful for clinicians to facilitate the decision-making process and optimize the diagnostics of meningitis.",0,0
5435,"Comparable Performance of Deep Learning-Based to Manual-Based Tumor Segmentation in KRAS/NRAS/BRAF Mutation Prediction With MR-Based Radiomics in Rectal Cancer. Radiomic features extracted from segmented tumor regions have shown great power in gene mutation prediction, while deep learning-based (DL-based) segmentation helps to address the inherent limitations of manual segmentation. We therefore investigated whether deep learning-based segmentation is feasible in predicting KRAS/NRAS/BRAF mutations of rectal cancer using MR-based radiomics. In this study, we proposed DL-based segmentation models with 3D V-net architecture. One hundred and eight patients' images (T2WI and DWI) were collected for training, and another 94 patients' images were collected for validation. We evaluated the DL-based segmentation manner and compared it with the manual-based segmentation manner through comparing the gene prediction performance of six radiomics-based models on the test set. The performance of the DL-based segmentation was evaluated by Dice coefficients, which are 0.878 Â± 0.214 and 0.955 Â± 0.055 for T2WI and DWI, respectively. The performance of the radiomics-based model in gene prediction based on DL-segmented VOI was evaluated by AUCs (0.714 for T2WI, 0.816 for DWI, and 0.887 for T2WI+DWI), which were comparable to that of corresponding manual-based VOI (0.637 for T2WI, <i>P</i>=0.188; 0.872 for DWI, <i>P</i>=0.181; and 0.906 for T2WI+DWI, <i>P</i>=0.676). The results showed that 3D V-Net architecture could conduct reliable rectal cancer segmentation on T2WI and DWI images. All-relevant radiomics-based models presented similar performances in KRAS/NRAS/BRAF prediction between the two segmentation manners.",1,1
5436,"CT-Based Pelvic T<sub>1</sub>-Weighted MR Image Synthesis Using UNet, UNet++ and Cycle-Consistent Generative Adversarial Network (Cycle-GAN). Computed tomography (CT) and magnetic resonance imaging (MRI) are the mainstay imaging modalities in radiotherapy planning. In MR-Linac treatment, manual annotation of organs-at-risk (OARs) and clinical volumes requires a significant clinician interaction and is a major challenge. Currently, there is a lack of available pre-annotated MRI data for training supervised segmentation algorithms. This study aimed to develop a deep learning (DL)-based framework to synthesize pelvic T<sub>1</sub>-weighted MRI from a pre-existing repository of clinical planning CTs.",0,0
5437,"Automated image classification of chest X-rays of COVID-19 using deep transfer learning. In December 2019, the city of Wuhan, located in the Hubei province of China became the epicentre of an outbreak of a pandemic called COVID-19 by the World Health Organisation. The detection of this virus by rRTPCR (Real-Time Reverse Transcription-Polymerase Chain Reaction) tests reported high false negative rate. The manifestations of CXR (Chest X-Ray) images contained salient features of the virus. The objective of this paper is to establish the application of an early automated screening model that uses low computational power coupled with raw radiology images to assist the physicians and radiologists in the early detection and isolation of potential positive COVID-19 patients, to stop the rapid spread of the virus in vulnerable countries with limited hospital capacities and low doctor to patient ratio in order to prevent the escalating death rates.",0,0
5438,"Deep Transfer Learning Based Unified Framework for COVID19 Classification and Infection Detection from Chest X-Ray Images. The presentation of the COVID19 has endangered several million lives worldwide causing thousands of deaths every day. Evolution of COVID19 as a pandemic calls for automated solutions for initial screening and treatment management. In addition to the thermal scanning mechanisms, findings from chest X-ray imaging examinations are reliable predictors in COVID19 detection, long-term monitoring and severity evaluation. This paper presents a novel deep transfer learning based framework for COVID19 detection and segmentation of infections from chest X-ray images. It is realized as a two-stage cascaded framework with classifier and segmentation subnetwork models. The classifier is modeled as a fine-tuned residual SqueezeNet network, and the segmentation network is implemented as a fine-tuned SegNet semantic segmentation network. The segmentation task is enhanced with a bioinspired Gaussian Mixture Model-based super pixel segmentation. This framework is trained and tested with two public datasets for binary and multiclass classifications and infection segmentation. It achieves accuracies of 99.69% and 99.48% for binary and three class classifications, and a mean accuracy of 83.437% for segmentation. Experimental results and comparative evaluations demonstrate the superiority of this unified model and signify potential extensions for biomarker definition and severity quantization.",0,0
5439,"An Automated Lightweight Deep Neural Network for Diagnosis of COVID-19 from Chest X-ray Images. Coronavirus (COVID-19) is an epidemic that is rapidly spreading and causing a severe healthcare crisis resulting in more than 40 million confirmed cases across the globe. There are many intensive studies on AI-based technique, which is time consuming and troublesome by considering heavyweight models in terms of more training parameters and memory cost, which leads to higher time complexity. To improve diagnosis, this paper is aimed to design and establish a unique lightweight deep learning-based approach to perform multi-class classification (normal, COVID-19, and pneumonia) and binary class classification (normal and COVID-19) on X-ray radiographs of chest. This proposed CNN scheme includes the combination of three CBR blocks (convolutional batch normalization ReLu) with learnable parameters and one global average pooling (GP) layer and fully connected layer. The overall accuracy of the proposed model achieved 98.33% and finally compared with the pre-trained transfer learning model (DenseNet-121, ResNet-101, VGG-19, and XceptionNet) and recent state-of-the-art model. For validation of the proposed model, several parameters are considered such as learning rate, batch size, number of epochs, and different optimizers. Apart from this, several other performance measures like tenfold cross-validation, confusion matrix, evaluation metrics, sarea under the receiver operating characteristics, kappa score and Mathew's correlation, and Grad-CAM heat map have been used to assess the efficacy of the proposed model. The outcome of this proposed model is more robust, and it may be useful for radiologists for faster diagnostics of COVID-19.",0,0
5440,"Radiologist-Level Two Novel and Robust Automated Computer-Aided Prediction Models for Early Detection of COVID-19 Infection from Chest X-ray Images. COVID-19 is an ongoing pandemic that is widely spreading daily and reaches a significant community spread. X-ray images, computed tomography (CT) images and test kits (RT-PCR) are three easily available options for predicting this infection. Compared to the screening of COVID-19 infection from X-ray and CT images, the test kits(RT-PCR) available to diagnose COVID-19 face problems such as high analytical time, high false negative outcomes, poor sensitivity and specificity. Radiological signatures that X-rays can detect have been found in COVID-19 positive patients. Radiologists may examine these signatures, but it's a time-consuming and error-prone process (riddled with intra-observer variability). Thus, the chest X-ray analysis process needs to be automated, for which AI-driven tools have proven to be the best choice to increase accuracy and speed up analysis time, especially in the case of medical image analysis. We shortlisted four datasets and 20 CNN-based models to test and validate the best ones using 16 detailed experiments with fivefold cross-validation. The two proposed models, ensemble deep transfer learning CNN model and hybrid LSTMCNN, perform the best. The accuracy of ensemble CNN was up to 99.78% (96.51% average-wise), F1-score up to 0.9977 (0.9682 average-wise) and AUC up to 0.9978 (0.9583 average-wise). The accuracy of LSTMCNN was up to 98.66% (96.46% average-wise), F1-score up to 0.9974 (0.9668 average-wise) and AUC up to 0.9856 (0.9645 average-wise). These two best pre-trained transfer learning-based detection models can contribute clinically by offering the patients prediction correctly and rapidly.",0,0
5441,"A Computationally Efficient Approach to Segmentation of the Aorta and Coronary Arteries Using Deep Learning. Early detection and diagnosis of coronary artery disease could reduce the risk of developing a heart attack. The coronary arteries are optimally visualised using computed tomography coronary angiography (CTCA) imaging. These images are reviewed by specialist radiologists who evaluate the coronary arteries for potential narrowing. A lack of radiologists in the UK is a constraint to timely diagnosis of coronary artery disease, particularly in the acute accident and emergency department setting. The development of automated methods by which coronary artery narrowing can be identified rapidly and accurately are therefore timely. Such complex computer based tools also need to be sufficiently computationally efficient that they can run on servers typically found in hospital settings, where graphical processing units for example are unavailable. We propose a fully automatic two-dimensional Unet model to segment the aorta and coronary arteries on CTCA images. Two models are trained to segment two regions of interest, (1) the aorta and the coronary arteries or (2) the coronary arteries alone. Our method achieves 91.20% and 88.80% dice similarity coefficient accuracy on regions of interest 1 and 2 respectively. Compared with a semi-automatic segmentation method, our model performs better when segmenting the coronary arteries alone. The performance of the proposed method is comparable to existing published two-dimensional or three-dimensional deep learning models. Importantly, the algorithmic and graphical processing unit memory efficiencies are maintained such that the model can be deployed without requiring graphical processing units, and therefore can be used in a hospital setting.",0,0
5443,Improving the Accuracy in Classification of Blood Pressure from Photoplethysmography Using Continuous Wavelet Transform and Deep Learning. Continuous wavelet transform (CWT) based scalogram can be used for photoplethysmography (PPG) signal transformation to classify blood pressure (BP) with deep learning. We aimed to investigate the determinants that can improve the accuracy of BP classification based on PPG and deep learning and establish a better algorithm for the prediction.,0,0
5447,"Deep Learning-Based Computed Tomography Image Features in the Detection and Diagnosis of Perianal Abscess Tissue. The performance characteristics of deep learning fully convolutional neural network (DLFCNN) algorithm-based computed tomography (CT) images were investigated in the detection and diagnosis of perianal abscess tissue. 60 patients who were medically diagnosed as perianal abscesses in the hospital were selected as the experimental group, and 60 healthy volunteers were selected as the control group. In this study, the DLFCNN algorithm based on deep learning was compared with the CNN algorithm and applied to the segmentation training of CT images of patients with perianal abscesses. Then, the segmentation metrics Jaccard, Dice coefficient, precision rate, and recall rate were compared by extracting the region of interest. The results showed that Jaccard (0.7326) calculated by the CNN algorithm was sharply lower than that of the DLFCNN algorithm (0.8525), and the Dice coefficient (0.7264) was also steeply lower than that of the DLFCNN algorithm (0.8434) (<i>P</i> < 0.05). The thickness range of the epidermis and dermis in patients from the experimental group was 4.1-4.9â€‰mm, which was markedly greater than the range of the control group (1.8-3.6â€‰mm) (<i>P</i> < 0.05). Besides, the CT value of the subcutaneous fascia in the experimental group (-95.45â€‰Â±â€‰8.26) hugely reduced compared with the control group (-76.34â€‰Â±â€‰7.69) (<i>P</i> < 0.05). The accuracy rate of the patients with perianal abscesses was 96.67% by multislice spiral CT (MSCT). Therefore, the DLFCNN algorithm in this study had good stability and good segmentation effect. The skin at the focal site of anal abscess was obviously thickened, and it was simple and accurate to use CT images in the diagnosis of patients with perianal abscesses, which could effectively locate the lesion and clarify the relationship between the lesion and the surrounding structure.",0,0
5450,"Analysis of oral microbiome in glaucoma patients using machine learning prediction models. <b>Purpose</b>: The microbiome is considered an environmental factor that contributes to the progression of several neurodegenerative diseases. However, the association between microbiome and glaucoma remains unclear. This study investigated the features of the oral microbiome in patients with glaucoma and analyzed the microbiome biomarker candidates using a machine learning approach to predict the severity of glaucoma. <b>Methods:</b> The taxonomic composition of the oral microbiome was obtained using 16S rRNA gene sequencing, operational taxonomic unit analysis, and diversity analysis. The differentially expressed gene (DEG) analysis was performed to determine the taxonomic differences between the microbiomes of patients with glaucoma and the control participants. Multinomial logistic regression and association rule mining analysis using machine learning were performed to identify the microbiome biomarker related to glaucoma severity. <b>Results:</b> DEG analysis of the oral microbiome of patients with glaucoma revealed significant depletion of <i>Lactococcus</i> (<i>P =Â </i>3.71e<sup>-31</sup>), whereas <i>Faecalibacterium</i> was enriched (<i>P</i> =Â 9.19e<sup>-14</sup>). The candidate rules generated from the oral microbiome, including <i>Lactococcus</i>, showed 96% accuracy for association with glaucoma. <b>Conclusions:</b> Our findings indicate microbiome biomarkers for glaucoma severity with high accuracy. The relatively low oral <i>Lactococcus</i> in the glaucoma population suggests that microbial dysbiosis could play an important role in the pathophysiology of glaucoma.",0,0
5454,"Quantum Machine Learning Architecture for COVID-19 Classification Based on Synthetic Data Generation Using Conditional Adversarial Neural Network. COVID-19 is a novel virus that affectsÂ the upper respiratory tract, as well as the lungs. The scale of the global COVID-19 pandemic, its spreading rate,Â and deaths are increasing regularly. Computed tomography (CT) scans can be used carefully to detect and analyzeÂ COVID-19 cases. In CT images/scans, ground-glass opacity (GGO) is found in the early stages of infection. WhileÂ in later stages, there is a superimposed pulmonary consolidation.",0,0
5456,"m5C-Related Signatures for Predicting Prognosis in Cutaneous Melanoma with Machine Learning. Cutaneous melanoma (CM) is one of the most life-threatening primary skin cancers and is prone to distant metastases. A widespread presence of posttranscriptional modification of RNA, 5-methylcytosine (m5C), has been observed in human cancers. However, the potential mechanism of the tumorigenesis and prognosis in CM by dysregulated m5C-related regulators is obscure.",0,0
5457,"Hybrid Deep-Learning and Machine-Learning Models for Predicting COVID-19. The COVID-19 pandemic has had a significant impact on public life and health worldwide, putting the world's healthcare systems at risk. The first step in stopping this outbreak is to detect the infection in its early stages, which will relieve the risk, control the outbreak's spread, and restore full functionality to the world's healthcare systems. Currently, PCR is the most prevalent diagnosis tool for COVID-19. However, chest X-ray images may play an essential role in detecting this disease, as they are successful for many other viral pneumonia diseases. Unfortunately, there are common features between COVID-19 and other viral pneumonia, and hence manual differentiation between them seems to be a critical problem and needs the aid of artificial intelligence. This research employs deep- and transfer-learning techniques to develop accurate, general, and robust models for detecting COVID-19. The developed models utilize either convolutional neural networks or transfer-learning models or hybridize them with powerful machine-learning techniques to exploit their full potential. For experimentation, we applied the proposed models to two data sets: the COVID-19 Radiography Database from Kaggle and a local data set from Asir Hospital, Abha, Saudi Arabia. The proposed models achieved promising results in detecting COVID-19 cases and discriminating them from normal and other viral pneumonia with excellent accuracy. The hybrid models extracted features from the flatten layer or the first hidden layer of the neural network and then fed these features into a classification algorithm. This approach enhanced the results further to full accuracy for binary COVID-19 classification and 97.8% for multiclass classification.",0,0
5468,"A Domain Adaptation Sparse Representation Classifier for Cross-Domain Electroencephalogram-Based Emotion Classification. The brain-computer interface (BCI) interprets the physiological information of the human brain in the process of consciousness activity. It builds a direct information transmission channel between the brain and the outside world. As the most common non-invasive BCI modality, electroencephalogram (EEG) plays an important role in the emotion recognition of BCI; however, due to the individual variability and non-stationary of EEG signals, the construction of EEG-based emotion classifiers for different subjects, different sessions, and different devices is an important research direction. Domain adaptation utilizes data or knowledge from more than one domain and focuses on transferring knowledge from the source domain (SD) to the target domain (TD), in which the EEG data may be collected from different subjects, sessions, or devices. In this study, a new domain adaptation sparse representation classifier (DASRC) is proposed to address the cross-domain EEG-based emotion classification. To reduce the differences in domain distribution, the local information preserved criterion is exploited to project the samples from SD and TD into a shared subspace. A common domain-invariant dictionary is learned in the projection subspace so that an inherent connection can be built between SD and TD. In addition, both principal component analysis (PCA) and Fisher criteria are exploited to promote the recognition ability of the learned dictionary. Besides, an optimization method is proposed to alternatively update the subspace and dictionary learning. The comparison of CSFDDL shows the feasibility and competitive performance for cross-subject and cross-dataset EEG-based emotion classification problems.",0,0
5470,"Deep Learning Classification of Unipolar Electrograms in Human Atrial Fibrillation: Application in Focal Source Mapping. Focal sources are potential targets for atrial fibrillation (AF) catheter ablation, but they can be time-consuming and challenging to identify when unipolar electrograms (EGM) are numerous and complex. Our aim was to apply deep learning (DL) to raw unipolar EGMs in order to automate putative focal sources detection. We included 78 patients from the Focal Source and Trigger (FaST) randomized controlled trial that evaluated the efficacy of adjunctive FaST ablation compared to pulmonary vein isolation alone in reducing AF recurrence. FaST sites were identified based on manual classification of sustained periodic unipolar QS EGMs over 5-s. All periodic unipolar EGMs were divided into training (<i>n</i> = 10,004) and testing cohorts (<i>n</i> = 3,180). DL was developed using residual convolutional neural network to discriminate between FaST and non-FaST. A gradient-based method was applied to interpret the DL model. DL classified FaST with a receiver operator characteristic area under curve of 0.904 Â± 0.010 (cross-validation) and 0.923 Â± 0.003 (testing). At a prespecified sensitivity of 90%, the specificity and accuracy were 81.9 and 82.5%, respectively, in detecting FaST. DL had similar performance (sensitivity 78%, specificity 89%) to that of FaST re-classification by cardiologists (sensitivity 78%, specificity 79%). The gradient-based interpretation demonstrated accurate tracking of unipolar QS complexes by select DL convolutional layers. In conclusion, our novel DL model trained on raw unipolar EGMs allowed automated and accurate classification of FaST sites. Performance was similar to FaST re-classification by cardiologists. Future application of DL to classify FaST may improve the efficiency of real-time focal source detection for targeted AF ablation therapy.",1,1
5473,"Combined Support Vector Machine Classifier and Brain Structural Network Features for the Individual Classification of Amnestic Mild Cognitive Impairment and Subjective Cognitive Decline Patients. Individuals with subjective cognitive decline (SCD) or amnestic mild cognitive impairment (aMCI) represent important targets for the early detection and intervention of Alzheimer's disease (AD). In this study, we employed a multi-kernel support vector machine (SVM) to examine whether white matter (WM) structural networks can be used for screening SCD and aMCI.",0,0
5485,"Thermal-based early breast cancer detection using inception V3, inception V4 and modified inception MV4. Breast cancer is one of the most significant causes of death for women around the world. Breast thermography supported by deep convolutional neural networks is expected to contribute significantly to early detection and facilitate treatment at an early stage. The goal of this study is to investigate the behavior of different recent deep learning methods for identifying breast disorders. To evaluate our proposal, we built classifiers based on deep convolutional neural networks modelling inception V3, inception V4, and a modified version of the latter called inception MV4. MV4 was introduced to maintain the computational cost across all layers by making the resultant number of features and the number of pixel positions equal. DMR database was used for these deep learning models in classifying thermal images of healthy and sick patients. A set of epochs 3-30 were used in conjunction with learning rates 1â€‰Ã—â€‰10<sup>-3</sup>, 1â€‰Ã—â€‰10<sup>-4</sup> and 1â€‰Ã—â€‰10<sup>-5</sup>, Minibatch 10 and different optimization methods. The training results showed that inception V4 and MV4 with color images, a learning rate of 1â€‰Ã—â€‰10<sup>-4</sup>, and SGDM optimization method, reached very high accuracy, verified through several experimental repetitions. With grayscale images, inception V3 outperforms V4 and MV4 by a considerable accuracy margin, for any optimization methods. In fact, the inception V3 (grayscale) performance is almost comparable to inception V4 and MV4 (color) performance but only after 20-30 epochs. inception MV4 achieved 7% faster classification response time compared to V4. The use of MV4 model is found to contribute to saving energy consumed and fluidity in arithmetic operations for the graphic processor. The results also indicate that increasing the number of layers may not necessarily be useful in improving the performance.",0,0
5491,"Pareto optimization of deep networks for COVID-19 diagnosis from chest X-rays. The year 2020 was characterized by the COVID-19 pandemic that has caused, by the end of March 2021, more than 2.5 million deaths worldwide. Since the beginning, besides the laboratory test, used as the gold standard, many applications have been applying deep learning algorithms to chest X-ray images to recognize COVID-19 infected patients. In this context, we found out that convolutional neural networks perform well on a single dataset but struggle to generalize to other data sources. To overcome this limitation, we propose a late fusion approach where we combine the outputs of several state-of-the-art CNNs, introducing a novel method that allows us to construct an optimum ensemble determining which and how many base learners should be aggregated. This choice is driven by a two-objective function that maximizes, on a validation set, the accuracy and the diversity of the ensemble itself. A wide set of experiments on several publicly available datasets, accounting for more than 92,000 images, shows that the proposed approach provides average recognition rates up to 93.54% when tested on external datasets.",0,0
5492,"Multi-label segmentation and detection of COVID-19 abnormalities from chest radiographs using deep learning. Due to COVID-19, demand for Chest Radiographs (CXRs) have increased exponentially. Therefore, we present a novel fully automatic modified Attention U-Net (CXAU-Net) multi-class segmentation deep model that can detect common findings of COVID-19 in CXR images. The architectural design of this model includes three novelties: first, an Attention U-net model with channel and spatial attention blocks is designed that precisely localize multiple pathologies; second, dilated convolution applied improves the sensitivity of the model to foreground pixels with additional receptive fields valuation, and third a newly proposed hybrid loss function combines both area and size information for optimizing model. The proposed model achieves average accuracy, DSC, and Jaccard index scores of 0.951, 0.993, 0.984, and 0.921, 0.985, 0.973 for image-based and patch-based approaches respectively for multi-class segmentation on Chest X-ray 14 dataset. Also, average DSC and Jaccard index scores of 0.998, 0.989 are achieved for binary-class segmentation on the Japanese Society of Radiological Technology (JSRT) CXR dataset. These results illustrate that the proposed model outperformed the state-of-the-art segmentation methods.",0,0
5495,Analysis of Transfer Learning for Select Retinal Disease Classification. To analyze the effect of transfer learning (TL) for classification of diabetic retinopathy (DR) by fundus photography and select retinal diseases by spectral-domain optical coherence tomography (SD-OCT).,0,0
5496,Comparing Performance of Different Predictive Models in Estimating Disease Progression in Alzheimer Disease. Automatic classification techniques provide tools to analyze complex data and predict disease progression.,0,0
5501,"LightGBM: an efficient and accurate method for predicting pregnancy diseases. As machine learning is becoming the fashion in disease prediction while no prediction model has performed very efficiently and accurately on predicting pregnancy diseases up to now, it's necessary to compare several common machine learning methods' performance on pregnancy diseases prediction and select out the best one. The data of two common pregnancy complications, pregnancy-induced hypertension (PIH) and Intrahepatic cholestasis of pregnancy (ICP), based on various maternal characteristics measured in patients' routine blood examination in 10-19â€‰weeks of gestation are considered to be suitable to be learned. This is a retrospective study of 320 healthy pregnancies in 10-19â€‰weeks, with 149 patients who subsequently developed PIH and 250 patients who subsequently developed ICP. Nine machine learning methods were used to predict PIH and ICP and their performance was compared via 8 evaluation indexes. Finally, the light Gradient Boosting Machine (lightGBM) is considered to be the best method to predict gestational diseases.Impact statement<b>What is already known on this subject?</b> As a kind of commonly used method in disease prediction, machine learning could be applied to clinical data for developing robust risk models and many achievements have been made. Also, machine learning can be used to predict pregnancy diseases. Although some machine learning methods have been used for screening gestational diseases, methods based on simple theories, such as logistic regression and decision tree, are frequently used. They don't always have a very satisfactory prediction results. Besides, only a few types of pregnancy diseases can be predicted.<b>What do the results of this study add?</b> LightGBM has the best prediction results of PIH and ICP among 9 machine learning methods in this study. It can predict PIH (AUC = 81.72%) with a sensitivity of 70.59%, and ICP (AUC = 95.91%) with a sensitivity of 97.91%.<b>What are the implications of these findings for clinical practice and/or further research?</b> A new model has been developed for effective first-trimester screening for two common pregnancy diseases, PIH and ICP. This lightGBM model can be used in relative hospitals and population of the research, and provide references for doctors' diagnosis and treatment of pregnant women. In further research, the predicted effect of lightGBM on daily practice and other pregnancy diseases such as pregnancy diabetes, will be verified.",0,0
5505,Machine learning-driven identification of novel patient factors for prediction of major complications after posterior cervical spinal fusion. Posterior cervical fusion is associated with increased rates of complications and readmission when compared to anterior fusion. Machine learning (ML) models for risk stratification of patients undergoing posterior cervical fusion remain limited. We aim to develop a novel ensemble ML algorithm for prediction of major perioperative complications and readmission after posterior cervical fusion and identify factors important to model performance.,0,0
5506,Machine Assist for Pediatric Posterior Fossa Tumor Diagnosis: A Multinational Study. Clinicians and machine classifiers reliably diagnose pilocytic astrocytoma (PA) on magnetic resonance imaging (MRI) but less accurately distinguish medulloblastoma (MB) from ependymoma (EP). One strategy is to first rule out the most identifiable diagnosis.,0,0
5508,"Uncertainty estimation and explainability in deep learning-based age estimation of the human brain: Results from the German National Cohort MRI study. Brain ageing is a complex neurobiological process associated with morphological changes that can be assessed on MRI scans. Recently, Deep learning (DL)-based approaches have been proposed for the prediction of chronological brain age from MR images yielding high accuracy. These approaches, however, usually do not address quantification of uncertainty and, therefore, intrinsic physiological variability. Considering uncertainty is essential for the interpretation of the difference between predicted and chronological age. In addition, DL-based models lack in explainability compared to classical approaches like voxel-based morphometry. In this study, we aim to address both, modeling uncertainty and providing visual explanations to explore physiological patterns in brain ageing. T1-weighted brain MRI datasets of 10691 participants of the German National Cohort Study, drawn from the general population, were included in this study (chronological age from 20 to 72 years). A regression model based on a 3D Convolutional Neural Network taking into account aleatoric noise was implemented for global as well as regional brain age estimation. We observed high overall accuracy of global brain age estimation with a mean absolute error of 3.2â€¯Â±â€¯2.5 years and mean uncertainty of 2.9â€¯Â±â€¯0.6 years. Regional brain age estimation revealed higher estimation accuracy and lower uncertainty in central compared to peripheral brain regions. Visual explanations illustrating the importance of brain sub-regions were generated using Grad-CAM: the derived saliency maps showed a high relevance of the lateral and third ventricles, the insular lobe as well as parts of the basal ganglia and the internal capsule.",0,0
5509,Optimal number of strong labels for curriculum learning with convolutional neural network to classify pulmonary abnormalities in chest radiographs. It is important to alleviate annotation efforts and costs by efficiently training on medical images. We performed a stress test on several strong labels for curriculum learning with a convolutional neural network to differentiate normal and five types of pulmonary abnormalities in chest radiograph images.,0,0
5512,"Automated ASPECTS for multi-modality CT predict infarct extent and outcome in large-vessel occlusion stroke. This study aimed to use the automated Alberta Stroke Program Early CT Score (ASPECTS) software to assess the value of different CT modalities (non-contrast CT, CT angiography [CTA]-arterial, CTA-venous, and arterial- and venous-phase mismatch-ASPECTS) in predicting the final infarct extent and clinical outcome in large-vessel occlusion stroke.",0,0
5513,"A semi-supervised autoencoder framework for joint generation and classification of breathing. One of the main problems with biomedical signals is the limited amount of patient-specific data and the significant amount of time needed to record the sufficient number of samples needed for diagnostic and treatment purposes. In this study, we present a framework to simultaneously generate and classify biomedical time series based on a modified Adversarial Autoencoder (AAE) algorithm and one-dimensional convolutions. Our work is based on breathing time series, with specific motivation to capture breathing motion during radiotherapy lung cancer treatments.",0,0
5514,"Precise laminae segmentation based on neural network for robot-assisted decompressive laminectomy. The decompressive laminectomy is one of the most common operations to treat lumbar spinal stenosis by removing the laminae above the spinal nerve. Recently, an increasing number of robots are deployed during the surgical process to reduce the burden on surgeons and to reduce complications. However, for the robot-assisted decompressive laminectomy, an accurate 3D model of laminae from a CT image is highly desired. The purpose of this paper is to precisely segment the laminae with fewer calculations.",0,0
5525,"A deep learning-based radiomic nomogram for prognosis and treatment decision in advanced nasopharyngeal carcinoma: A multicentre study. Induction chemotherapy (ICT) plus concurrent chemoradiotherapy (CCRT) and CCRT alone were the optional treatment regimens in locoregionally advanced nasopharyngeal carcinoma (NPC) patients. Currently, the choice of them remains equivocal in clinical practice. We aimed to develop a deep learning-based model for treatment decision in NPC.",0,0
5528,"Biomarkers of severe COVID-19 pneumonia on admission using data-mining powered by common laboratory blood tests-datasets. In the epidemiological COVID-19 research, artificial intelligence is a unique approach to make predictions about disease severity to manage COVID-19 patients. A limitation of artificial intelligence is, however, the high risk of bias. We investigated the skill of data mining and machine learning, two advanced forms of artificial intelligence, to predict severe COVID-19 pneumonia based on routine laboratory tests. A sample of 4009 COVID-19 patients was divided into Severe (PaO<sub>2</sub>< 60Â mmHg, 489 cases) and Non-Severe (PaO<sub>2</sub>Â â‰¥Â 60Â mmHg, 3520 cases) groups according to blood hypoxemia on admission and their laboratory datasets analyzed by the R software and WEKA workbench. After curation, data were processed for the selection of the most influential features including hemogram, pCO<sub>2</sub>, blood acid-base balance, prothrombin time, inflammation biomarkers, and glucose. The best fit of variables was successfully confirmed by either the Multilayer Perceptron, a feedforward neural network algorithm that performed machine recognition of severe COVID-19 with 96.5% precision, or by the C4.5 software, a supervised learning algorithm based on an objective-predefined variable (severity) that generated a decision tree with 89.4% precision. Finally, a complex bivariate Pearson's correlation matrix combined with advanced hierarchical clustering (dendrograms) were conducted for knowledge discovery. The hidden structure of the datasets revealed shift patterns related to the development of COVID-19-induced pneumonia that involved the lymphocyte-to-C-reactive protein and leukocyte-to-C-protein ratios, neutrophil %, pH and pCO<sub>2</sub>. The data mining approaches to the hematological fluctuations associated with severe COVID-19 pneumonia could not only anticipate adverse clinical outcomes, but also reveal putative therapeutic targets.",0,0
5529,"Identification of difficult to intubate patients from frontal face images using an ensemble of deep learning models. Failure to identify difficult intubation is the leading cause of anesthesia-related death and morbidity. Despite preoperative airway assessment, 75-93% of difficult intubations are unanticipated, and airway examination methods underperform, with sensitivities of 20-62% and specificities of 82-97%. To overcome these impediments, we aim to develop a deep learning model to identify difficult to intubate patients using frontal face images. We proposed an ensemble of convolutional neural networks which leverages a database of celebrity facial images to learn robust features of multiple face regions. This ensemble extracts features from patient images (nÂ =Â 152) which are subsequently classified by a respective ensemble of attention-based multiple instance learning models. Through majority voting, a patient is classified as difficult or easy to intubate. Whereas two conventional bedside tests resulted in AUCs of 0.6042 and 0.4661, the proposed method resulted in an AUC of 0.7105 using a cohort of 76 difficult and 76 easy to intubate patients. Generic features yielded AUCs of 0.4654-0.6278. The proposed model can operate at high sensitivity and low specificity (0.9079 and 0.4474) or low sensitivity and high specificity (0.3684 and 0.9605). The proposed ensembled model outperforms conventional bedside tests and generic features. Side facial images may improve the performance of the proposed model. The proposed method significantly surpasses conventional bedside tests and deep learning methods. We expect our model will play an important role in developing deep learning methods where frontal face features play an important role.",0,0
5531,"Machine learning for evolutive lymphoma and residual masses recognition in whole body diffusion weighted magnetic resonance images. After the treatment of the patients with malignant lymphoma, there may persist lesions that must be labeled either as evolutive lymphoma requiring new treatments or as residual masses. We present in this work, a machine learning-based computer-aided diagnosis (CAD) applied to whole-body diffusion-weighted magnetic resonance images.",0,0
5533,"A channel independent generalized seizure detection method for pediatric epileptic seizures. Epilepsy the disorder of the central nervous system has its worldwide presence in roughly 50 million people as estimated by the World Health Organization. Electroencephalogram (EEG) is one of the most common and non-invasive ways of analyzing and studying the subtle changes in neuronal activity of the brain during an epileptic seizure attack. These changes can be analyzed for developing an automated system that would assert the chances of an impending seizure. As changeable nature of seizure affects the patients from having a normal life, hence progress in developing new methods will improve the quality of life and also provide assistance in the medical sector. Objective of the proposed method is to avoid EEG channel selection and use all input EEG channel features to design a generalized epileptic seizure detection framework.",0,0
5535,"A risk prediction model of gestational diabetes mellitus before 16 gestational weeks in Chinese pregnant women. To develop a GDM risk stratification model in Chinese pregnant women using machine learning algorithm, for judgment of the risk of GDM before 16 gestation weeks.",0,0
5538,"Spectral clustering based on structural magnetic resonance imaging and its relationship with major depressive disorder and cognitive ability. There is increasing interest in using data-driven unsupervised methods to identify structural underpinnings of common mental illnesses, including major depressive disorder (MDD) and associated traits such as cognition. However, studies are often limited to severe clinical cases with small sample sizes and most do not include replication. Here, we examine two relatively large samples with structural magnetic resonance imaging (MRI), measures of lifetime MDD and cognitive variables: Generation Scotland (GS subsample, Nâ€‰=â€‰980) and UK Biobank (UKB, Nâ€‰=â€‰8,900), for discovery and replication, using an exploratory approach. Regional measures of FreeSurfer derived cortical thickness (CT), cortical surface area (CSA), cortical volume (CV) and subcortical volume (subCV) were input into a clustering process, controlling for common covariates. The main analysis steps involved constructing participant K-nearest neighbour graphs and graph partitioning with Markov stability to determine optimal clustering of participants. Resultant clusters were (1) checked whether they were replicated in an independent cohort and (2) tested for associations with depression status and cognitive measures. Participants separated into two clusters based on structural brain measurements in GS subsample, with large Cohen's d effect sizes between clusters in higher order cortical regions, commonly associated with executive function and decision making. Clustering was replicated in the UKB sample, with high correlations of cluster effect sizes for CT, CSA, CV and subCV between cohorts across regions. The identified clusters were not significantly different with respect to MDD case-control status in either cohort (GS subsample: p<sub>FDR</sub> â€‰=â€‰.2239-.6585; UKB: p<sub>FDR</sub> â€‰=â€‰.2003-.7690). Significant differences in general cognitive ability were, however, found between the clusters for both datasets, for CSA, CV and subCV (GS subsample: dâ€‰=â€‰0.2529-.3490, p<sub>FDR</sub> Â <â€‰.005; UKB: dâ€‰=â€‰0.0868-0.1070, p<sub>FDR</sub> Â <â€‰.005). Our results suggest that there are replicable natural groupings of participants based on cortical and subcortical brain measures, which may be related to differences in cognitive performance, but not to the MDD case-control status.",0,0
5541,"Deep Learning-Based classification of Breast Cancer Cells Using Transmembrane Receptor Dynamics. Motions of transmembrane receptors on cancer cell surfaces can reveal biophysical features of the cancer cells, thus providing a method for characterizing cancer cell phenotypes. While conventional analysis of receptor motions in the cell membrane mostly relies on the mean-squared displacement plots, much information is lost when producing these plots from the trajectories. Here we employ deep learning to classify breast cancer cell types based on the trajectories of epidermal growth factor receptor (EGFR). Our model is an artificial neural network trained on the EGFR motions acquired from six breast cancer cell lines of varying invasiveness and receptor status: MCF7 (hormone receptor-positive), BT474 (HER2-positive), SKBR3 (HER2-positive), MDA-MB-468 (triple-negative, TN), MDA-MB-231 (TN), and BT549 (TN).",0,0
5542,"Cognitive Determinants of Dysarthria in Parkinson's Disease: An Automated Machine Learning Approach. Dysarthric symptoms in Parkinson's disease (PD) vary greatly across cohorts. Abundant research suggests that such heterogeneity could reflect subject-level and task-related cognitive factors. However, the interplay of these variables during motor speech remains underexplored, let alone by administering validated materials to carefully matched samples with varying cognitive profiles and combining automated tools with machine learning methods.",0,0
5544,"Machine learning-based model for predicting 1Â year mortality of hospitalized patients with heart failure. Individual risk stratification is a fundamental strategy in managing patients with heart failure (HF). Artificial intelligence, particularly machine learning (ML), can develop superior models for predicting the prognosis of HF patients, and administrative claim data (ACD) are suitable for ML analysis because ACD is a structured database. The objective of this study was to analyse ACD using an ML algorithm, predict the 1Â year mortality of patients with HF, and finally develop an easy-to-use prediction model with high accuracy using the top predictors identified by the ML algorithm.",0,0
5548,"Accounting for symptom heterogeneity can improve neuroimaging models of antidepressant response after electroconvulsive therapy. Depression symptom heterogeneity limits the identifiability of treatment-response biomarkers. Whether improvement along dimensions of depressive symptoms relates to separable neural networks remains poorly understood. We build on work describing three latent symptom dimensions within the 17-item Hamilton Depression Rating Scale (HDRS) and use data-driven methods to relate multivariate patterns of patient clinical, demographic, and brain structural changes over electroconvulsive therapy (ECT) to dimensional changes in depressive symptoms. We included 110 ECT patients from Global ECT-MRI Research Collaboration (GEMRIC) sites who underwent structural MRI and HDRS assessments before and after treatment. Cross validated random forest regression models predicted change along symptom dimensions. HDRS symptoms clustered into dimensions of somatic disturbances (SoD), core mood and anhedonia (CMA), and insomnia. The coefficient of determination between predicted and actual changes were 22%, 39%, and 39% (all pâ€‰<â€‰.01) for SoD, CMA, and insomnia, respectively. CMA and insomnia change were predicted more accurately than HDRS-6 and HDRS-17 changes (pâ€‰<â€‰.05). Pretreatment symptoms, body-mass index, and age were important predictors. Important imaging predictors included the right transverse temporal gyrus and left frontal pole for the SoD dimension; right transverse temporal gyrus and right rostral middle frontal gyrus for the CMA dimension; and right superior parietal lobule and left accumbens for the insomnia dimension. Our findings support that recovery along depressive symptom dimensions is predicted more accurately than HDRS total scores and are related to unique and overlapping patterns of clinical and demographic data and volumetric changes in brain regions related to depression and near ECT electrodes.",0,0
5549,"Development of Machine Learning Models to Predict Probabilities and Types of Stroke at Prehospital Stage: the Japan Urgent Stroke Triage Score Using Machine Learning (JUST-ML). In conjunction with recent advancements in machine learning (ML), such technologies have been applied in various fields owing to their high predictive performance. We tried to develop prehospital stroke scale with ML. We conducted multi-center retrospective and prospective cohort study. The training cohort had eight centers in Japan from June 2015 to March 2018, and the test cohort had 13 centers from April 2019 to March 2020. We use the three different ML algorithms (logistic regression, random forests, XGBoost) to develop models. Main outcomes were large vessel occlusion (LVO), intracranial hemorrhage (ICH), subarachnoid hemorrhage (SAH), and cerebral infarction (CI) other than LVO. The predictive abilities were validated in the test cohort with accuracy, positive predictive value, sensitivity, specificity, area under the receiver operating characteristic curve (AUC), and F score. The training cohort included 3178 patients with 337 LVO, 487 ICH, 131 SAH, and 676 CI cases, and the test cohort included 3127 patients with 183 LVO, 372 ICH, 90 SAH, and 577 CI cases. The overall accuracies were 0.65, and the positive predictive values, sensitivities, specificities, AUCs, and F scores were stable in the test cohort. The classification abilities were also fair for all ML models. The AUCs for LVO of logistic regression, random forests, and XGBoost were 0.89, 0.89, and 0.88, respectively, in the test cohort, and these values were higher than the previously reported prediction models for LVO. The ML models developed to predict the probability and types of stroke at the prehospital stage had superior predictive abilities.",0,0
5551,"Identification of predictors and model for predicting prolonged length of stay in dengue patients. Our objective is to identify the predictive factors and predict hospital length of stay (LOS) in dengue patients, for efficient utilization of hospital resources.",0,0
5553,"A machine learning approach identifies 5-ASA and ulcerative colitis as being linked with higher COVID-19 mortality in patients with IBD. Inflammatory bowel diseases (IBD), namely Crohn's disease (CD) and ulcerative colitis (UC) are chronic inflammation within the gastrointestinal tract. IBD patient conditions and treatments, such as with immunosuppressants, may result in a higher risk of viral and bacterial infection and more severe outcomes of infections. The effect of the clinical and demographic factors on the prognosis of COVID-19 among IBD patients is still a significant area of investigation. The lack of available data on a large set of COVID-19 infected IBD patients has hindered progress. To circumvent this lack of large patient data, we present a random sampling approach to generate clinical COVID-19 outcomes (outpatient management, hospitalized and recovered, and hospitalized and deceased) on 20,000 IBD patients modeled on reported summary statistics obtained from the Surveillance Epidemiology of Coronavirus Under Research Exclusion (SECURE-IBD), an international database to monitor and report on outcomes of COVID-19 occurring in IBD patients. We apply machine learning approaches to perform a comprehensive analysis of the primary and secondary covariates to predict COVID-19 outcome in IBD patients. Our analysis reveals that age, medication usage and the number of comorbidities are the primary covariates, while IBD severity, smoking history, gender and IBD subtype (CD or UC) are key secondary features. In particular, elderly male patients with ulcerative colitis, several preexisting conditions, and who smoke comprise a highly vulnerable IBD population. Moreover, treatment with 5-ASAs (sulfasalazine/mesalamine) shows a high association with COVID-19/IBD mortality. Supervised machine learning that considers age, number of comorbidities and medication usage can predict COVID-19/IBD outcomes with approximately 70% accuracy. We explore the challenge of drawing demographic inferences from existing COVID-19/IBD data. Overall, there are fewer IBD case reports from US states with poor health ranking hindering these analyses. Generation of patient characteristics based on known summary statistics allows for increased power to detect IBD factors leading to variable COVID-19 outcomes. There is under-reporting of COVID-19 in IBD patients from US states with poor health ranking, underpinning the perils of using the repository to derive demographic information.",0,0
5554,"Deep learning-based gene selection in comprehensive gene analysis in pancreatic cancer. The selection of genes that are important for obtaining gene expression data is challenging. Here, we developed a deep learning-based feature selection method suitable for gene selection. Our novel deep learning model includes an additional feature-selection layer. After model training, the units in this layer with high weights correspond to the genes that worked effectively in the processing of the networks. Cancer tissue samples and adjacent normal pancreatic tissue samples were collected from 13 patients with pancreatic ductal adenocarcinoma during surgery and subsequently frozen. After processing, gene expression data were extracted from the specimens using RNA sequencing. Task 1 for the model training was to discriminate between cancerous and normal pancreatic tissue in six patients. Task 2 was to discriminate between patients with pancreatic cancer (n = 13) who survived for more than one year after surgery. The most frequently selected genes were ACACB, ADAMTS6, NCAM1, and CADPS in Task 1, and CD1D, PLA2G16, DACH1, and SOWAHA in Task 2. According to The Cancer Genome Atlas dataset, these genes are all prognostic factors for pancreatic cancer. Thus, the feasibility of using our deep learning-based method for the selection of genes associated with pancreatic cancer development and prognosis was confirmed.",0,0
5558,"Fast and Accurate Ophthalmic Medication Bottle Identification Using Deep Learning on a Smartphone Device. To assess the accuracy and efficacy of deep learning models, specifically convolutional neural networks (CNNs), to identify glaucoma medication bottles.",0,0
5563,"Probability calibration-based prediction of recurrence rate in patients with diffuse large B-cell lymphoma. Although many patients receive good prognoses with standard therapy, 30-50% of diffuse large B-cell lymphoma (DLBCL) cases may relapse after treatment. Statistical or computational intelligent models are powerful tools for assessing prognoses; however, many cannot generate accurate risk (probability) estimates. Thus, probability calibration-based versions of traditional machine learning algorithms are developed in this paper to predict the risk of relapse in patients with DLBCL.",0,0
5565,Efficiency of a deep learning-based artificial intelligence diagnostic system in spontaneous intracerebral hemorrhage volume measurement. Accurate measurement of hemorrhage volume is critical for both the prediction of prognosis and the selection of appropriate clinical treatment after spontaneous intracerebral hemorrhage (ICH). This study aimed to evaluate the performance and accuracy of a deep learning-based automated segmentation algorithm in segmenting spontaneous intracerebral hemorrhage (ICH) volume either with or without intraventricular hemorrhage (IVH) extension. We compared this automated pipeline with two manual segmentation techniques.,0,1
5566,"An artifÄ±cial Ä±ntelligence approach to automatic tooth detection and numbering in panoramic radiographs. Panoramic radiography is an imaging method for displaying maxillary and mandibular teeth together with their supporting structures. Panoramic radiography is frequently used in dental imaging due to its relatively low radiation dose, short imaging time, and low burden to the patient. We verified the diagnostic performance of an artificial intelligence (AI) system based on a deep convolutional neural network method to detect and number teeth on panoramic radiographs.",0,0
5569,Feature-fusion improves MRI single-shot deep learning detection of small brain metastases. To examine whether feature-fusion (FF) method improves single-shot detector's (SSD's) detection of small brain metastases on contrast-enhanced (CE) T1-weighted MRI.,0,0
5574,"Deep learning based classification of unsegmented phonocardiogram spectrograms leveraging transfer learning. <i>Objective.</i>Cardiovascular diseases (CVDs) are a main cause of deaths all over the world. This research focuses on computer-aided analysis of phonocardiogram (PCG) signals based on deep learning that can enable improved and timely detection of heart abnormalities. The two widely used publicly available PCG datasets are from the PhysioNet/CinC (2016) and PASCAL (2011) challenges. The datasets are significantly different in terms of the tools used for data acquisition, clinical protocols, digital storages and signal qualities, making it challenging to process and analyze.<i>Approach.</i>In this work, we have used short-time Fourier transform-based spectrograms to learn the representative patterns of the normal and abnormal PCG signals. Spectrograms generated from both the datasets are utilized to perform four different studies: (i) train, validate and test different variants of convolutional neural network (CNN) models with PhysioNet dataset, (ii) train, validate and test the best performing CNN structure on the PASCAL dataset, as well as (iii) on the combined PhysioNet-PASCAL dataset and (iv) finally, the transfer learning technique is employed to train the best performing pre-trained network from the first study with PASCAL dataset.<i>Main results.</i>The first study achieves an accuracy, sensitivity, specificity, precision and F1 scores of 95.75%, 96.3%, 94.1%, 97.52%, and 96.93%, respectively, while the second study shows accuracy, sensitivity, specificity, precision and F1 scores of 75.25%, 74.2%, 76.4%, 76.73%, and 75.42%, respectively. The third study shows accuracy, sensitivity, specificity, precision and F1 scores of 92.7%, 94.98%, 89.95%, 95.3% and 94.6%, respectively. Finally, the fourth study shows a precision of 96.98% on the noisy PASCAL dataset with transfer learning approach.<i>Significance.</i>The proposed approach employs a less complex and relatively light custom CNN model that outperforms most of the recent competing studies by achieving comparatively high classification accuracy and precision, making it suitable for screening CVDs using PCG signals.",0,0
5576,Usefulness of artificial intelligence for predicting recurrence following surgery for pancreatic cancer: Retrospective cohort study. or Purpose: Pancreatic ductal adenocarcinoma (PDAC) is a leading cause of mortality in the world with the overall 5-year survival rate of 6%. The survival of patients with PDAC is closely related to recurrence and therefore it is necessary to identify the risk factors for recurrence. This study uses artificial intelligence approaches and multi-center registry data to analyze the recurrence of pancreatic cancer after surgery and its major determinants.,0,0
5577,Distinguishing benign and malignant lesions on contrast-enhanced breast cone-beam CT with deep learning neural architecture search. To utilize a neural architecture search (NAS) approach to develop a convolutional neural network (CNN) method for distinguishing benign and malignant lesions on breast cone-beam CT (BCBCT).,0,0
5578,"Detection and PI-RADS classification of focal lesions in prostate MRI: Performance comparison between a deep learning-based algorithm (DLA) and radiologists with various levels of experience. To compare the performance of lesion detection and Prostate Imaging-Reporting and Data System (PI-RADS) classification between a deep learning-based algorithm (DLA), clinical reports and radiologists with different levels of experience in prostate MRI.",1,1
5580,"A benchmark for neural network robustness in skin cancer classification. One prominent application for deep learning-based classifiers is skin cancer classification on dermoscopic images. However, classifier evaluation is often limited to holdout data which can mask common shortcomings such as susceptibility to confounding factors. To increase clinical applicability, it is necessary to thoroughly evaluate such classifiers on out-of-distribution (OOD) data.",0,0
5581,"Explainable fuzzy neural network with easy-to-obtain physiological features for screening obstructive sleep apnea-hypopnea syndrome. Recently, several tools for screening obstructive sleep apnea-hypopnea syndrome (OSAHS) have been devised with varied shortcomings. To overcome these drawbacks, we aimed to propose a self-estimation method using an explainable prediction model with easy-to-obtain variables and evaluate its performance for predicting OSAHS.",0,0
5582,"A novel melanoma prediction model for imbalanced data using optimized SqueezeNet by bald eagle search optimization. Skin lesion classification plays a crucial role in diagnosing various gene and related local medical cases in the field of dermoscopy. In this paper, a new model for the classification of skin lesions as either normal or melanoma is presented. The proposed melanoma prediction model was evaluated on a large publicly available dataset called ISIC 2020. The main challenge of this dataset is severe class imbalance. This paper proposes an approach to overcome this problem using a random over-sampling method followed by data augmentation. Moreover, a new hybrid version of a convolutional neural network architecture and bald eagle search (BES) optimization is proposed. The BES algorithm is used to find the optimal values of the hyperparameters of a SqueezeNet architecture. The proposed melanoma skin cancer prediction model obtained an overall accuracy of 98.37%, specificity of 96.47%, sensitivity of 100%, f-score of 98.40%, and area under the curve of 99%. The experimental results showed the robustness and efficiency of the proposed model compared with VGG19, GoogleNet, and ResNet50. Additionally, the results showed that the proposed model was very competitive compared with the state of the art.",0,0
5585,"REUR: A unified deep framework for signet ring cell detection in low-resolution pathological images. Detecting signet ring cells (SRCs) in pathological images is essential for carcinoma diagnosis. However, it is time consuming for pathologists to detect SRCs manually from pathological images, and the accuracy of detecting them is also relatively low because of their small sizes. Recently, the exploration of deep learning methods in pathology analysis has been widely investigated by researchers. Nevertheless, the automatic detection of SRCs from real pathological images faces two problems. One is that labeled pathological images are insufficient and usually incomplete. The other is that the training data and the real clinical data have a large difference in resolution. Hence, adopting the transfer learning method affects the performance of deep learning methods. To address these two problems, we present a unified framework named REUR [RetinaNet combining USRNet (unfolding super-resolution network) with the RGHMC (revised gradient harmonizing mechanism classification) loss] that can accurately detect SRCs in low-resolution (LR) pathological images. First, the framework with the super-resolution (SR) module can address the difference in resolution between the training data and the real clinical data. Second, the framework with the label correction module can obtain the revised ground-truth labels from noisy examples, which are embedded into the gradient harmonizing mechanism to acquire the RGHMC loss. The results of the numerical experiments showed that the framework can perform better than other one-stage detectors based on the RetinaNet architecture in the high-resolution (HR) noisy dataset. It achieved a kappa value of 0.74 and an accuracy of 0.89 in the test with 27 randomly selected whole slide images (WSIs), and, thus, it can assist pathologists in better analyzing WSIs. The framework provides an essential method in computer-aided diagnosis for medical applications.",0,0
5586,"An approach to the classification of COVID-19 based on CT scans using convolutional features and genetic algorithms. COVID-19 is a respiratory disease that, as of July 15th, 2021, has infected more than 187 million people worldwide and is responsible for more than 4 million deaths. An accurate diagnosis of COVID-19 is essential for the treatment and control of the disease. The use of computed tomography (CT) has shown to be promising for evaluating patients suspected of COVID-19 infection. The analysis of a CT examination is complex, and requires attention from a specialist. This paper presents a methodology for detecting COVID-19 from CT images. We first propose a convolutional neural network architecture to extract features from CT images, and then optimize the hyperparameters of the network using a tree Parzen estimator to choose the best parameters. Following this, we apply a selection of features using a genetic algorithm. Finally, classification is performed using four classifiers with different approaches. The proposed methodology achieved an accuracy of 0.997, a kappa index of 0.995, an AUROC of 0.997, and an AUPRC of 0.997 on the SARS-CoV-2 CT-Scan dataset, and an accuracy of 0.987, a kappa index of 0.975, an AUROC of 0.989, and an AUPRC of 0.987 on the COVID-CT dataset, using our CNN after optimization of the hyperparameters, the selection of features and the multi-layer perceptron classifier. Compared with pretrained CNNs and related state-of-the-art works, the results achieved by the proposed methodology were superior. Our results show that the proposed method can assist specialists in screening and can aid in diagnosing patients with suspected COVID-19.",0,0
5587,"Deep learning and lung ultrasound for Covid-19 pneumonia detection and severity classification. The Covid-19 European outbreak in February 2020 has challenged the world's health systems, eliciting an urgent need for effective and highly reliable diagnostic instruments to help medical personnel. Deep learning (DL) has been demonstrated to be useful for diagnosis using both computed tomography (CT) scans and chest X-rays (CXR), whereby the former typically yields more accurate results. However, the pivoting function of a CT scan during the pandemic presents several drawbacks, including high cost and cross-contamination problems. Radiation-free lung ultrasound (LUS) imaging, which requires high expertise and is thus being underutilised, has demonstrated a strong correlation with CT scan results and a high reliability in pneumonia detection even in the early stages. In this study, we developed a system based on modern DL methodologies in close collaboration with Fondazione IRCCS Policlinico San Matteo's Emergency Department (ED) of Pavia. Using a reliable dataset comprising ultrasound clips originating from linear and convex probes in 2908 frames from 450 hospitalised patients, we conducted an investigation into detecting Covid-19 patterns and ranking them considering two severity scales. This study differs from other research projects by its novel approach involving four and seven classes. Patients admitted to the ED underwent 12 LUS examinations in different chest parts, each evaluated according to standardised severity scales. We adopted residual convolutional neural networks (CNNs), transfer learning, and data augmentation techniques. Hence, employing methodological hyperparameter tuning, we produced state-of-the-art results meeting F1 score levels, averaged over the number of classes considered, exceeding 98%, and thereby manifesting stable measurements over precision and recall.",0,0
5589,"Axillary lymph node metastasis prediction by contrast-enhanced computed tomography images for breast cancer patients based on deep learning. When doctors use contrast-enhanced computed tomography (CECT) images to predict the metastasis of axillary lymph nodes (ALN) for breast cancer patients, the prediction performance could be degraded by subjective factors such as experience, psychological factors, and degree of fatigue. This study aims to exploit efficient deep learning schemes to predict the metastasis of ALN automatically via CECT images. A new construction called deformable sampling module (DSM) was meticulously designed as a plug-and-play sampling module in the proposed deformable attention VGG19 (DA-VGG19). A dataset of 800 samples labeled from 800 CECT images of 401 breast cancer patients retrospectively enrolled in the last three years was adopted to train, validate, and test the deep convolutional neural network models. By comparing the accuracy, positive predictive value, negative predictive value, sensitivity and specificity indices, the performance of the proposed model is analyzed in detail. The best-performing DA-VGG19 model achieved an accuracy of 0.9088, which is higher than that of other classification neural networks. As such, the proposed intelligent diagnosis algorithm can provide doctors with daily diagnostic assistance and advice and reduce the workload of doctors. The source code mentioned in this article will be released later.",0,0
5590,"Personalized brachytherapy dose reconstruction using deep learning. Accurate calculation of the absorbed dose delivered to the tumor and normal tissues improves treatment gain factor, which is the major advantage of brachytherapy over external radiation therapy. To address the simplifications of TG-43 assumptions that ignore the dosimetric impact of medium heterogeneities, we proposed a deep learning (DL)-based approach, which improves the accuracy while requiring a reasonable computation time.",0,0
5592,Diagnostic value of texture analysis of apparent diffusion coefficient maps for differentiating fat-poor angiomyolipoma from non-clear-cell renal cell carcinoma. To investigate the feasibility of texture analysis of apparent diffusion coefficient (ADC) maps for differentiating fat-poor angiomyolipomas (fpAMLs) from non-clear-cell renal cell carcinomas (non-ccRCCs).,0,0
5597,"Deep-learning based detection of COVID-19 using lung ultrasound imagery. The COVID-19 pandemic has exposed the vulnerability of healthcare services worldwide, especially in underdeveloped countries. There is a clear need to develop novel computer-assisted diagnosis tools to provide rapid and cost-effective screening in places where massive traditional testing is not feasible. Lung ultrasound is a portable, easy to disinfect, low cost and non-invasive tool that can be used to identify lung diseases. Computer-assisted analysis of lung ultrasound imagery is a relatively recent approach that has shown great potential for diagnosing pulmonary conditions, being a viable alternative for screening and diagnosing COVID-19.",0,0
5601,"COVID-19 Screening in Chest X-Ray Images Using Lung Region Priors. Early screening of COVID-19 is essential for pandemic control, and thus to relieve stress on the health care system. Lung segmentation from chest X-ray (CXR) is a promising method for early diagnoses of pulmonary diseases. Recently, deep learning has achieved great success in supervised lung segmentation. However, how to effectively utilize the lung region in screening COVID-19 still remains a challenge due to domain shift and lack of manual pixel-level annotations. We hereby propose a multi-appearance COVID-19 screening framework by using lung region priors derived from CXR images. Firstly, we propose a multi-scale adversarial domain adaptation network (MS-AdaNet) to boost the cross-domain lung segmentation task as the prior knowledge to the classification network. Then, we construct a multi-appearance network (MA-Net), which is composed of three sub-networks to realize multi-appearance feature extraction and fusion using lung region priors. At last, we can obtain prediction results from normal, viral pneumonia, and COVID-19 using the proposed MA-Net. We extend the proposed MS-AdaNet for lung segmentation task on three different public CXR datasets. The results suggest that the MS-AdaNet outperforms contrastive methods in cross-domain lung segmentation. Moreover, experiments reveal that the proposed MA-Net achieves accuracy of 98.83% and F1-score of 98.71% on COVID-19 screening. The results indicate that the proposed MA-Net can obtain significant performance on COVID-19 screening.",0,0
5602,"Transferring Structured Knowledge in Unsupervised Domain Adaptation of a Sleep Staging Network. Automatic sleep staging based on deep learning (DL) has been attracting attention for analyzing sleep quality and determining treatment effects. It is challenging to acquire long-term sleep data from numerous subjects and manually labeling them even though most DL-based models are trained using large-scale sleep data to provide state-of-the-art performance. One way to overcome this data shortage is to create a pre-trained network with an existing large-scale dataset (source domain) that is applicable to small cohorts of datasets (target domain); however, discrepancies in data distribution between the domains prevent successful refinement of this approach. In this paper, we propose an unsupervised domain adaptation method for sleep staging networks to reduce discrepancies by realigning the domains in the same space and producing domain-invariant features. Specifically, in addition to a classical domain discriminator, we introduce local dis-criminators-subject and stage-to maintain the intrinsic structure of sleep data to decrease local misalignments while using adversarial learning to play a minimax game between the feature extractor and discriminators. Moreover, we present several optimization schemes during training because the conventional adversarial learning is not effective to our training scheme. We evaluate the performance of the proposed method by examining the staging performances of a baseline network compared with direct transfer (DT) learning in various conditions. The experimental results demonstrate that the proposed domain adaptation significantly improves the performance though it needs no labeled sleep data in target domain.",0,0
5603,"Integrated Clinical and CT based Artificial Intelligence nomogram for predicting severity and need for ventilator support in COVID-19 patients: A multi-site study. Almost 25% of COVID-19 patients end up in ICU needing critical mechanical ventilation support. There is currently no validated objective way to predict which patients will end up needing ventilator support, when the disease is mild and not progressed. N=869 patients from two sites (D1: N=822, D2: N=47) with baseline clinical characteristics and chest CT scans were considered for this study. The entire dataset was randomly divided into 70% training, D1 train (N=606) and 30% test-set (D test : D1 test (N=216) + D2 (N=47)). An expert radiologist delineated ground-glass-opacities (GGOs) and consolidation regions on a subset of D1 train, (D1 train_sub, N=88). These regions were automatically segmented and used along with their corresponding CT volumes to train an imaging AI predictor (AIP) on D1 train to predict the need of mechanical ventilators for COVID-19 patients. Finally, top five prognostic clinical factors selected using univariate analysis were integrated with AIP to construct an integrated clinical and AI imaging nomogram (ClAIN). Univariate analysis identified lactate dehydrogenase, prothrombin time, aspartate aminotransferase, %lymphocytes, albumin as top five prognostic clinical features. AIP yielded an AUC of 0.81 on D test and was independently prognostic irrespective of other clinical parameters on multivariable analysis (p<0.001). ClAIN improved the performance over AIP yielding an AUC of 0.84 (p=0.04) on D test. ClAIN outperformed AIP in predicting which COVID-19 patients ended up needing a ventilator. Our results across multiple sites suggest that ClAIN could help identify COVID-19 with severe disease more precisely and likely to end up on a life-saving mechanical ventilation.",0,0
5604,"Explainable Dynamic Multimodal Variational Autoencoder for the Prediction of Patients with Suspected Central Precocious Puberty. Central precocious puberty (CPP) is the most common type of precocious puberty and has a significant effect on children. A gonadotropin-releasing hormone (GnRH)-stimulation test is the gold standard for confirming CPP. This test, however, is costly and unpleasant for patients. Therefore, it is critical to developing alternative methods for CPP diagnosis in order to alleviate patient suffering. This study aims to develop an artificial intelligence (AI) diagnostic system for predicting response to the GnRH-stimulation test using data from laboratory tests, electronic health records (EHRs), and pelvic ultrasonography and left-hand radiography reports. The challenges are in integrating these mul-timodal features into a comprehensive deep learning model in order to achieve an accurate diagnosis while also accounting for the missing or incomplete modalities. To begin, we developed a dynamic multimodal variational autoencoder (DMVAE) that can exploit intrinsic correlations between different modalities to im-pute features for missing modalities. Next, we combined features from all modalities to predict the outcome of a CPP diagnosis. The experimental results (AUROC 0.9086) demonstrate that our DMVAE model is superior to standard methods. Additionally, we showed that by setting appropriate operating thresholds, clinicians could diagnose about two-thirds of patients with confidence (1.0 specificity). Only about one-third of patients require confirmation of their diagnoses using GnRH (or GnRH analog)-stimulation tests. To interpret the results, we implemented an explainer Shapley additive explanation (SHAP) to analyze the local and global feature attributions.",0,0
5605,"A Neural Network Estimation of Ankle Torques From Electromyography and Accelerometry. Estimations of human joint torques can provide clinically valuable information to inform patient care, plan therapy, and assess the design of wearable robotic devices. Predicting joint torques into the future can also be useful for anticipatory robot control design. In this work, we present a method of mapping joint torque estimates and sequences of torque predictions from motion capture and ground reaction forces to wearable sensor data using several modern types of neural networks. We use dense feedforward, convolutional, neural ordinary differential equation, and long short-term memory neural networks to learn the mapping for ankle plantarflexion and dorsiflexion torque during standing, walking, running, and sprinting, and consider both single-point torque estimation, as well as the prediction of a sequence of future torques. Our results show that long short-term memory neural networks, which consider incoming data sequentially, outperform dense feedforward, neural ordinary differential equation networks, and convolutional neural networks. Predictions of future ankle torques up to 0.4 s ahead also showed strong positive correlations with the actual torques. The proposed method relies on learning from a motion capture dataset, but once the model is built, the method uses wearable sensors that enable torque estimation without the motion capture data.",0,0
5613,Artificial intelligence to improve efficiency of administration of gross motor function assessment in children with cerebral palsy. To create a reduced version of the 66-item Gross Motor Function Measure (rGMFM-66) using innovative artificial intelligence methods to improve efficiency of administration of the GMFM-66.,0,0
5615,"Assessing Electrocardiogram and Respiratory Signal Quality of a Wearable Device (SensEcho): Semisupervised Machine Learning-Based Validation Study. With the development and promotion of wearable devices and their mobile health (mHealth) apps, physiological signals have become a research hotspot. However, noise is complex in signals obtained from daily lives, making it difficult to analyze the signals automatically and resulting in a high false alarm rate. At present, screening out the high-quality segments of the signals from huge-volume data with few labels remains a problem. Signal quality assessment (SQA) is essential and is able to advance the valuable information mining of signals.",0,0
5616,"Current-Visit and Next-Visit Prediction for Fatty Liver Disease With a Large-Scale Dataset: Model Development and Performance Comparison. Fatty liver disease (FLD) arises from the accumulation of fat in the liver and may cause liver inflammation, which, if not well controlled, may develop into liver fibrosis, cirrhosis, or even hepatocellular carcinoma.",0,0
5621,"Use of 816 consecutive burn wound biopsies to inform a histologic algorithm for burn depth categorization. Burn experts are only 77% accurate when subjectively assessing burn depth, leaving almost a quarter of patients to undergo unnecessary surgery or conversely suffer a delay in treatment. To aid clinicians in burn depth assessment (BDA), new technologies are being studied with machine learning algorithms calibrated to histologic standards. Our group has iteratively created a theoretical burn biopsy algorithm (BBA) based on histologic analysis, and subsequently informed it with the largest burn wound biopsy repository in the literature. Here, we sought to report that process.",0,0
5623,Evaluation of artificial intelligence-based quantitative analysis to identify clinically significant severe retinopathy of prematurity. To evaluate the screening potential of a deep learning algorithm derived severity score by determining its ability to detect clinically significant severe retinopathy of prematurity (ROP).,0,0
5624,"Diagnostic Accuracy and Performance of Artificial Intelligence in Detecting Lung Nodules in Patients With Complex Lung Disease: A Noninferiority Study. The aim of the study is to investigate the performance of artificial intelligence (AI) convolutional neural networks (CNN) in detecting lung nodules on chest computed tomography of patients with complex lung disease, and demonstrate its noninferiority when compared against an experienced radiologist through clinically relevant assessments.",1,1
5625,"Clinical Target Volume Auto-Segmentation of Esophageal Cancer for Radiotherapy After Radical Surgery Based on Deep Learning. Radiotherapy plays an important role in controlling the local recurrence of esophageal cancer after radical surgery. Segmentation of the clinical target volume is a key step in radiotherapy treatment planning, but it is time-consuming and operator-dependent. This paper introduces a deep dilated convolutional U-network to achieve fast and accurate clinical target volume auto-segmentation of esophageal cancer after radical surgery. The deep dilated convolutional U-network, which integrates the advantages of dilated convolution and the U-network, is an end-to-end architecture that enables rapid training and testing. A dilated convolution module for extracting multiscale context features containing the original information on fine texture and boundaries is integrated into the U-network architecture to avoid information loss due to down-sampling and improve the segmentation accuracy. In addition, batch normalization is added to the deep dilated convolutional U-network for fast and stable convergence. In the present study, the training and validation loss tended to be stable after 40 training epochs. This deep dilated convolutional U-network model was able to segment the clinical target volume with an overall mean Dice similarity coefficient of 86.7% and a respective 95% Hausdorff distance of 37.4 mm, indicating reasonable volume overlap of the auto-segmented and manual contours. The mean Cohen kappa coefficient was 0.863, indicating that the deep dilated convolutional U-network was robust. Comparisons with the U-network and attention U-network showed that the overall performance of the deep dilated convolutional U-network was best for the Dice similarity coefficient, 95% Hausdorff distance, and Cohen kappa coefficient. The test time for segmentation of the clinical target volume was approximately 25 seconds per patient. This deep dilated convolutional U-network could be applied in the clinical setting to save time in delineation and improve the consistency of contouring.",0,0
5626,"""Global"" cardiac atherosclerotic burden assessed by artificial intelligence-based versus manual segmentation in <sup>18</sup>F-sodium fluoride PET/CT scans: Head-to-head comparison. Artificial intelligence (AI) is known to provide effective means to accelerate and facilitate clinical and research processes. So in this study it was aimed to compare a AI-based method for cardiac segmentation in positron emission tomography/computed tomography (PET/CT) scans with manual segmentation to assess global cardiac atherosclerosis burden.",1,1
5631,Machine Learning Can Predict Level of Improvement in Shoulder Arthroplasty. The ability to accurately predict postoperative outcomes is of considerable interest in the field of orthopaedic surgery. Machine learning has been used as a form of predictive modeling in multiple health-care settings. The purpose of the current study was to determine whether machine learning algorithms using preoperative data can predict improvement in American Shoulder and Elbow Surgeons (ASES) scores for patients with glenohumeral osteoarthritis (OA) at a minimum of 2 years after shoulder arthroplasty.,0,0
5632,Deep learning for the standardized classification of Ki-67 in vulva carcinoma: A feasibility study. The aim of this study is to demonstrate the feasibility of automatic classification of Ki-67 histological immunostainings in patients with squamous cell carcinoma of the vulva using a deep convolutional neural network (dCNN).,0,0
5637,"Revisiting the dynamic risk profile of cardiovascular/non-cardiovascular multimorbidity in incident atrial fibrillation patients and five cardiovascular/non-cardiovascular outcomes: A machine-learning approach. Patients with atrial fibrillation (AF) usually have a heterogeneous co-morbid history, with dynamic changes in risk factors impacting on multiple adverse outcomes. We investigated a large prospective cohort of patients with multimorbidity, using a machine-learning approach, accounting for the dynamic nature of comorbidity risks and incident AF.",0,0
5641,"Effects of Brain Atlases and Machine Learning Methods on the Discrimination of Schizophrenia Patients: A Multimodal MRI Study. Recently, machine learning techniques have been widely applied in discriminative studies of schizophrenia (SZ) patients with multimodal magnetic resonance imaging (MRI); however, the effects of brain atlases and machine learning methods remain largely unknown. In this study, we collected MRI data for 61 first-episode SZ patients (FESZ), 79 chronic SZ patients (CSZ) and 205 normal controls (NC) and calculated 4 MRI measurements, including regional gray matter volume (GMV), regional homogeneity (ReHo), amplitude of low-frequency fluctuation and degree centrality. We systematically analyzed the performance of two classifications (SZ vs NC; FESZ vs CSZ) based on the combinations of three brain atlases, five classifiers, two cross validation methods and 3 dimensionality reduction algorithms. Our results showed that the groupwise whole-brain atlas with 268 ROIs outperformed the other two brain atlases. In addition, the leave-one-out cross validation was the best cross validation method to select the best hyperparameter set, but the classification performances by different classifiers and dimensionality reduction algorithms were quite similar. Importantly, the contributions of input features to both classifications were higher with the GMV and ReHo features of brain regions in the prefrontal and temporal gyri. Furthermore, an ensemble learning method was performed to establish an integrated model, in which classification performance was improved. Taken together, these findings indicated the effects of these factors in constructing effective classifiers for psychiatric diseases and showed that the integrated model has the potential to improve the clinical diagnosis and treatment evaluation of SZ.",0,0
5642,"Evaluation of Effect of Curcumin on Psychological State of Patients with Pulmonary Hypertension by Magnetic Resonance Image under Deep Learning. This research aimed to evaluate the right ventricular segmentation ability of magnetic resonance imaging (MRI) images based on deep learning and evaluate the influence of curcumin (Cur) on the psychological state of patients with pulmonary hypertension (PH). The heart MRI images were detected based on the You Only Look Once (YOLO) algorithm, and then the MRI image right ventricle segmentation algorithm was established based on the convolutional neural network (CNN) algorithm. The segmentation effect of the right ventricle in cardiac MRI images was evaluated regarding intersection-over-union (IOU), Dice coefficient, accuracy, and Jaccard coefficient. 30 cases of PH patients were taken as the research object. According to different treatments, they were rolled into control group (conventional treatment) and Cur group (conventional treatmentâ€‰+â€‰Cur), with 15 cases in each group. Changes in the scores of the self-rating anxiety scale (SAS) and self-rating depression scale (SDS) of the two groups of patients before and after treatment were analyzed. It was found that the average IOU of the heart target detection frame of the MRI image and the true bounding box before correction was 0.7023, and the IOU after correction was 0.9016. The Loss of the MRI image processed by the CNN algorithm was 0.05, which was greatly smaller than those processed by other algorithms. The Dice coefficient, Jaccard coefficient, and accuracy of the MRI image processed by CNN were 0.89, 0.881, and 0.994, respectively. The MRI images of PH patients showed that the anterior wall of the right ventricle was notably thickened, and the main pulmonary artery was greatly widened. After treatment, the SAR and SDS scores of the two groups were lower than those before treatment (<i>P</i> < 0.05), and the SAR and SDS scores of the curcumin group were lower than those of the control group (<i>P</i> < 0.05). To sum up, the right ventricular segmentation ability of MRI images based on deep learning was improved, and Cur can remarkably alleviate the psychological state of PH patients, which provided a reference for the diagnosis and treatment for PH patients.",0,0
5643,"Diagnosis and Treatment Effect of Convolutional Neural Network-Based Magnetic Resonance Image Features on Severe Stroke and Mental State. The purpose of this paper is to explore the impact of magnetic resonance imaging (MRI) image features based on convolutional neural network (CNN) algorithm and conditional random field on the diagnosis and mental state of patients with severe stroke. 208 patients with severe stroke who all received MRI examination were recruited as the research objects. According to cerebral small vascular disease (CSVD) score, the patients were divided into CSVD 0âˆ¼4 groups. The patients who completed the three-month follow-up were classified into cognitive impairment group (124 cases) and the noncognitive impairment group (84 cases) according to the cut-off point of the Montreal cognitive assessment (MOCA) scale score of 26. A novel image segmentation algorithm was proposed based on U-shaped fully CNN (U-Net) and conditional random field, which was compared with the fully CNN (FCN) algorithm and U-Net algorithm, and was applied to the MRI segmentation training of patients with severe stroke. It was found that the average symmetric surface distance (ASSD) (3.13â€‰Â±â€‰1.35), Hoffman distance (HD) (28.71â€‰Â±â€‰9.05), Dice coefficient (0.78â€‰Â±â€‰1.35), accuracy (0.74â€‰Â±â€‰0.11), and sensitivity (0.85â€‰Â±â€‰0.13) of the proposed algorithm were superior to those of FCN algorithm and U-Net algorithm. There were significant differences in the MOCA scores among the five groups of patients from CSVD 0 to CSVD 4 in the three time periods (0, 1, and 3 months) (<i>P</i> < 0.05). Differences in cerebral microhemorrhage (CMB), perivascular space (PVS), and number of cavities, Fazekas, and total CSVD scores between the two groups were significant (<i>P</i> < 0.05). Multivariate regression found that the number of PVS, white matter hyperintensity (WMH) Fazekas, and total CSVD score were independent factors of cognitive impairment. In short, MRI images based on deep learning image segmentation algorithm had good application value for clinical diagnosis and treatment of stroke and can effectively improve the detection effect of brain domain characteristics and psychological state of patients after stroke.",0,0
5644,"Magnetic Resonance Imaging Features of Cerebral Infarction in Critical Patients Based on Convolutional Neural Network. The clinical application of the artificial intelligence-assisted system in imaging was investigated by analyzing the magnetic resonance imaging (MRI) influence characteristics of cerebral infarction in critically ill patients based on the convolutional neural network (CNN). Fifty patients with cerebral infarction were enrolled and examined by MRI. Besides, a CNN artificial intelligence system was established for learning and training. The features were extracted from the MRI image results of the patients, and then, the data were calculated by computer technology. The gray-level cooccurrence matrix (GLCM) of T1-weighted images was 0.872â€‰Â±â€‰0.069; the reasonable prediction (ALL) result was 0.766â€‰Â±â€‰0.112; the gray-level run-length matrix (GLRLM) was 0.812â€‰Â±â€‰0.101; the multigray-level area size matrix (MGLSZM) result was 0.713â€‰Â±â€‰0.104; and the result of gray-scale area size matrix (GLSZM) was 0.598â€‰Â±â€‰0.099. The GLCM, ALL, GLRLM, MGLSZM, and GLSZM of enhanced T1-weighted images were 0.710â€‰Â±â€‰0.169, 0.742â€‰Â±â€‰0.099, 0.778â€‰Â±â€‰0.096, 0.801â€‰Â±â€‰0.104, and 0.598â€‰Â±â€‰0.099, respectively. The GLCM, ALL, GLRLM, MGLSZM, and GLSZM of T2-weighted images were 0.780â€‰Â±â€‰0.096, 0.798â€‰Â±â€‰0.087, 0.888â€‰Â±â€‰0.086, 0.768â€‰Â±â€‰0.112, and 0.767â€‰Â±â€‰0.100, respectively. In short, the image diagnosis method that could reduce the subjective visual judgment error to a certain extent was found by analyzing the characteristics of MRI images of critically ill patients with cerebral infarction based on CNN.",0,0
5647,"Machine learning using clinical data at baseline predicts the efficacy of vedolizumab at week 22 in patients with ulcerative colitis. Predicting the response of patients with ulcerative colitis (UC) to a biologic such as vedolizumab (VDZ) before administration is an unmet need for optimizing individual patient treatment. We hypothesized that the machine-learning approach with daily clinical information can be a new, promising strategy for developing a drug-efficacy prediction tool. Random forest with grid search and cross-validation was employed in Cohort 1 to determine the contribution of clinical features at baseline (week 0) to steroid-free clinical remission (SFCR) with VDZ at week 22. Among 49 clinical features including sex, age, height, body weight, BMI, disease duration/phenotype, treatment history, clinical activity, endoscopic activity, and blood test items, the top eight features (partial Mayo score, MCH, BMI, BUN, concomitant use of AZA, lymphocyte fraction, height, and CRP) were selected for logistic regression to develop a prediction model for SFCR at week 22. In the validation using the external Cohort 2, the positive and negative predictive values of the prediction model were 54.5% and 92.3%, respectively. The prediction tool appeared useful for identifying patients with UC who would not achieve SFCR at week 22 during VDZ therapy. This study provides a proof-of-concept that machine learning using real-world data could permit personalized treatment for UC.",0,0
5649,"Human activity recognition using wearable sensors, discriminant analysis, and long short-term memory-based neural structured learning. Healthcare using body sensor data has been getting huge research attentions by a wide range of researchers because of its good practical applications such as smart health care systems. For instance, smart wearable sensor-based behavior recognition system can observe elderly people in a smart eldercare environment to improve their lifestyle and can also help them by warning about forthcoming unprecedented events such as falls or other health risk, to prolong their independent life. Although there are many ways of using distinguished sensors to observe behavior of people, wearable sensors mostly provide reliable data in this regard to monitor the individual's functionality and lifestyle. In this paper, we propose a body sensor-based activity modeling and recognition system using time-sequential information-based deep Neural Structured Learning (NSL), a promising deep learning algorithm. First, we obtain data from multiple wearable sensors while the subjects conduct several daily activities. Once the data is collected, the time-sequential information then go through some statistical feature processing. Furthermore, kernel-based discriminant analysis (KDA) is applied to see the better clustering of the features from different activity classes by minimizing inner-class scatterings while maximizing inter-class scatterings of the samples. The robust time-sequential features are then applied with Neural Structured Learning (NSL) based on Long Short-Term Memory (LSTM), for activity modeling. The proposed approach achieved around 99% recall rate on a public dataset. It is also compared to existing different conventional machine learning methods such as typical Deep Belief Network (DBN), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN) where they yielded the maximum recall rate of 94%. Furthermore, a fast and efficient explainable Artificial Intelligence (XAI) algorithm, Local Interpretable Model-Agnostic Explanations (LIME) is used to explain and check the machine learning decisions. The robust activity recognition system can be adopted for understanding peoples' behavior in their daily life in different environments such as homes, clinics, and offices.",0,0
5654,"A Robust Machine Learning Based Framework for the Automated Detection of ADHD Using Pupillometric Biomarkers and Time Series Analysis. Accurate and efficient detection of attention-deficit/hyperactivity disorder (ADHD) is critical to ensure proper treatment for affected individuals. Current clinical examinations, however, are inefficient and prone to misdiagnosis, as they rely on qualitative observations of perceived behavior. We propose a robust machine learning based framework that analyzes pupil-size dynamics as an objective biomarker for the automated detection of ADHD. Our framework integrates a comprehensive pupillometric feature engineering and visualization pipeline with state-of-the-art binary classification algorithms and univariate feature selection. The support vector machine classifier achieved an average 85.6% area under the receiver operating characteristic (AUROC), 77.3% sensitivity, and 75.3% specificity using ten-fold nested cross-validation (CV) on a declassified dataset of 50 patients. 218 of the 783 engineered features, including fourier transform metrics, absolute energy, consecutive quantile changes, approximate entropy, aggregated linear trends, as well as pupil-size dilation velocity, were found to be statistically significant differentiators (p < 0.05), and provide novel behavioral insights into associations between pupil-size dynamics and the presence of ADHD. Despite a limited sample size, the strong AUROC values highlight the robustness of the binary classifiers in detecting ADHD-as such, with additional data, sensitivity and specificity metrics can be substantially augmented. This study is the first to apply machine learning based methods for the detection of ADHD using solely pupillometrics, and highlights its strength as a potential discriminative biomarker, paving the path for the development of novel diagnostic applications to aid in the detection of ADHD using oculometric paradigms and machine learning.",0,0
5662,"Deep Learning-Based Software Improves Clinicians' Detection Sensitivity of Aneurysms on Brain TOF-MRA. The detection of cerebral aneurysms on MRA is a challenging task. Recent studies have used deep learning-based software for automated detection of aneurysms on MRA and have reported high performance. The purpose of this study was to evaluate the incremental value of using deep learning-based software for the detection of aneurysms on MRA by 2 radiologists, a neurosurgeon, and a neurologist.",1,1
5663,"Deep learning based joint segmentation and characterization of multi-class retinal fluid lesions on OCT scans for clinical use in anti-VEGF therapy. In anti-vascular endothelial growth factor (anti-VEGF) therapy, an accurate estimation of multi-class retinal fluid (MRF) is required for the activity prescription and intravitreal dose. This study proposes an end-to-end deep learning-based retinal fluids segmentation network (RFS-Net) to segment and recognize three MRF lesion manifestations, namely, intraretinal fluid (IRF), subretinal fluid (SRF), and pigment epithelial detachment (PED), from multi-vendor optical coherence tomography (OCT) imagery. The proposed image analysis tool will optimize anti-VEGF therapy and contribute to reducing the inter- and intra-observer variability.",0,0
5670,Convolutional Neural Network of Multiparametric MRI Accurately Detects Axillary Lymph Node Metastasis in Breast Cancer Patients With Pre Neoadjuvant Chemotherapy. Accurate assessment of the axillary lymph nodes (aLNs) in breast cancer patients is essential for prognosis and treatment planning. Current radiological staging of nodal metastasis has poor accuracy. This study aimed to investigate the machine learning convolutional neural networks (CNNs) on multiparametric MRI to detect nodal metastasis with 18FDG-PET as ground truths.,0,0
5672,Identification of subgroups along the glycolysis-cholesterol synthesis axis and the development of an associated prognostic risk model. Skin cutaneous melanoma (SKCM) is one of the most highly prevalent and complicated malignancies. Glycolysis and cholesterogenesis pathways both play important roles in cancer metabolic adaptations. The main aims of this study are to subtype SKCM based on glycolytic and cholesterogenic genes and to build a clinical outcome predictive algorithm based on the subtypes.,0,0
5673,Potential of high dimensional radiomic features to assess blood components in intraaortic vessels in non-contrast CT scans. To assess the potential of radiomic features to quantify components of blood in intraaortic vessels to non-invasively predict moderate-to-severe anemia in non-contrast enhanced CT scans.,0,0
5678,"Validation of an Automatic Tagging System for Identifying Respiratory and Hemodynamic Deterioration Events in the Intensive Care Unit. Predictive models for critical events in the intensive care unit (ICU) might help providers anticipate patient deterioration. At the heart of predictive model development lies the ability to accurately label significant events, thereby facilitating the use of machine learning and similar strategies. We conducted this study to establish the validity of an automated system for tagging respiratory and hemodynamic deterioration by comparing automatic tags to tagging by expert reviewers.",1,1
5680,"Machine Learning for Antibiotic Resistance Prediction: A Prototype Using Off-the-Shelf Techniques and Entry-Level Data to Guide Empiric Antimicrobial Therapy. In the era of increasing antimicrobial resistance, the need for early identification and prompt treatment of multi-drug-resistant infections is crucial for achieving favorable outcomes in critically ill patients. As traditional microbiological susceptibility testing requires at least 24 hours, automated machine learning (AutoML) techniques could be used as clinical decision support tools to predict antimicrobial resistance and select appropriate empirical antibiotic treatment.",0,0
5682,"Distinguishable spatial-spectral feature learning neural network framework for motor imagery-based brain-computer interface. <i>Objective.</i>Spatial and spectral features extracted from electroencephalogram (EEG) are critical for the classification of motor imagery (MI) tasks. As prevalently used methods, the common spatial pattern (CSP) and filter bank CSP (FBCSP) can effectively extract spatial-spectral features from MI-related EEG. To further improve the separability of the CSP features, we proposed a distinguishable spatial-spectral feature learning neural network (DSSFLNN) framework for MI-based brain-computer interfaces (BCIs) in this study.<i>Approach.</i>The first step of the DSSFLNN framework was to extract FBCSP features from raw EEG signals. Then two squeeze-and-excitation modules were used to re-calibrate CSP features along the band-wise axis and the class-wise axis, respectively. Next, we used a parallel convolutional neural network module to learn distinguishable spatial-spectral features. Finally, the distinguishable spatial-spectral features were fed to a fully connected layer for classification. To verify the effectiveness of the proposed framework, we compared it with the state-of-the-art methods on BCI competition IV datasets 2a and 2b.<i>Main results.</i>The results showed that the DSSFLNN framework can achieve a mean Cohen's kappa value of 0.7 on two datasets, which outperformed the state-of-the-art methods. Moreover, two additional experiments were conducted and they proved that the combination of band-wise feature learning and class-wise feature learning can achieve significantly better performance than only using either one of them.<i>Significance.</i>The proposed DSSFLNN can effectively improve the decoding performance of MI-based BCIs.",0,0
5683,"Classification of error-related potentials evoked during stroke rehabilitation training. <i>Objective.</i>Error-related potentials (ErrPs) are elicited in the human brain following an error's perception. Recently, ErrPs have been observed in a novel task situation, i.e. when stroke patients perform upper-limb rehabilitation exercises. These ErrPs can be used to develop<i>assist-as-needed</i>(AAN) robotic stroke rehabilitation systems. However, to date, there is no reported research on assessing the feasibility of using the ErrPs to implement the AAN approach. Hence, in this study, we evaluated and compared the single-trial classification of novel ErrPs using various classical machine learning and deep learning approaches.<i>Approach.</i>Electroencephalogram data of 13 stroke patients recorded while performing an upper-limb physical rehabilitation exercise were used. Two classification approaches, one combining the xDAWN spatial filtering and support vector machines, and the other using a convolutional neural network-based double transfer learning, were utilized.<i>Main results.</i>Results showed that the ErrPs could be detected with a mean area under the receiver operating characteristics curve of 0.838, and a mean accuracy of 0.842, 0.257 above the chance level (<i>p</i>< 0.05), for a within-subject classification. The results indicated the feasibility of using ErrP signals in real-time AAN robot therapy with evidence from the conducted latency analysis, cross-subject classification, and three-class asynchronous classification.<i>Significance.</i>The findings presented support our proposed approach of using ErrPs as a measure to trigger and/or modulate as required the robotic assistance in a real-time<i>human-in-the-loop</i>robotic stroke rehabilitation system.",0,0
5684,Classifier Using Pontine Radial Diffusivity and Symptom Duration Accurately Predicts Recurrence of Trigeminal Neuralgia After Microvascular Decompression: A Pilot Study and Algorithm Description. Preprocedure diffusion tensor magnetic resonance imaging (MRI) may predict the response of trigeminal neuralgia (TN) patients to Gamma Knife (Elekta AB) and microvascular decompression (MVD).,0,0
5685,Bias and fairness assessment of a natural language processing opioid misuse classifier: detection and mitigation of electronic health record data disadvantages across racial subgroups. To assess fairness and bias of a previously validated machine learning opioid misuse classifier.,0,0
5688,"Radiomics machine learning study with a small sample size: Single random training-test set split may lead to unreliable results. This study aims to determine how randomly splitting a dataset into training and test sets affects the estimated performance of a machine learning model and its gap from the test performance under different conditions, using real-world brain tumor radiomics data. We conducted two classification tasks of different difficulty levels with magnetic resonance imaging (MRI) radiomics features: (1) ""Simple"" task, glioblastomas [n = 109] vs. brain metastasis [n = 58] and (2) ""difficult"" task, low- [n = 163] vs. high-grade [n = 95] meningiomas. Additionally, two undersampled datasets were created by randomly sampling 50% from these datasets. We performed random training-test set splitting for each dataset repeatedly to create 1,000 different training-test set pairs. For each dataset pair, the least absolute shrinkage and selection operator model was trained and evaluated using various validation methods in the training set, and tested in the test set, using the area under the curve (AUC) as an evaluation metric. The AUCs in training and testing varied among different training-test set pairs, especially with the undersampled datasets and the difficult task. The mean (Â±standard deviation) AUC difference between training and testing was 0.039 (Â±0.032) for the simple task without undersampling and 0.092 (Â±0.071) for the difficult task with undersampling. In a training-test set pair with the difficult task without undersampling, for example, the AUC was high in training but much lower in testing (0.882 and 0.667, respectively); in another dataset pair with the same task, however, the AUC was low in training but much higher in testing (0.709 and 0.911, respectively). When the AUC discrepancy between training and test, or generalization gap, was large, none of the validation methods helped sufficiently reduce the generalization gap. Our results suggest that machine learning after a single random training-test set split may lead to unreliable results in radiomics studies especially with small sample sizes.",0,0
5696,"Deep Learning for Retinal Image Quality Assessment of Optic Nerve Head Disorders. Deep learning (DL)-based retinal image quality assessment (RIQA) algorithms have been gaining popularity, as a solution to reduce the frequency of diagnostically unusable images. Most existing RIQA tools target retinal conditions, with a dearth of studies looking into RIQA models for optic nerve head (ONH) disorders. The recent success of DL systems in detecting ONH abnormalities on color fundus images prompts the development of tailored RIQA algorithms for these specific conditions. In this review, we discuss recent progress in DL-based RIQA models in general and the need for RIQA models tailored for ONH disorders. Finally, we propose suggestions for such models in the future.",0,0
5699,"Deep Learning With Anaphora Resolution for the Detection of Tweeters With Depression: Algorithm Development and Validation Study. Mental health problems are widely recognized as a major public health challenge worldwide. This concern highlights the need to develop effective tools for detecting mental health disorders in the population. Social networks are a promising source of data wherein patients publish rich personal information that can be mined to extract valuable psychological cues; however, these data come with their own set of challenges, such as the need to disambiguate between statements about oneself and third parties. Traditionally, natural language processing techniques for social media have looked at text classifiers and user classification models separately, hence presenting a challenge for researchers who want to combine text sentiment and user sentiment analysis.",0,0
5702,"Ranking Rule-Based Automatic Explanations for Machine Learning Predictions on Asthma Hospital Encounters in Patients With Asthma: Retrospective Cohort Study. Asthma hospital encounters impose a heavy burden on the health care system. To improve preventive care and outcomes for patients with asthma, we recently developed a black-box machine learning model to predict whether a patient with asthma will have one or more asthma hospital encounters in the succeeding 12 months. Our model is more accurate than previous models. However, black-box machine learning models do not explain their predictions, which forms a barrier to widespread clinical adoption. To solve this issue, we previously developed a method to automatically provide rule-based explanations for the model's predictions and to suggest tailored interventions without sacrificing model performance. For an average patient correctly predicted by our model to have future asthma hospital encounters, our explanation method generated over 5000 rule-based explanations, if any. However, the user of the automated explanation function, often a busy clinician, will want to quickly obtain the most useful information for a patient by viewing only the top few explanations. Therefore, a methodology is required to appropriately rank the explanations generated for a patient. However, this is currently an open problem.",0,0
5708,"Model-driven Deep Learning Method for Pancreatic Cancer Segmentation Based on Spiral-transformation. Pancreatic cancer is a lethal malignant tumor with one of the worst prognoses. Accurate segmentation of pancreatic cancer is vital in clinical diagnosis and treatment. Due to the unclear boundary and small size of cancers, it is challenging to both manually annotate and automatically segment cancers. Considering 3D information utilization and small sample sizes, we propose a model-driven deep learning method for pancreatic cancer segmentation based on spiral transformation. Specifically, a spiral-transformation algorithm with uniform sampling was developed to map 3D images onto 2D planes while preserving the spatial relationship between textures, thus addressing the challenge in effectively applying 3D contextual information in a 2D model. This study is the first to introduce spiral transformation in a segmentation task to provide effective data augmentation, alleviating the issue of small sample size. Moreover, a transformation-weight-corrected module was embedded into the deep learning model to unify the entire framework. It can achieve 2D segmentation and corresponding 3D rebuilding constraint to overcome non-unique 3D rebuilding results due to the uniform and dense sampling. A smooth regularization based on rebuilding prior knowledge was also designed to optimize segmentation results. The extensive experiments showed that the proposed method achieved a promising segmentation performance on multi-parametric MRIs, where T2, T1, ADC, DWI images obtained the DSC of 65.6%, 64.0%, 64.5%, 65.3%, respectively. This method can provide a novel paradigm to efficiently apply 3D information and augment sample sizes in the development of artificial intelligence for cancer segmentation. Our source codes will be released at https://github.com/SJTUBME-QianLab/Spiral-Segmentation.",0,0
5711,Machine Learning to Predict Tamoxifen Nonadherence Among US Commercially Insured Patients With Metastatic Breast Cancer. Adherence to tamoxifen citrate among women diagnosed with metastatic breast cancer can improve survival and minimize recurrence. This study aimed to use real-world data and machine learning (ML) methods to classify tamoxifen nonadherence.,0,0
5712,"Neural Speech Encoding in Infancy Predicts Future Language and Communication Difficulties. Purpose This study aimed to construct an objective and cost-effective prognostic tool to forecast the future language and communication abilities of individual infants. Method Speech-evoked electroencephalography (EEG) data were collected from 118 infants during the first year of life during the exposure to speech stimuli that differed principally in fundamental frequency. Language and communication outcomes, namely four subtests of the MacArthur-Bates Communicative Development Inventories (MCDI)-Chinese version, were collected between 3 and 16 months after initial EEG testing. In the two-way classification, children were classified into those with future MCDI scores below the 25th percentile for their age group and those above the same percentile, while the three-way classification classified them into < 25th, 25th-75th, and > 75th percentile groups. Machine learning (support vector machine classification) with cross validation was used for model construction. Statistical significance was assessed. Results Across the four MCDI measures of early gestures, later gestures, vocabulary comprehension, and vocabulary production, the areas under the receiver-operating characteristic curve of the predictive models were respectively .92 Â± .031, .91 Â± .028, .90 Â± .035, and .89 Â± .039 for the two-way classification, and .88 Â± .041, .89 Â± .033, .85 Â± .047, and .85 Â± .050 for the three-way classification (<i>p</i> < .01 for all models). Conclusions Future language and communication variability can be predicted by an objective EEG method that indicates the function of the auditory neural pathway foundational to spoken language development, with precision sufficient for individual predictions. Longer-term research is needed to assess predictability of categorical diagnostic status. Supplemental Material https://doi.org/10.23641/asha.15138546.",0,0
5716,"Identifying resting state differences salient for resilience to chronic pain based on machine learning multivariate pattern analysis. Studies have documented behavior differences between more versus less resilient adults with chronic pain (CP), but the presence and nature of underlying neurophysiological differences have received scant attention. In this study, we attempted to identify regions of interest (ROIs) in which resting state (Rs) brain activity discriminated more from less resilient CP subgroups based on multiple kernel learning (MKL). More and less resilient community-dwellers with chronic musculoskeletal pain (70 women, 39 men) engaged in structural and functional magnetic resonance imaging (MRI) scans, wherein MKL assessed Rs activity based on amplitude of low frequency fluctuations (ALFF), fractional amplitudes of low frequency fluctuations (fALFF), and regional homogeneity (ReHo) modalities to identify ROIs most salient for discriminating more versus less resilient subgroups. Compared to classification based on single modalities, multi-modal classification based on combined fALFF and ReHo features achieved a substantially higher classification accuracy rate (79%). Brain regions with the best discriminative power included those implicated in pain processing, reward, executive function, goal-directed action, emotion regulation and resilience to mood disorders though variation trends were not consistent between more and less resilient subgroups. Results revealed patterns of Rs activity that serve as possible biomarkers for resilience to chronic musculoskeletal pain.",0,0
5717,"Machine Learning-Enabled Determination of Diffuseness of Brain Arteriovenous Malformations from Magnetic Resonance Angiography. The diffuseness of brain arteriovenous malformations (bAVMs) is a significant factor in surgical outcome evaluation and hemorrhagic risk prediction. However, there are still predicaments in identifying diffuseness, such as the judging variety resulting from different experience and difficulties in quantification. The purpose of this study was to develop a machine learning (ML) model to automatically identify the diffuseness of bAVM niduses using three-dimensional (3D) time-of-flight magnetic resonance angiography (TOF-MRA) images. A total of 635 patients with bAVMs who underwent TOF-MRA imaging were enrolled. Three experienced neuroradiologists delineated the bAVM lesions and identified the diffuseness on TOF-MRA images, which were considered the ground-truth reference. The U-Net-based segmentation model was trained to segment lesion areas. Eight mainstream ML models were trained through the radiomic features of segmented lesions to identify diffuseness, based on which an integrated model was built and yielded the best performance. In the test set, the Dice score, F2 score, precision, and recall for the segmentation model were 0.80 [0.72-0.84], 0.80 [0.71-0.86], 0.84 [0.77-0.93], and 0.82 [0.69-0.89], respectively. For the diffuseness identification model, the ensemble-based model was applied with an area under the Receiver-operating characteristic curves (AUC) of 0.93 (95% CI 0.87-0.99) in the training set. The AUC, accuracy, precision, recall, and F1 score for the diffuseness identification model were 0.95, 0.90, 0.81, 0.84, and 0.83, respectively, in the test set. The ML models showed good performance in automatically detecting bAVM lesions and identifying diffuseness. The method may help to judge the diffuseness of bAVMs objectively, quantificationally, and efficiently.",0,0
5719,Using deep learning to assist readers during the arbitration process: a lesion-based retrospective evaluation of breast cancer screening performance. To evaluate if artificial intelligence (AI) can discriminate recalled benign from recalled malignant mammographic screening abnormalities to improve screening performance.,1,0
5720,Machine learning with multiparametric breast MRI for prediction of Ki-67 and histologic grade in early-stage luminal breast cancer. To investigate whether machine learning-based prediction models using 3-T multiparametric MRI (mpMRI) can predict Ki-67 and histologic grade in stage I-II luminal cancer.,0,0
5722,"Development and Validation of Unplanned Extubation Prediction Models Using Intensive Care Unit Data: Retrospective, Comparative, Machine Learning Study. Patient safety in the intensive care unit (ICU) is one of the most critical issues, and unplanned extubation (UE) is considered the most adverse event for patient safety. Prevention and early detection of such an event is an essential but difficult component of quality care.",0,0
5730,"Reconstruction of the left atrium for atrial fibrillation ablation using the machine learning CARTO 3Â m-FAM software. Atrial fibrillation (AF) ablation requires a precise reconstruction of the left atrium (LA) and pulmonary veins (PV). Model-based FAM (m-FAM) is a novel module recently developed for the CARTO system which applies machine learning techniques to LA reconstruction. We aimed to evaluate the feasibility and safety of a m-FAM-guided AF ablation as well as the accuracy of LA reconstruction using the cardiac computed tomography angiography (CTA) of the same patient LA as the gold standard, in 32 patients referred for AF ablation.",0,0
5731,"Overall Survival Prediction in Renal Cell Carcinoma Patients Using Computed Tomography Radiomic and Clinical Information. The aim of this work is to investigate the applicability of radiomic features alone and in combination with clinical information for the prediction of renal cell carcinoma (RCC) patients' overall survival after partial or radical nephrectomy. Clinical studies of 210 RCC patients from The Cancer Imaging Archive (TCIA) who underwent either partial or radical nephrectomy were included in this study. Regions of interest (ROIs) were manually defined on CT images. A total of 225 radiomic features were extracted and analyzed along with the 59 clinical features. An elastic net penalized Cox regression was used for feature selection. Accelerated failure time (AFT) with the shared frailty model was used to determine the effects of the selected features on the overall survival time. Eleven radiomic and twelve clinical features were selected based on their non-zero coefficients. Tumor grade, tumor malignancy, and pathology t-stage were the most significant predictors of overall survival (OS) among the clinical features (pâ€‰<â€‰0.002,â€‰<â€‰0.02, andâ€‰<â€‰0.018, respectively). The most significant predictors of OS among the selected radiomic features were flatness, area density, and median (pâ€‰<â€‰0.02,â€‰<â€‰0.02, andâ€‰<â€‰0.05, respectively). Along with important clinical features, such as tumor heterogeneity and tumor grade, imaging biomarkers such as tumor flatness, area density, and median are significantly correlated with OS of RCC patients.",0,0
5735,"A Deep Network for Joint Registration and Reconstruction of Images with Pathologies. Registration of images with pathologies is challenging due to tissue appearance changes and missing correspondences caused by the pathologies. Moreover, mass effects as observed for brain tumors may displace tissue, creating larger deformations over time than what is observed in a healthy brain. Deep learning models have successfully been applied to image registration to offer dramatic speed up and to use surrogate information (e.g., segmentations) during training. However, existing approaches focus on learning registration models using images from healthy patients. They are therefore not designed for the registration of images with strong pathologies for example in the context of brain tumors, and traumatic brain injuries. In this work, we explore a deep learning approach to register images with brain tumors to an atlas. Our model learns an appearance mapping from images with tumors to the atlas, while simultaneously predicting the transformation to atlas space. Using separate decoders, the network disentangles the tumor mass effect from the reconstruction of quasi-normal images. Results on both synthetic and real brain tumor scans show that our approach outperforms cost function masking for registration to the atlas and that reconstructed quasi-normal images can be used for better longitudinal registrations.",0,0
5740,Radiomics AI prediction for head and neck squamous cell carcinoma (HNSCC) prognosis and recurrence with target volume approach. To evaluate the performance of radiomics features extracted from planning target volume (PTV) and gross tumor volume (GTV) in the prediction of the death prognosis and cancer recurrence rate for head and neck squamous cell carcinoma (HNSCC).,0,0
5743,"Deep Learning for Identification of Acute Illness and Facial Cues of Illness. <b>Background:</b> The inclusion of facial and bodily cues (clinical gestalt) in machine learning (ML) models improves the assessment of patients' health status, as shown in genetic syndromes and acute coronary syndrome. It is unknown if the inclusion of clinical gestalt improves ML-based classification of acutely ill patients. As in previous research in ML analysis of medical images, simulated or augmented data may be used to assess the usability of clinical gestalt. <b>Objective:</b> To assess whether a deep learning algorithm trained on a dataset of simulated and augmented facial photographs reflecting acutely ill patients can distinguish between healthy and LPS-infused, acutely ill individuals. <b>Methods:</b> Photographs from twenty-six volunteers whose facial features were manipulated to resemble a state of acute illness were used to extract features of illness and generate a synthetic dataset of acutely ill photographs, using a neural transfer convolutional neural network (NT-CNN) for data augmentation. Then, four distinct CNNs were trained on different parts of the facial photographs and concatenated into one final, stacked CNN which classified individuals as healthy or acutely ill. Finally, the stacked CNN was validated in an external dataset of volunteers injected with lipopolysaccharide (LPS). <b>Results:</b> In the external validation set, the four individual feature models distinguished acutely ill patients with sensitivities ranging from 10.5% (95% CI, 1.3-33.1% for the skin model) to 89.4% (66.9-98.7%, for the nose model). Specificity ranged from 42.1% (20.3-66.5%) for the nose model and 94.7% (73.9-99.9%) for skin. The stacked model combining all four facial features achieved an area under the receiver characteristic operating curve (AUROC) of 0.67 (0.62-0.71) and distinguished acutely ill patients with a sensitivity of 100% (82.35-100.00%) and specificity of 42.11% (20.25-66.50%). <b>Conclusion:</b> A deep learning algorithm trained on a synthetic, augmented dataset of facial photographs distinguished between healthy and simulated acutely ill individuals, demonstrating that synthetically generated data can be used to develop algorithms for health conditions in which large datasets are difficult to obtain. These results support the potential of facial feature analysis algorithms to support the diagnosis of acute illness.",0,0
5744,"Identify Inflammatory Bowel Disease-Related Genes Based on Machine Learning. The patients of Inflammatory bowel disease (IBD) are increasing worldwide. IBD has the characteristics of recurring and difficult to cure, and it is also one of the high-risk factors for colorectal cancer (CRC). The occurrence of IBD is closely related to genetic factors, which prompted us to identify IBD-related genes. Based on the hypothesis that similar diseases are related to similar genes, we purposed a SVM-based method to identify IBD-related genes by disease similarities and gene interactions. One hundred thirty-five diseases which have similarities with IBD and their related genes were obtained. These genes are considered as the candidates of IBD-related genes. We extracted features of each gene and implemented SVM to identify the probability that it is related to IBD. Ten-cross validation was applied to verify the effectiveness of our method. The AUC is 0.93 and AUPR is 0.97, which are the best among four methods. We prioritized the candidate genes and did case studies on top five genes.",0,0
5745,Predicting Malignancy and Invasiveness of Pulmonary Subsolid Nodules on CT Images Using Deep Learning. To develop and validate a deep learning-based model on CT images for the malignancy and invasiveness prediction of pulmonary subsolid nodules (SSNs).,0,0
5758,"A bagging dynamic deep learning network for diagnosing COVID-19. COVID-19 is a serious ongoing worldwide pandemic. Using X-ray chest radiography images for automatically diagnosing COVID-19 is an effective and convenient means of providing diagnostic assistance to clinicians in practice. This paper proposes a bagging dynamic deep learning network (B-DDLN) for diagnosing COVID-19 by intelligently recognizing its symptoms in X-ray chest radiography images. After a series of preprocessing steps for images, we pre-train convolution blocks as a feature extractor. For the extracted features, a bagging dynamic learning network classifier is trained based on neural dynamic learning algorithm and bagging algorithm. B-DDLN connects the feature extractor and bagging classifier in series. Experimental results verify that the proposed B-DDLN achieves 98.8889% testing accuracy, whichÂ shows the best diagnosis performance among the existing state-of-the-art methods on the open image set. It also provides evidence for further detection and treatment.",0,0
5762,Evaluation of acute hematological toxicity by machine learning in gynecologic cancers using postoperative radiotherapy. The aim of the study is to investigate the factors affecting acute hematologic toxicity (HT) in the adjuvant radiotherapy (RT) of gynecologic cancers by machine learning.,0,0
5771,"dSPIC: a deep SPECT image classification network for automated multi-disease, multi-lesion diagnosis. Functional imaging especially the SPECT bone scintigraphy has been accepted as the effective clinical tool for diagnosis, treatment, evaluation, and prevention of various diseases including metastasis. However, SPECT imaging is brightly characterized by poor resolution, low signal-to-noise ratio, as well as the high sensitivity and low specificity because of the visually similar characteristics of lesions between diseases on imaging findings.",0,0
5773,"Concurrent assessment of gait kinematics using marker-based and markerless motion capture. Kinematic analysis is a useful and widespread tool used in research and clinical biomechanics for the quantification of human movement. Common marker-based optical motion capture systems are time intensive and require highly trained operators to obtain kinematic data. Markerless motion capture systems offer an alternative method for the measurement of kinematic data with several practical benefits. This work compared the kinematics of human gait measured using a deep learning algorithm-based markerless motion capture system to those from a standard marker-based motion capture system. Thirty healthy adult participants walked on a treadmill while data were simultaneously recorded using eight video cameras and seven infrared optical motion capture cameras, providing synchronized markerless and marker-based data for comparison. The average root mean square distance (RMSD) between corresponding joint centers was less than 2.5Â cm for all joints except the hip, which was 3.6Â cm. Lower limb segment angles relative to the global coordinate system indicated the global segment pose estimates from both systems were very similar, with RMSD of less than 5.5Â° for all segment angles except those that represent rotations about the long axis of the segment. Lower limb joint angles captured similar patterns for flexion/extension at all joints, ab/adduction at the knee and hip, and toe-in/toe-out at the ankle. These findings indicate that the markerless system would be a suitable alternative technology in cases where the practical benefits of markerless data collection are preferred.",0,0
5774,"Predicting apneic events in preterm infants using cardio-respiratory and movement features. Preterm neonates are prone to episodes of apnea, bradycardia and hypoxia (ABH) that can lead to neurological morbidities or even death. There is broad interest in developing methods for real-time prediction of ABH events to inform interventions that prevent or reduce their incidence and severity. Using advances in machine learning methods, this study develops an algorithm to predict ABH events.",0,0
5785,"Application of a deep-learning technique to non-linear images from human tissue biopsies for shedding new light on breast cancer diagnosis. The development of label-free non-invasive techniques to be used as diagnostic tools in cancer research is of great importance for improving the quality of life for millions of patients. Previous studies have demonstrated that Third Harmonic Generation (THG) imaging could differentiate malignant from benign unlabeled human breast biopsies and distinguish the different grades of cancer. Towards the application of such technologies to clinic, in the present report, a deep learning technique was applied to THG images recorded from breast cancer tissues of grades 0, I, II and III. By the implementation of a convolutional neural network (CNN) model, the differentiation of malignant from benign breast tissue samples and the discrimination of the different grades of cancer in a fast and accurate way were achieved. The obtained results provide a step ahead towards the use of optical diagnostic tools in conjunction with the CNN image classifier for the reliable and rapid malignancy diagnosis in clinic.",0,0
5790,"Comparison of an Automated Plate Assessment System (APAS Independence) and Artificial Intelligence (AI) to Manual Plate Reading of Methicillin-resistant and Methicillin-susceptible <i>Staphylococcus aureus</i> Chromagar Surveillance Cultures. <b>Background:</b> The Automated Plate Assessment System (APAS Independence) [Clever Culture System, BÃ¤ch, Switzerland] is an automated imaging station linked with interpretive software that detects target colonies of interest on chromogenic media and sorts samples as negative or presumptive positive. We evaluated the accuracy of the APAS to triage methicillin-resistant <i>Staphylococcus aureus</i> (MRSA) and <i>S. aureus</i>) cultures using chromogenic media compared to human interpretation. <b>Methods:</b> Patient samples collected from the nares on Eswabs were plated to BD BBLâ„¢ CHROMagarâ„¢ MRSA II and BD BBL CHROMagar Staph aureus and allowed to incubate for 20-24 h at 37Â°C in non-CO2. Mauve colonies are suggestive of <i>S. aureus</i> and were confirmed with latex agglutination. Following incubation, samples were first interrogated by APAS before being read by a trained technologist blinded to the APAS interpretation. The triaging by both APAS and the technologists were compared for accuracy. Any discordant results required further analysis by a third reader. <b>Results:</b> Over a five-month period, 5,913 CHROMagar MRSA cultures were evaluated. Of those, 236 were read as concordantly positive, 5,525 were read as concordantly negative, and 152 required discordant analysis. Positive and negative percent agreements (PPA, NPA) were 100% and 97.3%, respectively. The APAS detected 5 positive cultures that were missed by manual reading, and determined to be true positives. In a separate analysis, 744 CHROMagar Staph aureus plates were read in parallel. Of these, 133 were concordantly positive, 585 were concordantly negative, and 26 required discordant analysis. PPA and NPA were 95.7% and 96.7%, respectively. <b>Conclusion:</b> This study confirmed the high sensitivity of digital image analysis by the APAS Independence such that negative cultures can be reliably reported without technologist intervention (NPV 100% for CHROMagar MRSA and 99.0% for CHROMagar Staph aureus). Triaging using the APAS Independence may provide great efficiencies in a laboratory with high throughput of MRSA and <i>S. aureus</i> surveillance cultures.",1,1
5796,"External Validation of Deep Learning Algorithm for Detecting and Visualizing Femoral Neck Fracture Including Displaced and Non-displaced Fracture on Plain X-ray. This study aimed to develop a method for detection of femoral neck fracture (FNF) including displaced and non-displaced fractures using convolutional neural network (CNN) with plain X-ray and to validate its use across hospitals through internal and external validation sets. This is a retrospective study using hip and pelvic anteroposterior films for training and detecting femoral neck fracture through residual neural network (ResNet) 18 with convolutional block attention module (CBAM)â€‰+â€‰â€‰+â€‰. The study was performed at two tertiary hospitals between February and May 2020 and used data from January 2005 to December 2018. Our primary outcome was favorable performance for diagnosis of femoral neck fracture from negative studies in our dataset. We described the outcomes as area under the receiver operating characteristic curve (AUC), accuracy, Youden index, sensitivity, and specificity. A total of 4,189 images that contained 1,109 positive images (332 non-displaced and 777 displaced) and 3,080 negative images were collected from two hospitals. The test values after training with one hospital dataset were 0.999 AUC, 0.986 accuracy, 0.960 Youden index, and 0.966 sensitivity, and 0.993 specificity. Values of external validation with the other hospital dataset were 0.977, 0.971, 0.920, 0.939, and 0.982, respectively. Values of merged hospital datasets were 0.987, 0.983, 0.960, 0.973, and 0.987, respectively. A CNN algorithm for FNF detection in both displaced and non-displaced fractures using plain X-rays could be used in other hospitals to screen for FNF after training with images from the hospital of interest.",0,0
5798,"Robustness and performance of radiomic features in diagnosing cystic renal masses. We study the inter-reader variability in manual delineation of cystic renal masses (CRMs) presented in computerized tomography (CT) images and its effect on the classification performance of a machine learning algorithm in distinguishing benign from potentially malignant CRMs. In addition, we assessed whether the inclusion of higher-order robust radiomic features improves the classification performance over the use of first-order features.",0,0
5801,"Using Machine Learning to Predict Remission in Patients With Major Depressive Disorder Treated With Desvenlafaxine : Utiliser l'apprentissage machine pour prÃ©dire la rÃ©mission chez les patients souffrant de trouble dÃ©pressif majeur traitÃ©s par desvenlafaxine. Major depressive disorder (MDD) is a common and burdensome condition that has low rates of treatment success for each individual treatment. This means that many patients require several medication switches to achieve remission; selecting an effective antidepressant is typically a sequential trial-and-error process. Machine learning techniques may be able to learn models that can predict whether a specific patient will respond to a given treatment, before it is administered. This study uses baseline clinical data to create a machine-learned model that accurately predicts remission status for a patient after desvenlafaxine (DVS) treatment.",0,0
5805,"Mid-infrared spectral classification of endometrial cancer compared to benign controls in serum or plasma samples. This study demonstrates a discrimination of endometrial cancer <i>versus</i> (non-cancerous) benign controls based on mid-infrared (MIR) spectroscopy of dried plasma or serum liquid samples. A detailed evaluation was performed using four discriminant methods (LDA, QDA, kNN or SVM) to execute the classification task. The discriminant methods used in the study comprised methods that are widely used in the statistics (LDA and QDA) and machine learning literature (kNN and SVM). Of particular interest, is the impact of discrimination when presented with spectral data from a section of the bio-fingerprint region (1430 cm<sup>-1</sup> to 900 cm<sup>-1</sup>) in contrast to the more extended bio-fingerprint region used here (1800 cm<sup>-1</sup> to 900 cm<sup>-1</sup>). Quality metrics used were the misclassification rate, sensitivity, specificity, and Matthew's correlation coefficient (MCC). For plasma (with spectral data ranging from 1430 cm<sup>-1</sup> to 900 cm<sup>-1</sup>), the best performing classifier was kNN, which achieved a sensitivity, specificity and MCC of 0.865 Â± 0.043, 0.865 Â± 0.023 and 0.762 Â± 0.034, respectively. For serum (in the same wavenumber range), the best performing classifier was LDA, achieving a sensitivity, specificity and MCC of 0.899 Â± 0.023, 0.763 Â± 0.048 and 0.664 Â± 0.067, respectively. For plasma (with spectral data ranging from 1800 cm<sup>-1</sup> to 900 cm<sup>-1</sup>), the best performing classifier was SVM, with a sensitivity, specificity and MCC of 0.993 Â± 0.010, 0.815 Â± 0.000 and 0.815 Â± 0.010, respectively. For serum (in the same wavenumber range), QDA performed best achieving a sensitivity, specificity and MCC of 0.852 Â± 0.023, 0.700 Â± 0.162 and 0.557 Â± 0.012, respectively. Our findings demonstrate that even when a section of the bio-fingerprint region has been removed, good classification of endometrial cancer <i>versus</i> non-cancerous controls is still maintained. These findings suggest the potential of a MIR screening tool for endometrial cancer screening.",0,0
5807,A Machine Learning Approach in Predicting Mortality Following Emergency General Surgery. There is a significant mortality burden associated with emergency general surgery (EGS) procedures. The objective of this study was to develop and validate the use of a machine learning approach to predict mortality following EGS.,0,0
5808,"Mammographic Surveillance After Breast Conserving Therapy: Impact of Digital Breast Tomosynthesis and Artificial Intelligence-Based Computer-Aided Detection. <b>Background:</b> Postoperative mammograms present interpretive challenges due to postoperative distortion and hematomas. The application of digital breast tomosynthesis (DBT) and artificial intelligence-based computer-aided detection (AI-CAD) after breast concerving therapy (BCT) has not been widely investigated. <b>Objective:</b> To assess the impact of additional DBT or AI-CAD on recall rate and diagnostic performance in women undergoing mammographic surveillance after BCT. <b>Methods:</b> This retrospective study included 314 women (mean age 53.2Â±10.6 years; 4 with bilateral breast cancer) who underwent BCT followed by DBT (mean interval from surgery to DBT of 15.2Â±15.4 months). Three breast radiologists independently reviewed images in three sessions: digital mammography (DM), DM with DBT (DM+DBT), and DM with AI-CAD (DM+AI-CAD). Recall rates and diagnostic performance were compared between DM, DM+DBT, and DM+AI-CAD, using readers' mean results. <b>Results:</b> Of the 314 women, 6 breast recurrences (3 ipsilateral, 3 contralateral) developed at the time of surveillance mammography. Ipsilateral breast recall rate was lower for DM+AI-CAD (1.9%) than for DM (11.2%) or DM+DBT (4.1%) (p<.001). Contralateral breast recall rate was lower for DM+AI-CAD (1.5%, p<.001) than for DM (6.6%) but not DM+DBT (2.7%, p=.08). In ipsilateral breast, accuracy was higher for DM+AI-CAD (97.0%) than for DM (88.5%) or DM+DBT (94.8%) (p<.05); specificity was higher for DM+AICAD (98.3%) than for DM (89.3%) or DM+DBT (96.1%) (p<.05); sensitivity was lower for DM+AI-CAD (22.2%) than for DM (66.7%, p=.03) but not DM+DBT (22.2%, p>.99). In contralateral breast, accuracy was higher for DM+AI-CAD (97.1%) than for DM (92.5%, p<.001) but not DM+DBT (96.1%, p=.25); specificity was higher for DM+AI-CAD (98.6%) than for DM (93.7%, p<.001) but not DM+DBT (97.5%) (p=.09); sensitivity was not different between DM (33.3%), DM+DBT (22.2%), and DM+AI-CAD (11.1%) (p>.05). <b>Conclusion:</b> After BCT, adjunct DBT or AI-CAD reduced recall rates and improved accuracy in the ipsilateral and contralateral breasts compared with DM. In the ipsilateral breast, addition of AI-CAD resulted in lower recall rate and higher accuracy than addition of DBT. <b>Clinical Impact:</b> AI-CAD may help address the challenges of post-BCT surveillance mammograms.",1,1
5811,"Multimodal Autoencoder Predicts fNIRS Resting State From EEG Signals. In this work, we introduce a deep learning architecture for evaluation on multimodal electroencephalographic (EEG) and functional near-infrared spectroscopy (fNIRS) recordings from 40 epileptic patients. Long short-term memory units and convolutional neural networks are integrated within a multimodal sequence-to-sequence autoencoder. The trained neural network predicts fNIRS signals from EEG, sans a priori, by hierarchically extracting deep features from EEG full spectra and specific EEG frequency bands. Results show that higher frequency EEG ranges are predictive of fNIRS signals with the gamma band inputs dominating fNIRS prediction as compared to other frequency envelopes. Seed based functional connectivity validates similar patterns between experimental fNIRS and our model's fNIRS reconstructions. This is the first study that shows it is possible to predict brain hemodynamics (fNIRS) from encoded neural data (EEG) in the resting human epileptic brain based on power spectrum amplitude modulation of frequency oscillations in the context of specific hypotheses about how EEG frequency bands decode fNIRS signals.",0,0
5814,"Classification of true progression after radiotherapy of brain metastasis on MRI using artificial intelligence: a systematic review and meta-analysis. Classification of true progression from nonprogression (eg, radiation-necrosis) after stereotactic radiotherapy/radiosurgery of brain metastasis is known to be a challenging diagnostic task on conventional magnetic resonance imaging (MRI). The scope and status of research using artificial intelligence (AI) on classifying true progression are yet unknown.",0,0
5825,"Preoperative prediction of lymph node metastasis in patients with papillary thyroid carcinoma by an artificial intelligence algorithm. It is necessary to identify patients at risk of developing lymph node metastasis prior to papillary thyroid carcinoma (PTC) surgery. This can be challenging due to limiting factors, and an artificial intelligence algorithm may be a viable option.",0,0
5827,"Convolutional neural networks for the detection of malignant melanoma in dermoscopy images. Convolutional neural networks gained popularity due to their ability to detect and classify objects in images and videos. It gives also an opportunity to use them for medical tasks in such specialties like dermatology, radiology or ophthalmology. The aim of this study was to investigate the ability of convolutional neural networks to classify malignant melanoma in dermoscopy images.",0,0
5829,"Pan-Cancer Survival Classification With Clinicopathological and Targeted Gene Expression Features. Prognostication for patients with cancer is important for clinical planning and management, but remains challenging given the large number of factors that can influence outcomes. As such, there is a need to identify features that can robustly predict patient outcomes. We evaluated 8608 patient tumor samples across 16 cancer types from The Cancer Genome Atlas and generated distinct survival classifiers for each using clinical and histopathological data accessible to standard oncology workflows. For cancers that had poor model performance, we deployed a random-forest-embedded sequential forward selection approach that began with an initial subset of the 15 most predictive clinicopathological features before sequentially appending the next most informative gene as an additional feature. With classifiers derived from clinical and histopathological features alone, we observed cancer-type-dependent model performance and an area under the receiver operating curve (AUROC) range of 0.65 to 0.91 across all 16 cancer types for 1- and 3-year survival prediction, with some classifiers consistently outperforming those for others. As such, for cancers that had poor model performance, we posited that the addition of more complex biomolecular features could enhance our ability to prognose patients where clinicopathological features were insufficient. With the inclusion of gene expression data, model performance for 3 select cancers (glioblastoma, stomach/gastric adenocarcinoma, ovarian serous carcinoma) markedly increased from initial AUROC scores of 0.66, 0.69, and 0.67 to 0.76, 0.77, and 0.77, respectively. As a whole, this study provides a thorough examination of the relative contributions of clinical, pathological, and gene expression data in predicting overall survival and reveals cancer types for which clinical features are already strong predictors and those where additional biomolecular information is needed.",0,0
5830,"C+EffxNet: A novel hybrid approach for COVID-19 diagnosis on CT images based on CBAM and EfficientNet. COVID-19, one of the biggest diseases of our age, continues to spread rapidly around the world. Studies continue rapidly for the diagnosis and treatment of this disease. It is of great importance that individuals who are infected with this virus be isolated from the rest of the society so that the disease does not spread further. In addition to the tests performed in the detection process of the patients, X-ray and computed tomography are also used. In this study, a new hybrid model that can diagnose COVID-19 from computed tomography images created using EfficientNet, one of the current deep learning models, with a model consisting of attention blocks is proposed. In the first step of this new model, channel attention, spatial attention, and residual blocks are used to extract the most important features from the images. The extracted features are combined in accordance with the hyper-column technique. The combined features are given as input to the EfficientNet models in the second step of the model. The deep features obtained from this proposed hybrid model were classified with the Support Vector Machine classifier after feature selection. Principal Components Analysis was used for feature selection. The approach can accurately predict COVID-19 with a 99% accuracy rate. The first four versions of EfficientNet are used in the approach. In addition, Bayesian optimization was used in the hyper parameter estimation of the Support Vector Machine classifier. Comparative performance analysis of the approach with other approaches in the field is given.",0,0
5836,"Artificial intelligence-assisted fast screening cervical high grade squamous intraepithelial lesion and squamous cell carcinoma diagnosis and treatment planning. Every year cervical cancer affects more than 300,000 people, and on average one woman is diagnosed with cervical cancer every minute. Early diagnosis and classification of cervical lesions greatly boosts up the chance of successful treatments of patients, and automated diagnosis and classification of cervical lesions from Papanicolaou (Pap) smear images have become highly demanded. To the authors' best knowledge, this is the first study of fully automated cervical lesions analysis on whole slide images (WSIs) of conventional Pap smear samples. The presented deep learning-based cervical lesions diagnosis system is demonstrated to be able to detect high grade squamous intraepithelial lesions (HSILs) or higher (squamous cell carcinoma; SQCC), which usually immediately indicate patients must be referred to colposcopy, but also to rapidly process WSIs in seconds for practical clinical usage. We evaluate this framework at scale on a dataset of 143 whole slide images, and the proposed method achieves a high precision 0.93, recall 0.90, F-measure 0.88, and Jaccard index 0.84, showing that the proposed system is capable of segmenting HSILs or higher (SQCC) with high precision and reaches sensitivity comparable to the referenced standard produced by pathologists. Based on Fisher's Least Significant Difference (LSD) test (P < 0.0001), the proposed method performs significantly better than the two state-of-the-art benchmark methods (U-Net and SegNet) in precision, F-Measure, Jaccard index. For the run time analysis, the proposed method takes only 210 seconds to process a WSI and is 20 times faster than U-Net and 19 times faster than SegNet, respectively. In summary, the proposed method is demonstrated to be able to both detect HSILs or higher (SQCC), which indicate patients for further treatments, including colposcopy and surgery to remove the lesion, and rapidly processing WSIs in seconds for practical clinical usages.",0,0
5837,"Automatic detection of 39 fundus diseases and conditions in retinal photographs using deep neural networks. Retinal fundus diseases can lead to irreversible visual impairment without timely diagnoses and appropriate treatments. Single disease-based deep learning algorithms had been developed for the detection of diabetic retinopathy, age-related macular degeneration, and glaucoma. Here, we developed a deep learning platform (DLP) capable of detecting multiple common referable fundus diseases and conditions (39 classes) by using 249,620 fundus images marked with 275,543 labels from heterogenous sources. Our DLP achieved a frequency-weighted average F1 score of 0.923, sensitivity of 0.978, specificity of 0.996 and area under the receiver operating characteristic curve (AUC) of 0.9984 for multi-label classification in the primary test dataset and reached the average level of retina specialists. External multihospital test, public data test and tele-reading application also showed high efficiency for multiple retinal diseases and conditions detection. These results indicate that our DLP can be applied for retinal fundus disease triage, especially in remote areas around the world.",1,1
5841,Chest radiograph-based artificial intelligence predictive model for mortality in community-acquired pneumonia. Chest radiograph (CXR) is a basic diagnostic test in community-acquired pneumonia (CAP) with prognostic value. We developed a CXR-based artificial intelligence (AI) model (CAP AI predictive Engine: CAPE) and prospectively evaluated its discrimination for 30-day mortality.,0,0
5847,"Machine learning model for early prediction of acute kidney injury (AKI) in pediatric critical care. Acute kidney injury (AKI) in pediatric critical care patients is diagnosed using elevated serum creatinine, which occurs only after kidney impairment. There are no treatments other than supportive care for AKI once it has developed, so it is important to identify patients at risk to prevent injury. This study develops a machine learning model to learn pre-disease patterns of physiological measurements and predict pediatric AKI up to 48Â h earlier than the currently established diagnostic guidelines.",0,0
5851,"A Hybrid-Domain Deep Learning-Based BCI For Discriminating Hand Motion Planning From EEG Sources. In this paper, a hybrid-domain deep learning (DL)-based neural system is proposed to decode hand movement preparation phases from electroencephalographic (EEG) recordings. The system exploits information extracted from the temporal-domain and time-frequency-domain, as part of a hybrid strategy, to discriminate the temporal windows (i.e. EEG epochs) preceding hand sub-movements (open/close) and the resting state. To this end, for each EEG epoch, the associated cortical source signals in the motor cortex and the corresponding time-frequency (TF) maps are estimated via beamforming and Continuous Wavelet Transform (CWT), respectively. Two Convolutional Neural Networks (CNNs) are designed: specifically, the first CNN is trained over a dataset of temporal (T) data (i.e. EEG sources), and is referred to as T-CNN; the second CNN is trained over a dataset of TF data (i.e. TF-maps of EEG sources), and is referred to as TF-CNN. Two sets of features denoted as T-features and TF-features, extracted from T-CNN and TF-CNN, respectively, are concatenated in a single features vector (denoted as TTF-features vector) which is used as input to a standard multi-layer perceptron for classification purposes. Experimental results show a significant performance improvement of our proposed hybrid-domain DL approach as compared to temporal-only and time-frequency-only-based benchmark approaches, achieving an average accuracy of [Formula: see text]%.",0,0
5852,"Evaluation of super-resolution on 50 pancreatic cancer patients with real-time cine MRI from 0.35T MRgRT. MR-guided radiotherapy (MRgRT) systems provide excellent soft tissue imaging immediately prior to and in real time during radiation delivery for cancer treatment. However, 2D cine MRI often has limited spatial resolution due to high temporal resolution. This work applies a super resolution machine learning framework to 3.5 mm pixel edge length, low resolution (LR), sagittal 2D cine MRI images acquired on a MRgRT system to generate 0.9 mm pixel edge length, super resolution (SR), images originally acquired at 4 frames per second (FPS). LR images were collected from 50 pancreatic cancer patients treated on a ViewRay MR-LINAC. SR images were evaluated using three methods. 1) The first method utilized intrinsic image quality metrics for evaluation. 2) The second used relative metrics including edge detection and structural similarity index (SSIM). 3) Finally, automatically generated tumor contours were created on both low resolution and super resolution images to evaluate target delineation and compared with DICE and SSIM. Intrinsic image quality metrics all had statistically significant improvements for SR images versus LR images, with mean (Â±1 SD) BRISQUE scores of 29.65Â Â±Â 2.98 and 42.48Â Â±Â 0.98 for SR and LR, respectively. SR images showed good agreement with LR images in SSIM evaluation, indicating there was not significant distortion of the images. Comparison of LR and SR images with paired high resolution (HR) 3D images showed that SR images had a mean (Â±1 SD) SSIM value of 0.633Â Â±Â 0.063 and LR a value of 0.587Â Â±Â 0.067 (p â‰ª 0.05). Contours generated on SR images were also more robust to noise addition than those generated on LR images. This study shows that super resolution with a machine learning framework can generate high spatial resolution images from 4fps low spatial resolution cine MRI acquired on the ViewRay MR-LINAC while maintaining tumor contour quality and without significant acquisition or post processing delay.",0,0
5854,"Deep learning for colon cancer histopathological images analysis. Nowadays, digital pathology plays a major role in the diagnosis and prognosis of tumours. Unfortunately, existing methods remain limited when faced with the high resolution and size of Whole Slide Images (WSIs) coupled with the lack of richly annotated datasets. Regarding the ability of the Deep Learning (DL) methods to cope with the large scale applications, such models seem like an appealing solution for tissue classification and segmentation in histopathological images. This paper focuses on the use of DL architectures to classify and highlight colon cancer regions in a sparsely annotated histopathological data context. First, we review and compare state-of-the-art Convolutional Neural networks (CNN) including the AlexNet, vgg, ResNet, DenseNet and Inception models. To cope with the shortage of rich WSI datasets, we have resorted to the use of transfer learning techniques. This strategy comes with the hallmark of relying on a large size computer vision dataset (ImageNet) to train the network and generate a rich collection of learnt features. The testing and evaluation of such models on our AiCOLO colon cancer dataset ensure accurate patch-level classification results reaching up to 96.98% accuracy rate with ResNet. The CNN models have also been tested and evaluated with the CRC-5000, nct-crc-he-100k and merged datasets. ResNet respectively achieves 96.77%, 99.76% and 99.98% for the three publicly available datasets. Then, we present a pixel-wise segmentation strategy for colon cancer WSIs through the use of both UNet and SegNet models. We introduce a multi-step training strategy as a remedy for the sparse annotation of histopathological images. UNet and SegNet are used and tested in different training scenarios including data augmentation and transfer learning and ensure up to 76.18% and 81.22% accuracy rates. Besides, we test our training strategy and models on the CRC-5000, nct-crc-he-100k and Warwick datasets. Respective accuracy rates of 98.66%, 99.12% and 78.39% were achieved by SegNet. Finally, we analyze the existing models to discover the most suitable network and the most effective training strategy for our colon tumour segmentation case study.<sup>1</sup>.",0,0
5862,"Diagnostic performance of deep-learning-based screening methods for diabetic retinopathy in primary care-A meta-analysis. Diabetic retinopathy (DR) affects 10-24% of patients with diabetes mellitus type 1 or 2 in the primary care (PC) sector. As early detection is crucial for treatment, deep learning screening methods in PC setting could potentially aid in an accurate and timely diagnosis.",0,0
5867,"Towards Real-time Prediction of Freezing of Gait in Patients with Parkinsons Disease: A Novel Deep One-class Classifier. Freezing of gait (FoG) is a common motor dysfunction in individuals with Parkinsons disease. FoG impairs walking and is associated with increased fall risk. On-demand external cueing systems can detect FoG and provide stimuli to help individuals overcome freezing. Predicting FoG before onset enables preemptive cueing and may prevent FoG. However, detection and prediction remain challenging. If FoG data are not available for an individual, patient-independent models have been used to detect FoG, which have shown great sensitivity and poor specificity, or vice versa. In this study, we introduce a Deep Gait Anomaly Detector (DGAD) using a transfer learning-based approach to improve FoG detection accuracy. We also evaluate the effect of data augmentation and additional pre-FoG segments on prediction rate. Seven individuals with PD performed a series of daily walking tasks wearing inertial measurement units on their ankles. The DGAD algorithm demonstrated average sensitivity and specificity of 63.0% and 98.6% (3.2% improvement compared with the highest specificity in the literature). The target models identified 87.4% of FoG onsets, with 21.9% predicted. This study demonstrates our algorithm's potential for accurate identification of FoG and delivery of cues for patients for whom no FoG data is available for model training.",0,0
5873,"Machine-Deep-Ensemble Learning Model for Classifying Cybersickness Caused by Virtual Reality Immersion. This study aims to classify cybersickness (CS) caused by virtual reality (VR) immersion through a machine-deep-ensemble learning model. The heart rate variability and respiratory signal parameters of 20 subjects were measured, while watching a VR video for âˆ¼5 minutes. After the experiment, the subjects were examined for CS and questioned to determine their CS states. Based on the results, we constructed a machine-deep-ensemble learning model that could identify and classify VR immersion CS among subjects. The ensemble model comprised four stacked machine learning models (support vector machine [SVM], k-nearest neighbor [KNN], random forest, and AdaBoost), which were used to derive prediction data, and then, classified the prediction data using a convolution neural network. This model was a multiclass classification model, allowing us to classify subjects' CS into three states (neutral, non-CS, and CS). The accuracy of SVM, KNN, random forest, and AdaBoost was 94.23 percent, 92.44 percent, 93.20 percent, and 90.33 percent, respectively, and the ensemble model could classify the three states with an accuracy of 96.48 percent. This implied that the ensemble model has a higher classification performance than when each model is used individually. Our results confirm that CS caused by VR immersion can be detected as physiological signal data with high accuracy. Moreover, our proposed model can determine the presence or absence of CS as well as the neutral state. Clinical Trial Registration Number: 20-2021-1.",0,0
5876,"Automatic breast mass detection in mammograms using density of wavelet coefficients and a patch-based CNN. For the purpose of accurate and efficient mass detection in full-field digital mammograms, weÂ proposeÂ aÂ methodÂ for automated mass detection that consists ofÂ twoÂ stages: suspicious region localization and false-positive (FP) reduction, by classifying these regions into mass and non-mass regions (normal tissues).",0,0
5878,AI-enhanced simultaneous multiparametric <sup>18</sup>F-FDG PET/MRI for accurate breast cancer diagnosis. To assess whether a radiomics and machine learning (ML) model combining quantitative parameters and radiomics features extracted from simultaneous multiparametric <sup>18</sup>F-FDG PET/MRI can discriminate between benign and malignant breast lesions.,0,0
5884,Multiparametric mapping in the brain from conventional contrast-weighted images using deep learning. To develop a deep-learning-based method to quantify multiple parameters in the brain from conventional contrast-weighted images.,0,0
5886,"Bidirectional deep neural networks to integrate RNA and DNA data for predicting outcome forÂ patients withÂ hepatocellular carcinoma. <b>Aims:</b> Individualized patient profiling is instrumental for personalized management in hepatocellular carcinoma (HCC). This study built a model based on bidirectional deep neural networks (BiDNNs), an unsupervised machine-learning approach, to integrate multi-omics data and predict survival in HCC. <b>Methods:</b> DNA methylation and mRNA expression data for HCC samples from the TCGA database were integrated using BiDNNs. With optimal clusters as labels, a support vector machineÂ model was developed to predict survival. <b>Results:</b> Using the BiDNN-based model, samples were clustered into two survival subgroups. The survival subgroup classification was an independent prognostic factor. BiDNNs were superior to multimodal autoencoders. <b>Conclusion:</b>Â ThisÂ study constructed and validated a BiDNN-based model for predicting prognosis in HCC, withÂ implications for individualized therapies in HCC.",0,0
5887,"Convolutional Neural Networks for Automated Classification of Prostate Multiparametric Magnetic Resonance Imaging Based on Image Quality. Prostate magnetic resonance imaging (MRI) is technically demanding, requiring high image quality to reach its full diagnostic potential. An automated method to identify diagnostically inadequate images could help optimize image quality.",0,0
5889,Machine learning versus regression modelling in predicting individual healthcare costs from a representative sample of the nationwide claims database in France. Innovative provider payment methods that avoid adverse selection and reward performance require accurate prediction of healthcare costs based on individual risk adjustment. Our objective was to compare the performances of a simple neural network (NN) and random forest (RF) to a generalized linear model (GLM) for the prediction of medical cost at the individual level.,0,0
5893,"Feature Augmented Hybrid CNN for Stress Recognition Using Wrist-based Photoplethysmography Sensor. Stress is a physiological state that hampers mental health and has serious consequences to physical health. Moreover, the COVID-19 pandemic has increased stress levels among people across the globe. Therefore, continuous monitoring and detection of stress are necessary. The recent advances in wearable devices have allowed the monitoring of several physiological signals related to stress. Among them, wrist-worn wearable devices like smartwatches are most popular due to their convenient usage. And the photoplethysmography (PPG) sensor is the most prevalent sensor in almost all consumer-grade wrist-worn smartwatches. Therefore, this paper focuses on using a wrist-based PPG sensor that collects Blood Volume Pulse (BVP) signals to detect stress which may be applicable for consumer-grade wristwatches. Moreover, state-of-the-art works have used either classical machine learning algorithms to detect stress using hand-crafted features or have used deep learning algorithms like Convolutional Neural Network (CNN) which automatically extracts features. This paper proposes a novel hybrid CNN (H-CNN) classifier that uses both the hand-crafted features and the automatically extracted features by CNN to detect stress using the BVP signal. Evaluation on the benchmark WESAD dataset shows that, for 3-class classification (Baseline vs. Stress vs. Amusement), our proposed H-CNN outperforms traditional classifiers and normal CNN by 5% and 7% accuracy, and 10% and 7% macro F1 score, respectively. Also for 2-class classification (Stress vs. Non-stress), our proposed H-CNN outperforms traditional classifiers and normal CNN by 3% and ~5% accuracy, and ~3% and ~7% macro F1 score, respectively.",0,0
5894,"Novel Face Mask Detection Technique using Machine Learning to control COVID'19 pandemic. The COVID-19 pandemic has been scattering speedily around the world since 2019. Due to this pandemic, human life is becoming increasingly involutes and complex. Many people have died because of this virus. The lack of antiviral drugs is one of the reasons for the spreading of COVID-19 virus. This disease is spreading continuously and easily due to some common mistakes by people, like breathing, coughing and sneezing by infected persons. The main symptom is the normal flu. Therefore, in the present condition, the best precaution for this disease is the face mask, which covers both areas of mouth & nose. According to the government and the World Health Organization, everyone should wear a face mask in busy places like hospitals and marketplaces. In today's environment, it's difficult to tell if someone is wearing a mask or not, and physical inspection is impractical since it adds to labour costs. In this research, we present a mask detector that uses a machine learning facial categorization system to determine whether a person is wearing a mask or not, so that it may be connected to a CCTV system to verify that only persons wearing masks are allowed in.",0,0
5895,"A Holistic Performance Comparison for Lung Cancer Classification Using Swarm Intelligence Techniques. In the field of bioinformatics, feature selection in classification of cancer is a primary area of research and utilized to select the most informative genes from thousands of genes in the microarray. Microarray data is generally noisy, is highly redundant, and has an extremely asymmetric dimensionality, as the majority of the genes present here are believed to be uninformative. The paper adopts a methodology of classification of high dimensional lung cancer microarray data utilizing feature selection and optimization techniques. The methodology is divided into two stages; firstly, the ranking of each gene is done based on the standard gene selection techniques like Information Gain, Relief-F test, Chi-square statistic, and <i>T</i>-statistic test. As a result, the gathering of top scored genes is assimilated, and a new feature subset is obtained. In the second stage, the new feature subset is further optimized by using swarm intelligence techniques like Grasshopper Optimization (GO), Moth Flame Optimization (MFO), Bacterial Foraging Optimization (BFO), Krill Herd Optimization (KHO), and Artificial Fish Swarm Optimization (AFSO), and finally, an optimized subset is utilized. The selected genes are used for classification, and the classifiers used here are NaÃ¯ve Bayesian Classifier (NBC), Decision Trees (DT), Support Vector Machines (SVM), and <i>K</i>-Nearest Neighbour (KNN). The best results are shown when Relief-F test is computed with AFSO and classified with Decision Trees classifier for hundred genes, and the highest classification accuracy of 99.10% is obtained.",0,0
5896,Deep learning-enabled ultra-widefield retinal vessel segmentation with an automated quality-optimized angiographic phase selection tool. To demonstrate the feasibility of a deep learning-based vascular segmentation tool for UWFA and evaluate its ability to automatically identify quality-optimized phase-specific images.,0,0
5898,"Comparison of machine and deep learning for the classification of cervical cancer based on cervicography images. Cervical cancer is the second most common cancer in women worldwide with a mortality rate of 60%. Cervical cancer begins with no overt signs and has a long latent period, making early detection through regular checkups vitally immportant. In this study, we compare the performance of two different models, machine learning and deep learning, for the purpose of identifying signs of cervical cancer using cervicography images. Using the deep learning model ResNet-50 and the machine learning models XGB, SVM, and RF, we classified 4119 Cervicography images as positive or negative for cervical cancer using square images in which the vaginal wall regions were removed. The machine learning models extracted 10 major features from a total of 300 features. All tests were validated by fivefold cross-validation and receiver operating characteristics (ROC) analysis yielded the following AUCs: ResNet-50 0.97(CI 95% 0.949-0.976), XGB 0.82(CI 95% 0.797-0.851), SVM 0.84(CI 95% 0.801-0.854), RF 0.79(CI 95% 0.804-0.856). The ResNet-50 model showed a 0.15 point improvement (pâ€‰<â€‰0.05) over the average (0.82) of the three machine learning methods. Our data suggest that the ResNet-50 deep learning algorithm could offer greater performance than current machine learning models for the purpose of identifying cervical cancer using cervicography images.",0,0
5899,"Explainable DCNN based chest X-ray image analysis and classification for COVID-19 pneumonia detection. To speed up the discovery of COVID-19 disease mechanisms by X-ray images, this research developed a new diagnosis platform using a deep convolutional neural network (DCNN) that is able to assist radiologists with diagnosis by distinguishing COVID-19 pneumonia from non-COVID-19 pneumonia in patients based on chest X-ray classification and analysis. Such a tool can save time in interpreting chest X-rays and increase the accuracy and thereby enhance our medical capacity for the detection and diagnosis of COVID-19. The explainable method is also used in the DCNN to select instances of the X-ray dataset images to explain the behavior of training-learning models to achieve higher prediction accuracy. The average accuracy of our method is above 96%, which can replace manual reading and has the potential to be applied to large-scale rapid screening of COVID-9 for widely use cases.",0,0
5901,"Validating deep learning inference during chest X-ray classification for COVID-19 screening. The new coronavirus unleashed a worldwide pandemic in early 2020, and a fatality rate several times that of the flu. As the number of infections soared, and capabilities for testing lagged behind, chest X-ray (CXR) imaging became more relevant in the early diagnosis and treatment planning for patients with suspected or confirmed COVID-19 infection. In a few weeks, proposed new methods for lung screening using deep learning rapidly appeared, while quality assurance discussions lagged behind. This paper proposes a set of protocols to validate deep learning algorithms, including our ROI Hide-and-Seek protocol, which emphasizes or hides key regions of interest from CXR data. Our protocol allows assessing the classification performance for anomaly detection and its correlation to radiological signatures, an important issue overlooked in several deep learning approaches proposed so far. By running a set of systematic tests over CXR representations using public image datasets, we demonstrate the weaknesses of current techniques and offer perspectives on the advantages and limitations of automated radiography analysis when using heterogeneous data sources.",0,0
5905,Transparent Machine Learning Models to Diagnose Suspicious Thoracic Lesions Leveraging CT Guided Biopsy Data. To train and validate machine learning models capable of classifying suspicious thoracic lesions as benign or malignant and to further classify malignant lesions by pathologic subtype while quantifying feature importance for each classification.,0,0
5907,Machine learning models improve prediction of large vessel occlusion and mechanical thrombectomy candidacy in acute ischemic stroke. Early identification of large vessel occlusions (LVO) and timely recanalization are paramount to improved clinical outcomes in acute ischemic stroke. A stroke assessment that maximizes sensitivity and specificity for LVOs is needed to identify these cases and not overburden the health system with unnecessary transfers. Machine learning techniques are being used for predictive modeling in many aspects of stroke care and may have potential in predicting LVO presence and mechanical thrombectomy (MT) candidacy.,0,0
5908,"Analysis of risk factors correlated with angiographic vasospasm in patients with aneurysmal subarachnoid hemorrhage using explainable predictive modeling. Cerebral vasospasm (CAV) is a major complication of aneurysmal subarachnoid hemorrhage (aSAH) in patients with ruptured intracranial aneurysm. Explainable artificial intelligence (XAI) was used to analyze the contribution of risk factors on the development of CAV. We obtained data about patients (nÂ =Â 343) treated for aSAH in our hospital. Predictive factors including age, aneurysm size, Hunt and Hess grade, and modified Fisher grade were used as input to analyze the contribution and correlation of factors correlated with CAV using a random forest regressor. An analysis conducted using an XAI model showed that aneurysm size (27.6%) was most significantly associated with the development of CAV, followed by age (20.7%) and Glasgow coma scale score (7.1%). In some patients with an estimated artificial intelligence-selected CAV value of 51%, the important risk factors were aneurysm size (9.1Â mm) and location, and hypertension is also considered a major influencing factor. We could predict that Fisher grade 3 contributed to 20.3%, and the group using Antiplatelet contributed to 12.2% which is expected to lower cerebral CAV compared to the Control group (16.9%). The accuracy rate of the XAI system was 85.5% (area under the curveÂ =Â 0.88). Using the modeling, aneurysm size and age were quantitatively analyzed and were found to be significantly associated with CAV in patients with aSAH. Hence, XAI modeling techniques can be used to analyze factors correlated with CAV by schematizing prediction results in some patients. Moreover, poor Fisher grade and use of postoperative antiplatelet agent are important factors for prediction of CAV.",0,0
5909,Identifying juvenile myoclonic epilepsy via diffusion tensor imaging using machine learning analysis. The aim of this study was to evaluate the feasibility of using a machine learning approach based on diffusion tensor imaging (DTI) to identify patients with juvenile myoclonic epilepsy. We analyzed the usefulness of combining conventional DTI measures and structural connectomic profiles. This retrospective study was conducted at a tertiary hospital. We enrolled 55 patients with juvenile myoclonic epilepsy. All of the subjects underwent DTI from January 2017 to March 2020. We also enrolled 58 healthy subjects as a normal control group. We extracted conventional DTI measures and structural connectomic DTI profiles. We employed the support vector machines (SVM) algorithm to classify patients with juvenile myoclonic epilepsy and healthy subjects based on the conventional DTI measures and structural connectomic profiles. The SVM classifier based on conventional DTI measures had an accuracy of 68.1% and an area under the curve (AUC) of 0.682. Another SVM classifier based on the structural connectomic profiles demonstrated an accuracy of 72.7% and an AUC of 0.727. The SVM classifier based on combining the conventional DTI measures and structural connectomic profiles had an accuracy of 81.8% and an AUC of 0.818. DTI using machine learning is useful for classifying patients with juvenile myoclonic epilepsy and healthy subjects. Combining both the conventional DTI measures and structural connectomic profiles results in a better classification performance than using conventional DTI measures or the structural connectomic profiles alone to identify juvenile myoclonic epilepsy.,0,0
5911,Graph-theory based degree centrality combined with machine learning algorithms can predict response to treatment with antiepileptic medications in children with epilepsy. The purpose of the current study is to detect changes of graph-theory-based degree centrality (DC) and their relationship with the clinical treatment effects of anti-epileptic drugs (AEDs) for patients with childhood absence epilepsy (CAE) using resting-state functional MRI (RS-fMRI).,0,0
5919,"Chronic kidney disease diagnosis using decision tree algorithms. Chronic Kidney Disease (CKD), i.e., gradual decrease in the renal function spanning over a duration of several months to years without any major symptoms, is a life-threatening disease. It progresses in six stages according to the severity level. It is categorized into various stages based on the Glomerular Filtration Rate (GFR), which in turn utilizes several attributes, like age, sex, race and Serum Creatinine. Among multiple available models for estimating GFR value, Chronic Kidney Disease Epidemiology Collaboration (CKD-EPI), which is a linear model, has been found to be quite efficient because it allows detecting all CKD stages.",0,0
5920,"Real-time prediction of intradialytic relative blood volume: a proof-of-concept for integrated cloud computing infrastructure. Inadequate refilling from extravascular compartments during hemodialysis can lead to intradialytic symptoms, such as hypotension, nausea, vomiting, and cramping/myalgia. Relative blood volume (RBV) plays an important role in adapting the ultrafiltration rate which in turn has a positive effect on intradialytic symptoms. It has been clinically challenging to identify changes RBV in real time to proactively intervene and reduce potential negative consequences of volume depletion. Leveraging advanced technologies to process large volumes of dialysis and machine data in real time and developing prediction models using machine learning (ML) is critical in identifying these signals.",0,0
5921,Using a machine learning approach to identify key prognostic molecules for esophageal squamous cell carcinoma. A plethora of prognostic biomarkers for esophageal squamous cell carcinoma (ESCC) that have hitherto been reported are challenged with low reproducibility due to high molecular heterogeneity of ESCC. The purpose of this study was to identify the optimal biomarkers for ESCC using machine learning algorithms.,0,0
5923,Development and validation of a model to estimate the risk of acute ischemic stroke in geriatric patients with primary hypertension. This study aimed to construct and validate a prediction model of acute ischemic stroke in geriatric patients with primary hypertension.,0,0
5926,"Automatic, Qualitative Scoring of the Clock Drawing Test (CDT) Based on U-Net, CNN and Mobile Sensor Data. The Clock Drawing Test (CDT) is a rapid, inexpensive, and popular screening tool for cognitive functions. In spite of its qualitative capabilities in diagnosis of neurological diseases, the assessment of the CDT has depended on quantitative methods as well as manual paper based methods. Furthermore, due to the impact of the advancement of mobile smart devices imbedding several sensors and deep learning algorithms, the necessity of a standardized, qualitative, and automatic scoring system for CDT has been increased. This study presents a mobile phone application, mCDT, for the CDT and suggests a novel, automatic and qualitative scoring method using mobile sensor data and deep learning algorithms: CNN, a convolutional network, U-Net, a convolutional network for biomedical image segmentation, and the MNIST (Modified National Institute of Standards and Technology) database. To obtain DeepC, a trained model for segmenting a contour image from a hand drawn clock image, U-Net was trained with 159 CDT hand-drawn images at 128 Ã— 128 resolution, obtained via mCDT. To construct DeepH, a trained model for segmenting the hands in a clock image, U-Net was trained with the same 159 CDT 128 Ã— 128 resolution images. For obtaining DeepN, a trained model for classifying the digit images from a hand drawn clock image, CNN was trained with the MNIST database. Using DeepC, DeepH and DeepN with the sensor data, parameters of contour (0-3 points), numbers (0-4 points), hands (0-5 points), and the center (0-1 points) were scored for a total of 13 points. From 219 subjects, performance testing was completed with images and sensor data obtained via mCDT. For an objective performance analysis, all the images were scored and crosschecked by two clinical experts in CDT scaling. Performance test analysis derived a sensitivity, specificity, accuracy and precision for the contour parameter of 89.33, 92.68, 89.95 and 98.15%, for the hands parameter of 80.21, 95.93, 89.04 and 93.90%, for the numbers parameter of 83.87, 95.31, 87.21 and 97.74%, and for the center parameter of 98.42, 86.21, 96.80 and 97.91%, respectively. From these results, the mCDT application and its scoring system provide utility in differentiating dementia disease subtypes, being valuable in clinical practice and for studies in the field.",0,0
5928,"A Deep-Learning Based Posture Detection System for Preventing Telework-Related Musculoskeletal Disorders. The change from face-to-face work to teleworking caused by the pandemic has induced multiple workers to spend more time than usual in front of a computer; in addition, the sudden installation of workstations in homes means that not all of them meet the necessary characteristics for the worker to be able to position himself/herself comfortably with the correct posture in front of their computer. Furthermore, from the point of view of the medical personnel in charge of occupational risk prevention, an automated tool able to quantify the degree of incorrectness of a postural habit in a worker is needed. For this purpose, in this work, a system based on the postural detection of the worker is designed, implemented and tested, using a specialized hardware system that processes video in real time through convolutional neural networks. This system is capable of detecting the posture of the neck, shoulders and arms, providing recommendations to the worker in order to prevent possible health problems, due to poor posture. The results of the proposed system show that this video processing can be carried out in real time (up to 25 processed frames/sec) with a low power consumption (less than 10 watts) using specialized hardware, obtaining an accuracy of over 80% in terms of the pattern detected.",0,0
5934,"A Classification and Prediction Hybrid Model Construction with the IQPSO-SVM Algorithm for Atrial Fibrillation Arrhythmia. Atrial fibrillation (AF) is the most common cardiovascular disease (CVD), and most existing algorithms are usually designed for the diagnosis (i.e., feature classification) or prediction of AF. Artificial intelligence (AI) algorithms integrate the diagnosis of AF electrocardiogram (ECG) and predict the possibility that AF will occur in the future. In this paper, we utilized the MIT-BIH AF Database (AFDB), which is composed of data from normal people and patients with AF and onset characteristics, and the AFPDB database (i.e., PAF Prediction Challenge Database), which consists of data from patients with Paroxysmal AF (PAF; the records contain the ECG preceding an episode of PAF), and subjects who do not have documented AF. We extracted the respective characteristics of the databases and used them in modeling diagnosis and prediction. In the aspect of model construction, we regarded diagnosis and prediction as two classification problems, adopted the traditional support vector machine (SVM) algorithm, and combined them. The improved quantum particle swarm optimization support vector machine (IQPSO-SVM) algorithm was used to speed the training time. During the verification process, the clinical FZU-FPH database created by Fuzhou University and Fujian Provincial Hospital was used for hybrid model testing. The data were obtained from the Holter monitor of the hospital and encrypted. We proposed an algorithm for transforming the PDF ECG waveform images of hospital examination reports into digital data. For the diagnosis model and prediction model trained using the training set of the AFDB and AFPDB databases, the sensitivity, specificity, and accuracy measures were 99.2% and 99.2%, 99.2% and 93.3%, and 91.7% and 92.5% for the test set of the AFDB and AFPDB databases, respectively. Moreover, the sensitivity, specificity, and accuracy were 94.2%, 79.7%, and 87.0%, respectively, when tested using the FZU-FPH database with 138 samples of the ECG composed of two labels. The composite classification and prediction model using a new water-fall ensemble method had a total accuracy of approximately 91% for the test set of the FZU-FPH database with 80 samples with 120 segments of ECG with three labels.",0,0
5938,"Multi-Headed Conv-LSTM Network for Heart Rate Estimation during Daily Living Activities. Non-invasive photoplethysmography (PPG) technology was developed to track heart rate during physical activity under free-living conditions. Automated analysis of PPG has made it useful in both clinical and non-clinical applications. Because of their generalization capabilities, deep learning methods can be a major direction in the search for a heart rate estimation solution based on signals from wearable devices. A novel multi-headed convolutional neural network model enriched with long short-term memory cells (MH Conv-LSTM DeepPPG) was proposed for the estimation of heart rate based on signals measured by a wrist-worn wearable device, such as PPG and acceleration signals. For the PPG-DaLiA dataset, the proposed solution improves the performance of previously proposed methods. An experimental approach was used to develop the final network architecture. The average mean absolute error (MAE) of the final solution was 6.28 bpm and Pearson's correlation coefficient between the estimated and true heart rate values was 0.85.",0,0
5940,"Implementation of a Deep Learning Algorithm Based on Vertical Ground Reaction Force Time-Frequency Features for the Detection and Severity Classification of Parkinson's Disease. Conventional approaches to diagnosing Parkinson's disease (PD) and rating its severity level are based on medical specialists' clinical assessment of symptoms, which are subjective and can be inaccurate. These techniques are not very reliable, particularly in the early stages of the disease. A novel detection and severity classification algorithm using deep learning approaches was developed in this research to classify the PD severity level based on vertical ground reaction force (vGRF) signals. Different variations in force patterns generated by the irregularity in vGRF signals due to the gait abnormalities of PD patients can indicate their severity. The main purpose of this research is to aid physicians in detecting early stages of PD, planning efficient treatment, and monitoring disease progression. The detection algorithm comprises preprocessing, feature transformation, and classification processes. In preprocessing, the vGRF signal is divided into 10, 15, and 30 s successive time windows. In the feature transformation process, the time domain vGRF signal in windows with varying time lengths is modified into a time-frequency spectrogram using a continuous wavelet transform (CWT). Then, principal component analysis (PCA) is used for feature enhancement. Finally, different types of convolutional neural networks (CNNs) are employed as deep learning classifiers for classification. The algorithm performance was evaluated using <i>k</i>-fold cross-validation (<i>k</i>foldCV). The best average accuracy of the proposed detection algorithm in classifying the PD severity stage classification was 96.52% using ResNet-50 with vGRF data from the PhysioNet database. The proposed detection algorithm can effectively differentiate gait patterns based on time-frequency spectrograms of vGRF signals associated with different PD severity levels.",0,0
5944,"Classification of Approximal Caries in Bitewing Radiographs Using Convolutional Neural Networks. Dental caries is an extremely common problem in dentistry that affects a significant part of the population. Approximal caries are especially difficult to identify because their position makes clinical analysis difficult. Radiographic evaluation-more specifically, bitewing images-are mostly used in such cases. However, incorrect interpretations may interfere with the diagnostic process. To aid dentists in caries evaluation, computational methods and tools can be used. In this work, we propose a new method that combines image processing techniques and convolutional neural networks to identify approximal dental caries in bitewing radiographic images and classify them according to lesion severity. For this study, we acquired 112 bitewing radiographs. From these exams, we extracted individual tooth images from each exam, applied a data augmentation process, and used the resulting images to train CNN classification models. The tooth images were previously labeled by experts to denote the defined classes. We evaluated classification models based on the Inception and ResNet architectures using three different learning rates: 0.1, 0.01, and 0.001. The training process included 2000 iterations, and the best results were achieved by the Inception model with a 0.001 learning rate, whose accuracy on the test set was 73.3%. The results can be considered promising and suggest that the proposed method could be used to assist dentists in the evaluation of bitewing images, and the definition of lesion severity and appropriate treatments.",0,0
5949,"FAC-Net: Feedback Attention Network Based on Context Encoder Network for Skin Lesion Segmentation. Considerable research and surveys indicate that skin lesions are an early symptom of skin cancer. Segmentation of skin lesions is still a hot research topic. Dermatological datasets in skin lesion segmentation tasks generated a large number of parameters when data augmented, limiting the application of smart assisted medicine in real life. Hence, this paper proposes an effective feedback attention network (FAC-Net). The network is equipped with the feedback fusion block (FFB) and the attention mechanism block (AMB), through the combination of these two modules, we can obtain richer and more specific feature mapping without data enhancement. Numerous experimental tests were given by us on public datasets (ISIC2018, ISBI2017, ISBI2016), and a good deal of metrics like the Jaccard index (JA) and Dice coefficient (DC) were used to evaluate the results of segmentation. On the ISIC2018 dataset, we obtained results for DC equal to 91.19% and JA equal to 83.99%, compared with the based network. The results of these two main metrics were improved by more than 1%. In addition, the metrics were also improved in the other two datasets. It can be demonstrated through experiments that without any enhancements of the datasets, our lightweight model can achieve better segmentation performance than most deep learning architectures.",0,0
5954,"A Study on Seizure Detection of EEG Signals Represented in 2D. A seizure is a neurological disorder caused by abnormal neuronal discharges in the brain, which severely reduces the quality of life of patients and often endangers their lives. Automatic seizure detection is an important research area in the treatment of seizure and is a prerequisite for seizure intervention. Deep learning has been widely used for automatic detection of seizures, and many related research works decomposed the electroencephalogram (EEG) raw signal with a time window to obtain EEG signal slices, then performed feature extraction on the slices, and represented the obtained features as input data for neural networks. There are various methods for EEG signal decomposition, feature extraction, and representation, and most of the studies have been based on fixed hardware resources for the design of the scheme, which reduces the adaptability of the scheme in different application scenarios and makes it difficult to optimize the algorithms in the scheme. To address the above issues, this paper proposes a deep learning-based model for seizure detection, mainly characterized by the two-dimensional representation of EEG features and the scalability of neural networks. The model modularizes the main steps of seizure detection and improves the adaptability of the model to different hardware resource constraints, in order to increase the convenience of the algorithm optimization or the replacement of each module. The proposed model consists of five parts, and the model was tested using two epilepsy datasets separately. The experimental results showed that the proposed model has strong generality and good classification accuracy for seizure detection.",0,0
5958,"Affective Computing on Machine Learning-Based Emotion Recognition Using a Self-Made EEG Device. In this research, we develop an affective computing method based on machine learning for emotion recognition using a wireless protocol and a wearable electroencephalography (EEG) custom-designed device. The system collects EEG signals using an eight-electrode placement on the scalp; two of these electrodes were placed in the frontal lobe, and the other six electrodes were placed in the temporal lobe. We performed experiments on eight subjects while they watched emotive videos. Six entropy measures were employed for extracting suitable features from the EEG signals. Next, we evaluated our proposed models using three popular classifiers: a support vector machine (SVM), multi-layer perceptron (MLP), and one-dimensional convolutional neural network (1D-CNN) for emotion classification; both subject-dependent and subject-independent strategies were used. Our experiment results showed that the highest average accuracies achieved in the subject-dependent and subject-independent cases were 85.81% and 78.52%, respectively; these accuracies were achieved using a combination of the sample entropy measure and 1D-CNN. Moreover, our study investigates the T8 position (above the right ear) in the temporal lobe as the most critical channel among the proposed measurement positions for emotion classification through electrode selection. Our results prove the feasibility and efficiency of our proposed EEG-based affective computing method for emotion recognition in real-world applications.",0,0
5960,"Estimation of Stroke Volume Variance from Arterial Blood Pressure: Using a 1-D Convolutional Neural Network. We aimed to create a novel model using a deep learning method to estimate stroke volume variation (SVV), a widely used predictor of fluid responsiveness, from arterial blood pressure waveform (ABPW).",0,0
5969,"Deep and Wide Transfer Learning with Kernel Matching for Pooling Data from Electroencephalography and Psychological Questionnaires. Motor imagery (MI) promotes motor learning and encourages brain-computer interface systems that entail electroencephalogram (EEG) decoding. However, a long period of training is required to master brain rhythms' self-regulation, resulting in users with MI inefficiency. We introduce a parameter-based approach of cross-subject transfer-learning to improve the performances of poor-performing individuals in MI-based BCI systems, pooling data from labeled EEG measurements and psychological questionnaires via kernel-embedding. To this end, a Deep and Wide neural network for MI classification is implemented to pre-train the network from the source domain. Then, the parameter layers are transferred to initialize the target network within a fine-tuning procedure to recompute the Multilayer Perceptron-based accuracy. To perform data-fusion combining categorical features with the real-valued features, we implement stepwise kernel-matching via Gaussian-embedding. Finally, the paired source-target sets are selected for evaluation purposes according to the inefficiency-based clustering by subjects to consider their influence on BCI motor skills, exploring two choosing strategies of the best-performing subjects (source space): single-subject and multiple-subjects. Validation results achieved for discriminant MI tasks demonstrate that the introduced Deep and Wide neural network presents competitive performance of accuracy even after the inclusion of questionnaire data.",0,0
5972,"EEG-Based Emotion Recognition by Convolutional Neural Network with Multi-Scale Kernels. Besides facial or gesture-based emotion recognition, Electroencephalogram (EEG) data have been drawing attention thanks to their capability in countering the effect of deceptive external expressions of humans, like faces or speeches. Emotion recognition based on EEG signals heavily relies on the features and their delineation, which requires the selection of feature categories converted from the raw signals and types of expressions that could display the intrinsic properties of an individual signal or a group of them. Moreover, the correlation or interaction among channels and frequency bands also contain crucial information for emotional state prediction, and it is commonly disregarded in conventional approaches. Therefore, in our method, the correlation between 32 channels and frequency bands were put into use to enhance the emotion prediction performance. The extracted features chosen from the time domain were arranged into feature-homogeneous matrices, with their positions following the corresponding electrodes placed on the scalp. Based on this 3D representation of EEG signals, the model must have the ability to learn the local and global patterns that describe the short and long-range relations of EEG channels, along with the embedded features. To deal with this problem, we proposed the 2D CNN with different kernel-size of convolutional layers assembled into a convolution block, combining features that were distributed in small and large regions. Ten-fold cross validation was conducted on the DEAP dataset to prove the effectiveness of our approach. We achieved the average accuracies of 98.27% and 98.36% for arousal and valence binary classification, respectively.",0,0
5990,"Machine Learning Approach for Fatigue Estimation in Sit-to-Stand Exercise. Physical exercise (PE) has become an essential tool for different rehabilitation programs. High-intensity exercises (HIEs) have been demonstrated to provide better results in general health conditions, compared with low and moderate-intensity exercises. In this context, monitoring of a patients' condition is essential to avoid extreme fatigue conditions, which may cause physical and physiological complications. Different methods have been proposed for fatigue estimation, such as: monitoring the subject's physiological parameters and subjective scales. However, there is still a need for practical procedures that provide an objective estimation, especially for HIEs. In this work, considering that the sit-to-stand (STS) exercise is one of the most implemented in physical rehabilitation, a computational model for estimating fatigue during this exercise is proposed. A study with 60 healthy volunteers was carried out to obtain a data set to develop and evaluate the proposed model. According to the literature, this model estimates three fatigue conditions (low, moderate, and high) by monitoring 32 STS kinematic features and the heart rate from a set of ambulatory sensors (Kinect and Zephyr sensors). Results show that a random forest model composed of 60 sub-classifiers presented an accuracy of 82.5% in the classification task. Moreover, results suggest that the movement of the upper body part is the most relevant feature for fatigue estimation. Movements of the lower body and the heart rate also contribute to essential information for identifying the fatigue condition. This work presents a promising tool for physical rehabilitation.",0,0
6003,"Potential of Point-of-Care and At-Home Assessment of Immune Status via Rapid Cytokine Detection and Questionnaire-Based Anamnesis. Monitoring the immune system's status has emerged as an urgent demand in critical health conditions. The circulating cytokine levels in the blood reflect a thorough insight into the immune system status. Indeed, measuring one cytokine may deliver more information equivalent to detecting multiple diseases at a time. However, if the reported cytokine levels are interpreted with considering lifestyle and any comorbid health conditions for the individual, this will promote a more precise assessment of the immune status. Therefore, this study addresses the most recent advanced assays that deliver rapid, accurate measuring of the cytokine levels in human blood, focusing on add-on potentials for point-of-care (PoC) or personal at-home usage, and investigates existing health questionnaires as supportive assessment tools that collect all necessary information for the concrete analysis of the measured cytokine levels. We introduced a ten-dimensional featuring of cytokine measurement assays. We found 15 rapid cytokine assays with assay time less than 1 h; some could operate on unprocessed blood samples, while others are mature commercial products available in the market. In addition, we retrieved several health questionnaires that addressed various health conditions such as chronic diseases and psychological issues. Then, we present a machine learning-based solution to determine what makes the immune system fit. To this end, we discuss how to employ topic modeling for deriving the definition of immune fitness automatically from literature. Finally, we propose a prototype model to assess the fitness of the immune system through leveraging the derived definition of the immune fitness, the cytokine measurements delivered by a rapid PoC immunoassay, and the complementary information collected by the health questionnaire about other health factors. In conclusion, we discovered various advanced rapid cytokine detection technologies that are promising candidates for point-of-care or at-home usage; if paired with a health status questionnaire, the assessment of the immune system status becomes solid and we demonstrated potentials for promoting the assessment tool with data mining techniques.",0,0
6006,"A Framework for Maternal Physical Activities and Health Monitoring Using Wearable Sensors. We propose a physical activity recognition and monitoring framework based on wearable sensors during maternity. A physical activity can either create or prevent health issues during a given stage of pregnancy depending on its intensity. Thus, it becomes very important to provide continuous feedback by recognizing a physical activity and its intensity. However, such continuous monitoring is very challenging during the whole period of maternity. In addition, maintaining a record of each physical activity, and the time for which it was performed, is also a non-trivial task. We aim at such problems by first recognizing a physical activity via the data of wearable sensors that are put on various parts of body. We avoid the use of smartphones for such task due to the inconvenience caused by wearing it for activities such as ""eating"". In our proposed framework, a module worn on body consists of three sensors: a 3-axis accelerometer, 3-axis gyroscope, and temperature sensor. The time-series data from these sensors are sent to a Raspberry-PI via Bluetooth Low Energy (BLE). Various statistical measures (features) of this data are then calculated and represented in features vectors. These feature vectors are then used to train a supervised machine learning algorithm called classifier for the recognition of physical activity from the sensors data. Based on such recognition, the proposed framework sends a message to the care-taker in case of unfavorable situation. We evaluated a number of well-known classifiers on various features developed from overlapped and non-overlapped window size of time-series data. Our novel dataset consists of 10 physical activities performed by 61 subjects at various stages of maternity. On the current dataset, we achieve the highest recognition rate of 89% which is encouraging for a monitoring and feedback system.",0,0
6012,"Hybrid deep learning segmentation models for atherosclerotic plaque in internal carotid artery B-mode ultrasound. The automated and accurate carotid plaque segmentation in B-mode ultrasound (US) is an essential part of stroke risk stratification. Previous segmented methods used AtheroEdgeâ„¢ 2.0 (AtheroPointâ„¢, Roseville, CA) for the common carotid artery (CCA). This study focuses on automated plaque segmentation in the internal carotid artery (ICA) using solo deep learning (SDL) and hybrid deep learning (HDL) models. The methodology consists of a novel design of 10 types of SDL/HDL models (AtheroEdgeâ„¢ 3.0 systems (AtheroPointâ„¢, Roseville, CA) with a depth of four layers each. Five of the models use cross-entropy (CE)-loss, and the other five models use Dice similarity coefficient (DSC)-loss functions derived from UNet, UNet+, SegNet, SegNet-UNet, and SegNet-UNet+. The K10 protocol (Train:Test:90%:10%) was applied for all 10 models for training and predicting (segmenting) the plaque region, which was then quantified to compute the plaque area in mm<sup>2</sup>. Further, the data augmentation effect was analyzed. The database consisted of 970 ICA B-mode US scans taken from 99 moderate to high-risk patients. Using the difference area threshold of 10Â mm<sup>2</sup> between ground truth (GT) and artificial intelligence (AI), the area under the curve (AUC) values were 0.91, 0.911, 0.908, 0.905, and 0.898, all with a p-value of <0.001 (for CE-loss models) and 0.883, 0.889, 0.905, 0.889, and 0.907, all with a p-value of <0.001 (for DSC-loss models). The correlations between the AI-based plaque area and GT plaque area were 0.98, 0.96, 0.97, 0.98, and 0.97, all with a p-value of <0.001 (for CE-loss models) and 0.98, 0.98, 0.97, 0.98, and 0.98 (for DSC-loss models). Overall, the online system performs plaque segmentation in less than 1Â s. We validate our hypothesis that HDL and SDL models demonstrate comparable performance. SegNet-UNet was the best-performing hybrid architecture.",0,0
6015,"An Artificial Intelligence Algorithm to Predict Nodal Metastasis in Lung Cancer. Endobronchial Ultrasound (EBUS) features have high accuracy for predicting lymph node (LN) malignancy. However, their clinical application remains limited due to high operator dependency. We hypothesized that an Artificial Intelligence algorithm (NeuralSeg) is capable of accurately identifying and predicting LN malignancy based on EBUS images.",0,0
6017,Automatic breast lesion detection in ultrafast DCE-MRI using deep learning. We propose a deep learning-based computer-aided detection (CADe) method to detect breast lesions in ultrafast DCE-MRI sequences. This method uses both the 3D spatial information and temporal information obtained from the early-phase of the dynamic acquisition.,0,0
6019,"Development and validation of FootNet; a new kinematic algorithm to improve foot-strike and toe-off detection in treadmill running. The accurate detection of foot-strike and toe-off is often critical in the assessment of running biomechanics. The gold standard method for step event detection requires force data which are not always available. Although kinematics-based algorithms can also be used, their accuracy and generalisability are limited, often requiring corrections for speed or foot-strike pattern. The purpose of this study was to develop FootNet, a novel kinematics and deep learning-based algorithm for the detection of step events in treadmill running. Five treadmill running datasets were gathered and processed to obtain segment and joint kinematics, and to identify the contact phase within each gait cycle using force data. The proposed algorithm is based on a long short-term memory recurrent neural network and takes the distal tibia anteroposterior velocity, ankle dorsiflexion/plantar flexion angle and the anteroposterior and vertical velocities of the foot centre of mass as input features to predict the contact phase within a given gait cycle. The chosen model architecture underwent 5-fold cross-validation and the final model was tested in a subset of participants from each dataset (30%). Non-parametric Bland-Altman analyses (bias and [95% limits of agreement]) and root mean squared error (RMSE) were used to compare FootNet against the force data step event detection method. The association between detection errors and running speed, foot-strike angle and incline were also investigated. FootNet outperformed previously published algorithms (foot-strike bias = 0 [-10, 7] ms, RMSE = 5 ms; toe-off bias = 0 [-10, 10] ms, RMSE = 6 ms; and contact time bias = 0 [-15, 15] ms, RMSE = 8 ms) and proved robust to different running speeds, foot-strike angles and inclines. We have made FootNet's source code publicly available for step event detection in treadmill running when force data are not available.",0,0
6021,"Label-free imaging and classification of live P. falciparum enables high performance parasitemia quantification without fixation or staining. Manual microscopic inspection of fixed and stained blood smears has remained the gold standard for Plasmodium parasitemia analysis for over a century. Unfortunately, smear preparation consumes time and reagents, while manual microscopy is skill-dependent and labor-intensive. Here, we demonstrate that deep learning enables both life stage classification and accurate parasitemia quantification of ordinary brightfield microscopy images of live, unstained red blood cells. We tested our method using both a standard light microscope equipped with visible and near-ultraviolet (UV) illumination, and a custom-built microscope employing deep-UV illumination. While using deep-UV light achieved an overall four-category classification of Plasmodium falciparum blood stages of greater than 99% and a recall of 89.8% for ring-stage parasites, imaging with near-UV light on a standard microscope resulted in 96.8% overall accuracy and over 90% recall for ring-stage parasites. Both imaging systems were tested extrinsically by parasitemia titration, revealing superior performance over manually-scored Giemsa-stained smears, and a limit of detection below 0.1%. Our results establish that label-free parasitemia analysis of live cells is possible in a biomedical laboratory setting without the need for complex optical instrumentation. We anticipate future extensions of this work could enable label-free clinical diagnostic measurements, one day eliminating the need for conventional blood smear analysis.",0,1
6034,Improving workflow in prostate MRI: AI-based decision-making on biparametric or multiparametric MRI. To develop and validate an artificial intelligence algorithm to decide on the necessity of dynamic contrast-enhanced sequences (DCE) in prostate MRI.,0,0
6037,To Scan or Not to Scan: Development of a Clinical Decision Support Tool to Determine if Imaging Would Aid in the Diagnosis of Appendicitis. Appendicitis is one of the most common surgically treated diseases in the world. CT scans are often over-utilized and ordered before a surgeon has evaluated the patient. Our aim was to develop a tool using machine learning (ML) algorithms that would help determine if there would be benefit in obtaining a CT scan prior to surgeon consultation.,0,0
6045,"Convolutional neural network-based object detection model to identify gastrointestinal stromal tumors in endoscopic ultrasound images. We aimed to develop a convolutional neural network (CNN)-based object detection model for the discrimination of gastric subepithelial tumors, such as gastrointestinal stromal tumors (GISTs), and leiomyomas, in endoscopic ultrasound (EUS) images.",0,0
6046,"Radiomics-based MRI for predicting Erythropoietin-producing hepatocellular receptor A2 expression and tumor grade in brain diffuse gliomas. EphA2 is a key factor underlying invasive propensity of gliomas, and is associated with poor prognosis of tumors. We aimed to develop a radiomics-based imaging index for predicting EphA2 expression in diffuse gliomas, and further estimating its value for grading of tumors.",0,0
6055,"Highly Robust and Wearable Facial Expression Recognition via Deep-Learning-Assisted, Soft Epidermal Electronics. The facial expressions are a mirror of the elusive emotion hidden in the mind, and thus, capturing expressions is a crucial way of merging the inward world and virtual world. However, typical facial expression recognition (FER) systems are restricted by environments where faces must be clearly seen for computer vision, or rigid devices that are not suitable for the time-dynamic, curvilinear faces. Here, we present a robust, highly wearable FER system that is based on deep-learning-assisted, soft epidermal electronics. The epidermal electronics that can fully conform on faces enable high-fidelity biosignal acquisition without hindering spontaneous facial expressions, releasing the constraint of movement, space, and light. The deep learning method can significantly enhance the recognition accuracy of facial expression types and intensities based on a small sample. The proposed wearable FER system is superior for wide applicability and high accuracy. The FER system is suitable for the individual and shows essential robustness to different light, occlusion, and various face poses. It is totally different from but complementary to the computer vision technology that is merely suitable for simultaneous FER of multiple individuals in a specific place. This wearable FER system is successfully applied to human-avatar emotion interaction and verbal communication disambiguation in a real-life environment, enabling promising human-computer interaction applications.",0,0
6062,"Automated detection of pneumonia in lung ultrasound using deep video classification for COVID-19. There is a crucial need for quick testing and diagnosis of patients during the COVID-19 pandemic. Lung ultrasound is an imaging modality that is cost-effective, widely accessible, and can be used to diagnose acute respiratory distress syndrome in patients with COVID-19. It can be used to find important characteristics in the images, including A-lines, B-lines, consolidation, and pleural effusion, which all inform the clinician in monitoring and diagnosing the disease. With the use of portable ultrasound transducers, lung ultrasound images can be easily acquired, however, the images are often of poor quality. They often require an expert clinician interpretation, which may be time-consuming and is highly subjective. We propose a method for fast and reliable interpretation of lung ultrasound images by use of deep learning, based on the Kinetics-I3D network. Our learned model can classify an entire lung ultrasound scan obtained at point-of-care, without requiring the use of preprocessing or a frame-by-frame analysis. We compare our video classifier against ground truth classification annotations provided by a set of expert radiologists and clinicians, which include A-lines, B-lines, consolidation, and pleural effusion. Our classification method achieves an accuracy of 90% and an average precision score of 95% with the use of 5-fold cross-validation. The results indicate the potential use of automated analysis of portable lung ultrasound images to assist clinicians in screening and diagnosing patients.",1,1
6070,"Identifying Risk Factors for Complicated Post-operative Course in Tetralogy of Fallot Using a Machine Learning Approach. <b>Introduction:</b> Tetralogy of Fallot (TOF) repair is associated with excellent operative survival. However, a subset of patients experiences post-operative complications, which can significantly alter the early and late post-operative course. We utilized a machine learning approach to identify risk factors for post-operative complications after TOF repair. <b>Methods:</b> We conducted a single-center prospective cohort study of children <2 years of age with TOF undergoing surgical repair. The outcome was occurrence of post-operative cardiac complications, measured between TOF repair and hospital discharge or death. Predictors included patient, operative, and echocardiographic variables, including pre-operative right ventricular strain and fractional area change as measures of right ventricular function. Gradient-boosted quantile regression models (GBM) determined predictors of post-operative complications. Cross-validated GBMs were implemented with and without a filtering stage non-parametric regression model to select a subset of clinically meaningful predictors. Sensitivity analysis with gradient-boosted Poisson regression models was used to examine if the same predictors were identified in the subset of patients with at least one complication. <b>Results:</b> Of the 162 subjects enrolled between March 2012 and May 2018, 43 (26.5%) had at least one post-operative cardiac complication. The most frequent complications were arrhythmia requiring treatment (<i>N</i> = 22, 13.6%), cardiac catheterization (<i>N</i> = 17, 10.5%), and extracorporeal membrane oxygenation (ECMO) (<i>N</i> = 11, 6.8%). Fifty-six variables were used in the machine learning analysis, of which there were 21 predictors that were already identified from the first-stage regression. Duration of cardiopulmonary bypass (CPB) was the highest ranked predictor in all models. Other predictors included gestational age, pre-operative right ventricular (RV) global longitudinal strain, pulmonary valve Z-score, and immediate post-operative arterial oxygen level. Sensitivity analysis identified similar predictors, confirming the robustness of these findings across models. <b>Conclusions:</b> Cardiac complications after TOF repair are prevalent in a quarter of patients. A prolonged surgery remains an important predictor of post-operative complications; however, other perioperative factors are likewise important, including pre-operative right ventricular remodeling. This study identifies potential opportunities to optimize the surgical repair for TOF to diminish post-operative complications and secure improved clinical outcomes. Efforts toward optimizing pre-operative ventricular remodeling might mitigate post-operative complications and help reduce future morbidity.",0,0
6076,Prediction of EGFR Mutation Status Based on <sup>18</sup>F-FDG PET/CT Imaging Using Deep Learning-Based Model in Lung Adenocarcinoma. The purpose of this study was to develop a deep learning-based system to automatically predict epidermal growth factor receptor (EGFR) mutant lung adenocarcinoma in <sup>18</sup>F-fluorodeoxyglucose (FDG) positron emission tomography/computed tomography (PET/CT).,0,0
6077,"Quantitative Prediction of Microsatellite Instability in Colorectal Cancer With Preoperative PET/CT-Based Radiomics. Microsatellite instability (MSI) status is an important hallmark for prognosis prediction and treatment recommendation of colorectal cancer (CRC). To address issues due to the invasiveness of clinical preoperative evaluation of microsatellite status, we investigated the value of preoperative <sup>18</sup>F-FDG PET/CT radiomics with machine learning for predicting the microsatellite status of colorectal cancer patients.",0,0
6080,Application of CT-Based Radiomics in Discriminating Pancreatic Cystadenomas From Pancreatic Neuroendocrine Tumors Using Machine Learning Methods. The purpose of this study aimed at investigating the reliability of radiomics features extracted from contrast-enhanced CT in differentiating pancreatic cystadenomas from pancreatic neuroendocrine tumors (PNETs) using machine-learning methods.,0,0
6083,"Personalized stratification of hospitalization risk amidst COVID-19: A machine learning approach. <b>Objective:</b> In the wake of COVID-19, the United States (U.S.) developed a three stage plan to outline the parameters to determine when states may reopen businesses and ease travel restrictions. The guidelines also identify subpopulations of Americans deemed to be at high risk for severe disease should they contract COVID-19. These guidelines were based on population level demographics, rather than individual-level risk factors. As such, they may misidentify individuals at high risk for severe illness, and may therefore be of limited use in decisions surrounding resource allocation to vulnerable populations. The objective of this study was to evaluate a machine learning algorithm for prediction of serious illness due to COVID-19 using inpatient data collected from electronic health records. <b>Methods:</b> The algorithm was trained to identify patients for whom a diagnosis of COVID-19 was likely to result in hospitalization, and compared against four U.S. policy-based criteria: <i>age over 65; having a serious underlying health condition; age over 65 or having a serious underlying health condition;</i> and <i>age over 65 and having a serious underlying health condition</i>. <b>Results:</b> This algorithm identified 80% of patients at risk for hospitalization due to COVID-19, versus 62% identified by government guidelines. The algorithm also achieved a high specificity of 95%, outperforming government guidelines. <b>Conclusions:</b> This algorithm may identify individuals likely to require hospitalization should they contract COVID-19. This information may be useful to guide vaccine distribution, anticipate hospital resource needs, and assist health care policymakers to make care decisions in a more principled manner.",0,1
6085,"A Novel Weighted Consensus Machine Learning Model for COVID-19 Infection Classification Using CT Scan Images. As COVID-19 has spread rapidly, detection of the COVID-19 infection from radiology and radiography images is probably one of the quickest ways to diagnose the patients. Many researchers found the necessity to utilize chest X-ray and chest computed tomography imaging to diagnose COVID-19 infection. In this paper, our objective is to minimize the false negatives and false positives in the detection process. Reduction in the number of false negatives minimizes community spread of the COVID-19 pandemic. Reducing false positives help people avoid mental trauma and wasteful expenses. This paper proposes a novel weighted consensus model to minimize the number of false negatives and false positives without compromising accuracy. In the proposed novel weighted consensus model, the accuracy of individual classification models is normalized. While predicting, different models predict different classes, and the sum of the normalized accuracy for a particular class is then considered based on a predefined threshold value. We used traditional Machine Learning classification algorithms like Linear Regression, Support Vector Machine, <i>k</i>-Nearest Neighbours, Decision Tree, and Random Forest for the weighted consensus experimental evaluation. We predicted the classes, which provided better insights into the condition. The proposed model can perform as well as the existing state-of-the-art technique in terms of accuracy (99.64%) and reduce false negatives and false positives.",0,0
6089,"Human-in-the-Loop Predictive Analytics Using Statistical Learning. The human-in-the-loop cyber-physical system provides numerous solutions for the challenges faced by the doctors or medical practitioners. There is a linear trend of advancement and automation in the medical field for the early diagnosis of several diseases. One of the critical and challenging diseases in the medical field is coma. In the medical research field, currently, the prediction of these diseases is performed only using the data gathered from the devices only; however, the human's input is much essential to accurately understand their health condition to take appropriate decision on time. Therefore, we have proposed a healthcare framework involving the concept of artificial intelligence in the human-in- the-loop cyber-physical system. This model works via a response loop in which the human's intention is concluded by gathering biological signals and context data, and then, the decision is interpreted to a system action that is recognizable to the human in the physical environment, thereby completing the loop. In this paper, we have designed a model for early prognosis of coma using the electroencephalogram dataset. In the proposed approach, we have achieved the best results using a statistical learning algorithm called autoregressive integrated moving average in comparison to artificial neural networks and long short-term memory models. In order to measure the efficiency of our model, we have used the root mean squared error (RMSE), mean absolute error (MAE), and mean squared error (MSE) value to evaluate the linear models as it gives the difference between the measured value and true or correct value. We have achieved the least possible error value for our dataset. To conduct this experiment, we used the dataset available in the phsyionet opensource community.",0,0
6090,"Deep Learning-Based Denoised MRI Images for Correlation Analysis between Lumbar Facet Joint and Lumbar Disc Herniation in Spine Surgery. This work aimed to explore the relationship between spine surgery lumbar facet joint (LFJ) and lumbar disc herniation (LDH) via compressed sensing algorithm-based MRI images to analyze the clinical symptoms of patients with residual neurological symptoms after LDH. Under weighted BM3D denoising, Epigraph method was introduced to establish the novel CSMRI reconstruction algorithm (BEMRI). 127 patients with LDH were taken as the research objects. The BEMRI algorithm was compared with others regarding peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM). Patients' bilateral LFJ angles were compared. The relationships between LFJ angles, lumbar disc degeneration, and LFJ degeneration were analyzed. It turned out that the PSNR and SSIM of BEMRI algorithm were evidently superior to those of other algorithms. The proportion of patients with grade IV degeneration was at most 31.76%. Lumbar disc grading was positively correlated with change grading of LFJ degeneration (<i>P</i> < 0.001). LFJ asymmetry was positively correlated with LFJ degeneration grade and LDH (<i>P</i> < 0.001). Incidence of residual neurological symptoms in patients aged 61-70 years was as high as 63.77%. The proportion of patients with severe urinary excretion disorders was 71.96%. Therefore, the BEMRI algorithm improved the quality of MRI images. Degeneration of LDH was positively correlated with degeneration of LFJ. Asymmetry of LFJ was notably positively correlated with the degeneration of LFJ and LDH. Patients aged 61-70 years had a high incidence of residual neurological symptoms after surgery, most of which were manifested as urinary excretion disorders.",0,0
6091,"Artificial Intelligence Algorithm-Based Ultrasound Image Segmentation Technology in the Diagnosis of Breast Cancer Axillary Lymph Node Metastasis. This paper aimed to investigate the application of ultrasound image segmentation technology based on the back propagation neural network (BPNN) artificial intelligence algorithm in the diagnosis of breast cancer axillary lymph node metastasis, thereby providing a theoretical basis for clinical diagnosis. In this study, 90 breast cancer patients with axillary lymph node metastasis were selected as the research objects and rolled randomly into an experimental group and a control group. Besides, all of them were examined by ultrasound. The BPNN algorithm for the ultrasound image segmentation diagnosis method was applied to the patiens from the experimental group, while the control group was given routine ultrasound diagnosis. Thus, the value of this algorithm in ultrasonic diagnosis was compared and explored. The results showed that when the number of hidden layer nodes based on the BPNN artificial intelligence algorithm was 2, 3, 4, 5, 6, 7, and 8, the corresponding segmentation accuracy was 97.3%, 96.5%, 94.8%, 94.8%, and 94.1% in turn. Among them, the segmentation accuracy was the highest when the number of hidden layer nodes was 2. The correlation of independent variable bubble plot analysis showed that the presence or absence of capsules, the presence of crab feet or burrs in breast cancer lesions was critical influencing factors for the occurrence of axillary lymph node metastasis, and the standardized importance was 99.7% and 70.8%, respectively. Besides, the area under the two-dimensional receiver operating characteristic (ROC) curve of the BPNN artificial intelligence algorithm model classification was always greater than the area under the curve of manual segmentation, and the segmentation accuracy was 90.31%, 94.88%, 95.48%, 95.44%, and 97.65% in sequence. In addition, the segmentation specificity of different running times was higher than that of manual segmentation. In conclusion, the BPNN artificial intelligence algorithm had high accuracy, sensitivity, and specificity for ultrasound image segmentation, with a better segmentation effect. Therefore, it had a better diagnostic effect for breast cancer axillary lymph node metastasis.",0,0
6092,"Gene Mutation Classification through Text Evidence Facilitating Cancer Tumour Detection. A cancer tumour consists of thousands of genetic mutations. Even after advancement in technology, the task of distinguishing genetic mutations, which act as driver for the growth of tumour with passengers (Neutral Genetic Mutations), is still being done manually. This is a time-consuming process where pathologists interpret every genetic mutation from the clinical evidence manually. These clinical shreds of evidence belong to a total of nine classes, but the criterion of classification is still unknown. The main aim of this research is to propose a multiclass classifier to classify the genetic mutations based on clinical evidence (i.e., the text description of these genetic mutations) using Natural Language Processing (NLP) techniques. The dataset for this research is taken from Kaggle and is provided by the Memorial Sloan Kettering Cancer Center (MSKCC). The world-class researchers and oncologists contribute the dataset. Three text transformation models, namely, CountVectorizer, TfidfVectorizer, and Word2Vec, are utilized for the conversion of text to a matrix of token counts. Three machine learning classification models, namely, Logistic Regression (LR), Random Forest (RF), and XGBoost (XGB), along with the Recurrent Neural Network (RNN) model of deep learning, are applied to the sparse matrix (keywords count representation) of text descriptions. The accuracy score of all the proposed classifiers is evaluated by using the confusion matrix. Finally, the empirical results show that the RNN model of deep learning has performed better than other proposed classifiers with the highest accuracy of 70%.",0,0
6094,"Deep-Learning-Based Color Doppler Ultrasound Image Feature in the Diagnosis of Elderly Patients with Chronic Heart Failure Complicated with Sarcopenia. The neural network algorithm of deep learning was applied to optimize and improve color Doppler ultrasound images, which was used for the research on elderly patients with chronic heart failure (CHF) complicated with sarcopenia, so as to analyze the effect of the deep-learning-based color Doppler ultrasound image on the diagnosis of CHF. 259 patients were selected randomly in this study, who were admitted to hospital from October 2017 to March 2020 and were diagnosed with sarcopenia. Then, all of them underwent cardiac ultrasound examination and were divided into two groups according to whether deep learning technology was used for image processing or not. A group of routine unprocessed images was set as the control group, and the images processed by deep learning were set as the experimental group. The results of color Doppler images before and after processing were analyzed and compared; that is, the processed images of the experimental group were clearer and had higher resolution than the unprocessed images of the control group, with the peak signal-to-noise ratio (PSNR)â€‰=â€‰20 and structural similarity index measure (SSIM)â€‰=â€‰0.09; the similarity between the final diagnosis results and the examination results of the experimental group (93.5%) was higher than that of the control group (87.0%), and the comparison was statistically significant (<i>P</i> < 0.05); among all the patients diagnosed with sarcopenia, 88.9% were also eventually diagnosed with CHF and only a small part of them were diagnosed with other diseases, with statistical significance (<i>P</i> < 0.05). In conclusion, deep learning technology had certain application value in processing color Doppler ultrasound images. Although there was no obvious difference between the color Doppler ultrasound images before and after processing, they could all make a better diagnosis. Moreover, the research results showed the correlation between CHF and sarcopenia.",0,0
6095,Deep Learning-Based CT Image Characteristics and Postoperative Anal Function Restoration for Patients with Complex Anal Fistula. This study aimed to optimize the CT images of anal fistula patients using a convolutional neural network (CNN) algorithm to investigate the anal function recovery.,0,0
6097,"JOINT SEGMENTATION OF MULTIPLE SCLEROSIS LESIONS AND BRAIN ANATOMY IN MRI SCANS OF ANY CONTRAST AND RESOLUTION WITH CNNs. We present the first deep learning method to segment Multiple Sclerosis lesions and brain structures from MRI scans of any (possibly multimodal) contrast and resolution. Our method only requires segmentations to be trained (no images), as it leverages the generative model of Bayesian segmentation to generate synthetic scans with simulated lesions, which are then used to train a CNN. Our method can be retrained to segment at any resolution by adjusting the amount of synthesised partial volume. By construction, the synthetic scans are perfectly aligned with their labels, which enables training with noisy labels obtained with automatic methods. The training data are generated on the fly, and aggressive augmentation (including artefacts) is applied for improved generalisation. We demonstrate our method on two public datasets, comparing it with a state-of-the-art Bayesian approach implemented in FreeSurfer, and dataset specific CNNs trained on real data. The code is available at https://github.com/BBillot/SynthSeg.",0,0
6099,"Research on an Intelligent Lightweight-Assisted Pterygium Diagnosis Model Based on Anterior Segment Images. The lack of primary ophthalmologists in China results in the inability of basic-level hospitals to diagnose pterygium patients. To solve this problem, an intelligent-assisted lightweight pterygium diagnosis model based on anterior segment images is proposed in this study.",0,0
6102,"Nature inspired optimization model for classification and severity prediction in COVID-19 clinical dataset. The spread rate of COVID-19 is expected to be high in the wake of the virus's mutated strain found recently in a few countries. Fast diagnosis of the disease and knowing its severity are the two significant concerns of all physicians. Even though positive or negative diagnosis can be obtained through the RT-PCR test, an automatic model that predicts severity and the diagnosis will help medical practitioners to a great extend for affirming medication. Machine learning is an efficient tool that can process vast volume of data deposited in various formats, including clinical symptoms. In this work, we have developed machine learning models for analysing a clinical data set comprising 65000 records of patients, consisting of 26 features. An optimum set of features was derived from this data set by the proposed variant of artificial bee colony optimization algorithm. By making use of these features, a binary classifier is modelled with support vector machine for the screening of COVID-19 patients. Different models were tested for this purpose and the support vector machine has showcased the highest accuracy of 96%. Successively, severity prediction in COVID positive patients was also performed successfully by the logistic regression model. The model managed to predict three severity status viz mild, moderate, and severe. The confusion matrix and the precision-recall values (0.96 and 0.97) of the binary classifier indicate the classifier's efficiency in predicting positive cases correctly. The receiver operating curve generated for the severity predicting model shows the highest accuracy, 96.0% for class 1 and 85.0% for class 2 patients. Doctors can infer these results to finalize the type of treatment/care/facilities that need to be given to the patients from time to time.",0,0
6104,"Assessing the Adequacy of Hemodialysis Patients via the Graph-Based Takagi-Sugeno-Kang Fuzzy System. Maintenance hemodialysis is the main method for the treatment of end-stage renal disease in China. The <i>Kt</i>/<i>V</i> value is the gold standard of hemodialysis adequacy. However, <i>Kt</i>/<i>V</i> requires repeated blood drawing and evaluation; it is hard to monitor dialysis adequacy frequently. In order to meet the need for repeated clinical assessments of dialysis adequacy, we want to find a noninvasive way to assess dialysis adequacy. Therefore, we collect some clinically relevant data and develop a machine learning- (ML-) based model to predict dialysis adequacy for clinical hemodialysis patients. We collect 250 patients, including gender, age, ultrafiltration (UF), predialysis body weight (preBW), postdialysis body weights (postBW), blood pressure (BP), heart rate (HR), and blood flow (BF). An efficient graph-based Takagi-Sugeno-Kang Fuzzy System (G-TSK-FS) model is proposed to predict the dialysis adequacy of hemodialysis patients. The root mean square error (RMSE) of our model is 0.1578. The proposed model can be used as a feasible method to predict dialysis adequacy, providing a new way for clinical practice. Our G-TSK-FS model could be used as a feasible method to predict dialysis adequacy, providing a new way for clinical practice.",0,0
6105,"A Self-Representation-Based Fuzzy SVM Model for Predicting Vascular Calcification of Hemodialysis Patients. In end-stage renal disease (ESRD), vascular calcification risk factors are essential for the survival of hemodialysis patients. To effectively assess the level of vascular calcification, the machine learning algorithm can be used to predict the vascular calcification risk in ESRD patients. As the amount of collected data is unbalanced under different risk levels, it has an influence on the classification task. So, an effective fuzzy support vector machine based on self-representation (FSVM-SR) is proposed to predict vascular calcification risk in this work. In addition, our method is also compared with other conventional machine learning methods, and the results show that our method can better complete the classification task of the vascular calcification risk.",0,0
6109,"Predicting the Risk of Depression Based on ECG Using RNN. This paper presents a model to predict the risk of depression based on electrocardiogram (ECG). This proposed model uses a Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) autoencoder to predict normal, abnormal, and PVC heartbeats. The RNN model is a deep learning-based model to classify normal, abnormal, and PVC heartbeats. We used the model as a classifier. The model uses a heart rates dataset to predict abnormal and PVC heartbeats. As for the dataset, we have used 5000 ECG samples. The model was trained on a training dataset and validation dataset. After that, it was tested on a test dataset. The model is trained on normal heartbeat rates, so the model can predict any heartbeat rates other than normal. Our contribution here is to build a model that can differentiate between ""normal,"" ""abnormal,"" and ""risky"" heartbeats. Our model predicts ""normal"" heartbeats with 97.24% accuracy and can predict ""PVC"" heartbeats with 100% accuracy. Other than the accuracy, we evaluated our model on the training loss graphs. These two types of training loss graphs were evaluated as ""normal"" versus ""risky"" and ""abnormal"" versus ""risky."" We have seen great results there as well. The best losses for ""normal,"" ""abnormal,"" and ""risky"" are 5.71, 33.36, and 34.78. However, these results may improve if a larger dataset is used. In studies, it was found that patients suffering from depression may have a different kind of heartbeat than the normal ones. In most cases, it is PVC (Premature Ventricular Contraction) heartbeats. Therefore, the target is to predict abnormal heartbeats and PVC heartbeats.",0,0
6116,"Developing a Radiomics Signature for Supratentorial Extra-Ventricular Ependymoma Using Multimodal MR Imaging. <b>Rationale and Objectives:</b> To build a machine learning-based diagnostic model that can accurately distinguish adult supratentorial extraventricular ependymoma (STEE) from similarly appearing high-grade gliomas (HGG) using quantitative radiomic signatures from a multi-parametric MRI framework. <b>Materials and Methods:</b> We computed radiomic features on the preprocessed and segmented tumor masks from a pre-operative multimodal MRI dataset [contrast-enhanced T1 (T1ce), T2, fluid-attenuated inversion recovery (FLAIR), apparent diffusion coefficient (ADC)] from STEE (<i>n</i> = 15), HGG-Grade IV (HGG-G4) (<i>n</i> = 24), and HGG-Grade III (HGG-G3) (<i>n</i> = 36) patients, followed by an optimum two-stage feature selection and multiclass classification. Performance of multiple classifiers were evaluated on both unimodal and multimodal feature sets and most discriminative radiomic features involved in classification of STEE from HGG subtypes were obtained. <b>Results:</b> Multimodal features demonstrated higher classification performance over unimodal feature set in discriminating STEE and HGG subtypes with an accuracy of 68% on test data and above 80% on cross validation, along with an overall above 90% specificity. Among unimodal feature sets, those extracted from FLAIR demonstrated high classification performance in delineating all three tumor groups. Texture-based radiomic features particularly from FLAIR were most important in discriminating STEE from HGG-G4, whereas first-order features from T2 and ADC consistently ranked higher in differentiating multiple tumor groups. <b>Conclusions:</b> This study illustrates the utility of radiomics-based multimodal MRI framework in accurately discriminating similarly appearing adult STEE from HGG subtypes. Radiomic features from multiple MRI modalities could capture intricate and complementary information for a robust and highly accurate multiclass tumor classification.",0,0
6121,"Automated Scoring of Tablet-Administered Expressive Language Tests. Speech and language impairments are common pediatric conditions, with as many as 10% of children experiencing one or both at some point during development. Expressive language disorders in particular often go undiagnosed, underscoring the immediate need for assessments of expressive language that can be administered and scored reliably and objectively. In this paper, we present a set of highly accurate computational models for automatically scoring several common expressive language tasks. In our assessment framework, instructions and stimuli are presented to the child on a tablet computer, which records the child's responses in real time, while a clinician controls the pace and presentation of the tasks using a second tablet. The recorded responses for four distinct expressive language tasks (expressive vocabulary, word structure, recalling sentences, and formulated sentences) are then scored using traditional paper-and-pencil scoring and using machine learning methods relying on a deep neural network-based language representation model. All four tasks can be scored automatically from both clean and verbatim speech transcripts with very high accuracy at the item level (83-99%). In addition, these automated scores correlate strongly and significantly (Ï = 0.76-0.99, <i>p</i> < 0.001) with manual item-level, raw, and scaled scores. These results point to the utility and potential of automated computationally-driven methods of both administering and scoring expressive language tasks for pediatric developmental language evaluation.",0,0
6123,"Validity and Cultural Generalisability of a 5-Minute AI-Based, Computerised Cognitive Assessment in Mild Cognitive Impairment and Alzheimer's Dementia. <b>Introduction:</b> Early detection and monitoring of mild cognitive impairment (MCI) and Alzheimer's Disease (AD) patients are key to tackling dementia and providing benefits to patients, caregivers, healthcare providers and society. We developed the Integrated Cognitive Assessment (ICA); a 5-min, language independent computerised cognitive test that employs an Artificial Intelligence (AI) model to improve its accuracy in detecting cognitive impairment. In this study, we aimed to evaluate the generalisability of the ICA in detecting cognitive impairment in MCI and mild AD patients. <b>Methods:</b> We studied the ICA in 230 participants. 95 healthy volunteers, 80 MCI, and 55 mild AD participants completed the ICA, Montreal Cognitive Assessment (MoCA) and Addenbrooke's Cognitive Examination (ACE) cognitive tests. <b>Results:</b> The ICA demonstrated convergent validity with MoCA (Pearson r=0.58, p<0.0001) and ACE (r=0.62, p<0.0001). The ICA AI model was able to detect cognitive impairment with an AUC of 81% for MCI patients, and 88% for mild AD patients. The AI model demonstrated improved performance with increased training data and showed generalisability in performance from one population to another. The ICA correlation of 0.17 (<i>p</i> = 0.01) with education years is considerably smaller than that of MoCA (<i>r</i> = 0.34, <i>p</i> < 0.0001) and ACE (<i>r</i> = 0.41, <i>p</i> < 0.0001) which displayed significant correlations. In a separate study the ICA demonstrated no significant practise effect over the duration of the study. <b>Discussion:</b> The ICA can support clinicians by aiding accurate diagnosis of MCI and AD and is appropriate for large-scale screening of cognitive impairment. The ICA is unbiased by differences in language, culture, and education.",0,0
6132,"Data augmentation approaches using cycle-consistent adversarial networks for improving COVID-19 screening in portable chest X-ray images. The current COVID-19 pandemic, that has caused more than 100 million cases as well as more than two million deaths worldwide, demands the development of fast and accurate diagnostic methods despite the lack of available samples. This disease mainly affects the respiratory system of the patients and can lead to pneumonia and to severe cases of acute respiratory syndrome that result in the formation of several pathological structures in the lungs. These pathological structures can be explored taking advantage of chest X-ray imaging. As a recommendation for the health services, portable chest X-ray devices should be used instead of conventional fixed machinery, in order to prevent the spread of the pathogen. However, portable devices present several problems (specially those related with capture quality). Moreover, the subjectivity and the fatigue of the clinicians lead to a very difficult diagnostic process. To overcome that, computer-aided methodologies can be very useful even taking into account the lack of available samples that the COVID-19 affectation shows. In this work, we propose an improvement in the performance of COVID-19 screening, taking advantage of several cycle generative adversarial networks to generate useful and relevant synthetic images to solve the lack of COVID-19 samples, in the context of poor quality and low detail datasets obtained from portable devices. For validating this proposal for improved COVID-19 screening, several experiments were conducted. The results demonstrate that this data augmentation strategy improves the performance of a previous COVID-19 screening proposal, achieving an accuracy of 98.61% when distinguishing among NON-COVID-19 (<i>i.e.</i> normal control samples and samples with pathologies others than COVID-19) and genuine COVID-19 samples. It is remarkable that this methodology can be extrapolated to other pulmonary pathologies and even other medical imaging domains to overcome the data scarcity.",0,0
6133,"Wavelet and deep learning-based detection of SARS-nCoV from thoracic X-ray images for rapid and efficient testing. This paper proposes a wavelet and artificial intelligence-enabled rapid and efficient testing procedure for patients with Severe Acute Respiratory Coronavirus Syndrome (SARS-nCoV) through a deep learning approach from thoracic X-ray images. Presently, the virus infection is diagnosed primarily by a process called the real-time Reverse Transcriptase-Polymerase Chain Reaction (rRT-PCR) based on its genetic prints. This whole procedure takes a substantial amount of time to identify and diagnose the patients infected by the virus. The proposed research uses a wavelet-based convolution neural network architectures to detect SARS-nCoV. CNN is pre-trained on the ImageNet and trained end-to-end using thoracic X-ray images. To execute Discrete Wavelet Transforms (DWT), the available mother wavelet functions from different families, namely Haar, Daubechies, Symlet, Biorthogonal, Coiflet, and Discrete Meyer, were considered. Two-level decomposition via DWT is adopted to extract prominent features peripheral and subpleural ground-glass opacities, often in the lower lobes explicitly from thoracic X-ray images to suppress noise effect, further enhancing the signal to noise ratio. The proposed wavelet-based deep learning models of both, two-class instances (COVID vs. Normal) and four-class instances (COVID-19 vs. PNA bacterial vs. PNA viral vs. Normal) were validated from publicly available databases using k-Fold Cross Validation (k-Fold CV) technique. In addition to these X-ray images, images of recent COVID-19 patients were further used to examine the model's practicality and real-time feasibility in combating the current pandemic situation. It was observed that the Symlet 7 approximation component with two-level manifested the highest test accuracy of 98.87%, followed by Biorthogonal 2.6 with an efficiency of 98.73%. While the test accuracy for Symlet 7 and Biorthogonal 2.6 is high, Haar and Daubechies with two levels have demonstrated excellent validation accuracy on unseen data. It was also observed that the precision, the recall rate, and the dice similarity coefficient for four-class instances were 98%, 98%, and 99%, respectively, using the proposed algorithm.",0,0
6135,"Automated detection and quantification of Wilms' Tumor 1-positive cells in murine diabetic kidney disease. In diabetic kidney disease (DKD), podocyte depletion, and the subsequent migration of parietal epithelial cells (PECs) to the tuft, is a precursor to progressive glomerular damage, but the limitations of brightfield microscopy currently preclude direct pathological quantitation of these cells. Here we present an automated approach to podocyte and PEC detection developed using kidney sections from mouse model emulating DKD, stained first for Wilms' Tumor 1 (WT1) (podocyte and PEC marker) by immunofluorescence, then post-stained with periodic acid-Schiff (PAS). A generative adversarial network (GAN)-based pipeline was used to translate these PAS-stained sections into WT1-labeled IF images, enabling <i>in silico</i> label-free podocyte and PEC identification in brightfield images. Our method detected WT1-positive cells with high sensitivity/specificity (0.87/0.92). Additionally, our algorithm performed with a higher Cohen's kappa (0.85) than the average manual identification by three renal pathologists (0.78). We propose that this pipeline will enable accurate detection of WT1-positive cells in research applications.",1,1
6137,"A Distributed System Improves Inter-Observer and AI Concordance in Annotating Interstitial Fibrosis and Tubular Atrophy. Histologic examination of interstitial fibrosis and tubular atrophy (IFTA) is critical to determine the extent of irreversible kidney injury in renal disease. The current clinical standard involves pathologist's visual assessment of IFTA, which is prone to inter-observer variability. To address this diagnostic variability, we designed two case studies (CSs), including seven pathologists, using HistomicsTK- a distributed system developed by Kitware Inc. (Clifton Park, NY). Twenty-five whole slide images (WSIs) were classified into a training set of 21 and a validation set of four. The training set was composed of seven unique subsets, each provided to an individual pathologist along with four common WSIs from the validation set. In CS 1, all pathologists individually annotated IFTA in their respective slides. These annotations were then used to train a deep learning algorithm to computationally segment IFTA. In CS 2, manual and computational annotations from CS 1 were first reviewed by the annotators to improve concordance of IFTA annotation. Both the manual and computational annotation processes were then repeated as in CS1. The inter-observer concordance in the validation set was measured by Krippendorff's alpha (KA). The KA for the seven pathologists in CS1 was 0.62 with CI [0.57, 0.67], and after reviewing each other's annotations in CS2, 0.66 with CI [0.60, 0.72]. The respective CS1 and CS2 KA were 0.58 with CI [0.52, 0.64] and 0.63 with CI [0.56, 0.69] when including the deep learner as an eighth annotator. These results suggest that our designed annotation framework refines agreement of spatial annotation of IFTA and demonstrates a human-AI approach to significantly improve the development of computational models.",1,0
6140,"Evolving convolutional neural network parameters through the genetic algorithm for the breast cancer classification problem. Breast cancer is the most frequently diagnosed cancer and the leading cause of cancer mortality in women around the world. However, it can be controlled effectively by early diagnosis, followed by effective treatment. Clinical specialists take the advantages of computer-aided diagnosis (CAD) systems to make their diagnosis as accurate as possible. Deep learning techniques, such as the convolutional neural network (CNN), due to their classification capabilities on learned feature methods and ability of working with complex images, have been widely adopted in CAD systems. The parameters of the network, including the weights of the convolution filters and the weights of the fully connected layers, play a crucial role in the classification accuracy of any CNN model. The back-propagation technique is the most frequently used approach for training the CNN. However, this technique has some disadvantages, such as getting stuck in local minima. In this study, we propose to optimize the weights of the CNN using the genetic algorithm (GA). The work consists of designing a CNN model to facilitate the classification process, training the model using three different optimizers (mini-batch gradient descent, Adam, and GA), and evaluating the model through various experiments on the BreakHis dataset. We show that the CNN model trained through the GA performs as well as the Adam optimizer with a classification accuracy of 85%.",0,0
6141,Mathematical and deep learning analysis based on tissue dielectric properties at low frequencies predict outcome in human breast cancer. The early detection of human breast cancer represents a great chance of survival. Malignant tissues have more water content and higher electrolytes concentration while they have lower fat content than the normal. These cancer biochemical characters provide malignant tissue with high electric permittivity (ÎµÂ´) and conductivity (Ïƒ).,0,0
6142,Radiomics from Primary Tumor on Dual-Energy CT Derived Iodine Maps can Predict Cervical Lymph Node Metastasis in Papillary Thyroid Cancer. To develop and validate 2 iodine maps based radiomics nomograms for preoperatively predicting cervical lymph node metastasis (LNM) and central lymph node metastasis (CLNM) in papillary thyroid cancer (PTC).,0,0
6146,Lung Nodule Detectability of Artificial Intelligence-assisted CT Image Reading in Lung Cancer Screening. Artificial intelligence (AI)-based automatic lung nodule detection system improves the detection rate of nodules. It is important to evaluate the clinical value of AI system by comparing AI-assisted nodule detection with actu-al radiology reports.,1,1
6149,"The effect of principal component analysis in the diagnosis of congestive heart failure via heart rate variability analysis. In this study, we investigated the effect of principal component analysis (PCA) in congestive heart failure (CHF) diagnosis using various machine learning algorithms from 5-min HRV data. The extracted 59 heart rate variability (HRV) features consist of statistical time-domain measures, frequency-domain measures (power spectral density estimations from Fourier transform and Lomb-Scargle methods), time-frequency HRV measures (Wavelet transform), and nonlinear HRV measures (Poincare plot, symbolic dynamics, detrended fluctuation analysis, and sample entropy). All these HRV features are the classifiers' inputs. We repeated the study ten times using the first one to the first 10 principal components from PCA instead of all HRV features. Nine different classifiers, namely logistic regression, Naive Bayes, k-nearest neighbors, decision tree, AdaBoost, support vector machines, stochastic gradient descent, random forest, and artificial neuronal network (multilayer perceptron) are examined. The proposed study results in the 100% accuracy, 100% specificity, and 100% sensitivity after utilizing PCA (with the first eight principal components) using the Random Forest classifier where the maximum classifier performances are the 86% accuracy, 79% specificity, and 86% sensitivity before PCA. In conclusion, PCA is beneficial in the diagnosis of patients with CHF. In addition, we experienced the online Python-based visual machine learning tool, Orange, which can implement well-known machine learning algorithms.",0,0
6150,Diagnostic performance and image quality of deep learning image reconstruction (DLIR) on unenhanced low-dose abdominal CT for urolithiasis. Patients with urolithiasis undergo radiation overexposure from computed tomography (CT) scans. Improvement of image reconstruction is necessary for radiation dose reduction.,0,0
6151,"Assessment of appropriate body mass index cut-off points for long-term mortality among ST-elevation myocardial infarction survivors in Asian population using machine learning algorithm. Low body mass index (BMI) is a predictor of adverse events in patients with ST-elevated myocardial infarction (STEMI) in Western countries. Because the average BMI of Asians is significantly lower than that of the Western population, the appropriate cut-off BMI value and its role in long-term mortality are unclear in Asian patients. Between January 2006 and December 2017, 1215 patients who underwent percutaneous coronary intervention (PCI) for acute STEMI and were alive at discharge (mean age, 67.7Â years; male, 75.4%) were evaluated. The cut-off BMI value, which could predict all-cause mortality within 10Â years, was detected using a survival classification and regression tree (CART) model. The causes of death according to the BMI value were evaluated in each group. Based on the CART model, the patients were divided into three groups (BMIâ€‰<â€‰18Â kg/m<sup>2</sup>: 54 patients, 18Â kg/m<sup>2</sup>â€‰â‰¤â€‰BMIâ€‰â‰¤â€‰20Â kg/m<sup>2</sup>: 109 patients, and BMIâ€‰>â€‰20Â kg/m<sup>2</sup>: 1052 patients). The BMI decreased with age; with an increased BMI, patients with dyslipidemia, diabetes mellitus, and smoking habit increased. During the study period (median, 4.9Â years), 194 patients (26.8%) died (cardiac death, 59 patients; non-cardiac death, 135 patients). All-cause mortality was more frequent as the BMI decreased (BMIâ€‰<â€‰18Â kg/m<sup>2</sup>; 72.8%, 18Â kg/m<sup>2</sup>â€‰â‰¤â€‰BMIâ€‰â‰¤â€‰20Â kg/m<sup>2</sup>; 40.5%, and BMIâ€‰>â€‰20Â kg/m<sup>2</sup>; 22.8%; log-rank pâ€‰<â€‰0.001). Non-cardiac deaths were more frequent than cardiac deaths in all groups, and the dominance of non-cardiac death was highest in the lowest BMI group. Cut-off BMI values of 18Â kg/m<sup>2</sup> and 20Â kg/m<sup>2</sup> can predict long-term mortality after PCI in Asian STEMI survivors, whose cut-off value is lower than that in the Western populations. The main causes of death in this cohort differed according to the BMI values.",0,0
6152,Development of an AI system for accurately diagnose hepatocellular carcinoma from computed tomography imaging data. Computed tomography (CT) scan is frequently used to detect hepatocellular carcinoma (HCC) in routine clinical practice. The aim of this study is to develop a deep-learning AI system to improve the diagnostic accuracy of HCC by analysing liver CT imaging data.,0,0
6154,"Comparative analysis of pulmonary nodules segmentation using multiscale residual U-Net and fuzzy C-means clustering. Pulmonary nodules have different shapes and uneven density, and some nodules adhere to blood vessels, pleura and other anatomical structures, which increase the difficulty of nodule segmentation. The purpose of this paper is to use multiscale residual U-Net to accurately segment lung nodules with complex geometric shapes, while comparing it with fuzzy C-means clustering and manual segmentation.",0,1
6156,"Fully automated unified prognosis of Covid-19 chest X-ray/CT scan images using Deep Covix-Net model. SARS-COV2 (Covid-19) prevails in the form of multiple mutant variants causing pandemic situations around the world. Thus, medical diagnosis is not accurate. Although several clinical diagnostic methodologies have been introduced hitherto, chest X-ray and computed tomography (CT) imaging techniques complement the analytical methods (for instance, RT-PCR) to a certain extent. In this context, we demonstrate a novel framework by employing various image segmentation models to leverage the available image databases (9000 chest X-ray images and 6000 CT scan images). The proposed methodology is expected to assist in the prognosis of Covid-19-infected individuals through examination of chest X-rays and CT scans of images using the Deep Covix-Net model for identifying novel coronavirus-infected patients effectively and efficiently. The slice of the precision score is analysed in terms of performance metrics such as accuracy, the confusion matrix, and the receiver operating characteristic curve. The result leans on the database obtainable in the GitHub and Kaggle repository, conforming to their endorsed chest X-ray and CT images. The classification performances of various algorithms were examined for a test set with 1800 images. The proposed model achieved a 96.8% multiple-classification accuracy among Covid-19, normal, and pneumonia chest X-ray databases. Moreover, it attained a 97% accuracy among Covid-19 and normal CT scan images. Thus, the proposed mechanism achieves the rigorousness associated with the machine learning technique, providing rapid outcomes for both training and testing datasets.",0,0
6160,Can machine learning improve randomized clinical trial analysis? Recently a realistic simulator of patient seizure diaries was developed that can reproduce effects seen in randomized clinical trials (RCTs). RCTs suffer from high costs and statistical inefficiencies. Using realistic simulation and machine learning this study aimed to identify a more statistically efficient outcome metric.,0,0
6163,Deep neural network for automatic volumetric segmentation of whole-body CT images for body composition assessment. Body composition analysis on CT images is a valuable tool for sarcopenia assessment. We aimed to develop and validate a deep neural network applicable to whole-body CT images of PET-CT scan for the automatic volumetric segmentation of body composition.,0,0
6170,"Developing non-invasive bladder cancer screening methodology through potentiometric multisensor urine analysis. We report on the feasibility study exploring the potential of a simple electrochemical multisensor system as a tool for distinguishing between urine samples from patients with confirmed bladder cancer (36 samples) and healthy volunteers (51 samples). The potentiometric sensor responses obtained in urine samples were employed as the input data for various machine learning classification algorithms (logistic regression, random forest, extreme gradient boosting classifier, support vector machine, and voting classifier). The performance metrics of the classifiers were evaluated via Monte-Carlo cross-validation. The best model combining all the acquired data from the people aged 19-88 with different tumor grades and malignancies, including patients with recurrent bladder cancer, yielded 72% accuracy, 71% sensitivity, and 58% specificity. It was found that these metrics can be improved to 76% accuracy, 80% sensitivity, and 75% specificity when only a limited age group (50-88 years of age) is considered. Taking into account the simplicity of the proposed screening method, this technique appears to be a promising tool for further research.",0,0
6175,"CoLe-CNN+: Context learning - Convolutional neural network for COVID-19-Ground-Glass-Opacities detection and segmentation. The most common tool for population-wide COVID-19 identification is the Reverse Transcription-Polymerase Chain Reaction test that detects the presence of the virus in the throat (or sputum) in swab samples. This test has a sensitivity between 59% and 71%. However, this test does not provide precise information regarding the extension of the pulmonary infection. Moreover, it has been proven that through the reading of a computed tomography (CT) scan, a clinician can provide a more complete perspective of the severity of the disease. Therefore, we propose a comprehensive system for fully-automated COVID-19 detection and lesion segmentation from CT scans, powered by deep learning strategies to support decision-making process for the diagnosis of COVID-19.",0,0
6177,"Impact of transfer learning for human sperm segmentation using deep learning. Infertility affects approximately one in ten couples, and almost half of the infertility cases are due to the malefactor. To diagnose infertility and determine future treatment, a semen analysis is performed. Evaluation of sperm morphology is one of several steps in semen analysis, in which the shape and size of sperm parts are examined. The laboratories dedicated to this use traditional methods susceptible to errors. An alternative to replace the poor visual ability to assess sperm size and shape is to analyze sperm morphology with a computer's help. However, since the automatic sperm classification rates do not show an acceptable precision rate for use in the clinical setting, it is considered an exciting approach to focus efforts on improving the precision in sperm segmentation to extract the contour sperm before classification. This work aims to assess the utility of two image segmentation deep learning models for segmenting human sperm heads, acrosome, and nucleus.",0,0
6178,"A deep learning based ensemble learning method for epileptic seizure prediction. In epilepsy, patients suffer from seizures which cannot be controlled with medicines or surgical treatments in more than 30% of the cases. Prediction of epileptic seizures is extremely important so that they can be controlled with medication before they actually occur. Researchers have proposed multiple machine/deep learning based methods to predict epileptic seizures; however, accurate prediction of epileptic seizures with low false positive rate is still a challenge. In this research, we propose a deep learning based ensemble learning method to predict epileptic seizures. In the proposed method, EEG signals are preprocessed using empirical mode decomposition followed by bandpass filtering for noise removal. The class imbalance problem has been mitigated with synthetic preictal segments generated using generative adversarial networks. A three-layer customized convolutional neural network has been proposed to extract automated features from preprocessed EEG signals and combined them with handcrafted features to get a comprehensive feature set. The feature set is then used to train an ensemble classifier that combines the output of SVM, CNN and LSTM using Model agnostic meta learning. An average sensitivity of 96.28% and specificity of 95.65% with an average anticipation time of 33Â min on all subjects of CHBMIT has been achieved by the proposed method, whereas, on American epilepsy society-Kaggle seizure prediction dataset, an average sensitivity of 94.2% and specificity of 95.8% has been achieved on all subjects.",0,0
6180,A novel multiscale and multipath convolutional neural network based age-related macular degeneration detection using OCT images. One of the significant retinal diseases that affected older people is called Age-related Macular Degeneration (AMD). The first stage creates a blur effect on vision and later leads to central vision loss. Most people overlooked the primary stage blurring and converted it into an advanced stage. There is no proper treatment to cure the disease. So the early detection of AMD is essential to prevent its extension into the advanced stage. This paper proposes a novel deep Convolutional Neural Network (CNN) architecture to automate AMD diagnosis early from Optical Coherence Tomographic (OCT) images.,0,0
6182,"Dilated densely connected U-Net with uncertainty focus loss for 3D ABUS mass segmentation. Accurate segmentation of breast mass in 3D automated breast ultrasound (ABUS) images plays an important role in qualitative and quantitative ABUS image analysis. Yet this task is challenging due to the low signal to noise ratio and serious artifacts in ABUS images, the large shape and size variation of breast masses, as well as the small training dataset compared with natural images. The purpose of this study is to address these difficulties by designing a dilated densely connected U-Net (D<sup>2</sup>U-Net) together with an uncertainty focus loss.",0,0
6186,"Digital phenotyping of sleep patterns among heterogenous samples of Latinx adults using unsupervised learning. This study aimed to identify sleep disturbance subtypes (""phenotypes"") among Latinx adults based on objective sleep data using a flexible unsupervised machine learning technique.",0,0
6197,"[Classification Model of Corneal Opacity Based on Digital Image Features]. According to the digital image features of corneal opacity, a multi classification model of support vector machine (SVM) was established to explore the objective quantification method of corneal opacity.",0,0
6198,Diagnostic performance of deep learning models for detecting bone metastasis on whole-body bone scan in prostate cancer. We evaluated the performance of deep learning classifiers for bone scans of prostate cancer patients.,0,0
6199,"Cerebrospinal fluid flow cytometry distinguishes psychosis spectrum disorders from differential diagnoses. Psychotic disorders are common and disabling mental conditions. The relative importance of immune-related mechanisms in psychotic disorders remains subject of debate. Here, we present a large-scale retrospective study of blood and cerebrospinal fluid (CSF) immune cell profiles of psychosis spectrum patients. We performed basic CSF analysis and multi-dimensional flow cytometry of CSF and blood cells from 59 patients with primary psychotic disorders (F20, F22, F23, and F25) in comparison to inflammatory (49 RRMS and 16 NMDARE patients) and non-inflammatory controls (52 IIH patients). We replicated the known expansion of monocytes in the blood of psychosis spectrum patients, that we identified to preferentially affect classical monocytes. In the CSF, we found a relative shift from lymphocytes to monocytes, increased protein levels, and evidence of blood-brain barrier disruption in psychosis. In fact, these CSF features confidently distinguished autoimmune encephalitis from psychosis despite similar (initial) clinical features. We then constructed machine learning models incorporating blood and CSF parameters and demonstrated their superior ability to differentiate psychosis from non-inflammatory controls compared to individual parameters. Multi-dimensional and multi-compartment immune cell signatures can thus support the diagnosis of psychosis spectrum disorders with the potential to accelerate diagnosis and initiation of therapy.",0,0
6200,"Detection and classification of unilateral cleft alveolus with and without cleft palate on panoramic radiographs using a deep learning system. Although panoramic radiography has a role in the examination of patients with cleft alveolus (CA), its appearances is sometimes difficult to interpret. The aims of this study were to develop a computer-aided diagnosis system for diagnosing the CA status on panoramic radiographs using a deep learning object detection technique with and without normal data in the learning process, to verify its performance in comparison to human observers, and to clarify some characteristic appearances probably related to the performance. The panoramic radiographs of 383 CA patients with cleft palate (CA with CP) or without cleft palate (CA only) and 210 patients without CA (normal) were used to create two models on the DetectNet. The models 1 and 2 were developed based on the data without and with normal subjects, respectively, to detect the CAs and classify them into with or without CP. The model 2 reduced the false positive rate (1/30) compared to the model 1 (12/30). The overall accuracy of Model 2 was higher than Model 1 and human observers. The model created in this study appeared to have the potential to detect and classify CAs on panoramic radiographs, and might be useful to assist the human observers.",1,1
6201,"Support vector machine and deep-learning object detection for localisation of hard exudates. Hard exudates are one of the main clinical findings in the retinal images of patients with diabetic retinopathy. Detecting them early significantly impacts the treatment of underlying diseases; therefore, there is a need for automated systems with high reliability. We propose aÂ novel method for identifying and localising hard exudates in retinal images. To achieve fast image pre-scanning, a support vector machine (SVM) classifier was combined with a faster region-based convolutional neural network (faster R-CNN) object detector for the localisation of exudates. Rapid pre-scanning filtered out exudate-free samples using a feature vector extracted from the pre-trained ResNet-50 network. Subsequently, the remaining samples were processed using a faster R-CNN detector for detailed analysis. When evaluating all the exudates as individual objects, the SVM classifier reduced the false positive rate by 29.7% and marginally increased the false negative rate by 16.2%. When evaluating all the images, we recorded a 50% reduction in the false positive rate, without any decrease in the number of false negatives. The interim results suggested that pre-scanning the samples using the SVM prior to implementing the deep-network object detector could simultaneously improve and speed up the current hard exudates detection method, especially when there is paucity of training data.",0,0
6202,"Towards precision cardiometabolic prevention: results from a machine learning, semi-supervised clustering approach in the nationwide population-based ORISCAV-LUX 2 study. Given the rapid increase in the incidence of cardiometabolic conditions, there is an urgent need for better approaches to prevent as many cases as possible and move from a one-size-fits-all approach to a precision cardiometabolic prevention strategy in the general population. We used data from ORISCAV-LUX 2, a nationwide, cross-sectional, population-based study. On the 1356 participants, we used a machine learning semi-supervised cluster method guided by body mass index (BMI) and glycated hemoglobin (HbA1c), and a set of 29 cardiometabolic variables, to identify subgroups of interest for cardiometabolic health. Cluster stability was assessed with the Jaccard similarity index. We have observed 4 clusters with a very high stability (ranging between 92 and 100%). Based on distinctive features that deviate from the overall population distribution, we have labeled Cluster 1 (Nâ€‰=â€‰729, 53.76%) as ""Healthy"", Cluster 2 (Nâ€‰=â€‰508, 37.46%) as ""Family history-Overweight-High Cholesterol "", Cluster 3 (Nâ€‰=â€‰91, 6.71%) as ""Severe Obesity-Prediabetes-Inflammation"" and Cluster 4 (Nâ€‰=â€‰28, 2.06%) as ""Diabetes-Hypertension-Poor CV Health"". Our work provides an in-depth characterization and thus, a better understanding of cardiometabolic health in the general population. Our data suggest that such a clustering approach could now be used to define more targeted and tailored strategies for the prevention of cardiometabolic diseases at a population level. This study provides a first step towards precision cardiometabolic prevention and should be externally validated in other contexts.",0,0
6207,"Does real-time artificial intelligence-based visual pathology enhancement of three-dimensional optical coherence tomography scans optimise treatment decision in patients with nAMD? Rationale and design of the RAZORBILL study. Artificial intelligence (AI)-based clinical decision support tools, being developed across multiple fields in medicine, need to be evaluated for their impact on the treatment and outcomes of patients as well as optimisation of the clinical workflow. The <i>RAZORBILL</i> study will investigate the impact of advanced AI segmentation algorithms on the disease activity assessment in patients with neovascular age-related macular degeneration (nAMD) by enriching three-dimensional (3D) retinal optical coherence tomography (OCT) scans with automated fluid and layer quantification measurements.",0,0
6210,"COVID-19 diagnosis and severity detection from CT-images using transfer learning and back propagation neural network. COVID-19 diagnosis in symptomatic patients is an important factor for arranging the necessary lifesaving facilities like ICU care and ventilator support. For this purpose, we designed a computer-aided diagnosis and severity detection method by using transfer learning and a back propagation neural network.",0,0
6216,Prediction of the local treatment outcome in patients with oropharyngeal squamous cell carcinoma using deep learning analysis of pretreatment FDG-PET images. This study aimed to assess the utility of deep learning analysis using pretreatment FDG-PET images to predict local treatment outcome in oropharyngeal squamous cell carcinoma (OPSCC) patients.,0,0
6218,"Development and Validation of a Bayesian Network for Supporting the Etiological Diagnosis of Uveitis. The etiological diagnosis of uveitis is complex. We aimed to implement and validate a Bayesian belief network algorithm for the differential diagnosis of the most relevant causes of uveitis. The training dataset (<i>n</i> = 897) and the test dataset (<i>n</i> = 154) were composed of all incident cases of uveitis admitted to two internal medicine departments, in two independent French centers (Lyon, 2003-2016 and Dijon, 2015-2017). The etiologies of uveitis were classified into eight groups. The algorithm was based on simple epidemiological characteristics (age, gender, and ethnicity) and anatomoclinical features of uveitis. The cross-validated estimate obtained in the training dataset concluded that the etiology of uveitis determined by the experts corresponded to one of the two most probable diagnoses in at least 77% of the cases. In the test dataset, this probability reached at least 83%. For the training and test datasets, when the most likely diagnosis was considered, the highest sensitivity was obtained for spondyloarthritis and HLA-B27-related uveitis (76% and 63%, respectively). The respective specificities were 93% and 54%. This algorithm could help junior and general ophthalmologists in the differential diagnosis of uveitis. It could guide the diagnostic work-up and help in the selection of further diagnostic investigations.",0,0
6221,"Forecasting Progressive Trends in Keratoconus by Means of a Time Delay Neural Network. Early and accurate detection of keratoconus progression is particularly important for the prudent, cost-effective use of corneal cross-linking and judicious timing of clinical follow-up visits. The aim of this study was to verify whether a progression could be predicted based on two prior tomography measurements and to verify the accuracy of the system when labelling the eye as stable or suspect progressive. Data from 743 patients measured by Pentacam (Oculus, Wetzlar, Germany) were available, and they were filtered and preprocessed to data quality needs. The time delay neural network received six features as input, measured in two consecutive examinations, predicted the future values, and determined the classification (stable or suspect progressive) based on the significance of the change from the baseline. The system showed a sensitivity of 70.8% and a specificity of 80.6%. On average, the positive and negative predictive values were 71.4% and 80.2%. Including data of less quality (as defined by the software) did not significantly worsen the results. This predictive system constitutes another step towards a personalized management of keratoconus. While the results obtained were modest and perhaps insufficient to decide on a surgical procedure, such as cross-linking, they may be useful to customize the timing for the patient's next follow-up.",0,0
6222,"Fully Automated Colorimetric Analysis of the Optic Nerve Aided by Deep Learning and Its Association with Perimetry and OCT for the Study of Glaucoma. Laguna-ONhE is an application for the colorimetric analysis of optic nerve images, which topographically assesses the cup and the presence of haemoglobin. Its latest version has been fully automated with five deep learning models. In this paper, perimetry in combination with Laguna-ONhE or Cirrus-OCT was evaluated.",0,0
6223,"An Assistive Role of a Machine Learning Network in Diagnosis of Middle Ear Diseases. The present study aimed to develop a machine learning network to diagnose middle ear diseases with tympanic membrane images and to identify its assistive role in the diagnostic process. The medical records of subjects who underwent ear endoscopy tests were reviewed. From these records, 2272 diagnostic tympanic membranes images were appropriately labeled as normal, otitis media with effusion (OME), chronic otitis media (COM), or cholesteatoma and were used for training. We developed the ""ResNet18 + Shuffle"" network and validated the model performance. Seventy-one representative cases were selected to test the final accuracy of the network and resident physicians. We asked 10 resident physicians to make diagnoses from tympanic membrane images with and without the help of the machine learning network, and the change of the diagnostic performance of resident physicians with the aid of the answers from the machine learning network was assessed. The devised network showed a highest accuracy of 97.18%. A five-fold validation showed that the network successfully diagnosed ear diseases with an accuracy greater than 93%. All resident physicians were able to diagnose middle ear diseases more accurately with the help of the machine learning network. The increase in diagnostic accuracy was up to 18% (1.4% to 18.4%). The machine learning network successfully classified middle ear diseases and was assistive to clinicians in the interpretation of tympanic membrane images.",1,1
6247,"Fusion of Higher Order Spectra and Texture Extraction Methods for Automated Stroke Severity Classification with MRI Images. This paper presents a scientific foundation for automated stroke severity classification. We have constructed and assessed a system which extracts diagnostically relevant information from Magnetic Resonance Imaging (MRI) images. The design was based on 267 images that show the brain from individual subjects after stroke. They were labeled as either Lacunar Syndrome (LACS), Partial Anterior Circulation Syndrome (PACS), or Total Anterior Circulation Stroke (TACS). The labels indicate different physiological processes which manifest themselves in distinct image texture. The processing system was tasked with extracting texture information that could be used to classify a brain MRI image from a stroke survivor into either LACS, PACS, or TACS. We analyzed 6475 features that were obtained with Gray-Level Run Length Matrix (GLRLM), Higher Order Spectra (HOS), as well as a combination of Discrete Wavelet Transform (DWT) and Gray-Level Co-occurrence Matrix (GLCM) methods. The resulting features were ranked based on the <i>p</i>-value extracted with the Analysis Of Variance (ANOVA) algorithm. The ranked features were used to train and test four types of Support Vector Machine (SVM) classification algorithms according to the rules of 10-fold cross-validation. We found that SVM with Radial Basis Function (RBF) kernel achieves: Accuracy (ACC) = 93.62%, Specificity (SPE) = 95.91%, Sensitivity (SEN) = 92.44%, and Dice-score = 0.95. These results indicate that computer aided stroke severity diagnosis support is possible. Such systems might lead to progress in stroke diagnosis by enabling healthcare professionals to improve diagnosis and management of stroke patients with the same resources.",0,0
6248,"Automatic COVID-19 Detection Using Exemplar Hybrid Deep Features with X-ray Images. COVID-19 and pneumonia detection using medical images is a topic of immense interest in medical and healthcare research. Various advanced medical imaging and machine learning techniques have been presented to detect these respiratory disorders accurately. In this work, we have proposed a novel COVID-19 detection system using an exemplar and hybrid fused deep feature generator with X-ray images. The proposed Exemplar COVID-19FclNet9 comprises three basic steps: exemplar deep feature generation, iterative feature selection and classification. The novelty of this work is the feature extraction using three pre-trained convolutional neural networks (CNNs) in the presented feature extraction phase. The common aspects of these pre-trained CNNs are that they have three fully connected layers, and these networks are AlexNet, VGG16 and VGG19. The fully connected layer of these networks is used to generate deep features using an exemplar structure, and a nine-feature generation method is obtained. The loss values of these feature extractors are computed, and the best three extractors are selected. The features of the top three fully connected features are merged. An iterative selector is used to select the most informative features. The chosen features are classified using a support vector machine (SVM) classifier. The proposed COVID-19FclNet9 applied nine deep feature extraction methods by using three deep networks together. The most appropriate deep feature generation model selection and iterative feature selection have been employed to utilise their advantages together. By using these techniques, the image classification ability of the used three deep networks has been improved. The presented model is developed using four X-ray image corpora (DB1, DB2, DB3 and DB4) with two, three and four classes. The proposed Exemplar COVID-19FclNet9 achieved a classification accuracy of 97.60%, 89.96%, 98.84% and 99.64% using the SVM classifier with 10-fold cross-validation for four datasets, respectively. Our developed Exemplar COVID-19FclNet9 model has achieved high classification accuracy for all four databases and may be deployed for clinical application.",0,0
6253,"Identification of CNGB1 as a Predictor of Response to Neoadjuvant Chemotherapy in Muscle-Invasive Bladder Cancer. Cisplatin-based neoadjuvant chemotherapy (NAC) is recommended prior to radical cystectomy for muscle-invasive bladder cancer (MIBC) patients. Despite a 5-10% survival benefit, some patients do not respond and experience substantial toxicity and delay in surgery. To date, there are no clinically approved biomarkers predictive of response to NAC and their identification is urgently required for more precise delivery of care. To address this issue, a multi-methods analysis approach of machine learning and differential gene expression analysis was undertaken on a cohort of 30 MIBC cases highly selected for an exquisitely strong response to NAC or marked resistance and/or progression (discovery cohort). RGIFE (ranked guided iterative feature elimination) machine learning algorithm, previously demonstrated to have the ability to select biomarkers with high predictive power, identified a 9-gene signature (<i>CNGB1</i>, <i>GGH</i>, <i>HIST1H4F</i>, <i>IDO1</i>, <i>KIF5A</i>, <i>MRPL4</i>, <i>NCDN</i>, <i>PRRT3</i>, <i>SLC35B3</i>) able to select responders from non-responders with 100% predictive accuracy. This novel signature correlated with overall survival in meta-analysis performed using published NAC treated-MIBC microarray data (validation cohort 1, <i>n</i> = 26, Log rank test, <i>p</i> = 0.02). Corroboration with differential gene expression analysis revealed cyclic nucleotide-gated channel, <i>CNGB1</i>, as the top ranked upregulated gene in non-responders to NAC. A higher CNGB1 immunostaining score was seen in non-responders in tissue microarray analysis of the discovery cohort (<i>n</i> = 30, <i>p</i> = 0.02). Kaplan-Meier analysis of a further cohort of MIBC patients (validation cohort 2, <i>n</i> = 99) demonstrated that a high level of CNGB1 expression associated with shorter cancer specific survival (<i>p</i> < 0.001). Finally, in vitro studies showed siRNA-mediated CNGB1 knockdown enhanced cisplatin sensitivity of MIBC cell lines, J82 and 253JB-V. Overall, these data reveal a novel signature gene set and <i>CNGB1</i> as a simpler proxy as a promising biomarker to predict chemoresponsiveness of MIBC patients.",0,0
6254,"Deep Learning Fast Screening Approach on Cytological Whole Slides for Thyroid Cancer Diagnosis. Thyroid cancer is the most common cancer in the endocrine system, and papillary thyroid carcinoma (PTC) is the most prevalent type of thyroid cancer, accounting for 70 to 80% of all thyroid cancer cases. In clinical practice, visual inspection of cytopathological slides is an essential initial method used by the pathologist to diagnose PTC. Manual visual assessment of the whole slide images is difficult, time consuming, and subjective, with a high inter-observer variability, which can sometimes lead to suboptimal patient management due to false-positive and false-negative. In this study, we present a fully automatic, efficient, and fast deep learning framework for fast screening of papanicolaou-stained thyroid fine needle aspiration (FNA) and ThinPrep (TP) cytological slides. To the authors' best of knowledge, this work is the first study to build an automated deep learning framework for identification of PTC from both FNA and TP slides. The proposed deep learning framework is evaluated on a dataset of 131 WSIs, and the results show that the proposed method achieves an accuracy of 99%, precision of 85%, recall of 94% and F1-score of 87% in segmentation of PTC in FNA slides and an accuracy of 99%, precision of 97%, recall of 98%, F1-score of 98%, and Jaccard-Index of 96% in TP slides. In addition, the proposed method significantly outperforms the two state-of-the-art deep learning methods, i.e., U-Net and SegNet, in terms of accuracy, recall, F1-score, and Jaccard-Index (p<0.001). Furthermore, for run-time analysis, the proposed fast screening method takes 0.4 min to process a WSI and is 7.8 times faster than U-Net and 9.1 times faster than SegNet, respectively.",0,0
6256,"Rapid Spectroscopic Liquid Biopsy for the Universal Detection of Brain Tumours. To support the early detection and diagnosis of brain tumours we have developed a rapid, cost-effective and easy to use spectroscopic liquid biopsy based on the absorbance of infrared radiation. We have previously reported highly sensitive results of our approach which can discriminate patients with a recent brain tumour diagnosis and asymptomatic controls. Other liquid biopsy approaches (e.g., based on tumour genetic material) report a lower classification accuracy for early-stage tumours. In this manuscript we present an investigation into the link between brain tumour volume and liquid biopsy test performance.",0,0
6257,"A Means of Assessing Deep Learning-Based Detection of ICOS Protein Expression in Colon Cancer. Biomarkers identify patient response to therapy. The potential immune-checkpoint biomarker, Inducible T-cell COStimulator (ICOS), expressed on regulating T-cell activation and involved in adaptive immune responses, is of great interest. We have previously shown that open-source software for digital pathology image analysis can be used to detect and quantify ICOS using cell detection algorithms based on traditional image processing techniques. Currently, artificial intelligence (AI) based on deep learning methods is significantly impacting the domain of digital pathology, including the quantification of biomarkers. In this study, we propose a general AI-based workflow for applying deep learning to the problem of cell segmentation/detection in IHC slides as a basis for quantifying nuclear staining biomarkers, such as ICOS. It consists of two main parts: a simplified but robust annotation process, and cell segmentation/detection models. This results in an optimised annotation process with a new user-friendly tool that can interact with1 other open-source software and assists pathologists and scientists in creating and exporting data for deep learning. We present a set of architectures for cell-based segmentation/detection to quantify and analyse the trade-offs between them, proving to be more accurate and less time consuming than traditional methods. This approach can identify the best tool to deliver the prognostic significance of ICOS protein expression.",0,0
6258,"Deep Learning for Automatic Subclassification of Gastric Carcinoma Using Whole-Slide Histopathology Images. Histomorphologic types of gastric cancer (GC) have significant prognostic values that should be considered during treatment planning. Because the thorough quantitative review of a tissue slide is a laborious task for pathologists, deep learning (DL) can be a useful tool to support pathologic workflow. In the present study, a fully automated approach was applied to distinguish differentiated/undifferentiated and non-mucinous/mucinous tumor types in GC tissue whole-slide images from The Cancer Genome Atlas (TCGA) stomach adenocarcinoma dataset (TCGA-STAD). By classifying small patches of tissue images into differentiated/undifferentiated and non-mucinous/mucinous tumor tissues, the relative proportion of GC tissue subtypes can be easily quantified. Furthermore, the distribution of different tissue subtypes can be clearly visualized. The patch-level areas under the curves for the receiver operating characteristic curves for the differentiated/undifferentiated and non-mucinous/mucinous classifiers were 0.932 and 0.979, respectively. We also validated the classifiers on our own GC datasets and confirmed that the generalizability of the classifiers is excellent. The results indicate that the DL-based tissue classifier could be a useful tool for the quantitative analysis of cancer tissue slides. By combining DL-based classifiers for various molecular and morphologic variations in tissue slides, the heterogeneity of tumor tissues can be unveiled more efficiently.",0,0
6259,"Deep Learning Segmentation of Triple-Negative Breast Cancer (TNBC) Patient Derived Tumor Xenograft (PDX) and Sensitivity of Radiomic Pipeline to Tumor Probability Boundary. Preclinical magnetic resonance imaging (MRI) is a critical component in a co-clinical research pipeline. Importantly, segmentation of tumors in MRI is a necessary step in tumor phenotyping and assessment of response to therapy. However, manual segmentation is time-intensive and suffers from inter- and intra- observer variability and lack of reproducibility. This study aimed to develop an automated pipeline for accurate localization and delineation of TNBC PDX tumors from preclinical T1w and T2w MR images using a deep learning (DL) algorithm and to assess the sensitivity of radiomic features to tumor boundaries. We tested five network architectures including U-Net, dense U-Net, Res-Net, recurrent residual UNet (R2UNet), and dense R2U-Net (D-R2UNet), which were compared against manual delineation by experts. To mitigate bias among multiple experts, the simultaneous truth and performance level estimation (STAPLE) algorithm was applied to create consensus maps. Performance metrics (F1-Score, recall, precision, and AUC) were used to assess the performance of the networks. Multi-contrast D-R2UNet performed best with F1-score = 0.948; however, all networks scored within 1-3% of each other. Radiomic features extracted from D-R2UNet were highly corelated to STAPLE-derived features with 67.13% of T1w and 53.15% of T2w exhibiting correlation Ï â‰¥ 0.9 (<i>p</i> â‰¤ 0.05). D-R2UNet-extracted features exhibited better reproducibility relative to STAPLE with 86.71% of T1w and 69.93% of T2w features found to be highly reproducible (CCC â‰¥ 0.9, <i>p</i> â‰¤ 0.05). Finally, 39.16% T1w and 13.9% T2w features were identified as insensitive to tumor boundary perturbations (Spearman correlation (-0.4 â‰¤ Ï â‰¤ 0.4). We developed a highly reproducible DL algorithm to circumvent manual segmentation of T1w and T2w MR images and identified sensitivity of radiomic features to tumor boundaries.",0,1
6260,"Machine Learning Approaches to Classify Primary and Metastatic Cancers Using Tissue of Origin-Based DNA Methylation Profiles. Metastatic cancers account for up to 90% of cancer-related deaths. The clear differentiation of metastatic cancers from primary cancers is crucial for cancer type identification and developing targeted treatment for each cancer type. DNA methylation patterns are suggested to be an intriguing target for cancer prediction and are also considered to be an important mediator for the transition to metastatic cancer. In the present study, we used 24 cancer types and 9303 methylome samples downloaded from publicly available data repositories, including The Cancer Genome Atlas (TCGA) and the Gene Expression Omnibus (GEO). We constructed machine learning classifiers to discriminate metastatic, primary, and non-cancerous methylome samples. We applied support vector machines (SVM), Naive Bayes (NB), extreme gradient boosting (XGBoost), and random forest (RF) machine learning models to classify the cancer types based on their tissue of origin. RF outperformed the other classifiers, with an average accuracy of 99%. Moreover, we applied local interpretable model-agnostic explanations (LIME) to explain important methylation biomarkers to classify cancer types.",0,0
6261,"A Patient-Derived Organoid-Based Radiosensitivity Model for the Prediction of Radiation Responses in Patients with Rectal Cancer. Patient-derived tumor organoids closely resemble original patient tumors. We conducted this co-clinical trial with treatment-naive rectal cancer patients and matched patient-derived tumor organoids to determine whether a correlation exists between experimental results obtained after irradiation in patients and organoids. Between November 2017 and March 2020, we prospectively enrolled 33 patients who were diagnosed with mid-to-lower rectal adenocarcinoma based on endoscopic biopsy findings. We constructed a prediction model through a machine learning algorithm using clinical and experimental radioresponse data. Our data confirmed that patient-derived tumor organoids closely recapitulated original tumors, both pathophysiologically and genetically. Radiation responses in patients were positively correlated with those in patient-derived tumor organoids. Our machine learning-based prediction model showed excellent performance. In the prediction model for good responders trained using the random forest algorithm, the area under the curve, accuracy, and kappa value were 0.918, 81.5%, and 0.51, respectively. In the prediction model for poor responders, the area under the curve, accuracy, and kappa value were 0.971, 92.1%, and 0.75, respectively. Our patient-derived tumor organoid-based radiosensitivity model could lead to more advanced precision medicine for treating patients with rectal cancer.",0,0
6263,"Site-Specific Variation in Radiomic Features of Head and Neck Squamous Cell Carcinoma and Its Impact on Machine Learning Models. Current radiomic studies of head and neck squamous cell carcinomas (HNSCC) are typically based on datasets combining tumors from different locations, assuming that the radiomic features are similar based on histopathologic characteristics. However, molecular pathogenesis and treatment in HNSCC substantially vary across different tumor sites. It is not known if a statistical difference exists between radiomic features from different tumor sites and how they affect machine learning model performance in endpoint prediction. To answer these questions, we extracted radiomic features from contrast-enhanced neck computed tomography scans (CTs) of 605 patients with HNSCC originating from the oral cavity, oropharynx, and hypopharynx/larynx. The difference in radiomic features of tumors from these sites was assessed using statistical analyses and Random Forest classifiers on the radiomic features with 10-fold cross-validation to predict tumor sites, nodal metastasis, and HPV status. We found statistically significant differences (<i>p</i>-value â‰¤ 0.05) between the radiomic features of HNSCC depending on tumor location. We also observed that differences in quantitative features among HNSCC from different locations impact the performance of machine learning models. This suggests that radiomic features may reveal biologic heterogeneity complementary to current gold standard histopathologic evaluation. We recommend considering tumor site in radiomic studies of HNSCC.",0,0
6264,"Machine Learning Models to Predict Survival Outcomes According to the Surgical Approach of Primary Radical Hysterectomy in Patients with Early Cervical Cancer. We purposed to develop machine learning models predicting survival outcomes according to the surgical approach for radical hysterectomy (RH) in early cervical cancer. In total, 1056 patients with 2009 FIGO stage IB cervical cancer who underwent primary type C RH by either open or laparoscopic surgery were included in this multicenter retrospective study. The whole dataset consisting of patients' clinicopathologic data was split into training and test sets with a 4:1 ratio. Using the training set, we developed models predicting the probability of 5-year progression-free survival (PFS) and overall survival (OS) with tenfold cross validation. The developed models were validated in the test set. In terms of predictive performance, we measured the area under the receiver operating characteristic curve (AUC) values. The logistic regression models comprised of preoperative variables yielded AUCs of 0.679 and 0.715 for predicting 5-year PFS and OS rates, respectively. Combining both logistic regression and multiple machine learning models, we constructed hybrid ensemble models, and these models showed much improved predictive performance, with 0.741 and 0.759 AUCs for predicting 5-year PFS and OS rates, respectively. We successfully developed models predicting disease recurrence and mortality after primary RH in patients with early cervical cancer. As the predicted value is calculated based on the preoperative factors, such as the surgical approach, these ensemble models would be useful for making decisions when choosing between open or laparoscopic RH.",0,0
6265,"Statistical Meta-Analysis of Risk Factors for Endometrial Cancer and Development of a Risk Prediction Model Using an Artificial Neural Network Algorithm. In this study we wished to determine the rank order of risk factors for endometrial cancer and calculate a pooled risk and percentage risk for each factor using a statistical meta-analysis approach. The next step was to design a neural network computer model to predict the overall increase or decreased risk of cancer for individual patients. This would help to determine whether this prediction could be used as a tool to decide if a patient should be considered for testing and to predict diagnosis, as well as to suggest prevention measures to patients.",0,0
6270,"Predicting Hemodynamic Failure Development in PICU Using Machine Learning Techniques. The present work aims to identify the predictors of hemodynamic failure (HF) developed during pediatric intensive care unit (PICU) stay testing a set of machine learning techniques (MLTs), comparing their ability to predict the outcome of interest. The study involved patients admitted to PICUs between 2010 and 2020. Data were extracted from the Italian Network of Pediatric Intensive Care Units (TIPNet) registry. The algorithms considered were generalized linear model (GLM), recursive partition tree (RPART), random forest (RF), neural networks models, and extreme gradient boosting (XGB). Since the outcome is rare, upsampling and downsampling algorithms have been applied for imbalance control. For each approach, the main performance measures were reported. Among an overall sample of 29,494 subjects, only 399 developed HF during the PICU stay. The median age was about two years, and the male gender was the most prevalent. The XGB algorithm outperformed other MLTs in predicting HF development, with a median ROC measure of 0.780 (IQR 0.770-0.793). PIM 3, age, and base excess were found to be the strongest predictors of outcome. The present work provides insights for the prediction of HF development during PICU stay using machine-learning algorithms.",0,0
6273,"Predictors of Newborn's Weight for Height: A Machine Learning Study Using Nationwide Multicenter Ultrasound Data. There has been no machine learning study with a rich collection of clinical, sonographic markers to compare the performance measures for a variety of newborns' weight-for-height indicators. This study compared the performance measures for a variety of newborns' weight-for-height indicators based on machine learning, ultrasonographic data and maternal/delivery information. The source of data for this study was a multi-center retrospective study with 2949 mother-newborn pairs. The mean-squared-error-over-variance measures of five machine learning approaches were compared for newborn's weight, newborn's weight/height, newborn's weight/height<sup>2</sup> and newborn's weight/hieght<sup>3</sup>. Random forest variable importance, the influence of a variable over average node impurity, was used to identify major predictors of these newborns' weight-for-height indicators among ultrasonographic data and maternal/delivery information. Regarding ultrasonographic fetal biometry, newborn's weight, newborn's weight/height and newborn's weight/height<sup>2</sup> were better indicators with smaller mean-squared-error-over-variance measures than newborn's weight/height<sup>3</sup>. Based on random forest variable importance, the top six predictors of newborn's weight were the same as those of newborn's weight/height and those of newborn's weight/height<sup>2</sup>: gestational age at delivery time, the first estimated fetal weight and abdominal circumference in week 36 or later, maternal weight and body mass index at delivery time, and the first biparietal diameter in week 36 or later. These six predictors also ranked within the top seven for large-for-gestational-age and the top eight for small-for-gestational-age. In conclusion, newborn's weight, newborn's weight/height and newborn's weight/height<sup>2</sup> are more suitable for ultrasonographic fetal biometry with smaller mean-squared-error-over-variance measures than newborn's weight/height<sup>3</sup>. Machine learning with ultrasonographic data would be an effective noninvasive approach for predicting newborn's weight, weight/height and weight/height<sup>2</sup>.",0,0
6274,"Combination of Plasma-Based Metabolomics and Machine Learning Algorithm Provides a Novel Diagnostic Strategy for Malignant Mesothelioma. Malignant mesothelioma (MM) is an aggressive and incurable carcinoma that is primarily caused by asbestos exposure. However, the current diagnostic tool for MM is still under-developed. Therefore, the aim of this study is to explore the diagnostic significance of a strategy that combined plasma-based metabolomics with machine learning algorithms for MM.",0,0
6275,"Machine-Learning-Based Radiomics MRI Model for Survival Prediction of Recurrent Glioblastomas Treated with Bevacizumab. Anti-angiogenic therapy with bevacizumab is a widely used therapeutic option for recurrent glioblastoma (GBM). Nevertheless, the therapeutic response remains highly heterogeneous among GBM patients with discordant outcomes. Recent data have shown that radiomics, an advanced recent imaging analysis method, can help to predict both prognosis and therapy in a multitude of solid tumours. The objective of this study was to identify novel biomarkers, extracted from MRI and clinical data, which could predict overall survival (OS) and progression-free survival (PFS) in GBM patients treated with bevacizumab using machine-learning algorithms. In a cohort of 194 recurrent GBM patients (age range 18-80), radiomics data from pre-treatment T2 FLAIR and gadolinium-injected MRI images along with clinical features were analysed. Binary classification models for OS at 9, 12, and 15 months were evaluated. Our classification models successfully stratified the OS. The AUCs were equal to 0.78, 0.85, and 0.76 on the test sets (0.79, 0.82, and 0.87 on the training sets) for the 9-, 12-, and 15-month endpoints, respectively. Regressions yielded a C-index of 0.64 (0.74) for OS and 0.57 (0.69) for PFS. These results suggest that radiomics could assist in the elaboration of a predictive model for treatment selection in recurrent GBM patients.",0,0
6276,"Prediction of In-Hospital Cardiac Arrest Using Shallow and Deep Learning. Sudden cardiac arrest can leave serious brain damage or lead to death, so it is very important to predict before a cardiac arrest occurs. However, early warning score systems including the National Early Warning Score, are associated with low sensitivity and false positives. We applied shallow and deep learning to predict cardiac arrest to overcome these limitations. We evaluated the performance of the Synthetic Minority Oversampling Technique Ratio. We evaluated the performance using a Decision Tree, a Random Forest, Logistic Regression, Long Short-Term Memory model, Gated Recurrent Unit model, and LSTM-GRU hybrid models. Our proposed Logistic Regression demonstrated a higher positive predictive value and sensitivity than traditional early warning systems.",0,0
6277,"Using Slit-Lamp Images for Deep Learning-Based Identification of Bacterial and Fungal Keratitis: Model Development and Validation with Different Convolutional Neural Networks. In this study, we aimed to develop a deep learning model for identifying bacterial keratitis (BK) and fungal keratitis (FK) by using slit-lamp images. We retrospectively collected slit-lamp images of patients with culture-proven microbial keratitis between 1 January 2010 and 31 December 2019 from two medical centers in Taiwan. We constructed a deep learning algorithm consisting of a segmentation model for cropping cornea images and a classification model that applies different convolutional neural networks (CNNs) to differentiate between FK and BK. The CNNs included DenseNet121, DenseNet161, DenseNet169, DenseNet201, EfficientNetB3, InceptionV3, ResNet101, and ResNet50. The model performance was evaluated and presented as the area under the curve (AUC) of the receiver operating characteristic curves. A gradient-weighted class activation mapping technique was used to plot the heat map of the model. By using 1330 images from 580 patients, the deep learning algorithm achieved the highest average accuracy of 80.0%. Using different CNNs, the diagnostic accuracy for BK ranged from 79.6% to 95.9%, and that for FK ranged from 26.3% to 65.8%. The CNN of DenseNet161 showed the best model performance, with an AUC of 0.85 for both BK and FK. The heat maps revealed that the model was able to identify the corneal infiltrations. The model showed a better diagnostic accuracy than the previously reported diagnostic performance of both general ophthalmologists and corneal specialists.",1,0
6278,"Comparison of the Predicting Performance for Fate of Medial Meniscus Posterior Root Tear Based on Treatment Strategies: A Comparison between Logistic Regression, Gradient Boosting, and CNN Algorithms. This study aimed to validate the accuracy and prediction performance of machine learning (ML), deep learning (DL), and logistic regression methods in the treatment of medial meniscus posterior root tears (MMPRT). From July 2003 to May 2018, 640 patients diagnosed with MMPRT were included. First, the affecting factors for the surgery were evaluated using statistical analysis. Second, AI technology was introduced using X-ray and MRI. Finally, the accuracy and prediction performance were compared between ML&DL and logistic regression methods. Affecting factors of the logistic regression method corresponded well with the feature importance of the six top-ranked factors in the ML&DL method. There was no significant difference when comparing the accuracy, F1-score, and error rate between ML&DL and logistic regression methods (accuracy = 0.89 and 0.91, F1 score = 0.89 and 0.90, error rate = 0.11 and 0.09; <i>p</i> = 0.114, 0.422, and 0.119, respectively). The area under the curve (AUC) values showed excellent test quality for both ML&DL and logistic regression methods (AUC = 0.97 and 0.94, respectively) in the evaluation of prediction performance (<i>p</i> = 0.289). The affecting factors of the logistic regression method and the influence of the ML&DL method were not significantly different. The accuracy and performance of the ML&DL method in predicting the fate of MMPRT were comparable to those of the logistic regression method. Therefore, this ML&DL algorithm could potentially predict the outcome of the MMRPT in various fields and situations. Furthermore, our method could be efficiently implemented in current clinical practice.",0,0
6282,"Dilated Semantic Segmentation for Breast Ultrasonic Lesion Detection Using Parallel Feature Fusion. Breast cancer is becoming more dangerous by the day. The death rate in developing countries is rapidly increasing. As a result, early detection of breast cancer is critical, leading to a lower death rate. Several researchers have worked on breast cancer segmentation and classification using various imaging modalities. The ultrasonic imaging modality is one of the most cost-effective imaging techniques, with a higher sensitivity for diagnosis. The proposed study segments ultrasonic breast lesion images using a Dilated Semantic Segmentation Network (Di-CNN) combined with a morphological erosion operation. For feature extraction, we used the deep neural network DenseNet201 with transfer learning. We propose a 24-layer CNN that uses transfer learning-based feature extraction to further validate and ensure the enriched features with target intensity. To classify the nodules, the feature vectors obtained from DenseNet201 and the 24-layer CNN were fused using parallel fusion. The proposed methods were evaluated using a 10-fold cross-validation on various vector combinations. The accuracy of CNN-activated feature vectors and DenseNet201-activated feature vectors combined with the Support Vector Machine (SVM) classifier was 90.11 percent and 98.45 percent, respectively. With 98.9 percent accuracy, the fused version of the feature vector with SVM outperformed other algorithms. When compared to recent algorithms, the proposed algorithm achieves a better breast cancer diagnosis rate.",0,0
6289,"Automated FBSE-EWT based learning framework for detection of epileptic seizures using time-segmented EEG signals. Epilepsy is a neurological disorder that has severely affected many people's lives across the world. Electroencephalogram (EEG) signals are used to characterize the brain's state and detect various disorders. The EEG signals are non-stationary and non-linear in nature. Therefore, it is challenging to accurately process and learn from the recorded EEG signals in order to detect disorders like epilepsy. This paper proposed an automated learning framework using the Fourier-Bessel series expansion-based empirical wavelet transform (FBSE-EWT) method for detecting epileptic seizures from EEG signals. The scale-space boundary detection method was adopted to segment the Fourier-Bessel series expansion (FBSE) spectrum of multiple frame-size time-segmented EEG signals. Multiple frame-size time-segmented EEG signal's analysis was done using four different frame sizes: full, half, quarter, and half-quarter length of recorded EEG signals. Two different time-segmentation approaches were investigated on EEG signals: 1) segmenting signals based on multiple frame-size and 2) segmenting signals based on multiple frame-size with zero-padding the remaining signal. The FBSE-EWT method was applied to decompose the EEG signals into narrow sub-band signals. Features such as line-length (LL), log-energy-entropy (LEnt), and norm-entropy (NEnt) were computed from various frequency range sub-band signals. The relief-F feature ranking method was employed to select the most significant features; this reduces the computational burden of the models. The top-ranked accumulated features were used for classification using least square-support machine learning (LS-SVM), support vector machine (SVM), k-nearest neighbor (k-NN), and ensemble bagged tree classifiers. The proposed framework for epileptic seizure detection was evaluated on two publicly available benchmark EEG datasets: the Bonn EEG dataset and Children's Hospital Boston (CHB) and the Massachusetts Institute of Technology (MIT), well known as the CHB-MIT scalp EEG dataset. Training and testing of the models were performed using the 10-fold cross-validation technique. The FBSE-EWT based learning framework was compared with other state-of-the-art methods using both datasets. Experimental results showed that the proposed framework achieved 100Â % classification accuracy on the Bonn EEG dataset, whereas 99.84Â % classification accuracy on the CHB-MIT scalp EEG dataset.",0,0
6293,"A fusion decision system to identify and grade malnutrition in cancer patients: Machine learning reveals feasible workflow from representative real-world data. Most nutritional assessment tools are based on pre-defined questionnaires or consensus guidelines. However, it has been postulated that population data can be used directly to develop a solution for assessing malnutrition. This study established a machine learning (ML)-based, individualized decision system to identify and grade malnutrition using large-scale data from cancer patients.",0,0
6300,"Tumor radiomics signature for artificial neural network-assisted detection of neck metastasis in patient with tongue cancer. To determine the neck management of tongue cancer, this study attempted to construct an artificial neural network (ANN)-assisted model based on computed tomography (CT) radiomics of primary tumors to predict neck lymph node (LN) status in patients with tongue squamous cell carcinoma (SCC).",0,0
6301,"Identification and Characterization of Senescence Phenotype in Lung Adenocarcinoma with High Drug Sensitivity. Lung adenocarcinoma (LUAD) is a major health problem with minimal prognosis. Heterogeneity is a central determinant of the treatment outcome, requiring the identification of new subclasses of LUAD. Senescence has emerged as a crucial regulator of metastasis and drug response. Ionizing radiation- and doxorubicin-induced senescence associated genes in lung fibroblasts and K-means clustering were used to identify high- and low-senescence (HS and LS) classes among LUAD patients identified in The Cancer Genome Atlas (TCGA-LUAD). The LS group showed significantly poorer survival (P = 0.01) and greater activation of proliferative signaling pathways, proliferation, wound healing, and genetic aberrations. The TP53 mutation rate was significantly greater in the HS group (P < 0.0001), explaining the phenotype. Also, genome-wide hypomethylation was significantly greater in the LS group than in the HS group. Interestingly, pathway analysis identified silencing of Wnt signaling in the HS group. The machine learning-based recursive feature elimination technique was used to identify a 20-gene senescence signature in TCGA-LUAD samples. The presence of a senescence phenotype with poor survival was validatedÂ in an independent patient cohort and a cell-line cohort using unsupervised clustering of samplesÂ based onÂ a 20-gene signature. On further analysis, HS cells were more resistant to drugs, particularly histone deacetylase inhibitors. Taken together, a novel subtype of LUAD with reduced Wnt signaling and high drug resistance was identified.",0,0
6303,"Automatic classification and detection of oral cancer in photographic images using deep learning algorithms. Oral cancer is a deadly disease among the most common malignant tumors worldwide, and it has become an increasingly important public health problem in developing and low-to-middle income countries. This study aims to use the convolutional neural network (CNN) deep learning algorithms to develop an automated classification and detection model for oral cancer screening.",0,0
6304,"A machine-learning algorithm for the reliable identification of oral lichen planus. Oral lichen planus (OLP) is a relatively common oral disorder which shares clinical and histopathological features with other lichenoid lesions, leading to considerable inter-observer disagreement. This negatively impacts understanding of the pathogenesis and malignant transformation potential of this condition.",0,0
6312,"Epileptic Spike Detection Using Neural Networks with Linear-Phase Convolutions. To cope with the lack of highly skilled professionals, machine learning with proper signal processing is key for establishing automated diagnostic-aid technologies with which to conduct epileptic electroencephalogram (EEG) testing. In particular, frequency filtering with the appropriate passbands is essential for enhancing the biomarkerssuch as epileptic spike wavesthat are noted in the EEG. This paper introduces a novel class of neural networks (NNs) that have a bank of linear-phase finite impulse response filters at the first layer as a preprocessor that can behave as bandpass filters that extract biomarkers without destroying waveforms because of a linear-phase condition. Besides, the parameters of the filters are also data-driven. The proposed NNs were trained with a large amount of clinical EEG data, including 15,833 epileptic spike waveforms recorded from 50 patients, and their labels were annotated by specialists. In the experiments, we compared three scenarios for the first layer: no preprocessing, discrete wavelet transform, and the proposed data-driven filters. The experimental results show that the trained data-driven filter bank with supervised learning behaves like multiple bandpass filters. In particular, the trained filter passed a frequency band of approximately 1030 Hz. Moreover, the proposed method detected epileptic spikes, with the area under the receiver operating characteristic curve of 0.967 in the mean of 50 intersubject validations.",0,0
6315,Machine Learning Model to Predict Ventilator Associated Pneumonia in patients with Traumatic Brain Injury: The C.5 Decision Tree Approach. There is paucity in the literature to predict the occurrence of Ventilator Associated Pneumonia (VAP) in patients with Traumatic Brain Injury (TBI). We aimed to build a C.5. Decision Tree (C.5 DT) machine learning model to predict VAP in patients with moderate to severe TBI.,0,0
6322,"Assessment of hip displacement in children with cerebral palsy using machine learning approach. Manual measurements of migration percentage (MP) on pelvis radiographs for assessing hip displacement are subjective and time consuming. A deep learning approach using convolution neural networks (CNNs) to automatically measure the MP was proposed. The pre-trained Inception ResNet v2 was fine tuned to detect locations of the eight reference landmarks used for MP measurements. A second network, fine-tuned MobileNetV2, was trained on the regions of interest to obtain more precise landmarks' coordinates. The MP was calculated from the final estimated landmarks' locations. A total of 122 radiographs were divided into 57 for training, 10 for validation, and 55 for testing. The mean absolute difference (MAD) and intra-class correlation coefficient (ICC [2,1]) of the comparison for the MP on 110 measurements (left and right hips) were 4.5 [Formula: see text] 4.3% (95% CI, 3.7-5.3%) and 0.91, respectively. Sensitivity and specificity were 87.8% and 93.4% for the classification of hip displacement (MP-threshold of 30%), and 63.2% and 94.5% for the classification of surgery-needed hips (MP-threshold of 40%). The prediction results were returned within 5Â s. The developed fine-tuned CNNs detected the landmarks and provided automatic MP measurements with high accuracy and excellent reliability, which can assist clinicians to diagnose hip displacement in children with CP.",0,0
6325,"Hierarchical convolutional models for automatic pneu-monia diagnosis based on X-ray images: new strategies in public health. Despite some limits, our findings support the notion that deep learning methods can be used to simplify the diagnostic process and improve disease management.",0,0
6329,"High WHSC1L1 Expression Reduces Survival Rates in Operated Breast Cancer Patients with Decreased CD8+ T Cells: Machine Learning Approach. Nuclear receptor-binding SET domain protein (NSD), a histone methyltransferase, is known to play an important role in cancer pathogenesis. The WHSC1L1 (Wolf-Hirschhorn syndrome candidate 1-like 1) gene, encoding NSD3, is highly expressed in breast cancer, but its role in the development of breast cancer is still unknown. The purpose of this study was to analyze the survival rates and immune responses of breast cancer patients with high WHSC1L1 expression and to validate the results using gradient boosting machine (GBM) in breast cancer. We investigated the clinicopathologic parameters, proportions of immune cells, pathway networks and in vitro drug responses according to WHSC1L1 expression in 456, 1500 and 776 breast cancer patients from the Hanyang University Guri Hospital, METABRIC and TCGA, respectively. High WHSC1L1 expression was associated with poor prognosis, decreased CD8+ T cells and high CD274 expression (encoding PD-L1). In the pathway networks, WHSC1L1 was indirectly linked to the regulation of the lymphocyte apoptotic process. The GBM model with WHSC1L1 showed improved prognostic performance compared with the model without WHSC1L1. We found that VX-11e, CZC24832, LY2109761, oxaliplatin and erlotinib were effective in inhibiting breast cancer cell lines with high WHSC1L1 expression. High WHSC1L1 expression could play potential roles in the progression of breast cancer and targeting WHSC1L1 could be a potential strategy for the treatment of breast cancer.",0,0
6332,"Building a Cardiovascular Disease Prediction Model for Smartwatch Users Using Machine Learning: Based on the Korea National Health and Nutrition Examination Survey. Smartwatches have the potential to support health care in everyday life by supporting self-monitoring of health conditions and personal activities. This paper aims to develop a model that predicts the prevalence of cardiovascular disease using health-related data that can be easily measured by smartwatch users. To this end, the data corresponding to the health-related data variables provided by the smartwatch are selected from the Korea National Health and Nutrition Examination Survey. To classify the prevalence of cardiovascular disease with these selected variables, we apply logistic regression, artificial neural network, and support vector machine among machine learning classification techniques, and compare the appropriateness of the algorithm through classification performance indicators. The prediction model using support vector machine showed the highest accuracy. Next, we analyze which structures or parameters of the support vector machine contribute to increasing accuracy and derive the importance of input variables. Since it is very important to diagnose cardiovascular disease early correctly, we expect that this model will be very useful if there is a tool to predict whether cardiovascular disease develops or not.",0,0
6347,"A Machine Learning Algorithm for Quantitatively Diagnosing Oxidative Stress Risks in Healthy Adult Individuals Based on Health Space Methodology: A Proof-of-Concept Study Using Korean Cross-Sectional Cohort Data. Oxidative stress aggravates the progression of lifestyle-related chronic diseases. However, knowledge and practices that enable quantifying oxidative stress are still lacking. Here, we performed a proof-of-concept study to predict the oxidative stress status in a healthy population using retrospective cohort data from Boramae medical center in Korea (<i>n</i> = 1328). To obtain binary performance measures, we selected healthy controls versus oxidative disease cases based on the ""health space"" statistical methodology. We then developed a machine learning algorithm for discrimination of oxidative stress status using least absolute shrinkage and selection operator (LASSO)/elastic net regression with 10-fold cross-validation. A proposed fine-tune model included 16 features out of the full spectrum of diverse and complex data. The predictive performance was externally evaluated by generating receiver operating characteristic curves with area under the curve of 0.949 (CI 0.925 to 0.974), sensitivity of 0.923 (CI 0.879 to 0.967), and specificity of 0.855 (CI 0.795 to 0.915). Moreover, the discrimination power was confirmed by applying the proposed diagnostic model to the full dataset consisting of subjects with various degrees of oxidative stress. The results provide a feasible approach for stratifying the oxidative stress risks in the healthy population and selecting appropriate strategies for individual subjects toward implementing data-driven precision nutrition.",0,0
6349,"Modeling and Predicting the Cell Migration Properties from Scratch Wound Healing Assay on Cisplatin-Resistant Ovarian Cancer Cell Lines Using Artificial Neural Network. The study of artificial neural networks (ANN) has undergone a tremendous revolution in recent years, boosted by deep learning tools. The presence of a greater number of learning tools and their applications, in particular, favors this revolution. However, there is a significant need to deal with the issue of implementing a systematic method during the development phase of the ANN to increase its performance. A multilayer feedforward neural network (FNN) was proposed in this paper to predict the cell migration assay on cisplatin-sensitive and cisplatin-resistant (CisR) ovarian cancer (OC) cell lines via scratch wound healing assay. An FNN training algorithm model was generated using the MATLAB fitting function in a MATLAB script to accomplish this task. The input parameters were types of cell lines, times, and wound area, and outputs were relative wound area, percentage of wound closure, and wound healing speed. In addition, we tested and compared the initial accuracy of various supervised learning classifier and support vector regression (SVR) algorithms. The proposed ANN model achieved good agreement with the experimental data and minimized error between the estimated and experimental values. The conclusions drawn demonstrate that the developed ANN model is a useful, accurate, fast, and inexpensive method to predict cancerous cell migration characteristics evaluated via scratch wound healing assay.",0,0
6350,"Clusters of Physical Frailty and Cognitive Impairment and Their Associated Comorbidities in Older Primary Care Patients. (1) Objectives: We aimed to identify clusters of physical frailty and cognitive impairment in a population of older primary care patients and correlate these clusters with their associated comorbidities. (2) Methods: We used a latent class analysis (LCA) as the clustering technique to separate different stages of mild cognitive impairment (MCI) and physical frailty into clusters; the differences were assessed by using a multinomial logistic regression model. (3) Results: Four clusters (latent classes) were identified: (1) highly functional (the mean and SD of the ""frailty"" test 0.58 Â± 0.72 and the Mini-Mental State Examination (MMSE) test 27.42 Â± 1.5), (2) cognitive impairment (0.97 Â± 0.78 and 21.94 Â± 1.95), (3) cognitive frailty (3.48 Â± 1.12 and 19.14 Â± 2.30), and (4) physical frailty (3.61 Â± 0.77 and 24.89 Â± 1.81). (4) Discussion: The comorbidity patterns distinguishing the clusters depend on the degree of development of cardiometabolic disorders in combination with advancing age. The physical frailty phenotype is likely to exist separately from the cognitive frailty phenotype and includes common musculoskeletal diseases.",0,0
6354,"Identification of Neurodegenerative Diseases Based on Vertical Ground Reaction Force Classification Using Time-Frequency Spectrogram and Deep Learning Neural Network Features. A novel identification algorithm using a deep learning approach was developed in this study to classify neurodegenerative diseases (NDDs) based on the vertical ground reaction force (vGRF) signal. The irregularity of NDD vGRF signals caused by gait abnormalities can indicate different force pattern variations compared to a healthy control (HC). The main purpose of this research is to help physicians in the early detection of NDDs, efficient treatment planning, and monitoring of disease progression. The detection algorithm comprises a preprocessing process, a feature transformation process, and a classification process. In the preprocessing process, the five-minute vertical ground reaction force signal was divided into 10, 30, and 60 s successive time windows. In the feature transformation process, the time-domain vGRF signal was modified into a time-frequency spectrogram using a continuous wavelet transform (CWT). Then, feature enhancement with principal component analysis (PCA) was utilized. Finally, a convolutional neural network, as a deep learning classifier, was employed in the classification process of the proposed detection algorithm and evaluated using leave-one-out cross-validation (LOOCV) and <i>k</i>-fold cross-validation (<i>k</i>-fold CV, <i>k</i> = 5). The proposed detection algorithm can effectively differentiate gait patterns based on a time-frequency spectrogram of a vGRF signal between HC subjects and patients with neurodegenerative diseases.",0,0
6355,"Quantitative Evaluation of Task-Induced Neurological Outcome after Stroke. Electroencephalography (EEG) can access ischemic stroke-derived cortical impairment and is believed to be a prospective predictive method for acute stroke prognostics, neurological outcome, and post-stroke rehabilitation management. This study aims to quantify EEG features to understand task-induced neurological declines due to stroke and evaluate the biomarkers to distinguish the ischemic stroke group and the healthy adult group. We investigated forty-eight stroke patients (average age 72.2 years, 62% male) admitted to the rehabilitation center and seventy-five healthy adults (average age 77 years, 31% male) with no history of known neurological diseases. EEG was recorded through frontal, central, temporal, and occipital cortical electrodes (Fz, C1, C2, T7, T8, Oz) using wireless EEG devices and a newly developed data acquisition platform within three months after the appearance of symptoms of ischemic stroke (clinically confirmed). Continuous EEG data were recorded during the consecutive resting, motor (walking and working activities), and cognitive reading tasks. The statistical results showed that alpha, theta, and delta activities are biomarkers classifying the stroke patients and the healthy adults in the motor and cognitive states. DAR and DTR of the stroke group differed significantly from those of the healthy control group during the resting, motor, and cognitive tasks. Using the machine-learning approach, the C5.0 model showed 78% accuracy for the resting state, 89% accuracy in the functional motor walking condition, 84% accuracy in the working condition, and 85% accuracy in the cognitive reading state for classification the stroke group and the control group. This study is expected to be helpful for post-stroke treatment and post-stroke recovery.",0,0
6364,Preoperative Radiomics Approach to Evaluating Tumor-Infiltrating CD8<sup>+</sup> T Cells in Patients With Pancreatic Ductal Adenocarcinoma Using Noncontrast Magnetic Resonance Imaging. CD8<sup>+</sup> T cell in pancreatic ductal adenocarcinoma (PDAC) is closely related to the prognosis and treatment response of patients. Accurate preoperative CD8<sup>+</sup> T-cell expression can better identify the population benefitting from immunotherapy.,0,0
6365,"Angiography-based coronary flow reserve: The feasibility of automatic computation by artificial intelligence. Coronary flow reserve (CFR) has prognostic value in patients with coronary artery disease. However, its measurement is complex, and automatic methods for CFR computation are scarcely available. We developed an automatic method for CFR computation based on coronary angiography and assessed its feasibility.",0,0
6377,"Virtual Patient-Specific Quality Assurance of IMRT Using UNet++: Classification, Gamma Passing Rates Prediction, and Dose Difference Prediction. The dose verification in radiotherapy quality assurance (QA) is time-consuming and places a heavy workload on medical physicists. To provide a clinical tool to perform patient specific QA accurately, the UNet++ is investigated to classify failed or pass fields (the GPR lower than 85% is considered ""failed"" while the GPR higher than 85% is considered ""pass""), predict gamma passing rates (GPR) for different gamma criteria, and predict dose difference from virtual patient-specific quality assurance in radiotherapy. UNet++ was trained and validated with 473 fields and tested with 95 fields. All plans used Portal Dosimetry for dose verification pre-treatment. Planar dose distribution of each field was used as the input for UNet++, with QA classification results, gamma passing rates of different gamma criteria, and dose difference were used as the output. In the test set, the accuracy of the classification model was 95.79%. The mean absolute error (MAE) were 0.82, 0.88, 2.11, 2.52, and the root mean squared error (RMSE) were 1.38, 1.57, 3.33, 3.72 for 3%/3mm, 3%/2Â mm, 2%/3Â mm, 2%/2Â mm, respectively. The trend and position of the predicted dose difference were consistent with the measured dose difference. In conclusion, the Virtual QA based on UNet++ can be used to classify the field passed or not, predict gamma pass rate for different gamma criteria, and predict dose difference. The results show that UNet++ based Virtual QA is promising in quality assurance for radiotherapy.",0,0
6378,"Predicting Tyrosine Kinase Inhibitor Treatment Response in Stage IV Lung Adenocarcinoma Patients With EGFR Mutation Using Model-Based Deep Transfer Learning. For stage IV patients harboring EGFR mutations, there is a differential response to the first-line TKI treatment. We constructed three-dimensional convolutional neural networks (CNN) with deep transfer learning to stratify patients into subgroups with different response and progression risks.",0,0
6380,"Presentation of a Segmentation Method for a Diabetic Retinopathy Patient's Fundus Region Detection Using a Convolutional Neural Network. Diabetic retinopathy is characteristic of a local distribution that involves early-stage risk factors and can forecast the evolution of the illness or morphological lesions related to the abnormality of retinal blood flows. Regional variations in retinal blood flow and modulation of retinal capillary width in the macular area and the retinal environment are also linked to the course of diabetic retinopathy. Despite the fact that diabetic retinopathy is frequent nowadays, it is hard to avoid. An ophthalmologist generally determines the seriousness of the retinopathy of the eye by directly examining color photos and evaluating them by visually inspecting the fundus. It is an expensive process because of the vast number of diabetic patients around the globe. We used the IDRiD data set that contains both typical diabetic retinopathic lesions and normal retinal structures. We provided a CNN architecture for the detection of the target region of 80 patients' fundus imagery. Results demonstrate that the approach described here can nearly detect 83.84% of target locations. This result can potentially be utilized to monitor and regulate patients.",0,0
6384,"Prediction of BRCA Gene Mutation in Breast Cancer Based on Deep Learning and Histopathology Images. Breast cancer is one of the most common cancers and the leading cause of death from cancer among women worldwide. The genetic predisposition to breast cancer may be associated with a mutation in particular genes such as gene BRCA1/2. Patients who carry a germline pathogenic mutation in BRCA1/2 genes have a significantly increased risk of developing breast cancer and might benefit from targeted therapy. However, genetic testing is time consuming and costly. This study aims to predict the risk of gBRCA mutation by using the whole-slide pathology features of breast cancer H&E stains and the patients' gBRCA mutation status.",0,0
6390,"Deep Learning on MRI Images for Diagnosis of Lung Cancer Spinal Bone Metastasis. This paper aimed to explore the adoption of deep learning algorithms in lung cancer spinal bone metastasis diagnosis. Comprehensive analysis was carried out with the aid of AdaBoost algorithm and Chan-Vese (CV) algorithm. 87 patients with lung cancer spinal bone metastasis were taken as research subjects, and comprehensive evaluation was made in terms of preliminary classification of images, segmentation results, Dice index, and Jaccard coefficient. After the case of misjudgment on whether there was hot spot was excluded, the initial classification accuracy of the AdaBoost algorithm can reach 96.55%. True positive rate (TPR) was 2.3%, and false negative rate (FNR) was 1.15%. 45 MRI images with hot spots were utilized as test set to detect the segmentation accuracy of CV, maximum between-cluster variance method (OTSU), and region growing algorithm. The results showed that the Dice index and Jaccard coefficient of the CV algorithm were 0.8591 and 0.8002, respectively, which were considerably superior to OTSU (0.6125 and 0.5541) and region growing algorithm (0.7293 and 0.6598). In summary, the AdaBoost algorithm was adopted for image preliminary classification, and CV algorithm for image segmentation was ideal for the diagnosis of lung cancer spinal bone metastasis and it was worthy of clinical promotion.",0,0
6391,"Early Prediction of COVID-19 Ventilation Requirement and Mortality from Routinely Collected Baseline Chest Radiographs, Laboratory, and Clinical Data with Machine Learning. Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), emerged in Wuhan, China, in late 2019 and created a global pandemic that overwhelmed healthcare systems. COVID-19, as of July 3, 2021, yielded 182 million confirmed cases and 3.9 million deaths globally according to the World Health Organization. Several patients who were initially diagnosed with mild or moderate COVID-19 later deteriorated and were reclassified to severe disease type.",0,0
6392,"Automated segmentation of the optic disc from fundus images using an asymmetric deep learning network. Accurate segmentation of the optic disc (OD) regions from color fundus images is a critical procedure for computer-aided diagnosis of glaucoma. We present a novel deep learning network to automatically identify the OD regions. On the basis of the classical U-Net framework, we define a unique sub-network and a decoding convolutional block. The sub-network is used to preserve important textures and facilitate their detections, while the decoding block is used to improve the contrast of the regions-of-interest with their background. We integrate these two components into the classical U-Net framework to improve the accuracy and reliability of segmenting the OD regions depicted on color fundus images. We train and evaluate the developed network using three publicly available datasets (<i>i.e.</i>, MESSIDOR, ORIGA, and REFUGE). The results on an independent testing set (n=1,970 images) show a segmentation performance with an average Dice similarity coefficient (DSC), intersection over union (IOU), and Matthew's correlation coefficient (MCC) of 0.9377, 0.8854, and 0.9383 when trained on the global field-of-view images, respectively, and 0.9735, 0.9494, and 0.9594 when trained on the local disc region images. When compared with the other three classical networks (<i>i.e.</i>, the U-Net, M-Net, and Deeplabv3) on the same testing datasets, the developed network demonstrates a relatively higher performance.",0,0
6396,"Automated tumor proportion score analysis for PD-L1 (22C3) expression in lung squamous cell carcinoma. Programmed cell death ligend-1 (PD-L1) expression by immunohistochemistry (IHC) assays is a predictive marker of anti-PD-1/PD-L1 therapy response. With the popularity of anti-PD-1/PD-L1 inhibitor drugs, quantitative assessment of PD-L1 expression becomes a new labor for pathologists. Manually counting the PD-L1 positive stained tumor cells is an obviously subjective and time-consuming process. In this paper, we developed a new computer aided Automated Tumor Proportion Scoring System (ATPSS) to determine the comparability of image analysis with pathologist scores. A three-stage process was performed using both image processing and deep learning techniques to mimic the actual diagnostic flow of the pathologists. We conducted a multi-reader multi-case study to evaluate the agreement between pathologists and ATPSS. Fifty-one surgically resected lung squamous cell carcinoma were prepared and stained using the Dako PD-L1 (22C3) assay, and six pathologists with different experience levels were involved in this study. The TPS predicted by the proposed model had high and statistically significant correlation with sub-specialty pathologists' scores with Mean Absolute Error (MAE) of 8.65 (95% confidence interval (CI): 6.42-10.90) and Pearson Correlation Coefficient (PCC) of 0.9436 ([Formula: see text]), and the performance on PD-L1 positive cases achieved by our method surpassed that of non-subspecialty and trainee pathologists. Those experimental results indicate that the proposed automated system can be a powerful tool to improve the PD-L1 TPS assessment of pathologists.",1,1
6408,"Detection of subclinical rheumatic heart disease in children using a deep learning algorithm on digital stethoscope: a study protocol. Rheumatic heart diseases (RHDs) contribute significant morbidity and mortality globally. To reduce the burden of RHD, timely initiation of secondary prophylaxis is important. The objectives of this study are to determine the frequency of subclinical RHD and to train a deep learning (DL) algorithm using waveform data from the digital auscultatory stethoscope (DAS) in predicting subclinical RHD.",0,0
6414,Rapid Exclusion of COVID Infection With the Artificial Intelligence Electrocardiogram. To rapidly exclude severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection using artificial intelligence applied to the electrocardiogram (ECG).,0,0
6417,ACCV: automatic classification algorithm of cataract video based on deep learning. A real-time automatic cataract-grading algorithm based on cataract video is proposed.,0,0
6418,"Computer-aided diagnosis with a convolutional neural network algorithm for automated detection of urinary tract stones on plain X-ray. Recent increased use of medical images induces further burden of their interpretation for physicians. A plain X-ray is a low-cost examination that has low-dose radiation exposure and high availability, although diagnosing urolithiasis using this method is not always easy. Since the advent of a convolutional neural network via deep learning in the 2000s, computer-aided diagnosis (CAD) has had a great impact on automatic image analysis in the urological field. The objective of our study was to develop a CAD system with deep learning architecture to detect urinary tract stones on a plain X-ray and to evaluate the model's accuracy.",0,0
6421,"Present Limitations of Artificial Intelligence in the Emergency Setting - Performance Study of a Commercial, Computer-Aided Detection Algorithm for Pulmonary Embolism. â€‚Since artificial intelligence is transitioning from an experimental stage to clinical implementation, the aim of our study was to evaluate the performance of a commercial, computer-aided detection algorithm of computed tomography pulmonary angiograms regarding the presence of pulmonary embolism in the emergency room.",0,0
6422,"Artificial Intelligence in Chest Radiography Reporting Accuracy: Added Clinical Value in the Emergency Unit Setting Without 24/7 Radiology Coverage. Chest radiographs (CXRs) are commonly performed in emergency units (EUs), but the interpretation requires radiology experience. We developed an artificial intelligence (AI) system (precommercial) that aims to mimic board-certified radiologists' (BCRs') performance and can therefore support non-radiology residents (NRRs) in clinical settings lacking 24/7 radiology coverage. We validated by quantifying the clinical value of our AI system for radiology residents (RRs) and EU-experienced NRRs in a clinically representative EU setting.",1,1
6424,"MuscleNET: mapping electromyography to kinematic and dynamic biomechanical variables by machine learning. <i>Objective.</i>This paper proposes machine learning models for mapping surface electromyography (sEMG) signals to regression of joint angle, joint velocity, joint acceleration, joint torque, and activation torque.<i>Approach.</i>The regression models, collectively known as MuscleNET, take one of four forms: ANN (forward artificial neural network), RNN (recurrent neural network), CNN (convolutional neural network), and RCNN (recurrent convolutional neural network). Inspired by conventional biomechanical muscle models, delayed kinematic signals were used along with sEMG signals as the machine learning model's input; specifically, the CNN and RCNN were modeled with novel configurations for these input conditions. The models' inputs contain either raw or filtered sEMG signals, which allowed evaluation of the filtering capabilities of the models. The models were trained using human experimental data and evaluated with different individual data.<i>Main results.</i>Results were compared in terms of regression error (using the root-mean-square) and model computation delay. The results indicate that the RNN (with filtered sEMG signals) and RCNN (with raw sEMG signals) models, both with delayed kinematic data, can extract underlying motor control information (such as joint activation torque or joint angle) from sEMG signals in pick-and-place tasks. The CNNs and RCNNs were able to filter raw sEMG signals.<i>Significance.</i>All forms of MuscleNET were found to map sEMG signals within 2 ms, fast enough for real-time applications such as the control of exoskeletons or active prostheses. The RNN model with filtered sEMG and delayed kinematic signals is particularly appropriate for applications in musculoskeletal simulation and biomechatronic device control.",0,0
6425,"An end-to-end CNN with attentional mechanism applied to raw EEG in a BCI classification task. <i>Objective.</i>Motor-imagery (MI) classification base on electroencephalography (EEG) has been long studied in neuroscience and more recently widely used in healthcare applications such as mobile assistive robots and neurorehabilitation. In particular, EEG-based MI classification methods that rely on convolutional neural networks (CNNs) have achieved relatively high classification accuracy. However, naively training CNNs to classify raw EEG data from all channels, especially for high-density EEG, is computationally demanding and requires huge training sets. It often also introduces many irrelevant input features, making it difficult for the CNN to extract the informative ones. This problem is compounded by a dearth of training data, which is particularly acute for MI tasks, because these are cognitively demanding and thus fatigue inducing.<i>Approach.</i>To address these issues, we proposed an end-to-end CNN-based neural network with attentional mechanism together with different data augmentation (DA) techniques. We tested it on two benchmark MI datasets, brain-computer interface (BCI) competition IV 2a and 2b. In addition, we collected a new dataset, recorded using high-density EEG, and containing both MI and motor execution (ME) tasks, which we share with the community.<i>Main results.</i>Our proposed neural-network architecture outperformed all state-of-the-art methods that we found in the literature, with and without DA, reaching an average classification accuracy of 93.6% and 87.83% on BCI 2a and 2b, respectively. We also directly compare decoding of MI and ME tasks. Focusing on MI classification, we find optimal channel configurations and the best DA techniques as well as investigate combining data across participants and the role of transfer learning.<i>Significance.</i>Our proposed approach improves the classification accuracy for MI in the benchmark datasets. In addition, collecting our own dataset enables us to compare MI and ME and investigate various aspects of EEG decoding critical for neuroscience and BCI.",0,0
6428,A pipeline to quantify spinal cord atrophy with deep learning: Application to differentiation of MS and NMOSD patients. Quantitative measurement of various anatomical regions of the brain and spinal cord (SC) in MRI images are used as unique biomarkers to consider progress and effects of demyelinating diseases of the central nervous system. This paper presents a fully-automated image processing pipeline which quantifies the SC volume of MRI images.,0,0
6429,"Clustering patients and caregivers for technology design: A step prior to the design of an innovative technological device for the detection of epileptic seizures. Seizure detection using heart rate variability, from a detailed analysis by deep learning analysis system, may help patients with epilepsy to manage their symptoms. This exploratory study aims to identify patient and caregiver groups, according to acceptability factors.",0,0
6430,"Automatic multiclass intramedullary spinal cord tumor segmentation on MRI with deep learning. Spinal cord tumors lead to neurological morbidity and mortality. Being able to obtain morphometric quantification (size, location, growth rate) of the tumor, edema, and cavity can result in improved monitoring and treatment planning. Such quantification requires the segmentation of these structures into three separate classes. However, manual segmentation of three-dimensional structures is time consuming, tedious and prone to intra- and inter-rater variability, motivating the development of automated methods. Here, we tailor a model adapted to the spinal cord tumor segmentation task. Data were obtained from 343 patients using gadolinium-enhanced T1-weighted and T2-weighted MRI scans with cervical, thoracic, and/or lumbar coverage. The dataset includes the three most common intramedullary spinal cord tumor types: astrocytomas, ependymomas, and hemangioblastomas. The proposed approach is a cascaded architecture with U-Net-based models that segments tumors in a two-stage process: locate and label. The model first finds the spinal cord and generates bounding box coordinates. The images are cropped according to this output, leading to a reduced field of view, which mitigates class imbalance. The tumor is then segmented. The segmentation of the tumor, cavity, and edema (as a single class) reached 76.7Â Â±Â 1.5% of Dice score and the segmentation of tumors alone reached 61.8Â Â±Â 4.0% Dice score. The true positive detection rate was above 87% for tumor, edema, and cavity. To the best of our knowledge, this is the first fully automatic deep learning model for spinal cord tumor segmentation. The multiclass segmentation pipeline is available in the Spinal Cord Toolbox (https://spinalcordtoolbox.com/). It can be run with custom data on a regular computer within seconds.",0,0
6435,"Learning-to-augment strategy using noisy and denoised data: Improving generalizability of deep CNN for the detection of COVID-19 in X-ray images. Chest X-ray images are used in deep convolutional neural networks for the detection of COVID-19, the greatest human challenge of the 21st century. Robustness to noise and improvement of generalization are the major challenges in designing these networks. In this paper, we introduce a strategy for data augmentation using the determination of the type and value of noise density to improve the robustness and generalization of deep CNNs for COVID-19 detection. Firstly, we present a learning-to-augment approach that generates new noisy variants of the original image data with optimized noise density. We apply a Bayesian optimization technique to control and choose the optimal noise type and its parameters. Secondly, we propose a novel data augmentation strategy, based on denoised X-ray images, that uses the distance between denoised and original pixels to generate new data. We develop an autoencoder model to create new data using denoised images corrupted by the Gaussian and impulse noise. A database of chest X-ray images, containing COVID-19 positive, healthy, and non-COVID pneumonia cases, is used to fine-tune the pre-trained networks (AlexNet, ShuffleNet, ResNet18, and GoogleNet). The proposed method performs better results compared to the state-of-the-art learning to augment strategies in terms of sensitivity (0.808), specificity (0.915), and F-Measure (0.737). The source code of the proposed method is available at https://github.com/mohamadmomeny/Learning-to-augment-strategy.",0,0
6438,"Differentiation of Active Corneal Infections from Healed Scars Using Deep Learning. To develop and evaluate an automated, portable algorithm to differentiate active corneal ulcers from healed scars using only external photographs.",0,0
6439,"Hippocampal volume reduction is associated with direct measure of insulin resistance in adults. Hippocampal integrity is highly susceptible to metabolic dysfunction, yet its mechanisms are not well defined. We studied 126 healthy individuals aged 23-61 years. Insulin resistance (IR) was quantified by measuring steady-state plasma glucose (SSPG) concentration during the insulin suppression test. Body mass index (BMI), adiposity, fasting insulin, glucose, leptin as well as structural neuroimaing with automatic hippocampal subfield segmentation were performed. Data analysis using unsupervised machine learning (k-means clustering) identified two subgroups reflecting a pattern of more pronounced hippocampal volume reduction being concurrently associated with greater adiposity and insulin resistance; the hippocampal volume reductions were uniform across subfields. Individuals in the most deviant subgroup were predominantly women (79 versus 42 %) with higher BMI [27.9 (2.5) versus 30.5 (4.6) kg/m<sup>2</sup>], IR (SSPG concentration, [156 (61) versus 123 (70) mg/dL] and leptinemia [21.7 (17.0) versus 44.5 (30.4) Î¼g/L]. The use of person-based modeling in healthy individuals suggests that adiposity, insulin resistance and compromised structural hippocampal integrity behave as a composite phenotype; female sex emerged as risk factor for this phenotype.",0,0
6441,"Impact of the clinical use of artificial intelligence-assisted neoplasia detection for colonoscopy: a large-scale prospective, propensity score-matched study (with video). Recently, the use of computer-aided detection (CADe) for colonoscopy has been investigated to improve the adenoma detection rate (ADR). We aimed to assess the efficacy of a regulatory-approved CADe in a large-scale study with high numbers of patients and endoscopists.",1,1
6443,Utilizing deep neural networks and electroencephalogram for objective evaluation of surgeon's distraction during robot-assisted surgery. To develop an algorithm for objective evaluation of distraction of surgeons during robot-assisted surgery (RAS).,0,0
6450,"Automatic detection of vessel structure by deep learning using intravascular ultrasound images of the coronary arteries. Intravascular ultrasound (IVUS) is a diagnostic modality used during percutaneous coronary intervention. However, specialist skills are required to interpret IVUS images. To address this issue, we developed a new artificial intelligence (AI) program that categorizes vessel components, including calcification and stents, seen in IVUS images of complex lesions. When developing our AI using U-Net, IVUS images were taken from patients with angina pectoris and were manually segmented into the following categories: lumen area, medial plus plaque area, calcification, and stent. To evaluate our AI's performance, we calculated the classification accuracy of vessel components in IVUS images of vessels with clinically significantly narrowed lumina (< 4 mm2) and those with severe calcification. Additionally, we assessed the correlation between lumen areas in manually-labeled ground truth images and those in AI-predicted images, the mean intersection over union (IoU) of a test set, and the recall score for detecting stent struts in each IVUS image in which a stent was present in the test set. Among 3738 labeled images, 323 were randomly selected for use as a test set. The remaining 3415 images were used for training. The classification accuracies for vessels with significantly narrowed lumina and those with severe calcification were 0.97 and 0.98, respectively. Additionally, there was a significant correlation in the lumen area between the ground truth images and the predicted images (Ï = 0.97, R2 = 0.97, p < 0.001). However, the mean IoU of the test set was 0.66 and the recall score for detecting stent struts was 0.64. Our AI program accurately classified vessels requiring treatment and vessel components, except for stents in IVUS images of complex lesions. AI may be a powerful tool for assisting in the interpretation of IVUS imaging and could promote the popularization of IVUS-guided percutaneous coronary intervention in a clinical setting.",0,0
6454,"Dual Convolutional Neural Networks for Breast Mass Segmentation and Diagnosis in Mammography. Deep convolutional neural networks (CNNs) have emerged as a new paradigm for Mammogram diagnosis. Contemporary CNN-based computer-aided-diagnosis systems (CADs) for breast cancer directly extract latent features from input mammogram image and ignore the importance of morphological features. In this paper, we introduce a novel end-to-end deep learning framework for mammogram image processing, which computes mass segmentation and simultaneously predicts diagnosis results. Specifically, our method is constructed in a dual-path architecture that solves the mapping in a dual-problem manner, with an additional consideration of important shape and boundary knowledge. One path, called the Locality Preserving Learner (LPL), is devoted to hierarchically extracting and exploiting intrinsic features of the input. Whereas the other path, called the Conditional Graph Learner (CGL), focuses on generating geometrical features via modeling pixel-wise image to mask correlations. By integrating the two learners, both the cancer semantics and cancer representations are well learned, and the component learning paths in return complement each other, contributing an improvement to the mass segmentation and cancer classification problem at the same time. In addition, by integrating an automatic detection set-up, the DualCoreNet achieves fully automatic breast cancer diagnosis practically. Experimental results show that in benchmark DDSM dataset, DualCoreNet has outperformed other related works in both segmentation and classification tasks, achieving 92.27% DI coefficient and 0.85 AUC score. In another benchmark INbreast dataset, DualCoreNet achieves the best mammography segmentation (93.69% DI coefficient) and competitive classification performance (0.93 AUC score).",0,0
6455,"Wearables-Only Analysis of Muscle and Joint Mechanics: An EMG-Driven Approach. Complex sensor arrays prohibit practical deployment of existing wearables-based algorithms for free-living analysis of muscle and joint mechanics. Machine learning techniques have been proposed as a potential solution, however, they are less interpretable and generalizable when compared to physics-based techniques. Herein, we propose a hybrid method utilizing inertial sensor- and electromyography (EMG)-driven simulation of muscle contraction to characterize knee joint and muscle mechanics during walking gait. Machine learning is used only to map a subset of measured muscle excitations to a full set thereby reducing the number of required sensors. We demonstrate the utility of the approach for estimating net knee flexion moment (KFM) as well as individual muscle moment and work during the stance phase of gait across nine unimpaired subjects. Across all subjects, KFM was estimated with 0.91 %BWH RMSE and strong correlations (r = 0.87) compared to ground truth inverse dynamics analysis. Estimates of individual muscle moments were strongly correlated (r = 0.81-0.99) with a reference EMG-driven technique using optical motion capture and a full set of electrodes as were estimates of muscle work (r = 0.88-0.99). Implementation of the proposed technique in the current work included instrumenting only three muscles with surface electrodes (lateral and medial gastrocnemius and vastus medialis) and both the thigh and shank segments with inertial sensors. These sensor locations permit instrumentation of a knee brace/sleeve facilitating a practically deployable mechanism for monitoring muscle and joint mechanics with performance comparable to the current state-of-the-art.",0,0
6464,"Digital twins, artificial intelligence, and machine learning technology to identify a real personalized motion axis of the tibiotalar joint for robotics in total ankle arthroplasty. Axial alignment of the talar implant in total ankle arthroplasty remains a major issue, since the real axis of motion of each patient is impossible to determine with usual techniques. Further knowledge regarding individual axis of motion of the ankle is therefore needed.",0,0
6465,Sensor and machine learning-based assessment of gap balancing in cadaveric unicompartmental knee arthroplasty surgical training. The aim of this study was to assess the difference between flexion and extension contact forces-gap balance-after Oxford mobile-bearing medial unicompartmental knee arthroplasty (UKA) performed by surgeons with varying levels of experience.,1,0
6467,Can AI distinguish a bone radiograph from photos of flowers or cars? Evaluation of bone age deep learning model on inappropriate data inputs. To evaluate the behavior of a publicly available deep convolutional neural network (DCNN) bone age algorithm when presented with inappropriate data inputs in both radiological and non-radiological domains.,0,0
6476,Predicting the Risk of Ischemic Stroke in Patients Treated with Novel Oral Anticoagulants: A Machine Learning Approach. The aim of this cohort study was to estimate the predictors of ischemic stroke in patients treated with non-vitamin K antagonist oral anticoagulants (NOACs) in a large database containing data from general practitioners in Germany using machine learning methods.,0,0
6477,"A Machine Learning Tool Using Digital Microscopy (Morphogo) for the Identification of Abnormal Lymphocytes in the Bone Marrow. Morphological analysis of the bone marrow is an essential step in the diagnosis of hematological disease. The conventional analysis of bone marrow smears is performed under a manual microscope, which is labor-intensive and subject to interobserver variability. The morphological differential diagnosis of abnormal lymphocytes from normal lymphocytes is still challenging. The digital pathology methods integrated with advances in machine learning enable new diagnostic features/algorithms from digital bone marrow cell images in order to optimize classification, thus providing a robust and faster screening diagnostic tool. We have developed a machine learning system, Morphogo, based on algorithms to discriminate abnormal lymphocytes from normal lymphocytes using digital imaging analysis. We retrospectively reviewed 347 cases of bone marrow digital images. Among them, 53 cases had a clinical history and the diagnosis of marrow involvement with lymphoma was confirmed either by morphology or flow cytometry. We split the 53 cases into two groups for training and testing with 43 and 10 cases, respectively. The selected 15,353 cell images were reviewed by pathologists, based on morphological visual appearance, from 43 patients whose diagnosis was confirmed by complementary tests. To expand the range and the precision of recognizing the lymphoid cells in the marrow by automated digital microscopy systems, we developed an algorithm that incorporated color and texture in addition to geometrical cytological features of the variable lymphocyte images which were applied as the training data set. The selected images from the 10 patients were analyzed by the trained artificial intelligence-based recognition system and compared with the final diagnosis rendered by pathologists. The positive predictive value for the identification of the categories of reactive/normal lymphocytes and abnormal lymphoid cells was 99.04%. It seems likely that further training and improvement of the algorithms will facilitate further subclassification of specific lineage subset pathology, e.g., diffuse large B-cell lymphoma from chronic lymphocytic leukemia/small lymphocytic lymphoma, follicular lymphoma, mantle cell lymphoma or even hairy cell leukemia in cases of abnormal malignant lymphocyte classes in the future. This research demonstrated the feasibility of digital pathology and emerging machine learning approaches to automatically diagnose lymphoma cells in the bone marrow based on cytological-histological analyses.",0,0
6478,"Deep learning multimodal fNIRS and EEG signals for bimanual grip force decoding. <i>Objective.</i>Non-invasive brain-machine interfaces (BMIs) offer an alternative, safe and accessible way to interact with the environment. To enable meaningful and stable physical interactions, BMIs need to decode forces. Although previously addressed in the unimanual case, controlling forces from both hands would enable BMI-users to perform a greater range of interactions. We here investigate the decoding of hand-specific forces.<i>Approach.</i>We maximise cortical information by using electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS) and developing a deep-learning architecture with attention and residual layers (<i>cnnatt</i>) to improve their fusion. Our task required participants to generate hand-specific force profiles on which we trained and tested our deep-learning and linear decoders.<i>Main results.</i>The use of EEG and fNIRS improved the decoding of bimanual force and the deep-learning models outperformed the linear model. In both cases, the greatest gain in performance was due to the detection of force generation. In particular, the detection of forces was hand-specific and better for the right dominant hand and<i>cnnatt</i>was better at fusing EEG and fNIRS. Consequently, the study of<i>cnnatt</i>revealed that forces from each hand were differently encoded at the cortical level.<i>Cnnatt</i>also revealed traces of the cortical activity being modulated by the level of force which was not previously found using linear models.<i>Significance.</i>Our results can be applied to avoid hand-cross talk during hand force decoding to improve the robustness of BMI robotic devices. In particular, we improve the fusion of EEG and fNIRS signals and offer hand-specific interpretability of the encoded forces which are valuable during motor rehabilitation assessment.",0,0
6480,"Unsupervised machine learning reveals key immune cell subsets in COVID-19, rhinovirus infection, and cancer therapy. For an emerging disease like COVID-19, systems immunology tools may quickly identify and quantitatively characterize cells associated with disease progression or clinical response. With repeated sampling, immune monitoring creates a real-time portrait of the cells reacting to a novel virus before disease-specific knowledge and tools are established. However, single cell analysis tools can struggle to reveal rare cells that are under 0.1% of the population. Here, the machine learning workflow Tracking Responders EXpanding (T-REX) was created to identify changes in both rare and common cells across human immune monitoring settings. T-REX identified cells with highly similar phenotypes that localized to hotspots of significant change during rhinovirus and SARS-CoV-2 infections. Specialized MHCII tetramer reagents that mark rhinovirus-specific CD4+ cells were left out during analysis and then used to test whether T-REX identified biologically significant cells. T-REX identified rhinovirus-specific CD4+ T cells based on phenotypically homogeneous cells expanding by â‰¥95% following infection. T-REX successfully identified hotspots of virus-specific T cells by comparing infection (day 7) to either pre-infection (day 0) or post-infection (day 28) samples. Plotting the direction and degree of change for each individual donor provided a useful summary view and revealed patterns of immune system behavior across immune monitoring settings. For example, the magnitude and direction of change in some COVID-19 patients was comparable to blast crisis acute myeloid leukemia patients undergoing a complete response to chemotherapy. Other COVID-19 patients instead displayed an immune trajectory like that seen in rhinovirus infection or checkpoint inhibitor therapy for melanoma. The T-REX algorithm thus rapidly identifies and characterizes mechanistically significant cells and places emerging diseases into a systems immunology context for comparison to well-studied immune changes.",0,0
6484,"Predictive Modeling of Colonoscopic Findings in a Fecal Immunochemical Test-Based Colorectal Cancer Screening Program. The fecal immunochemical test (FIT) is the primary modality used by the Los Angeles County Department of Health Services (LADHS) for colorectal cancer (CRC) screening in average-risk patients. Some patients referred for FIT-positive diagnostic colonoscopy have neither adenomas nor more advanced pathology. We aimed to identify predictors of false-positive FIT (FP-FIT) results in our largely disenfranchised, low socioeconomic status population.",0,0
6490,"Development and Validation of a Convolutional Neural Network for Automated Detection of Scaphoid Fractures on Conventional Radiographs. To compare the performance of a convolutional neural network (CNN) to that of 11 radiologists in detecting scaphoid bone fractures on conventional radiographs of the hand, wrist, and scaphoid.",1,1
6491,Impact of Upstream Medical Image Processing on Downstream Performance of a Head CT Triage Neural Network. To develop a convolutional neural network (CNN) to triage head CT (HCT) studies and investigate the effect of upstream medical image processing on the CNN's performance.,0,0
6494,Deep Learning Systems for Pneumothorax Detection on Chest Radiographs: A Multicenter External Validation Study. To assess the generalizability of a deep learning pneumothorax detection model on datasets from multiple external institutions and examine patient and acquisition factors that might influence performance.,0,0
6495,A Deep Learning-based Model for Detecting Abnormalities on Brain MR Images for Triaging: Preliminary Results from a Multisite Experience. To develop a deep learning model for detecting brain abnormalities on MR images.,0,0
6496,"Automated Identification of Orthopedic Implants on Radiographs Using Deep Learning. Accurate identification of metallic orthopedic implant design is important for preoperative planning of revision arthroplasty. Surgical records of implant models are frequently unavailable. The aim of this study was to develop and evaluate a convolutional neural network for identifying orthopedic implant models using radiographs. In this retrospective study, 427 knee and 922 hip unilateral anteroposterior radiographs, including 12 implant models from 650 patients, were collated from an orthopedic center between March 2015 and November 2019 to develop classification networks. A total of 198 images paired with autogenerated image masks were used to develop a U-Net segmentation network to automatically zero-mask around the implants on the radiographs. Classification networks processing original radiographs, and two-channel conjoined original and zero-masked radiographs, were ensembled to provide a consensus prediction. Accuracies of five senior orthopedic specialists assisted by a reference radiographic gallery were compared with network accuracy using McNemar exact test. When evaluated on a balanced unseen dataset of 180 radiographs, the final network achieved a 98.9% accuracy (178 of 180) and 100% top-three accuracy (180 of 180). The network performed superiorly to all five specialists (76.1% [137 of 180] median accuracy and 85.6% [154 of 180] best accuracy; both <i>P</i> < .001), with robustness to scan quality variation and difficult to distinguish implants. A neural network model was developed that outperformed senior orthopedic specialists at identifying implant models on radiographs; real-world application can now be readily realized through training on a broader range of implants and joints, supported by all code and radiographs being made freely available. <i>Supplemental material is available for this article.</i> <b>Keywords:</b> Neural Networks, Skeletal-Appendicular, Knee, Hip, Computer Applications-General (Informatics), Prostheses, Technology Assess-ment, Observer Performance Â© RSNA, 2021.",1,1
6497,"Detection and Semiquantitative Analysis of Cardiomegaly, Pneumothorax, and Pleural Effusion on Chest Radiographs. To develop and evaluate deep learning models for the detection and semiquantitative analysis of cardiomegaly, pneumothorax, and pleural effusion on chest radiographs.",0,0
6498,Classification of Myocardial <sup>18</sup>F-FDG PET Uptake Patterns Using Deep Learning. To perform automated myocardial segmentation and uptake classification from whole-body fluorine 18 fluorodeoxyglucose (FDG) PET.,0,0
6499,Optimizing Deep Learning Algorithms for Segmentation of Acute Infarcts on Non-Contrast Material-enhanced CT Scans of the Brain Using Simulated Lesions. To test the efficacy of lesion segmentation using a deep learning algorithm on non-contrast material-enhanced CT (NCCT) images with synthetic lesions resembling acute infarcts.,0,0
6500,A Deep Learning Approach to Re-create Raw Full-Field Digital Mammograms for Breast Density and Texture Analysis. To develop a computational approach to re-create rarely stored for-processing (raw) digital mammograms from routinely stored for-presentation (processed) mammograms.,0,0
6501,"Evaluation of eye tracking for a decision support application. Eye tracking is used widely to investigate attention and cognitive processes while performing tasks in electronic medical record (EMR) systems. We explored a novel application of eye tracking to collect training data for a machine learning-based clinical decision support tool that predicts which patient data are likely to be relevant for a clinical task. Specifically, we investigated in a laboratory setting the accuracy of eye tracking compared to manual annotation for inferring which patient data in the EMR are judged to be relevant by physicians. We evaluated several methods for processing gaze points that were recorded using a low-cost eye-tracking device. Our results show that eye tracking achieves accuracy and precision of 69% and 53%, respectively compared to manual annotation and are promising for machine learning. The methods for processing gaze points and scripts that we developed offer a first step in developing novel uses for eye tracking for clinical decision support.",0,0
6502,"Machine learning for modeling the progression of Alzheimer disease dementia using clinical data: a systematic literature review. Alzheimer disease (AD) is the most common cause of dementia, a syndrome characterized by cognitive impairment severe enough to interfere with activities of daily life. We aimed to conduct a systematic literature review (SLR) of studies that applied machine learning (ML) methods to clinical data derived from electronic health records in order to model risk for progression of AD dementia.",0,0
6506,"Novel coronavirus pneumonia detection and segmentation based on the deep-learning method. Segmentation of coronavirus disease 2019 (COVID-19) lesions is a difficult task due to high uncertainty in the shape, size and location of the lesions. CT scan image is an important means of diagnosing COVID-19, but it requires doctors to observe a large number of scan images repeatedly to determine the patient's condition. Moreover, the low contrast of CT scan and the presence of tissues such as blood vessels in the background increase the difficulty of diagnosis. To solve this problem, we proposed an improved segmentation model called the residual attention U-shaped network (ResAU-Net).",0,0
6507,"Aortography Keypoint Tracking for Transcatheter Aortic Valve Implantation Based on Multi-Task Learning. Currently, transcatheter aortic valve implantation (TAVI) represents the most efficient treatment option for patients with aortic stenosis, yet its clinical outcomes largely depend on the accuracy of valve positioning that is frequently complicated when routine imaging modalities are applied. Therefore, existing limitations of perioperative imaging underscore the need for the development of novel visual assistance systems enabling accurate procedures. In this paper, we propose an original multi-task learning-based algorithm for tracking the location of anatomical landmarks and labeling critical keypoints on both aortic valve and delivery system during TAVI. In order to optimize the speed and precision of labeling, we designed nine neural networks and then tested them to predict 11 keypoints of interest. These models were based on a variety of neural network architectures, namely MobileNet V2, ResNet V2, Inception V3, Inception ResNet V2 and EfficientNet B5. During training and validation, ResNet V2 and MobileNet V2 architectures showed the best prediction accuracy/time ratio, predicting keypoint labels and coordinates with 97/96% accuracy and 4.7/5.6% mean absolute error, respectively. Our study provides evidence that neural networks with these architectures are capable to perform real-time predictions of aortic valve and delivery system location, thereby contributing to the proper valve positioning during TAVI.",0,0
6508,"BGM-Net: Boundary-Guided Multiscale Network for Breast Lesion Segmentation in Ultrasound. Automatic and accurate segmentation of breast lesion regions from ultrasonography is an essential step for ultrasound-guided diagnosis and treatment. However, developing a desirable segmentation method is very difficult due to strong imaging artifacts e.g., speckle noise, low contrast and intensity inhomogeneity, in breast ultrasound images. To solve this problem, this paper proposes a novel boundary-guided multiscale network (BGM-Net) to boost the performance of breast lesion segmentation from ultrasound images based on the feature pyramid network (FPN). First, we develop a boundary-guided feature enhancement (BGFE) module to enhance the feature map for each FPN layer by learning a boundary map of breast lesion regions. The BGFE module improves the boundary detection capability of the FPN framework so that weak boundaries in ambiguous regions can be correctly identified. Second, we design a multiscale scheme to leverage the information from different image scales in order to tackle ultrasound artifacts. Specifically, we downsample each testing image into a coarse counterpart, and both the testing image and its coarse counterpart are input into BGM-Net to predict a fine and a coarse segmentation maps, respectively. The segmentation result is then produced by fusing the fine and the coarse segmentation maps so that breast lesion regions are accurately segmented from ultrasound images and false detections are effectively removed attributing to boundary feature enhancement and multiscale image information. We validate the performance of the proposed approach on two challenging breast ultrasound datasets, and experimental results demonstrate that our approach outperforms state-of-the-art methods.",0,0
6510,"A Deep Unsupervised Learning Model for Artifact Correction of Pelvis Cone-Beam CT. In recent years, cone-beam computed tomography (CBCT) is increasingly used in adaptive radiation therapy (ART). However, compared with planning computed tomography (PCT), CBCT image has much more noise and imaging artifacts. Therefore, it is necessary to improve the image quality and HU accuracy of CBCT. In this study, we developed an unsupervised deep learning network (CycleGAN) model to calibrate CBCT images for the pelvis to extend potential clinical applications in CBCT-guided ART.",0,0
6511,"Multi-Compartment Spatially-Derived Radiomics From Optical Coherence Tomography Predict Anti-VEGF Treatment Durability in Macular Edema Secondary to Retinal Vascular Disease: Preliminary Findings. Diabetic macular edema (DME) and retinal vein occlusion (RVO) are the leading causes of visual impairments across the world. Vascular endothelial growth factor (VEGF) stimulates breakdown of blood-retinal barrier that causes accumulation of fluid within macula. Anti-VEGF therapy is the first-line treatment for both the diseases; however, the degree of response varies for individual patients. The main objective of this work was to identify the (i) texture-based radiomics features within individual fluid and retinal tissue compartments of baseline spectral-domain optical coherence tomography (SD-OCT) images and (ii) the specific spatial compartments that contribute most pertinent features for predicting therapeutic response.",0,0
6512,"Gaussian process-based kernel as a diagnostic model for prediction of type 2 diabetes mellitus risk using non-linear heart rate variability features. The main objective of the study was to develop a low-cost, non-invasive diagnostic model for the early prediction of T2DM risk and validation of this model on patients. The model was designed based on the machine learning classification technique using non-linear Heart rate variability (HRV) features. The electrocardiogram of the healthy subjects (nâ€‰=â€‰35) and T2DM subjects (nâ€‰=â€‰100) were recorded in the supine position for 15Â min, and HRV features were extracted. The significant non-linear HRV features were identified through statistical analysis. It was found that Poincare plot features (SD1 and SD2) can differentiate the T2DM subject data from healthy subject data. Several machine learning classifiers, such as Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis, NaÃ¯ve Bayes, and Gaussian Process Classifier (GPC), have classified the data based on the cross-validation approach. A GP classifier was implemented using three kernels, namely radial basis, linear, and polynomial kernel, considering the ability to handle the non-linear data. The classifier performance was evaluated and compared using performance metrics such as accuracy(AC), sensitivity(SN), specificity(SP), precision(PR), F1 score, and area under the receiver operating characteristic curve(AUC). Initially, all non-linear HRV features were selected for classification, but the specificity of the model was the limitation. Thus, only two Poincare plot features were used to design the diagnostic model. Our diagnostic model shows the performance using GPC based linear kernel as AC of 92.59%, SN of 96.07%, SP of 81.81%, PR of 94.23%, F1 score of 0.95, and AUC of 0.89, which are more extensive compared to other classification models. Further, the diagnostic model was deployed on the hardware module. Its performance on unknown/test data was validated on 65 subjects (healthy nâ€‰=â€‰15 and T2DM nâ€‰=â€‰50). Considering the desirable performance of the diagnostic model, it can be used as an initial screening test tool for a healthcare practitioner to predict T2DM risk.",0,0
6513,"Synthetic CT generation from weakly paired MR images using cycle-consistent GAN for MR-guided radiotherapy. Although MR-guided radiotherapy (MRgRT) is advancing rapidly, generating accurate synthetic CT (sCT) from MRI is still challenging. Previous approaches using deep neural networks require large dataset of precisely co-registered CT and MRI pairs that are difficult to obtain due to respiration and peristalsis. Here, we propose a method to generate sCT based on deep learning training with weakly paired CT and MR images acquired from an MRgRT system using a cycle-consistent GAN (CycleGAN) framework that allows the unpaired image-to-image translation in abdomen and thorax. Data from 90 cancer patients who underwent MRgRT were retrospectively used. CT images of the patients were aligned to the corresponding MR images using deformable registration, and the deformed CT (dCT) and MRI pairs were used for network training and testing. The 2.5D CycleGAN was constructed to generate sCT from the MRI input. To improve the sCT generation performance, a perceptual loss that explores the discrepancy between high-dimensional representations of images extracted from a well-trained classifier was incorporated into the CycleGAN. The CycleGAN with perceptual loss outperformed the U-net in terms of errors and similarities between sCT and dCT, and dose estimation for treatment planning of thorax, and abdomen. The sCT generated using CycleGAN produced virtually identical dose distribution maps and dose-volume histograms compared to dCT. CycleGAN with perceptual loss outperformed U-net in sCT generation when trained with weakly paired dCT-MRI for MRgRT. The proposed method will be useful to increase the treatment accuracy of MR-only or MR-guided adaptive radiotherapy.",0,0
6515,"Improving convolutional neural networks performance for image classification using test time augmentation: a case study using MURA dataset. Bone fractures are one of the main causes to visit the emergency room (ER); the primary method to detect bone fractures is using X-Ray images. X-Ray images require an experienced radiologist to classify them; however, an experienced radiologist is not always available in the ER. An accurate automatic X-Ray image classifier in the ER can help reduce error rates by providing an instant second opinion to the emergency doctor. Deep learning is an emerging trend in artificial intelligence, where an automatic classifier can be trained to classify musculoskeletal images. Image augmentations techniques have proven their usefulness in increasing the deep learning model's performance. Usually, in the image classification domain, the augmentation techniques are used during training the network and not during the testing phase. Test time augmentation (TTA) can increase the model prediction by providing, with a negligible computational cost, several transformations for the same image. In this paper, we investigated the effect of TTA on image classification performance on the MURA dataset. Nine different augmentation techniques were evaluated to determine their performance compared to predictions without TTA. Two ensemble techniques were assessed as well, the majority vote and the average vote. Based on our results, TTA increased classification performance significantly, especially for models with a low score.",0,0
6518,Prediction of the progression from mild cognitive impairment to Alzheimer's disease using a radiomics-integrated model. This study aimed to build and validate a radiomics-integrated model with whole-brain magnetic resonance imaging (MRI) to predict the progression of mild cognitive impairment (MCI) to Alzheimer's disease (AD).,0,0
6523,"Surface-Based Falff: A Potential Novel Biomarker for Prediction of Radiation Encephalopathy in Patients With Nasopharyngeal Carcinoma. Radiation encephalopathy (RE) is an important potential complication in patients with nasopharyngeal carcinoma (NPC) who undergo radiotherapy (RT) that can affect the quality of life. However, a functional imaging biomarker of pre-symptomatic RE has not yet been established. This study aimed to assess radiation-induced gray matter functional alterations and explore fractional amplitude of low-frequency fluctuation (fALFF) as an imaging biomarker for predicting or diagnosing RE in patients with NPC. A total of 60 patients with NPC were examined, 21 in the pre-RT cohort and 39 in the post-RT cohort. Patients in the post-RT cohort were further divided into two subgroups according to the occurrence of RE in follow-up: post-RT <sub>non-RE</sub> (<i>n</i> = 21) and post-RT <sub>REproved</sub> <sub>infollow-up</sub> (<i>n</i> = 18). Surface-based and volume-based fALFF were used to detect radiation-induced functional alterations. Functional derived features were then adopted to construct a predictive model for the diagnosis of RE. We observed that surface-based fALFF could sensitively detect radiation-induced functional alterations in the intratemporal brain regions (such as the hippocampus and superior temporal gyrus), as well as the extratemporal regions (such as the insula and prefrontal lobe); however, no significant intergroup differences were observed using volume-based fALFF. No significant correlation between fALFF and radiation dose to the ipsilateral temporal lobe was observed. Support vector machine (SVM) analysis revealed that surface-based fALFF in the bilateral superior temporal gyri and left insula exhibited impressive performance (accuracy = 80.49%) in identifying patients likely to develop RE. We conclude that surface-based fALFF may serve as a sensitive imaging biomarker in the prediction of RE.",0,0
6524,"Machine Learning Algorithms are Superior to Conventional Regression Models in Predicting Risk Stratification of COVID-19 Patients. It is very important to determine the risk of patients developing severe or critical COVID-19, but most of the existing risk prediction models are established using conventional regression models. We aim to use machine learning algorithms to develop predictive models and compare predictive performance with logistic regression models.",0,0
6525,"Machine Learning in an Elderly Man with Heart Failure. Machine learning is a branch of artificial intelligence and can be used to predict important outcomes in a wide variety of medical conditions. With the widespread use of electronic medical records, the vast amount of data required for this process is now readily available. The following case demonstrates the application of machine learning to an elderly man with heart failure. The algorithms used, namely, decision tree and random forest, both correctly differentiated heart failure with preserved ejection fraction from heart failure with reduced ejection fraction. This has important treatment and prognostic ramifications and can be completed at the point of care while awaiting confirmation via echocardiogram. Viewing the machine learning process through a patient-centered lens, as in this case, highlights the key role we as physicians have in the implementation and supervision of machine learning.",0,0
6529,"Deep graph neural network-based prediction of acute suicidal ideation in young adults. Precise remote evaluation of both suicide risk and psychiatric disorders is critical for suicide prevention as well as for psychiatric well-being. Using questionnaires is an alternative to labor-intensive diagnostic interviews in a large general population, but previous models for predicting suicide attempts suffered from low sensitivity. We developed and validated a deep graph neural network model that increased the prediction sensitivity of suicide risk in young adults (nâ€‰=â€‰17,482 for training; nâ€‰=â€‰14,238 for testing) using multi-dimensional questionnaires and suicidal ideation within 2Â weeks as the prediction target. The best model achieved a sensitivity of 76.3%, specificity of 83.4%, and an area under curve of 0.878 (95% confidence interval, 0.855-0.899). We demonstrated that multi-dimensional deep features covering depression, anxiety, resilience, self-esteem, and clinico-demographic information contribute to the prediction of suicidal ideation. Our model might be useful for the remote evaluation of suicide risk in the general population of young adults for specific situations such as the COVID-19 pandemic.",0,0
6530,"Development of novel artificial intelligence systems to predict facial morphology after orthognathic surgery and orthodontic treatment in Japanese patients. From a socio-psychological standpoint, improving the morphology of the facial soft-tissues is regarded as an important therapeutic goal in modern orthodontic treatment. Currently, many of the algorithms used in commercially available software programs that are said to provide the function of performing profile prediction are based on the false assumption that the amount of movement of hard-tissue and soft-tissue has a proportional relationship. The specification of the proportionality constant value depends on the operator, and there is little evidence to support the validity of the prediction result. Thus, the present study attempted to develop artificial intelligence (AI) systems that predict the three-dimensional (3-D) facial morphology after orthognathic surgery and orthodontic treatment based on the results of previous treatment. This was a retrospective study in a secondary adult care setting. A total of 137 patients who underwent orthognathic surgery (nâ€‰=â€‰72) and orthodontic treatment with four premolar extraction (nâ€‰=â€‰65) were enrolled. Lateral cephalograms and 3-D facial images were obtained before and after treatment. We have developed two AI systems to predict facial morphology after orthognathic surgery (System S) and orthodontic treatment (System E) using landmark-based geometric morphometric methods together with deep learning methods; where cephalometric changes during treatment and the coordinate values of the faces before treatment were employed as predictive variables. Eleven-fold cross-validation showed that the average system errors were 0.94Â mm and 0.69Â mm for systems S and E, respectively. The total success rates, when success was defined by a system error ofâ€‰<â€‰1Â mm, were 54% and 98% for systems S and E, respectively. The total success rates when success was defined by a system error ofâ€‰<â€‰2Â mm were both 100%. AI systems to predict facial morphology after treatment were therefore confirmed to be clinically acceptable.",0,0
6531,"Real-worldï»¿ artificial intelligence-based opportunistic screening for diabetic retinopathy in endocrinology and indigenous healthcare settings in Australia. This study investigated the diagnostic performance, feasibility, and end-user experiences of an artificial intelligence (AI)-assisted diabetic retinopathy (DR) screening model in real-world Australian healthcare settings. The study consisted of two components: (1) DR screening of patients using an AI-assisted system and (2) in-depth interviews with health professionals involved in implementing screening. Participants with type 1 or type 2 diabetes mellitus attending two endocrinology outpatient and three Aboriginal Medical Services clinics between March 2018 and May 2019 were invited to a prospective observational study. A single 45-degree (macula centred), non-stereoscopic, colour retinal image was taken of each eye from participants and were instantly screened for referable DR using a custom offline automated AI system. A total of 236 participants, including 174 from endocrinology and 62 from Aboriginal Medical Services clinics, provided informed consent and 203 (86.0%) were included in the analysis. A total of 33 consenting participants (14%) were excluded from the primary analysis due to ungradable or missing images from small pupils (n =Â 21, 63.6%), cataract (nÂ = 7, 21.2%), poor fixation (n = 2, 6.1%), technical issues (nÂ = 2, 6.1%),Â and corneal scarring (n = 1, 3%). The area under the curve, sensitivity, and specificity of the AI system for referable DR were 0.92, 96.9% and 87.7%, respectively. There were 51Â disagreements between the reference standard and index test diagnoses, including 29 which were manually graded as ungradable,Â 21Â false positives,Â and oneÂ false negative. A total of 28 participants (11.9%) were referred for follow-up based on new ocular findings, among whom, 15 (53.6%) were able to be contacted and 9 (60%) adhered to referral. Of 207 participants who completed a satisfaction questionnaire, 93.7% specified they were either satisfied or extremely satisfied, and 93.2% specified they would be likely or extremely likely to use this service again. Clinical staff involved in screening most frequently noted that the AI system was easy to use, and the real-time diagnostic report was useful. Our study indicates that AI-assisted DR screening model is accurate and well-accepted by patients and clinicians in endocrinology and indigenous healthcare settings. Future deployments of AI-assisted screening models would require consideration of downstream referral pathways.",1,1
6535,"Development and validation of a deep learning system to classify aetiology and predict anatomical outcomes of macular hole. To develop a deep learning (DL) model for automatic classification of macular hole (MH) aetiology (idiopathic or secondary), and a multimodal deep fusion network (MDFN) model for reliable prediction of MH status (closed or open) at 1â€‰month after vitrectomy and internal limiting membrane peeling (VILMP).",0,0
6541,"Development and validation of a machine-learning ALS survival model lacking vital capacity (VC-Free) for use in clinical trials during the COVID-19 pandemic. <i>Introduction:</i> Vital capacity (VC) is routinely used for ALS clinical trial eligibility determinations, often to exclude patients unlikely to survive trial duration. However, spirometry has been limited by the COVID-19 pandemic. We developed a machine-learning survival model without the use of baseline VC and asked whether it could stratify clinical trial participants and a wider ALS clinic population. <i>Methods</i>. A gradient boosting machine survival model lacking baseline VC (VC-Free) was trained using the PRO-ACT ALS database and compared to a multivariable model that included VC (VCI) and a univariable baseline %VC model (UNI). Discrimination, calibration-in-the-large and calibration slope were quantified. Models were validated using 10-fold internal cross validation, the VITALITY-ALS clinical trial placebo arm and data from the Emory University tertiary care clinic. Simulations were performed using each model to estimate survival of patients predicted to have aâ€‰>â€‰50% one year survival probability. <i>Results</i>. The VC-Free model suffered a minor performance decline compared to the VCI model yet retained strong discrimination for stratifying ALS patients. Both models outperformed the UNI model. The proportion of excluded vs. included patients who died through one year was on average 27% vs. 6% (VCI), 31% vs. 7% (VC-Free), and 13% vs. 10% (UNI). <i>Conclusions</i>. The VC-Free model offers an alternative to the use of VC for eligibility determinations during the COVID-19 pandemic. The observation that the VC-Free model outperforms the use of VC in a broad ALS patient population suggests the use of prognostic strata in future, post-pandemic ALS clinical trial eligibility screening determinations.",0,0
6542,"Estimation of forced vital capacity using speech acoustics in patients with ALS. In this study, we present and provide validation data for a tool that predicts forced vital capacity (FVC) from speech acoustics collected remotely via a mobile app without the need for any additional equipment (e.g. a spirometer). We trained a machine learning model on a sample of healthy participants and participants with amyotrophic lateral sclerosis (ALS) to learn a mapping from speech acoustics to FVC and used this model to predict FVC values in a new sample from a different study of participants with ALS. We further evaluated the cross-sectional accuracy of the model and its sensitivity to within-subject change in FVC. We found that the predicted and observed FVC values in the test sample had a correlation coefficient of .80 and mean absolute error between .54â€‰L and .58â€‰L (18.5% to 19.5%). In addition, we found that the model was able to detect longitudinal decline in FVC in the test sample, although to a lesser extent than the observed FVC values measured using a spirometer, and was highly repeatable (ICC = 0.92-0.94), although to a lesser extent than the actual FVC (ICC = .97). These results suggest that sustained phonation may be a useful surrogate for VC in both research and clinical environments.",0,0
6550,"Coronavirus disease analysis using chest X-ray images and a novel deep convolutional neural network. The recent emergence of a highly infectious and contagious respiratory viral disease known as COVID-19 has vastly impacted human lives and overloaded the health care system. Therefore, it is crucial to develop a fast and accurate diagnostic system for the timely identification of COVID-19 infected patients and thus to help control its spread.",0,0
6553,"Evolution of Deep Learning Algorithms for MRI-Based Brain Tumor Image Segmentation. Brain tumor textures are among the most challenging features for neuroradiologists to extract from magnetic resonance images (MRIs). Exceptionally high-grade tumors such as gliomas require quick and precise diagnosis and medical intervention due to their infiltrative and fast-spreading nature. Therefore, they require computer assistance instead of manual methods. Deep learning (DL) methods are currently on the rise and have become an active field of research in several domains varying from stock market analysis to deep space object detection. They have very promising potential in brain tumor feature extraction from MRIs. Convolutional neural network (CNN) architectures, one of the most influential families of DL algorithms, have undergone a profound transformation since their first successes. This has led to increasing feature extraction quality and algorithm generalizability over various brain tumor types and grades. This review paper presents an explanatory and comparative survey on MRI-based brain tumor image segmentation. First, it provides the survey background and the typical process chain for brain MRI segmentation using CNNs. Second, it details the typical CNN architecture structure and its advantages over other machine learning algorithms. CNN architectures proposed for this purpose are enumerated and classified corresponding to their complexity, and then compared using specific metrics that consider the datasets they use.",0,0
6560,"Learning from Highly Confident Samples for Automatic Knee Osteoarthritis Severity Assessment: Data from the Osteoarthritis Initiative. Knee osteoarthritis (OA) is a chronic disease that considerably reduces patients' life quality. Preventive therapies require early detection and lifetime monitor of OA progression. In the clinical environment, the severity of OA is classified by Kellgren and Lawrence (KL) grading system, ranging from KL-0 to KL-4. Recently, deep learning methods were applied to OA severity assessment to improve the accuracy and efficiency. Researchers fine-tuned convolution neural networks (CNN) on the OA dataset and built end-to-end approaches. However, this task is still challenging due to the ambiguity between adjacent grading, especially in early-stage OA. Low confident samples, which are less representative than the typical ones, undermine the training process. Targeting the uncertainty in the OA dataset, we propose a novel learning scheme that dynamically separates the data into two sets according to their reliability. Besides, we design a hybrid loss function to help CNN learn from the two sets accordingly. With the proposed approach, we emphasize the typical samples and control the impacts of low confident cases. Experiments are conducted in a five-fold manner. Our method achieves a mean accuracy of 70.13\% on the five-class OA assessment task, which outperforms all other start-of-art methods. Despite that early-stage OA detection still benefits from the human intervention of lesion region selection, our approach achieves superior performance on the KL-0 vs. KL-2 task. Moreover, we design an experiment to validate large-scale automatic data refining during training. The result verifies the ability of characterizing low confidence samples by our approach. Dataset used in this paper was obtained from the osteoarthritis Initiative.",0,0
6561,"From online handwriting to synthetic images for Alzheimer's disease detection using a deep transfer learning approach. Early diagnosis of neurodegenerative disorders, such as Alzheimer's Disease (AD), is very important to reduce their effects and to improve both quality and life expectancy of patients. In this context, it is generally agreed that handwriting is one of the first skills altered by the onset of such diseases. For this reason, the analysis of handwriting and the study of its alterations have become of great interest in order to formulate the diagnosis as soon as possible. A fundamental aspect for the use of these techniques is the definition of effective features, which allows the system to distinguish the natural alterations of handwriting due to age, from those caused by neurodegenerative disorders. Starting from these considerations, the aim of our study is to verify whether the combined use of both shape and dynamic features allows a decision support system to improve performance for AD diagnosis. To this purpose, starting from a database of on-line handwriting samples, we generated for each of them an off-line synthetic color image, where the color of each elementary trait encodes, in the three RGB channels, the dynamic information associated with that trait. In order to verify the importance and the specific role played by shape information, we also generated an off-line synthetic binary image for each handwriting sample, where background pixels have white color, while those corresponding to the traits have black color. Finally, we exploited the ability of Convolutional Neural Network (CNN) to automatically extract features on both color and binary images. We carried out a large set of experiments for comparing the results obtained by using on-line features with those obtained by using the off-line features provided by CNN on both color and binary images.",0,0
6565,"Anomalous gait feature classification from 3-D motion capture data. The gait kinematics of an individual is affected by various factors, including age, anthropometry, gender, and disease. Detecting anomalous gait features aids in the diagnosis and treatment of gait-related diseases. The objective of this study was to develop a machine learning method for automatically classifying five anomalous gait features, i.e., toe-out, genu varum, pes planus, hindfoot valgus, and forward head posture features, from three-dimensional data on gait kinematics. Gait data and gait feature labels of 488 subjects were acquired. The orientations of the human body segments during a gait cycle were mapped to a low-dimensional latent gait vector using a variational autoencoder. A two-layer neural network was trained to classify five gait features using logistic regression and calculate an anomalous gait feature vector (AGFV). The proposed network showed balanced accuracies of 82.8% for a toe-out, 85.9% for hindfoot valgus, 80.2% for pes planus, 73.2% for genu varum, and 92.9% for forward head posture when the AGFV was rounded to the nearest zero or 1. Multiple anomalous gait features were detectable using the proposed method, which has a practical advantage over current gait indices, including the gait deviation index with a single value. The overall results confirmed the feasibility of using the proposed method for screening subjects with anomalous gait features using three-dimensional motion capture data.",0,0
6571,"Automatic segmentation of the temporomandibular joint disc on magnetic resonance images using a deep learning technique. The aims of the present study were to construct a deep learning model for automatic segmentation of the temporomandibular joint (TMJ) disc on magnetic resonance (MR) images, and to evaluate the performances using the internal and external test data.",0,0
6572,Automatic segmentation of lung tumors on CT images based on a 2D & 3D hybrid convolutional neural network. A stable and accurate automatic tumor delineation method has been developed to facilitate the intelligent design of lung cancer radiotherapy process. The purpose of this paper is to introduce an automatic tumor segmentation network for lung cancer on CT images based on deep learning.,0,0
6576,"Carotid intima media thickness measurements coupled with stroke severity strongly predict short-term outcome in patients with acute ischemic stroke: a machine learning study. Acute ischemic stroke (IS) is one of the leading causes of morbidity, functional disability and mortality worldwide. The objective was to evaluate IS risk factors and imaging variables as predictors of short-term disability and mortality in IS. Consecutive 106 IS patients were enrolled. We examined the accuracy of IS severity using the National Institutes of Health Stroke Scale (NIHSS), carotid intima-media thickness (cIMT) and carotid stenosis (both assessed using ultrasonography with doppler) predicting IS outcome assessed with the modified Rankin scale (mRS) three months after hospital admission. Poor prognosis (mRSâ€‰â‰¥â€‰3) at three months was predicted by carotid stenosis (â‰¥â€‰50%), type 2 diabetes mellitus and NIHSS with an accuracy of 85.2% (sensitivity: 90.2%; specificity: 81.8%). The mRS score at three months was strongly predicted by NIHSS (Î²â€‰=â€‰0.709, pâ€‰<â€‰0.001). Short-term mortality was strongly predicted using a neural network model with cIMT (â‰¥â€‰1.0Â mm versusâ€‰<â€‰1.0Â mm), NIHSS and age, yielding an area under the receiving operator characteristic curve of 0.977 and an accuracy of 94.7% (sensitivity: 100.0%; specificity: 90.9%). High NIHSS (â‰¥â€‰15) and cIMT (â‰¥â€‰1.0Â mm) increased the probability of dying with hazard ratios of 7.62 and 3.23, respectively. Baseline NIHSS was significantly predicted by the combined effects of age, large artery atherosclerosis stroke, sex, cIMT, body mass index, and smoking. In conclusion, high values of cIMT and NIHSS at admission strongly predict short-term functional impairment as well as mortality three months after IS, underscoring the importance of those measurements to predict clinical IS outcome.",0,0
6582,Performance of a Convolutional Neural Network and Explainability Technique for 12-Lead Electrocardiogram Interpretation. Millions of clinicians rely daily on automated preliminary electrocardiogram (ECG) interpretation. Critical comparisons of machine learning-based automated analysis against clinically accepted standards of care are lacking.,1,1
6585,A Novel Deep Learning System for Diagnosing Early Esophageal Squamous Cell Carcinoma: A Multicenter Diagnostic Study. This study aims to construct a real-time deep convolutional neural networks (DCNNs) system to diagnose early esophageal squamous cell carcinoma (ESCC) with white light imaging endoscopy.,0,0
6589,Prediction of Critical Care Outcome for Adult Patients Presenting to Emergency Department Using Initial Triage Information: An XGBoost Algorithm Analysis. The emergency department (ED) triage system to classify and prioritize patients from high risk to less urgent continues to be a challenge.,0,0
6591,"[Machine learning and suicide prevention: is an algorithm the solution?] Suicide is inherently difficult to predict. Epidemiological research identified many general risk factors such as a depression, but these predictors have limited predictive power. Machine learning offers a set of tools that can combine hundreds of predictors resulting in the most optimal prediction. It might therefore offer a powerful way to predict inherently complex behaviour such as suicide. In a recent study, state of the art ML algorithms where applied to a large Swedish dataset of 126.205 patients treated in psychiatry containing over 400 potential risk factors. Although the presented results such as an area under the curve if 88% sounds promising, many questions on for example the cost of a false negative remain unanswered. In our comment, we critically discuss the presented findings, and bring up some unanswered questions.",0,0
6592,"Weakly supervised learning on unannotated H&E-stained slides predicts BRAF mutation in thyroid cancer with high accuracy. Deep neural networks (DNNs) that predict mutational status from H&E slides of cancers can enable inexpensive and timely precision oncology. Although expert knowledge is reliable for annotating regions informative of malignancy and other known histologic patterns (strong supervision), it is unreliable for identifying regions informative of mutational status. This poses a serious impediment to obtaining higher prognostic accuracy and discovering new knowledge of pathobiology. We used a weakly supervised learning technique to train a DNN to predict BRAF V600E mutational status, determined using DNA testing, in H&E-stained images of thyroid cancer tissue without regional annotations. Our discovery cohort was a tissue microarray of only 85 patients from a single hospital. On a large independent external cohort of 444 patients from other hospitals, the trained model gave an area under the receiver operating characteristic curve ofÂ 0.98 (95% CI 0.97-1.00), which is much higher than the previously reported results for detecting any mutation using H&E by DNNs trained using strong supervision. We also developed a visualization technique that can automatically highlight regions the DNN found most informative for predicting mutational status. Our visualization is spatially granular and highly specific in highlighting strong negative and positive regions and moves us toward explainable artificial intelligence. Using t-tests, we confirmed that the proportions of follicular or papillary histology and oncocytic cytology, as noted for each patient by a pathologist who was blinded to the mutational status, were significantly different between mutated and wildtype patients. However, based solely on these features noted by the pathologist, a logistic regression classifier gave an average area under the receiver operating characteristic curve ofÂ 0.78 in five-fold cross-validation, which is much lower than that obtained using the DNN. These results highlight the potential of weakly supervised learning for training DNN models for problems where the informative visual patterns and their locations are not known a priori. Â© 2021 The Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.",0,0
6598,"Activity detection and classification from wristband accelerometer data collected on people with type 1 diabetes in free-living conditions. This paper introduces methods to estimate aspects of physical activity and sedentary behavior from three-axis accelerometer data collected with a wrist-worn device at a sampling rate of 32 [Hz] on adults with type 1 diabetes (T1D) in free-living conditions. In particular, we present two methods able to detect and grade activity based on its intensity and individual fitness as sedentary, mild, moderate or vigorous, and a method that performs activity classification in a supervised learning framework to predict specific user behaviors. Population results for activity level grading show multi-class average accuracy of 99.99%, precision of 98.0Â Â±Â 2.2%, recall of 97.9Â Â±Â 3.5% and F1 score of 0.9Â Â±Â 0.0. As for the specific behavior prediction, our best performing classifier, gave population multi-class average accuracy of 92.43Â Â±Â 10.32%, precision of 92.94Â Â±Â 9.80%, recall of 92.20Â Â±Â 10.16% and F1 score of 92.56Â Â±Â 9.94%. Our investigation showed that physical activity and sedentary behavior can be detected, graded and classified with good accuracy and precision from three-axial accelerometer data collected in free-living conditions on people with T1D. This is particularly significant in the context of automated glucose control systems for diabetes, in that the methods we propose have the potential to inform changes in treatment parameters in response to the intensity of physical activity, allowing patients to meet their glycemic targets.",0,0
6601,"Brain network excitatory/inhibitory imbalance is a biomarker for drug-naive Rolandic epilepsy: A radiomics strategy. Seizure occurs when the balance between excitatory and inhibitory (E/I) inputs to neurons is perturbed, resulting in abnormal electrical activity. This study investigated whether an existing E/I imbalance in neural networks is a useful diagnostic biomarker for Rolandic epilepsy by a resting-state dynamic causal modeling-based support vector machine (rs-DCM-SVM) algorithm.",0,0
6611,"Personalized prediction of repetitive transcranial magnetic stimulation clinical response in medication-refractory depression data. This article describes a dataset that was generated as part of the article: Personalized prediction of transcranial magnetic stimulation clinical response in patients with treatment-refractory depression using neuroimaging biomarkers and machine learning (DOI: 10.1016/j.jad.2021.04.081). We collected resting-state functional Magnetic Resonance Imaging data from 70 medication-refractory depressed subjects before undergoing four weeks of repetitive transcranial magnetic stimulation targeting the left dorsolateral prefrontal cortex. The data presented here include information about the seed-based analyses such as regions of interest, individual/group functional connectivity maps and contrast maps. The contrast maps are controlled for age, gender, duration of the current depressive episode, duration since the first depressive episode, and symptom scores. Demographics, clinical characteristics, and categorical treatment response variables are reported as well. Further, the individual connectivity values of the identified neuroimaging biomarkers of long-term clinical response were used as features in the support vector machine models are presented in combination with the trained classifiers of the support vector machine models. Post hoc analyses that were not published in the original analyses are presented as well. Finally, the R or MATLAB code scripts for all figures published in the co-submitted paper are included.",0,0
6617,"A novel deep learning based method for COVID-19 detection from CT image. The novel Coronavirus named COVID-19 that World Health Organization (WHO) announced as a pandemic rapidly spread worldwide. Fast diagnosis of the virus infection is critical to prevent further spread of the virus, help identify the infected population, and cure the patients. Due to the increasing rate of infection and the limitations of the diagnosis kit, auxiliary detection tools are needed. Recent studies show that a deep learning model that comes up with the salient information of CT images can aid in the COVID-19 diagnosis. This study proposes a novel deep learning structure that the pooling layer of this model is a combination of pooling and the Squeeze Excitation Block (SE-block) layer. The proposed model uses Batch Normalization and Mish Function to optimize convergence time and performance of COVID-19 diagnosis. A dataset of two public hospitals was used to evaluate the proposed model. Moreover, it was compared to some different popular deep neural networks (DNN). The results expressed an accuracy of 99.03 with a recognition time of test mode of 0.069Â ms in graphics processing unit (GPU). Furthermore, the best network results in classification metrics parameters and real-time applications belong to the proposed model.",0,0
6618,"The Impacts of Subthalamic Nucleus-Deep Brain Stimulation (STN-DBS) on the Neuropsychiatric Function of Patients with Parkinson's Disease Using Image Features of Magnetic Resonance Imaging under the Artificial Intelligence Algorithms. This study was to explore the effect of subthalamic nucleus- (STN-) deep brain stimulation (DBS) on the neuropsychiatric function of Parkinson's disease (PD) patients using the magnetic resonance imaging (MRI) image analysis technology and the artificial intelligence (AI) algorithm. In this study, 40 PD patients admitted to our hospital from August 2018 to March 2020 were selected as the research objects, and they were divided into a control group and an observation group according to the random number table method, with 20 cases in each group. The patients in the control group were given oral treatment with levodopa tablets; and patients in the observation group were treated with STN-DBSâ€‰+â€‰levodopa tablets. In patients, MRI examinations were performed before and after the treatment, and the image optimization processing algorithm under AI was adopted to process the images. The MRI imaging results of the two groups of patients were observed, analyzed, and compared before and after treatment; and the sports, cognition, and mental states of the two groups of patients were analyzed. It was believed that the MRI image before using the AI algorithm was blurry, and the image was clear after the noise reduction optimization process, which was convenient for observation. The data analysis revealed that the signal-to-noise ratio (SNR) after denoising (32.41) and structural similarity (SSIM) (0.79) had been improved. The results of the study suggested that the space occupation and bleeding symptoms of the two groups of patients were reduced after treatment, and those in the observation group were better than those of the control group; the incidences of dyskinesia and motor symptom fluctuations in the observation group were 5% and 0%, respectively, which were lower than those in the control group (35% and 25%, respectively). After treatment, the Unified Parkinson's Disease Rating Scale (UPDRS) score of the two groups of patients decreased, and it was lower in the observation group than in the control group; and the Montreal Cognitive Assessment (MoCA) and Mini-Mental State Scale (MMSE) scores increased, and those in the observation group were higher in contrast to those in the control group (all <i>P</i> < 0.05). STN-DBS was beneficial to improve the clinical symptoms of patients and delay the progress of the disease, and MRI based on AI algorithms can effectively observe the changes in the neuropsychiatric function of patients, which was conducive to further clinical diagnosis and treatment.",0,0
6619,"Diagnosis of COVID-19 and non-COVID-19 patients by classifying only a single cough sound. In the last month of 2019, a new virus emerged in China, spreading rapidly and affecting the whole world. This virus, which is called corona, is the most contagious type of virus that humanity has ever encountered. The virus has caused a huge crisis worldwide as it leads to severe infections and eventually death in humans. On March 11, 2020, it was announced by the World Health Organization that a COVID-19 outbreak has occurred. Computer-aided digital technologies, which eliminate many problems and provide convenience in people's lives, did not leave humanity alone in this regard and rushed to provide a solution for this unfortunate event. One of the important aspects in which computer-aided digital technologies can be effective is the diagnosis of the disease. Reverse transcription-polymerase chain reaction (RT-PCR), which is a standard and precise technique for diagnosing the disease, is an expensive and time-consuming method. Moreover, its availability is not the same all over the world. For this reason, it can be very attractive and important to distinguish the COVID-19 disease from a cold or flu through a cough sound analysis via smartphones which have entered into the lives of many people in recent years. In this study, we proposed a machine learning-based system to distinguish patients with COVID-19 from non-COVID-19 patients by analyzing only a single cough sound. Two different data sets were used, one accessible for the public and the other available on request. After combining the data sets, the features were obtained from the cough sounds using the mel-frequency cepstral coefficients (MFCCs) method, and then, they were classified with seven different machine learning classifiers. To determine the optimum values of hyperparameters for MFCCs and classifiers, the leave-one-out cross-validation (LOO-CV) strategy was implemented. Based on the results, the k-nearest neighbors classifier based on the Euclidean distance (<i>k</i>NN Euclidean) with the accuracy rate, sensitivity of COVID-19, sensitivity of non-COVID-19, F-measure, and area under the ROC curve (AUC) of 0.9833, 1.0000, 0.9720, 0.9799, and 0.9860, respectively, is more successful than other classifiers. Finally, the best and most effective features were determined for each classifier using the sequential forward selection (SFS) method. According to the results, the proposed system is excellent compared with similar studies in the literature and can be easily used in smartphones and facilitate the diagnosis of COVID-19 patients. In addition, since the used data set includes reflex and unconscious coughs, the results showed that conscious or unconscious coughing has no effect on the diagnosis of COVID-19 patients based on the cough sound.",0,0
6620,"Improving effectiveness of different deep learning-based models for detecting COVID-19 from computed tomography (CT) images. COVID-19 has caused a pandemic crisis that threatens the world in many areas, especially in public health. For the diagnosis of COVID-19, computed tomography has a prognostic role in the early diagnosis of COVID-19 as it provides both rapid and accurate results. This is crucial to assist clinicians in making decisions for rapid isolation and appropriate patient treatment. Therefore, many researchers have shown that the accuracy of COVID-19 patient detection from chest CT images using various deep learning systems is extremely optimistic. Deep learning networks such as convolutional neural networks (CNNs) require substantial training data. One of the biggest problems for researchers is accessing a significant amount of training data. In this work, we combine methods such as segmentation, data augmentation and generative adversarial network (GAN) to increase the effectiveness of deep learning models. We propose a method that generates synthetic chest CT images using the GAN method from a limited number of CT images. We test the performance of experiments (with and without GAN) on internal and external dataset. When the CNN is trained on real images and synthetic images, a slight increase in accuracy and other results are observed in the internal dataset, but between <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>3</mn> <mo>%</mo></mrow> </math> and <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mn>9</mn> <mo>%</mo></mrow> </math> in the external dataset. It is promising according to the performance results that the proposed method will accelerate the detection of COVID-19 and lead to more robust systems.",0,0
6624,"Automated detection of retinal exudates and drusen in ultra-widefield fundus images based on deep learning. Retinal exudates and/or drusen (RED) can be signs of many fundus diseases that can lead to irreversible vision loss. Early detection and treatment of these diseases are critical for improving vision prognosis. However, manual RED screening on a large scale is time-consuming and labour-intensive. Here, we aim to develop and assess a deep learning system for automated detection of RED using ultra-widefield fundus (UWF) images.",0,0
6628,"Eye tracking based dyslexia detection using a holistic approach. A new detection method for cognitive impairments is presented utilizing an eye tracking signals in a text reading test. This research enhances published articles that extract combination of various features. It does so by processing entire eye-tracking records either in time or frequency whereas applying only basic signal pre-processing. Such signals were classified as a whole by Convolutional Neural Networks (CNN) that hierarchically extract substantial features scatter either in time or frequency and nonlinearly binds them using machine learning to minimize a detection error. In the experiments we used a 100 fold cross validation and a dataset containing signals of 185 subjects (88 subjects with low risk and 97 subjects with high risk of dyslexia). In a series of experiments it was found that magnitude spectrum based representation of time interpolated eye-tracking signals recorded the best results, i.e. an average accuracy of 96.6% was reached in comparison to 95.6% that is the best published result on the same database. These findings suggest that a holistic approach involving small but complex enough CNNs applied to properly pre-process and expressed signals provides even better results than a combination of meticulously selected well-known features.",0,0
6630,"Development and validation of a new diabetes index for the risk classification of present and new-onset diabetes: multicohort study. In this study, we aimed to propose a novel diabetes index for the risk classification based on machine learning techniques with a high accuracy for diabetes mellitus. Upon analyzing their demographic and biochemical data, we classified the 2013-16 Korea National Health and Nutrition Examination Survey (KNHANES), the 2017-18 KNHANES, and the Korean Genome and Epidemiology StudyÂ (KoGES), as the derivation, internal validation, and external validation sets, respectively. We constructed a new diabetes index using logistic regression (LR) and calculated the probability of diabetes in the validation sets. We used the area under the receiver operating characteristic curve (AUROC) and Cox regression analysis to measure the performance of the internal and external validation sets, respectively. We constructed a gender-specific diabetes prediction model, having a resultant AUROC of 0.93 and 0.94 for men and women, respectively. Based on this probability, we classified participants into five groups and analyzed cumulative incidence from the KoGES dataset. Group 5 demonstrated significantly worse outcomes than those in other groups. Our novel model for predicting diabetes, based on two large-scale population-based cohort studies, showed high sensitivity and selectivity. Therefore, our diabetes index can be used to classify individuals at high risk of diabetes.",0,0
6631,"Imputation of the continuous arterial line blood pressure waveform from non-invasive measurements using deep learning. In two-thirds of intensive care unit (ICU) patients and 90% of surgical patients, arterial blood pressure (ABP) is monitored non-invasively but intermittently using a blood pressure cuff. Since even a few minutes of hypotension increases the risk of mortality and morbidity, for the remaining (high-risk) patients ABP is measured continuously using invasive devices, and derived values are extracted from the recorded waveforms. However, since invasive monitoring is associated with major complications (infection, bleeding, thrombosis), the ideal ABP monitor should be both non-invasive and continuous. With large volumes of high-fidelity physiological waveforms, it may be possible today to impute a physiological waveform from other available signals. Currently, the state-of-the-art approaches for ABP imputation only aim at intermittent systolic and diastolic blood pressure imputation, and there is no method that imputes the continuous ABP waveform. Here, we developed a novel approach to impute the continuous ABP waveform non-invasively using two continuously-monitored waveforms that are currently part of the standard-of-care, the electrocardiogram (ECG) and photo-plethysmogram (PPG), by adapting a deep learning architecture designed for image segmentation. Using over 150,000Â min of data collected at two separate health systems from 463 patients, we demonstrate that our model provides a highly accurate prediction of the continuous ABP waveform (root mean square error 5.823 (95% CI 5.806-5.840) mmHg), as well as the derived systolic (mean difference 2.398â€‰Â±â€‰5.623Â mmHg) and diastolic blood pressure (mean difference -â€‰2.497â€‰Â±â€‰3.785Â mmHg) compared to arterial line measurements. Our approach can potentially be used to measure blood pressure continuously and non-invasively for all patients in the acute care setting, without the need for any additional instrumentation beyond the current standard-of-care.",0,0
6633,"Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer's disease in a cross-sectional multi-cohort study. Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer's disease (nâ€‰=â€‰206) and mild cognitive impairment (nâ€‰=â€‰354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community.",0,0
6634,"Machine learning-based prediction of acute kidney injury after nephrectomy in patients with renal cell carcinoma. The precise prediction of acute kidney injury (AKI) after nephrectomy for renal cell carcinoma (RCC) is an important issue because of its relationship with subsequent kidney dysfunction and high mortality. Herein we addressed whether machine learning (ML) algorithms could predict postoperative AKI risk better than conventional logistic regression (LR) models. A total of 4104 RCC patients who had undergone unilateral nephrectomy from January 2003 to December 2017 were reviewed. ML models such as support vector machine, random forest, extreme gradient boosting, and light gradient boosting machine (LightGBM) were developed, and their performance based on the area under the receiver operating characteristic curve, accuracy, and F1 score was compared with that of the LR-based scoring model. Postoperative AKI developed in 1167 patients (28.4%). All the ML models had higher performance index values than the LR-based scoring model. Among them, the LightGBM model had the highest value of 0.810 (0.783-0.837). The decision curve analysis demonstrated a greater net benefit of the ML models than the LR-based scoring model over all the ranges of threshold probabilities. The application of ML algorithms improves the predictability of AKI after nephrectomy for RCC, and these models perform better than conventional LR-based models.",0,0
6637,"Accuracy of automated machine learning in classifying retinal pathologies from ultra-widefield pseudocolour fundus images. Automated machine learning (AutoML) is a novel tool in artificial intelligence (AI). This study assessed the discriminative performance of AutoML in differentiating retinal vein occlusion (RVO), retinitis pigmentosa (RP) and retinal detachment (RD) from normal fundi using ultra-widefield (UWF) pseudocolour fundus images.",0,0
6641,"Treatment outcome clustering patterns correspond to discrete asthma phenotypes in children. Despite widely and regularly used therapy asthma in children is not fully controlled. Recognizing the complexity of asthma phenotypes and endotypes imposed the concept of precision medicine in asthma treatment. By applying machine learning algorithms assessed with respect to their accuracy in predicting treatment outcome, we have successfully identified 4 distinct clusters in a pediatric asthma cohort with specific treatment outcome patterns according to changes in lung function (FEV<sub>1</sub> and MEF<sub>50</sub>), airway inflammation (FENO) and disease control likely affected by discrete phenotypes at initial disease presentation, differing in the type and level of inflammation, age of onset, comorbidities, certain genetic and other physiologic traits. The smallest and the largest of the 4 clusters- 1 (Nâ€‰=â€‰58) and 3 (Nâ€‰=â€‰138) had better treatment outcomes compared to clusters 2 and 4 and were characterized by more prominent atopic markers and a predominant allelic (A allele) effect for rs37973 in the GLCCI1 gene previously associated with positive treatment outcomes in asthmatics. These patients also had a relatively later onset of disease (6â€‰+â€‰yrs). Clusters 2 (Nâ€‰=â€‰87) and 4 (Nâ€‰=â€‰64) had poorer treatment success, but varied in the type of inflammation (predominantly neutrophilic for cluster 4 and likely mixed-type for cluster 2), comorbidities (obesity for cluster 2), level of systemic inflammation (highest hsCRP for cluster 2) and platelet count (lowest for cluster 4). The results of this study emphasize the issues in asthma management due to the overgeneralized approach to the disease, not taking into account specific disease phenotypes.",0,0
6642,"Genetic syndromes screening by facial recognition technology: VGG-16 screening model construction and evaluation. Many genetic syndromes (GSs) have distinct facial dysmorphism, and facial gestalts can be used as a diagnostic tool for recognizing a syndrome. Facial recognition technology has advanced in recent years, and the screening of GSs by facial recognition technology has become feasible. This study constructed an automatic facial recognition model for the identification of children with GSs.",0,0
6643,"Sch-net: a deep learning architecture for automatic detectionÂ of schizophrenia. Schizophrenia is a chronic and severe mental disease, which largely influences the daily life and work of patients. Clinically, schizophrenia with negative symptoms is usually misdiagnosed. The diagnosis is also dependent on the experience of clinicians. It is urgent to develop an objective and effective method to diagnose schizophrenia with negative symptoms. Recent studies had shown that impaired speech could be considered as an indicator to diagnose schizophrenia. The literature about schizophrenic speech detection was mainly based on feature engineering, in which effective feature extraction is difficult because of the variability of speech signals.",0,0
6650,Machine learning directed interventions associate with decreased hospitalization rates in hemodialysis patients. An integrated kidney disease company uses machine learning (ML) models that predict the 12-month risk of an outpatient hemodialysis (HD) patient having multiple hospitalizations to assist with directing personalized interdisciplinary interventions in a Dialysis Hospitalization Reduction Program (DHRP). We investigated the impact of risk directed interventions in the DHRP on clinic-wide hospitalization rates.,0,0
6654,"Detecting formal thought disorder by deep contextualized word representations. Computational linguistics has enabled the introduction of objective tools that measure some of the symptoms of schizophrenia, including the coherence of speech associated with formal thought disorder (FTD). Our goal was to investigate whether neural network based utterance embeddings are more accurate in detecting FTD than models based on individual indicators. The present research used a comprehensive Embeddings from Language Models (ELMo) approach to represent interviews with patients suffering from schizophrenia (N=35) and with healthy people (N=35). We compared its results to the approach described by Bedi etÂ al. (2015), referred to here as the coherence model. Evaluations were also performed by a clinician using the Scale for the Assessment of Thought, Language and Communication (TLC). Using all six TLC questions the ELMo obtained an accuracy of 80% in distinguishing patients from healthy people. Previously used coherence models were less accurate at 70%. The classifying clinician was accurate 74% of the time. Our analysis shows that both ELMo and TLC are sensitive to the symptoms of disorganization in patients. In this study methods using text representations from language models were more accurate than those based solely on the assessment of FTD, and can be used as measures of disordered language that complement human clinical ratings.",1,1
6655,"CT-based radiomics model with machine learning for predicting primary treatment failure in diffuse large B-cell Lymphoma. Biomarkers which can identify Diffuse Large B-Cell Lymphoma (DLBCL) likely to be refractory to first-line therapy are essential for selecting this population prior to therapy initiation to offer alternate therapeutic options that can improve prognosis. We tested the ability of a CT-based radiomics approach with machine learning to predict Primary Treatment Failure (PTF)-DLBCL from initial imaging evaluation. Twenty-six refractory patients were matched to 26 non-refractory patients, yielding 180 lymph nodes for analysis. Manual 3D delineation of the total node volume was performed by two independent readers to test the reproducibility. Then, 1218 hand-crafted radiomic features were extracted. The Random Forests machine learning approach was used as a classifier for constructing the prediction models. Seventy percent of the nodes were randomly assigned to a training set and the remaining 30% were assigned to an independent test set. The final model was tested on the dataset from the 2 readers, showing a mean accuracy, sensitivity and specificity of 73%, 62% and 82%, respectively, for distinguishing between refractory and non-refractory patients. The area under the receiver operating characteristic curve (AUC) was 0.83 and 0.79 for the two readers. We conclude that machine learning CT-based radiomics analysis is able to identify a priori PTF-DLBCL with a good accuracy.",0,0
6656,"A deep learning approach to quantify auditory hair cells. Hearing loss affects millions of people worldwide. Yet, there are still no curative therapies for sensorineural hearing loss. Frequent causes of sensorineural hearing loss are due to damage or loss of the sensory hair cells, the spiral ganglion neurons, or the synapses between them. Culturing the organ of Corti allows the study of all these structures in an experimental model, which is easy to manipulate. Therefore, the in vitro culture of the neonatal mammalian organ of Corti remains a frequently used experimental system, in which hair cell survival is routinely assessed. However, the analysis of the surviving hair cells is commonly performed via manual counting, which is a time-consuming process and the inter-rater reliability can be an issue. Here, we describe a deep learning approach to quantify hair cell survival in the murine organ of Corti explants. We used StarDist, a publicly available platform and plugin for Fiji (Fiji is just ImageJ), to train and apply our own custom deep learning model. We successfully validated our model in untreated, cisplatin, and gentamicin treated organ of Corti explants. Therefore, deep learning is a valuable approach for quantifying hair cell survival in organ of Corti explants. Moreover, we also demonstrate how the publicly available Fiji plugin StarDist can be efficiently used for this purpose.",0,0
6657,"Deep-gated recurrent unit and diet network-based genome-wide association analysis for detecting the biomarkers of Alzheimer's disease. Genome-wide association analysis (GWAS) is a commonly used method to detect the potential biomarkers of Alzheimer's disease (AD). Most existing GWAS methods entail a high computational cost, disregard correlations among imaging data and correlations among genetic data, and ignore various associations between longitudinal imaging and genetic data. A novel GWAS method was proposed to identify potential AD biomarkers and address these problems. A network based on a gated recurrent unit was applied without imputing incomplete longitudinal imaging data to integrate the longitudinal data of variable lengths and extract an image representation. In this study, a modified diet network that can considerably reduce the number of parameters in the genetic network was proposed to perform GWAS between image representation and genetic data. Genetic representation can be extracted in this way. A link between genetic representation and AD was established to detect potential AD biomarkers. The proposed method was tested on a set of simulated data and a real AD dataset. Results of the simulated data showed that the proposed method can accurately detect relevant biomarkers. Moreover, the results of real AD dataset showed that the proposed method can detect some new risk-related genes of AD. Based on previous reports, no research has incorporated a deep-learning model into a GWAS framework to investigate the potential information on super-high-dimensional genetic data and longitudinal imaging data and create a link between imaging genetics and AD for detecting potential AD biomarkers. Therefore, the proposed method may provide new insights into the underlying pathological mechanism of AD.",0,0
6659,Machine-Learning-Derived Model for the Stratification of Cardiovascular risk in Patients with Ischemic Stroke. Background Stratification of cardiovascular risk in patients with ischemic stroke is important as it may inform management strategies. We aimed to develop a machine-learning-derived prognostic model for the prediction of cardiovascular risk in ischemic stroke patients.,0,0
6664,"Early Alzheimer's disease diagnosis with the contrastive loss using paired structural MRIs. Alzheimer's Disease (AD) is a chronic and fatal neurodegenerative disease with progressive impairment of memory. Brain structural magnetic resonance imaging (sMRI) has been widely applied as important biomarkers of AD. Various machine learning approaches, especially deep learning-based models, have been proposed for the early diagnosis of AD and monitoring the disease progression on sMRI data. However, the requirement for a large number of training images still hinders the extensive usage of AD diagnosis. In addition, due to the similarities in human whole-brain structure, finding the subtle brain changes is essential to extract discriminative features from limited sMRI data effectively.",0,0
6666,"Enhancing P300 based character recognition performance using a combination of ensemble classifiers and a fuzzy fusion method. P300-based brain-computer interfaces provide communication pathways without the need for muscle activity by recognizing electrical signals from the brain. The P300 speller is one of the most commonly used BCI applications, as it is very simple and reliable, and it is capable of reaching satisfactory communication performance. However, as with other BCIs, it remains a challenge to improve the P300 speller's performance to increase its practical usability.",0,0
6668,"A multi-layer model for the early detection of COVID-19. Current COVID-19 screening efforts mainly rely on reported symptoms and the potential exposure to infected individuals. Here, we developed a machine-learning model for COVID-19 detection that uses four layers of information: (i) sociodemographic characteristics of the individual, (ii) spatio-temporal patterns of the disease, (iii) medical condition and general health consumption of the individual and (iv) information reported by the individual during the testing episode. We evaluated our model on 140 682 members of Maccabi Health Services who were tested for COVID-19 at least once between February and October 2020. These individuals underwent, in total, 264 516 COVID-19 PCR tests, out of which 16 512 were positive. Our multi-layer model obtained an area under the curve (AUC) of 81.6% when evaluated over all the individuals in the dataset, and an AUC of 72.8% when only individuals who did not report any symptom were included. Furthermore, considering only information collected before the testing episode-i.e. before the individual had the chance to report on any symptom-our model could reach a considerably high AUC of 79.5%. Our ability to predict early on the outcomes of COVID-19 tests is pivotal for breaking transmission chains, and can be used for a more efficient testing policy.",0,0
6670,"Automatic segmentation of rectal tumor on diffusion-weighted images by deep learning with U-Net. Manual delineation of a rectal tumor on a volumetric image is time-consuming and subjective. Deep learning has been used to segment rectal tumors automatically on T2-weighted images, but automatic segmentation on diffusion-weighted imaging is challenged by noise, artifact, and low resolution. In this study, a volumetric U-shaped neural network (U-Net) is proposed to automatically segment rectal tumors on diffusion-weighted images.",0,0
6674,"Network-guided identification of cancer-selective combinatorial therapies in ovarian cancer. Each patient's cancer consists of multiple cell subpopulations that are inherently heterogeneous and may develop differing phenotypes such as drug sensitivity or resistance. A personalized treatment regimen should therefore target multiple oncoproteins in the cancer cell populations that are driving the treatment resistance or disease progression in a given patient to provide maximal therapeutic effect, while avoiding severe co-inhibition of non-malignant cells that would lead to toxic side effects. To address the intra- and inter-tumoral heterogeneity when designing combinatorial treatment regimens for cancer patients, we have implemented a machine learning-based platform to guide identification of safe and effective combinatorial treatments that selectively inhibit cancer-related dysfunctions or resistance mechanisms in individual patients. In this case study, we show how the platform enables prediction of cancer-selective drug combinations for patients with high-grade serous ovarian cancer using single-cell imaging cytometry drug response assay, combined with genome-wide transcriptomic and genetic profiles. The platform makes use of drug-target interaction networks to prioritize those combinations that warrant further preclinical testing in scarce patient-derived primary cells. During the case study in ovarian cancer patients, we investigated (i) the relative performance of various ensemble learning algorithms for drug response prediction, (ii) the use of matched single-cell RNA-sequencing data to deconvolute cell population-specific transcriptome profiles from bulk RNA-seq data, (iii) and whether multi-patient or patient-specific predictive models lead to better predictive accuracy. The general platform and the comparison results are expected to become useful for future studies that use similar predictive approaches also in other cancer types.",0,0
6685,"Automated delineation of head and neck organs at risk using synthetic MRI-aided mask scoring regional convolutional neural network. Auto-segmentation algorithms offer a potential solution to eliminate the labor-intensive, time-consuming, and observer-dependent manual delineation of organs-at-risk (OARs) in radiotherapy treatment planning. This study aimed to develop a deep learning-based automated OAR delineation method to tackle the current challenges remaining in achieving reliable expert performance with the state-of-the-art auto-delineation algorithms.",0,0
6688,"Artificial Intelligence-Based Prediction of Lung Cancer Risk Using Nonimaging Electronic Medical Records: Deep Learning Approach. Artificial intelligence approaches can integrate complex features and can be used to predict a patient's risk of developing lung cancer, thereby decreasing the need for unnecessary and expensive diagnostic interventions.",0,0
6689,"A Deep Neural Network for Estimating Low-Density Lipoprotein Cholesterol From Electronic Health Records: Real-Time Routine Clinical Application. Previously, we constructed a deep neural network (DNN) model to estimate low-density lipoprotein cholesterol (LDL-C).",0,0
6691,"Deep Learning to Determine the Activity of Pulmonary Tuberculosis on Chest Radiographs. Background Determining the activity of pulmonary tuberculosis on chest radiographs is difficult. Purpose To develop a deep learning model to identify active pulmonary tuberculosis on chest radiographs. Materials and Methods Chest radiographs were retrospectively gathered from a multicenter consecutive cohort with pulmonary tuberculosis who were successfully treated between 2011 and 2017, along with normal radiographs to enrich a negative class. The pretreatment and posttreatment radiographs were labeled as positive and negative classes, respectively. A neural network was trained with those radiographs to calculate the probability of active versus healed tuberculosis. A single-center consecutive cohort (test set 1; 89 patients, 148 radiographs) and data from one multicenter randomized controlled trial (test set 2; 366 patients, 3774 radiographs) were used to test the model. The area under the receiver operating characteristic curve (AUC) was used to evaluate the performance of the model and of the four expert readers. Results In total, 6654 pre- and posttreatment radiographs from 3327 patients (mean age Â± standard deviation, 55 years Â± 19; 1884 men) with pulmonary tuberculosis and 3182 normal radiographs from as many patients (mean age, 53 years Â± 14; 1629 men) were gathered. For test set 1, the model showed a higher AUC (0.83; 95% CI: 0.73, 0.89) than one pulmonologist (0.69; 95% CI: 0.61, 0.76; <i>P</i> < .001) and performed similarly to the other readers (AUC, 0.79-0.80; <i>P</i> = .14-.23). For 200 randomly selected radiographs from test set 2, the model had a higher AUC (0.84) than the pulmonologists (0.71 and 0.74; <i>P</i> < .001 and .01, respectively) and performed similarly to the radiologists (0.79 and 0.80; <i>P</i> = .08 and .06, respectively). The model output increased by 0.30 on average with a higher degree of smear positivity (95% CI: 0.20, 0.39; <i>P</i> < .001) and decreased during treatment (baseline, 3 months, and 6 months: 0.85, 0.51, and 0.26, respectively). Conclusion A deep learning model performed similarly to radiologists for accurately determining the activity of pulmonary tuberculosis on chest radiographs; it also was able to follow posttreatment changes. Â© RSNA, 2021 <i>Online supplemental material is available for this article.</i>",1,1
6697,"Identification of oral precancerous and cancerous tissue by swept source optical coherence tomography. Distinguishing cancer from precancerous lesions is critical and challenging in oral medicine. As a noninvasive method, optical coherence tomography (OCT) has the advantages of real-time, in vivo, and large-depth imaging. Texture information hidden in OCT images can provide an important auxiliary effect for improving diagnostic accuracy. The aim of this study is to explore a reliable and accurate OCT-based method for the screening and diagnosis of human oral diseases, especially oral cancer.",0,0
6699,"A supervised machine learning algorithm predicts intraoperative CSF leak in endoscopic transsphenoidal surgery for pituitary adenomas: model development and prospective validation. Despite advances in endoscopic transnasal transsphenoidal surgery (ETNS) for pituitary adenomas (PAs), cerebrospinal fluid (CSF) leakage remains a life-threatening complication predisposing to major morbidity and mortality. In the current study we developed a supervised ML model able to predict the risk of intraoperative CSF leakage by comparing different machine learning (ML) methods and explaining the functioning and the rationale of the best performing algorithm.",0,0
6702,Development of an artificial intelligence diagnostic system for lower urinary tract dysfunction in men. To establish an artificial intelligence diagnostic system for lower urinary tract function in men with lower urinary tract symptoms using only uroflowmetry data and to evaluate its usefulness.,0,0
6710,"Assessing the predictive accuracy of lung cancer, metastases, and benign lesions using an artificial intelligence-driven computer aided diagnosis system. Artificial intelligence (AI) products have been widely used for the clinical detection of primary lung tumors. However, their performance and accuracy in risk prediction for metastases or benign lesions remain underexplored. This study evaluated the accuracy of an AI-driven commercial computer-aided detection (CAD) product (InferRead CT Lung Research, ICLR) in malignancy risk prediction using a real-world database.",0,0
6716,"The Application of Machine Learning in Predicting Outcome of Cryotherapy and Immunotherapy for Wart Removal. Warts can be extremely painful conditions that may be associated with localised bleeding and discharge. They are commonly treated by cryotherapy or immunotherapy. However, each of these therapies have discomforting side effects and are no official dermatological guideline that exist that may be used to determine which of these methods would work on an individual patient.",0,0
6720,"A deep-learning method using computed tomography scout images for estimating patient body weight. Body weight is an indispensable parameter for determination of contrast medium dose, appropriate drug dosing, or management of radiation dose. However, we cannot always determine the accurate patient body weight at the time of computed tomography (CT) scanning, especially in emergency care. Time-efficient methods to estimate body weight with high accuracy before diagnostic CT scans currently do not exist. In this study, on the basis of 1831 chest and 519 abdominal CT scout images with the corresponding body weights, we developed and evaluated deep-learning models capable of automatically predicting body weight from CT scout images. In the model performance assessment, there were strong correlations between the actual and predicted body weights in both chest (Ïâ€‰=â€‰0.947, pâ€‰<â€‰0.001) and abdominal datasets (Ïâ€‰=â€‰0.869, pâ€‰<â€‰0.001). The mean absolute errors were 2.75Â kg and 4.77Â kg for the chest and abdominal datasets, respectively. Our proposed method with deep learning is useful for estimating body weights from CT scout images with clinically acceptable accuracy and potentially could be useful for determining the contrast medium dose and CT dose management in adult patients with unknown body weight.",0,0
6721,"The incremental value of computed tomography of COVID-19 pneumonia in predicting ICU admission. Triage is crucial for patient's management and estimation of the required intensive care unit (ICU) beds is fundamental for health systems during the COVID-19 pandemic. We assessed whether chest computed tomography (CT) of COVID-19 pneumonia has an incremental role in predicting patient's admission to ICU. We performed volumetric and texture analysis of the areas of the affected lung in CT of 115 outpatients with COVID-19 infection presenting to the emergency room with dyspnea and unresponsive hypoxyemia. Admission blood laboratory including lymphocyte count, serum lactate dehydrogenase, D-dimer and C-reactive protein and the ratio between the arterial partial pressure of oxygen and inspired oxygen were collected. By calculating the areas under the receiver-operating characteristic curves (AUC), we compared the performance of blood laboratory-arterial gas analyses features alone and combined with the CT features in two hybrid models (Hybrid radiological and Hybrid radiomics)for predicting ICU admission. Following a machine learning approach, 63 patients were allocated to the training and 52 to the validation set. Twenty-nine (25%) of patients were admitted to ICU. The Hybrid radiological model comprising the lung %consolidation performed significantly (pâ€‰=â€‰0.04) better in predicting ICU admission in the validation (AUCâ€‰=â€‰0.82; 95% confidence interval 0.73-0.97) set than the blood laboratory-arterial gas analyses features alone (AUCâ€‰=â€‰0.71; 95% confidence interval 0.56-0.86). A risk calculator for ICU admission was derived and is available at: https://github.com/cgplab/covidapp . The volume of the consolidated lung in CT of patients with COVID-19 pneumonia has a mild but significant incremental value in predicting ICU admission.",0,0
6722,"Comparing COVID-19 risk factors in Brazil using machine learning: the importance of socioeconomic, demographic and structural factors. The COVID-19 pandemic continues to have a devastating impact on Brazil. Brazil's social, health and economic crises are aggravated by strong societal inequities and persisting political disarray. This complex scenario motivates careful study of the clinical, socioeconomic, demographic and structural factors contributing to increased risk of mortality from SARS-CoV-2 in Brazil specifically. We consider the Brazilian SIVEP-Gripe catalog, a very rich respiratory infection dataset which allows us to estimate the importance of several non-laboratorial and socio-geographic factors on COVID-19 mortality. We analyze the catalog using machine learning algorithms to account for likely complex interdependence between metrics. The XGBoost algorithm achieved excellent performance, producing an AUC-ROC of 0.813 (95%Â CI 0.810-0.817), and outperforming logistic regression. Using our model we found that, in Brazil, socioeconomic, geographical and structural factors are more important than individual comorbidities. Particularly important factors were: The state of residence and its development index; the distance to the hospital (especially for rural and less developed areas); the level of education; hospital funding model and strain. Ethnicity is also confirmed to be more important than comorbidities but less than the aforementioned factors. In conclusion, socioeconomic and structural factors are as important as biological factors in determining the outcome of COVID-19. This has important consequences for policy making, especially on vaccination/non-pharmacological preventative measures, hospital management and healthcare network organization.",0,0
6723,"A stacking ensemble deep learning approach to cancer type classification based on TCGA data. Cancer tumor classification based on morphological characteristics alone has been shown to have serious limitations. Breast, lung, colorectal, thyroid, and ovarian are the most commonly diagnosed cancers among women. Precise classification of cancers into their types is considered a vital problem for cancer diagnosis and therapy. In this paper, we proposed a stacking ensemble deep learning model based on one-dimensional convolutional neural network (1D-CNN) to perform a multi-class classification on the five common cancers among women based on RNASeq data. The RNASeq gene expression data was downloaded from Pan-Cancer Atlas using GDCquery function of the TCGAbiolinks package in the R software. We used least absolute shrinkage and selection operator (LASSO) as feature selection method. We compared the results of the new proposed model with and without LASSO with the results of the single 1D-CNN and machine learning methods which include support vector machines with radial basis function, linear, and polynomial kernels; artificial neural networks; k-nearest neighbors; bagging trees. The results show that the proposed model with and without LASSO has a better performance compared to other classifiers. Also, the results show that the machine learning methods (SVM-R, SVM-L, SVM-P, ANN, KNN, and bagging trees) with under-sampling have better performance than with over-sampling techniques. This is supported by the statistical significance test of accuracy where the p-values for differences between the SVM-R and SVM-P, SVM-R and ANN, SVM-R and KNN are found to be pâ€‰=â€‰0.003, pâ€‰=â€‰â€‰<â€‰0.001, and pâ€‰=â€‰â€‰<â€‰0.001, respectively. Also, SVM-L had a significant difference compared to ANN pâ€‰=â€‰0.009. Moreover, SVM-P and ANN, SVM-P and KNN are found to be significantly different with p-values pâ€‰=â€‰â€‰<â€‰0.001 and pâ€‰=â€‰â€‰<â€‰0.001, respectively. In addition, ANN and bagging trees, ANN and KNN were found to be significantly different with p-values pâ€‰=â€‰â€‰<â€‰0.001 and pâ€‰=â€‰0.004, respectively. Thus, the proposed model can help in the early detection and diagnosis of cancer in women, and hence aid in designing early treatment strategies to improve survival.",0,0
6726,"Vocal features obtained through automated methods in verbal fluency tasks can aid the identification of mixed episodes in bipolar disorder. There is a lack of consensus on the diagnostic thresholds that could improve the detection accuracy of bipolar mixed episodes in clinical settings. Some studies have shown that voice features could be reliable biomarkers of manic and depressive episodes compared to euthymic states, but none thus far have investigated whether they could aid the distinction between mixed and non-mixed acute bipolar episodes. Here we investigated whether vocal features acquired via verbal fluency tasks could accurately classify mixed states in bipolar disorder using machine learning methods. Fifty-six patients with bipolar disorder were recruited during an acute episode (19 hypomanic, 8 mixed hypomanic, 17 with mixed depression, 12 with depression). Nine different trials belonging to four conditions of verbal fluency tasks-letter, semantic, free word generation, and associational fluency-were administered. Spectral and prosodic features in three conditions were selected for the classification algorithm. Using the leave-one-subject-out (LOSO) strategy to train the classifier, we calculated the accuracy rate, the F1 score, and the Matthews correlation coefficient (MCC). For depression versus mixed depression, the accuracy and F1 scores were high, i.e., respectively 0.83 and 0.86, and the MCC was of 0.64. For hypomania versus mixed hypomania, accuracy and F1 scores were also high, i.e., 0.86 and 0.75, respectively, and the MCC was of 0.57. Given the high rates of correctly classified subjects, vocal features quickly acquired via verbal fluency tasks seem to be reliable biomarkers that could be easily implemented in clinical settings to improve diagnostic accuracy.",0,0
6727,"A machine learning case-control classifier for schizophrenia based on DNA methylation in blood. Epigenetic dysregulation is thought to contribute to the etiology of schizophrenia (SZ), but the cell type-specificity of DNA methylation makes population-based epigenetic studies of SZ challenging. To train an SZ case-control classifier based on DNA methylation in blood, therefore, we focused on human genomic regions of systemic interindividual epigenetic variation (CoRSIVs), a subset of which are represented on the Illumina Human Methylation 450K (HM450) array. HM450 DNA methylation data on whole blood of 414 SZ cases and 433 non-psychiatric controls were used as training data for a classification algorithm with built-in feature selection, sparse partial least squares discriminate analysis (SPLS-DA); application of SPLS-DA to HM450 data has not been previously reported. Using the first two SPLS-DA dimensions we calculated a ""risk distance"" to identify individuals with the highest probability of SZ. The model was then evaluated on an independent HM450 data set on 353 SZ cases and 322 non-psychiatric controls. Our CoRSIV-based model classified 303 individuals as cases with a positive predictive value (PPV) of 80%, far surpassing the performance of a model based on polygenic risk score (PRS). Importantly, risk distance (based on CoRSIV methylation) was not associated with medication use, arguing against reverse causality. Risk distance and PRS were positively correlated (Pearson râ€‰=â€‰0.28, Pâ€‰=â€‰1.28â€‰Ã—â€‰10<sup>-12</sup>), and mediational analysis suggested that genetic effects on SZ are partially mediated by altered methylation at CoRSIVs. Our results indicate two innate dimensions of SZ risk: one based on genetic, and the other on systemic epigenetic variants.",0,0
6728,"Predicting Molecular Phenotypes from Histopathology Images: A Transcriptome-Wide Expression-Morphology Analysis in Breast Cancer. Molecular profiling is central in cancer precision medicine but remains costly and is based on tumor average profiles. Morphologic patterns observable in histopathology sections from tumors are determined by the underlying molecular phenotype and therefore have the potential to be exploited for prediction of molecular phenotypes. We report here the first transcriptome-wide expression-morphology (EMO) analysis in breast cancer, where individual deep convolutional neural networks were optimized and validated for prediction of mRNA expression in 17,695 genes from hematoxylin and eosin-stained whole slide images. Predicted expressions in 9,334 (52.75%) genes were significantly associated with RNA sequencing estimates. We also demonstrated successful prediction of an mRNA-based proliferation score with established clinical value. The results were validated in independent internal and external test datasets. Predicted spatial intratumor variabilities in expression were validated through spatial transcriptomics profiling. These results suggest that EMO provides a cost-efficient and scalable approach to predict both tumor average and intratumor spatial expression from histopathology images. SIGNIFICANCE: Transcriptome-wide expression morphology deep learning analysis enables prediction of mRNA expression and proliferation markers from routine histopathology whole slide images in breast cancer.",0,0
6729,Using the Super Learner algorithm to predict risk of 30-day readmission after bariatric surgery in the United States. Risk prediction models that estimate patient probabilities of adverse events are commonly deployed in bariatric surgery. The objective was to validate a machine learning (Super Learner) prediction model of 30-day readmission after bariatric surgery in comparison with a traditional logistic regression.,0,0
6745,"Prediction of diabetic protein markers based on an ensemble method. <b>Introduction</b>: A diabetic protein marker is a type of protein that is closely related to diabetes. This kind of protein plays an important role in the prevention and diagnosis of diabetes. Therefore, it is necessary to identify an effective method for predicting diabetic protein markers. In this study, we propose using ensemble methods to predict diabetic protein markers. <b>Methodological issues</b>: The ensemble method consists of two aspects. First, we combine a feature extraction method to obtain mixed features. Next, we classify the protein using ensemble classifiers. We use three feature extraction methods in the ensemble method, including composition and physicochemical features (abbreviated as 188D), adaptive skip gram features (abbreviated as 400D) and g-gap (abbreviated as 670D). There are six traditional classifiers in this study: decision tree, Naive Bayes, logistic regression, part, k-nearest neighbor, and kernel logistic regression. The ensemble classifiers are random forest and vote. First, we used feature extraction methods and traditional classifiers to classify protein sequences. Then, we compared the combined feature extraction methods with single methods. Next, we compared ensemble classifiers to traditional classifiers. Finally, we used ensemble classifiers and combined feature extraction methods to predict samples. <b>Results</b>: The results indicated that ensemble methods outperform single methods with respect to either ensemble classifiers or combined feature extraction methods. When the classifier is a random forest and the feature extraction method is 588D (combined 188D and 400D), the performance is best among all methods. The second best ensemble feature extraction method is 1285D (combining the three methods) with random forest. The best single feature extraction method is 188D, and the worst one is g-gap. <b>Conclusion</b>: According to the results, the ensemble method, either the combined feature extraction method or the ensemble classifier, was better than the single method. We anticipate that ensemble methods will be a useful tool for identifying diabetic protein markers in a cost-effective manner.",0,0
6746,"Transfer learning artificial intelligence for automated detection of atrial fibrillation in patients undergoing evaluation for suspected obstructive sleep apnoea: a feasibility study. Individuals with obstructive sleep apnoea (OSA) experience a higher burden of atrial fibrillation (AF) than the general population, and many cases of AF remain undetected. We tested the feasibility of an artificial intelligence (AI) approach to opportunistic detection of AF from single-lead electrocardiograms (ECGs) which are routinely recorded during in-laboratory polysomnographic sleep studies.",0,0
6752,"Quantifying Parkinson's disease motor severity under uncertainty using MDS-UPDRS videos. Parkinson's disease (PD) is a brain disorder that primarily affects motor function, leading to slow movement, tremor, and stiffness, as well as postural instability and difficulty with walking/balance. The severity of PD motor impairments is clinically assessed by part III of the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS), a universally-accepted rating scale. However, experts often disagree on the exact scoring of individuals. In the presence of label noise, training a machine learning model using only scores from a single rater may introduce bias, while training models with multiple noisy ratings is a challenging task due to the inter-rater variabilities. In this paper, we introduce an ordinal focal neural network to estimate the MDS-UPDRS scores from input videos, to leverage the ordinal nature of MDS-UPDRS scores and combat class imbalance. To handle multiple noisy labels per exam, the training of the network is regularized via rater confusion estimation (RCE), which encodes the rating habits and skills of raters via a confusion matrix. We apply our pipeline to estimate MDS-UPDRS test scores from their video recordings including gait (with multiple Raters, R=3) and finger tapping scores (single rater). On a sizable clinical dataset for the gait test (N=55), we obtained a classification accuracy of 72% with majority vote as ground-truth, and an accuracy of âˆ¼84% of our model predicting at least one of the raters' scores. Our work demonstrates how computer-assisted technologies can be used to track patients and their motor impairments, even when there is uncertainty in the clinical ratings. The latest version of the code will be available at https://github.com/mlu355/PD-Motor-Severity-Estimation.",0,0
6755,"Artificial intelligence for classification of temporal lobe epilepsy with ROI-level MRI data: A worldwide ENIGMA-Epilepsy study. Artificial intelligence has recently gained popularity across different medical fields to aid in the detection of diseases based on pathology samples or medical imaging findings. Brain magnetic resonance imaging (MRI) is a key assessment tool for patients with temporal lobe epilepsy (TLE). The role of machine learning and artificial intelligence to increase detection of brain abnormalities in TLE remains inconclusive. We used support vector machine (SV) and deep learning (DL) models based on region of interest (ROI-based) structural (nÂ =Â 336) and diffusion (nÂ =Â 863) brain MRI data from patients with TLE with (""lesional"") and without (""non-lesional"") radiographic features suggestive of underlying hippocampal sclerosis from the multinational (multi-center) ENIGMA-Epilepsy consortium. Our data showed that models to identify TLE performed better or similar (68-75%) compared to models to lateralize the side of TLE (56-73%, except structural-based) based on diffusion data with the opposite pattern seen for structural data (67-75% to diagnose vs. 83% to lateralize). In other aspects, structural and diffusion-based models showed similar classification accuracies. Our classification models for patients with hippocampal sclerosis were more accurate (68-76%) than models that stratified non-lesional patients (53-62%). Overall, SV and DL models performed similarly with several instances in which SV mildly outperformed DL. We discuss the relative performance of these models with ROI-level data and the implications for future applications of machine learning and artificial intelligence in epilepsy care.",0,0
6759,"Multimodal Machine Learning Using Visual Fields and Peripapillary Circular OCT Scans in Detection of Glaucomatous Optic Neuropathy. To develop and validate a multimodal artificial intelligence algorithm, FusionNet, using the pattern deviation probability plots from visual field (VF) reports and circular peripapillary OCT scans to detect glaucomatous optic neuropathy (GON).",0,0
6765,"Machine learning prediction of dropping out of outpatients with alcohol use disorders. Alcohol use disorder (AUD) is a chronic disease with a higher recurrence rate than that of other mental illnesses. Moreover, it requires continuous outpatient treatment for the patient to maintain abstinence. However, with a low probability of these patients to continue outpatient treatment, predicting and managing patients who might discontinue treatment becomes necessary. Accordingly, we developed a machine learning (ML) algorithm to predict which the risk of patients dropping out of outpatient treatment schemes.",0,0
6767,Short- and long-term mortality prediction after an acute ST-elevation myocardial infarction (STEMI) in Asians: A machine learning approach. Conventional risk score for predicting short and long-term mortality following an ST-segment elevation myocardial infarction (STEMI) is often not population specific.,0,0
6768,"VoxelHop: Successive Subspace Learning for ALS Disease Classification Using Structural MRI. Deep learning has great potential for accurate detection and classification of diseases with medical imaging data, but the performance is often limited by the number of training datasets and memory requirements. In addition, many deep learning models are considered a ``black-box,"" thereby often limiting their adoption in clinical applications. To address this, we present a successive subspace learning model, termed VoxelHop, for accurate classification of Amyotrophic Lateral Sclerosis (ALS) using T2-weighted structural MRI data. Compared with popular convolutional neural network (CNN) architectures, VoxelHop has modular and transparent structures with fewer parameters without any backpropagation, so is well-suited to small dataset size and 3D volume data. Our VoxelHop has four key components, including (1) sequential expansion of near-to-far neighborhood for multi-channel 3D data; (2) subspace approximation for unsupervised dimension reduction; (3) label-assisted regression for supervised dimension reduction; and (4) concatenation of features and classification between controls and patients. Our experimental results demonstrate that our framework using a total of 20 controls and 26 patients achieves an accuracy of 93.48 % and an AUC score of 0.9394 in differentiating patients from controls, even with a relatively small number of datasets, showing its robustness and effectiveness. Our thorough evaluations also show its validity and superiority to the state-of-the-art 3D CNN classification methods. Our framework can easily be generalized to other classification tasks using different modalities.",0,0
6776,"Simultaneous brain structure segmentation in magnetic resonance images using deep convolutional neural networks. In brain magnetic resonance imaging (MRI) examinations, rapidly acquired two-dimensional (2D) T1-weighted sagittal slices are typically used to confirm brainstem atrophy and the presence of signals in the posterior pituitary gland. Image segmentation is essential for the automatic evaluation of chronological changes in the brainstem and pituitary gland. Thus, the purpose of our study was to use deep learning to automatically segment internal organs (brainstem, corpus callosum, pituitary, cerebrum, and cerebellum) in midsagittal slices of 2D T1-weighted images. Deep learning for the automatic segmentation of seven regions in the images was accomplished using two different methods: patch-based segmentation and semantic segmentation. The networks used for patch-based segmentation were AlexNet, GoogLeNet, and ResNet50, whereas semantic segmentation was accomplished using SegNet, VGG16-weighted SegNet, and U-Net. The precision and Jaccard index were calculated, and the extraction accuracy of the six convolutional network (DCNN) systems was evaluated. The highest precision (0.974) was obtained with the VGG16-weighted SegNet, and the lowest precision (0.506) was obtained with ResNet50. Based on the data, calculation times, and Jaccard indices obtained in this study, segmentation on a 2D image may be considered a viable and effective approach. We found that the optimal automatic segmentation of organs (brainstem, corpus callosum, pituitary, cerebrum, and cerebellum) on brain sagittal T1-weighted images could be achieved using SegNet with VGG16.",0,0
6777,"Deep Learning Based Capsule Neural Network Model for Breast Cancer Diagnosis Using Mammogram Images. Breast cancer is a commonly occurring disease in women all over the world. Mammogram is an efficient technique used for screening and identification of abnormalities over the breast region. Earlier identification of breast cancer enhances the prognosis of patients and is mainly based on the experience of the radiologist in interpretation of mammogram with quality of image. The advent of Deep Learning (DL) and Computer Vision techniques is widely used to perform breast cancer diagnosis. This paper presents a new Optimal Multi-Level Thresholding-based Segmentation with DL enabled Capsule Network (OMLTS-DLCN) breast cancer diagnosis model utilizing digital mammograms. The OMLTS-DLCN model involves an Adaptive Fuzzy based median filtering (AFF) technique as a pre-processing step to eradicate the noise that exists in the mammogram images. Besides, Optimal Kapur's based Multilevel Thresholding with Shell Game Optimization (SGO) algorithm (OKMT-SGO) is applied for breast cancer segmentation. In addition, the proposed model involves a CapsNet based feature extractor and Back-Propagation Neural Network (BPNN) classification model is employed to detect the existence of breast cancer. The diagnostic outcomes of the presented OMLTS-DLCN technique is examined by means of benchmark Mini-MIAS dataset and DDSM dataset. The experimental values obtained highlights the superior performance of the OMLTS-DLCN model with a higher accuracy of 98.50 and 97.55% on the Mini-MIAS dataset and DDSM dataset, respectively.",0,0
6778,"CAFT: a deep learning-based comprehensive abdominal fat analysis tool for large cohort studies. There is increasing appreciation of the association of obesityÂ beyond co-morbidities, such as cancers, Type 2 diabetes, hypertension, and stroke to also impact upon the muscle to give rise to sarcopenic obesity. Phenotypic knowledge of obesity is crucial for profiling and management of obesity, as different fat-subcutaneous adipose tissue depots (SAT) and visceral adipose tissue depots (VAT) have various degrees of influence on metabolic syndrome and morbidities. Manual segmentation is time consuming and laborious. Study focuses on the development of a deep learning-based, complete data processing pipeline for MRI-based fat analysis, for large cohort studies which include (1) data augmentation and preprocessing (2) model zoo (3) visualization dashboard, and (4) correction tool, for automated quantification of fat compartments SAT and VAT.",0,0
6794,"Pain Intensity Assessment in Sickle Cell Disease Patients Using Vital Signs During Hospital Visits. Pain in sickle cell disease (SCD) is often associated with increased morbidity, mortality, and high healthcare costs. The standard method for predicting the absence, presence, and intensity of pain has long been self-report. However, medical providers struggle to manage patients based on subjective pain reports correctly and pain medications often lead to further difficulties in patient communication as they may cause sedation and sleepiness. Recent studies have shown that objective physiological measures can predict subjective self-reported pain scores for inpatient visits using machine learning (ML) techniques. In this study, we evaluate the generalizability of ML techniques to data collected from 50 patients over an extended period across three types of hospital visits (i.e., inpatient, outpatient and outpatient evaluation). We compare five classification algorithms for various pain intensity levels at both intra-individual (within each patient) and inter-individual (between patients) level. While all the tested classifiers perform much better than chance, a Decision Tree (DT) model performs best at predicting pain on an 11-point severity scale (from 0-10) with an accuracy of 0.728 at an inter-individual level and 0.653 at an intra-individual level. The accuracy of DT significantly improves to 0.941 on a 2-point rating scale (i.e., no/mild pain: 0-5, severe pain: 6-10) at an inter-individual level. Our experimental results demonstrate that ML techniques can provide an objective and quantitative evaluation of pain intensity levels for all three types of hospital visits.",0,0
6796,"A Hybrid Method of Covid-19 Patient Detection from Modified CT-Scan/Chest-X-Ray Images Combining Deep Convolutional Neural Network And Two- Dimensional Empirical Mode Decomposition. The outbreak of the SARS-CoV-2/Covid-19 virus in 2019-2020 has made the world look for fast and accurate detection methods of the disease. The most commonly used tools for detecting Covid patients are Chest-X-ray or Chest-CT-scans of the patient. However, sometimes it's hard for the physicians to diagnose the SARS-CoV-2 infection from the raw image. Moreover, sometimes, deep-learning-based techniques, using raw images, fail to detect the infection. Hence, this paper represents a hybrid method employing both traditional signal processing and deep learning technique for quick detection of SARS-CoV-2 patients based on the CT-scan and Chest-X-ray images of a patient. Unlike the other AI-based methods, here, a CT-scan/Chest-X-ray image is decomposed by two-dimensional Empirical Mode Decomposition (2DEMD), and it generates different orders of Intrinsic Mode Functions (IMFs). Next, The decomposed IMF signals are fed into a deep Convolutional Neural Network (CNN) for feature extraction and classification of Covid patients and Non-Covid patients. The proposed method is validated on three publicly available SARS-CoV-2 data sets using two deep CNN architectures. In all the databases, the modified CT-scan/Chest-X-ray image provides a better result than the raw image in terms of classification accuracy of two fundamental CNNs. This paper represents a new viewpoint of extracting preprocessed features from the raw image using 2DEMD.",0,0
6797,"COVID TV-Unet: Segmenting COVID-19 chest CT images using connectivity imposed Unet. The novel corona-virus disease (COVID-19) pandemic has caused a major outbreak in more than 200 countries around the world, leading to a severe impact on the health and life of many people globally. By October 2020, more than 44 million people were infected, and more than 1,000,000 deaths were reported. Computed Tomography (CT) images can be used as an alternative to the time-consuming RT-PCR test, to detect COVID-19. In this work we propose a segmentation framework to detect chest regions in CT images, which are infected by COVID-19. An architecture similar to a Unet model was employed to detect ground glass regions on a voxel level. As the infected regions tend to form connected components (rather than randomly distributed voxels), a suitable regularization term based on 2D-anisotropic total-variation was developed and added to the loss function. The proposed model is therefore called ""TV-Unet"". Experimental results obtained on a relatively large-scale CT segmentation dataset of around 900 images, incorporating this new regularization term leads to a 2% gain on overall segmentation performance compared to the Unet trained from scratch. Our experimental analysis, ranging from visual evaluation of the predicted segmentation results to quantitative assessment of segmentation performance (precision, recall, Dice score, and mIoU) demonstrated great ability to identify COVID-19 associated regions of the lungs, achieving a mIoU rate of over 99%, and a Dice score of around 86%.",0,0
6801,"Deep Transfer Learning-Based Framework for COVID-19 Diagnosis Using Chest CT Scans and Clinical Information. The Coronavirus Disease 2019 (COVID-19) which first emerged in Wuhan, China in late December, 2019, has now spread to all the countries in the world. Conventional testing methods such as the antigen test, serology tests, and polymerase chain reaction tests are widely used. However, the test results can take anything from a few hours to a few days to reach the patient. Chest CT scan images have been used as alternatives for the detection of COVID-19 infection. Use of CT scan images alone might have limited capabilities, which calls attention to incorporating clinical features. In this paper, deep learning algorithms have been utilized to integrate the chest CT scan images obtained from patients with their clinical characteristics for fast and accurate diagnosis of COVID-19 patients. The framework uses an ANN to obtain the probability of the patient being infected with COVID-19 using their clinical information. Beyond a certain threshold, the chest CT scan of the patient is classified using a deep learning model which has been trained to classify the CT scan with 99% accuracy.",0,0
6802,"DenseNet Convolutional Neural Networks Application for Predicting COVID-19 Using CT Image. Recently, the destructive impact of Coronavirus 2019, commonly known as COVID-19, has affected public health and human lives. This catastrophic effect disrupted human experience by introducing an exponentially more damaging unpredictable health crisis since the Second World War (Kursumovic et al. in Anaesthesia 75: 989-992, 2020). Strong communicable characteristics of COVID-19 within human communities make the world's crisis a severe pandemic. Due to the unavailable vaccine of COVID-19 to control rather than cure, early and accurate detection of the virus can be a promising technique for tracking and preventing the infection from spreading (e.g., by isolating the patients). This situation indicates improving the auxiliary COVID-19 detection technique. Computed tomography (CT) imaging is a widely used technique for pneumonia because of its expected availability. The artificial intelligence-aided images analysis might be a promising alternative for identifying COVID-19. This paper presents a promising technique of predicting COVID-19 patients from the CT image using convolutional neural networks (CNN). The novel approach is based on the most recent modified CNN architecture (DenseNet-121) to predict COVID-19. The results outperformed 92% accuracy, with a 95% recall showing acceptable performance for the prediction of COVID-19.",0,0
6803,"Towards data-driven stroke rehabilitation via wearable sensors and deep learning. Recovery after stroke is often incomplete, but rehabilitation training may potentiate recovery by engaging endogenous neuroplasticity. In preclinical models of stroke, high doses of rehabilitation training are required to restore functional movement to the affected limbs of animals. In humans, however, the necessary dose of training to potentiate recovery is not known. This ignorance stems from the lack of objective, pragmatic approaches for measuring training doses in rehabilitation activities. Here, to develop a measurement approach, we took the critical first step of automatically identifying functional primitives, the basic building block of activities. Forty-eight individuals with chronic stroke performed a variety of rehabilitation activities while wearing inertial measurement units (IMUs) to capture upper body motion. Primitives were identified by human labelers, who labeled and segmented the associated IMU data. We performed automatic classification of these primitives using machine learning. We designed a convolutional neural network model that outperformed existing methods. The model includes an initial module to compute separate embeddings of different physical quantities in the sensor data. In addition, it replaces batch normalization (which performs normalization based on statistics computed from the training data) with instance normalization (which uses statistics computed from the test data). This increases robustness to possible distributional shifts when applying the method to new patients. With this approach, we attained an average classification accuracy of 70%. Thus, using a combination of IMU-based motion capture and deep learning, we were able to identify primitives automatically. This approach builds towards objectively-measured rehabilitation training, enabling the identification and counting of functional primitives that accrues to a training dose.",0,0
6807,"An Integrated Deep Network for Cancer Survival Prediction Using Omics Data. As a highly sophisticated disease that humanity faces, cancer is known to be associated with dysregulation of cellular mechanisms in different levels, which demands novel paradigms to capture informative features from different omics modalities in an integrated way. Successful stratification of patients with respect to their molecular profiles is a key step in precision medicine and in tailoring personalized treatment for critically ill patients. In this article, we use an integrated deep belief network to differentiate high-risk cancer patients from the low-risk ones in terms of the overall survival. Our study analyzes RNA, miRNA, and methylation molecular data modalities from both labeled and unlabeled samples to predict cancer survival and subsequently to provide risk stratification. To assess the robustness of our novel integrative analytics, we utilize datasets of three cancer types with 836 patients and show that our approach outperforms the most successful supervised and semi-supervised classification techniques applied to the same cancer prediction problems. In addition, despite the preconception that deep learning techniques require large size datasets for proper training, we have illustrated that our model can achieve better results for moderately sized cancer datasets.",0,0
6808,"Lung Cancer Segmentation With Transfer Learning: Usefulness of a Pretrained Model Constructed From an Artificial Dataset Generated Using a Generative Adversarial Network. <b>Purpose:</b> The purpose of this study was to develop and evaluate lung cancer segmentation with a pretrained model and transfer learning. The pretrained model was constructed from an artificial dataset generated using a generative adversarial network (GAN). <b>Materials and Methods:</b> Three public datasets containing images of lung nodules/lung cancers were used: LUNA16 dataset, Decathlon lung dataset, and NSCLC radiogenomics. The LUNA16 dataset was used to generate an artificial dataset for lung cancer segmentation with the help of the GAN and 3D graph cut. Pretrained models were then constructed from the artificial dataset. Subsequently, the main segmentation model was constructed from the pretrained models and the Decathlon lung dataset. Finally, the NSCLC radiogenomics dataset was used to evaluate the main segmentation model. The Dice similarity coefficient (DSC) was used as a metric to evaluate the segmentation performance. <b>Results:</b> The mean DSC for the NSCLC radiogenomics dataset improved overall when using the pretrained models. At maximum, the mean DSC was 0.09 higher with the pretrained model than that without it. <b>Conclusion:</b> The proposed method comprising an artificial dataset and a pretrained model can improve lung cancer segmentation as confirmed in terms of the DSC metric. Moreover, the construction of the artificial dataset for the segmentation using the GAN and 3D graph cut was found to be feasible.",0,0
6816,Keratoconus detection of changes using deep learning of colour-coded maps. To evaluate the accuracy of convolutional neural networks technique (CNN) in detecting keratoconus using colour-coded corneal maps obtained by a Scheimpflug camera.,0,0
6817,"Robust chest CT image segmentation of COVID-19 lung infection based on limited data. The coronavirus disease 2019 (COVID-19) affects billions of lives around the world and has a significant impact on public healthcare. For quantitative assessment and disease monitoring medical imaging like computed tomography offers great potential as alternative to RT-PCR methods. For this reason, automated image segmentation is highly desired as clinical decision support. However, publicly available COVID-19 imaging data is limited which leads to overfitting of traditional approaches.",0,0
6827,"Precision Medicine Enables More TNM-Like Staging in Patients With Chronic Limb Threatening Ischemia. <b>Introduction:</b> In cancer, there are survival-based staging systems and tailored, stage-based treatments. There is little personalized treatment in vascular disease. The 2019 Global Vascular Guidelines on the Management of CLTI proposed successful treatment hinges upon Patient risk, Limb severity, and ANatomic complexity (PLAN). We sought to confirm a three axis approach and define how increasing severity affects mortality, not just limb loss. <b>Methods:</b> Patients revascularized for incident CLTI at our institution from 2013 to 2017 were included. Outcomes were mortality, limb loss, the composite endpoint of amputation-free survival. Using Bayesian machine learning, specifically supervised topic modeling, clusters of patient features associated with mortality were formed after controlling for revascularization type. Patients were assigned to the cluster they belonged to with highest probability; clusters were characterized by analyzing the characteristics of patients within them. Patient outcomes were used to order the clusters into stages with increasing mortality. <b>Results:</b> We defined three distinct clusters as the basis for patient- and limb-centered stages. Across stages, rates of 1-year mortality were 7.6, 13.8, 18.9% and rates of amputation-free survival were 84.8, 79.3, and 63.2%. Stage one had patients with rest pain and previous revascularization who were less likely to have wounds, diabetes, and renal disease. Stage two had doubled mortality, likely related to diabetes prevalence. Stage three is characterized by high rates of complicated comorbidities, particularly end stage renal disease, and significantly higher rate of limb loss (22.6 vs. 8% in stages one and two). <b>Conclusion:</b> Using precision medicine, we have demonstrated clustering of CLTI patients that can be used toward a robust staging system. We provide empiric evidence for PLAN and detail about how changes in each variable affect survival and amputation-free survival.",0,0
6829,"Artificial Intelligence-Aided Recognition of Pathological Characteristics and Subtype Classification of Superficial Perivascular Dermatitis. <b>Background:</b> Superficial perivascular dermatitis, an important type of inflammatory dermatosis, comprises various skin diseases, which are difficult to distinguish by clinical manifestations and need pathological imaging observation. Coupled with its complex pathological characteristics, the subtype classification depends to a great extent on dermatopathologists. There is an urgent need to develop an efficient approach to recognize the pathological characteristics and classify the subtypes of superficial perivascular dermatitis. <b>Methods:</b> 3,954 pathological images (4 Ã— and 10 Ã—) of three subtypes-psoriasiform, spongiotic and interface-of superficial perivascular dermatitis were captured from 327 cases diagnosed both clinically and pathologically. The control group comprised 1,337 pathological images of 85 normal skin tissue slides taken from the edge of benign epidermal cysts. First, senior dermatologists and dermatopathologists followed the structure-pattern analysis method to label the pathological characteristics that significantly contribute to classifying different subtypes on 4 Ã— and 10 Ã— images. A cascaded deep learning algorithm framework was then proposed to establish pixel-level pathological characteristics' masks and classify the subtypes by supervised learning. <b>Results:</b> 13 different pathological characteristics were recognized, and the accuracy of subtype classification was 85.24%. In contrast, the accuracy of the subtype classification model without recognition was 71.35%. <b>Conclusion:</b> Our cascaded deep learning model used small samples to deliver efficient recognition of pathological characteristics and subtype classification simultaneously. Moreover, the proposed method could be applied to both microscopic images and digital scanned images.",0,0
6830,"Routine Hematological Parameters May Be Predictors of COVID-19 Severity. To date, coronavirus disease 2019 (COVID-19) has affected over 100 million people globally. COVID-19 can present with a variety of different symptoms leading to manifestation of disease ranging from mild cases to a life-threatening condition requiring critical care-level support. At present, a rapid prediction of disease severity and critical care requirement in COVID-19 patients, in early stages of disease, remains an unmet challenge. Therefore, we assessed whether parameters from a routine clinical hematology workup, at the time of hospital admission, can be valuable predictors of COVID-19 severity and the requirement for critical care. Hematological data from the day of hospital admission (day of positive COVID-19 test) for patients with severe COVID-19 disease (requiring critical care during illness) and patients with non-severe disease (not requiring critical care) were acquired. The data were amalgamated and cleaned and modeling was performed. Using a decision tree model, we demonstrated that routine clinical hematology parameters are important predictors of COVID-19 severity. This proof-of-concept study shows that a combination of activated partial thromboplastin time, white cell count-to-neutrophil ratio, and platelet count can predict subsequent severity of COVID-19 with high sensitivity and specificity (area under ROC 0.9956) at the time of the patient's hospital admission. These data, pending further validation, indicate that a decision tree model with hematological parameters could potentially form the basis for a rapid risk stratification tool that predicts COVID-19 severity in hospitalized patients.",0,0
6834,"MBFFNet: Multi-Branch Feature Fusion Network for Colonoscopy. Colonoscopy is currently one of the main methods for the detection of rectal polyps, rectal cancer, and other diseases. With the rapid development of computer vision, deep learning-based semantic segmentation methods can be applied to the detection of medical lesions. However, it is challenging for current methods to detect polyps with high accuracy and real-time performance. To solve this problem, we propose a multi-branch feature fusion network (MBFFNet), which is an accurate real-time segmentation method for detecting colonoscopy. First, we use UNet as the basis of our model architecture and adopt stepwise sampling with channel multiplication to integrate features, which decreases the number of flops caused by stacking channels in UNet. Second, to improve model accuracy, we extract features from multiple layers and resize feature maps to the same size in different ways, such as up-sampling and pooling, to supplement information lost in multiplication-based up-sampling. Based on mIOU and Dice loss with cross entropy (CE), we conduct experiments in both CPU and GPU environments to verify the effectiveness of our model. The experimental results show that our proposed MBFFNet is superior to the selected baselines in terms of accuracy, model size, and flops. mIOU, <i>F</i> score, and Dice loss with CE reached 0.8952, 0.9450, and 0.1602, respectively, which were better than those of UNet, UNet++, and other networks. Compared with UNet, the flop count decreased by 73.2%, and the number of participants also decreased. The actual segmentation effect of MBFFNet is only lower than that of PraNet, the number of parameters is 78.27% of that of PraNet, and the flop count is 0.23% that of PraNet. In addition, experiments on other types of medical tasks show that MBFFNet has good potential for general application in medical image segmentation.",0,0
6837,"Identification of Snails and <i>Schistosoma</i> of Medical Importance <i>via</i> Convolutional Neural Networks: A Proof-of-Concept Application for Human Schistosomiasis. In recent decades, computer vision has proven remarkably effective in addressing diverse issues in public health, from determining the diagnosis, prognosis, and treatment of diseases in humans to predicting infectious disease outbreaks. Here, we investigate whether convolutional neural networks (CNNs) can also demonstrate effectiveness in classifying the environmental stages of parasites of public health importance and their invertebrate hosts. We used schistosomiasis as a reference model. Schistosomiasis is a debilitating parasitic disease transmitted to humans <i>via</i> snail intermediate hosts. The parasite affects more than 200 million people in tropical and subtropical regions. We trained our CNN, a feed-forward neural network, on a limited dataset of 5,500 images of snails and 5,100 images of cercariae obtained from schistosomiasis transmission sites in the Senegal River Basin, a region in western Africa that is hyper-endemic for the disease. The image set included both images of two snail genera that are relevant to schistosomiasis transmission - that is, <i>Bulinus</i> spp. and <i>Biomphalaria pfeifferi</i> - as well as snail images that are non-component hosts for human schistosomiasis. Cercariae shed from <i>Bi. pfeifferi and Bulinus</i> spp. snails were classified into 11 categories, of which only two, <i>S. haematobium</i> and <i>S. mansoni</i>, are major etiological agents of human schistosomiasis. The algorithms, trained on 80% of the snail and parasite dataset, achieved 99% and 91% accuracy for snail and parasite classification, respectively, when used on the hold-out validation dataset - a performance comparable to that of experienced parasitologists. The promising results of this proof-of-concept study suggests that this CNN model, and potentially similar replicable models, have the potential to support the classification of snails and parasite of medical importance. In remote field settings where machine learning algorithms can be deployed on cost-effective and widely used mobile devices, such as smartphones, these models can be a valuable complement to laboratory identification by trained technicians. Future efforts must be dedicated to increasing dataset sizes for model training and validation, as well as testing these algorithms in diverse transmission settings and geographies.",1,1
6840,"Advanced Deep Learning Approach to Automatically Segment Malignant Tumors and Ablation Zone in the Liver With Contrast-Enhanced CT. Liver cancer is one of the most commonly diagnosed cancer, and energy-based tumor ablation is a widely accepted treatment. Automatic and robust segmentation of liver tumors and ablation zones would facilitate the evaluation of treatment success. The purpose of this study was to develop and evaluate an automatic deep learning based method for (1) segmentation of liver and liver tumors in both arterial and portal venous phase for pre-treatment CT, and (2) segmentation of liver and ablation zones in both arterial and portal venous phase for after ablation treatment.",0,0
6841,"A Deep-Learning Model With the Attention Mechanism Could Rigorously Predict Survivals in Neuroblastoma. Neuroblastoma is one of the most devastating forms of childhood cancer. Despite large amounts of attempts in precise survival prediction in neuroblastoma, the prediction efficacy remains to be improved.",0,0
6843,"Intelligent predictions of Covid disease based on lung CT images using machine learning strategy. Covid or Corona Virus, a term ruling the world from past two years and causes a huge destruction in all countries. One of the most important Covid disease identification method is Lung based Computed Tomography (CT) image scanning, in which it provides an effective disease identification means in clear manner. However, this Lung CT image based disease detection principles are complex to health care representatives and doctors to predict the Covid disease accurately. Several manual errors and medical flaws are raised day-by-day, so that a new systematic methodology is required to identify the Covid disease effectively with respect to machine learning principles. The machine learning principles are most popular to identify the respective disease efficiently as well as classify the disease in accurate manner without any time consumption. The infected portions of the chest are identified accurately and report to the respective person without any delay. In this paper, a new machine learning strategy is introduced called Hybrid Disease Detection Principle (HDDP), in which it is derived from the two classical machine learning algorithms called Convolutional Neural Network (CNN) and the AdaBoost Classifier. Both these algorithms are integrated together to produce a new strategy called HDDP, in which it process the lung CT image based on the machine learning factors such as pre-processing, feature extraction and classification. Based on these effective image processing strategies the proposed algorithm handles the CT images to predict the Covid disease and report to the respective user with proper accuracy ratio. This paper intends to provide effcient disease predictions as well as provide a sufficient support to medical people and patients in fine manner to assist them with modern classification algorithms.",0,0
6845,"Non-Invasive Glucose Monitoring Using Optical Sensor and Machine Learning Techniques for Diabetes Applications. Diabetes is a major public health challenge affecting more than 451 million people. Physiological and experimental factors influence the accuracy of non-invasive glucose monitoring, and these need to be overcome before replacing the finger prick method. Also, the suitable employment of machine learning techniques can significantly improve the accuracy of glucose predictions. One aim of this study is to use light sources with multiple wavelengths to enhance the sensitivity and selectivity of glucose detection in an aqueous solution. Multiple wavelength measurements have the potential to compensate for errors associated with inter- and intra-individual differences in blood and tissue components. In this study, the transmission measurements of a custom built optical sensor are examined using 18 different wavelengths between 410 and 940 nm. Results show a high correlation value (0.98) between glucose concentration and transmission intensity for four wavelengths (485, 645, 860 and 940 nm). Five machine learning methods are investigated for glucose predictions. When regression methods are used, 9% of glucose predictions fall outside the correct range (normal, hypoglycemic or hyperglycemic). The prediction accuracy is improved by applying classification methods on sets of data arranged into 21 classes. Data within each class corresponds to a discrete 10 mg/dL glucose range. Classification based models outperform regression, and among them, the support vector machine is the most successful with F1-score of 99%. Additionally, Clarke error grid shows that 99.75% of glucose readings fall within the clinically acceptable zones. This is an important step towards critical diagnosis during an emergency patient situation.",0,0
6848,"Performance-weighted-voting model: An ensemble machine learning method for cancer type classification using whole-exome sequencing mutation. With improvements in next-generation DNA sequencing technology, lower cost is needed to collect genetic data. More machine learning techniques can be used to help with cancer analysis and diagnosis.",0,0
6851,"A Comparative Analysis of Machine Learning Algorithms to Predict Alzheimer's Disease. Alzheimer's disease has been one of the major concerns recently. Around 45 million people are suffering from this disease. Alzheimer's is a degenerative brain disease with an unspecified cause and pathogenesis which primarily affects older people. The main cause of Alzheimer's disease is Dementia, which progressively damages the brain cells. People lost their thinking ability, reading ability, and many more from this disease. A machine learning system can reduce this problem by predicting the disease. The main aim is to recognize Dementia among various patients. This paper represents the result and analysis regarding detecting Dementia from various machine learning models. The Open Access Series of Imaging Studies (OASIS) dataset has been used for the development of the system. The dataset is small, but it has some significant values. The dataset has been analyzed and applied in several machine learning models. Support vector machine, logistic regression, decision tree, and random forest have been used for prediction. First, the system has been run without fine-tuning and then with fine-tuning. Comparing the results, it is found that the support vector machine provides the best results among the models. It has the best accuracy in detecting Dementia among numerous patients. The system is simple and can easily help people by detecting Dementia among them.",0,0
6852,"Artificial Intelligence Pulse Coupled Neural Network Algorithm in the Diagnosis and Treatment of Severe Sepsis Complicated with Acute Kidney Injury under Ultrasound Image. The objective of this study was to explore the diagnosis of severe sepsis complicated with acute kidney injury (AKI) by ultrasonic image information based on the artificial intelligence pulse coupled neural network (PCNN) algorithm. In this study, an algorithm of ultrasonic image information enhancement based on the artificial intelligence PCNN was constructed and compared with the histogram equalization algorithm and linear transformation algorithm. After that, it was applied to the ultrasonic image diagnosis of 20 cases of severe sepsis combined with AKI in hospital. The condition of each patient was diagnosed by ultrasound image performance, change of renal resistance index (RRI), ultrasound score, and receiver operator characteristic curve (ROC) analysis. It was found that the histogram distribution of this algorithm was relatively uniform, and the information of each gray level was obviously retained and enhanced, which had the best effect in this algorithm; there was a marked individual difference in the values of RRI. Overall, the values of RRI showed a slight upward trend after admission to the intensive care unit (ICU). The RRI was taken as the dependent variable, time as the fixed-effect model, and patients as the random effect; the parameter value of time was between 0.012 and 0.015, <i>p</i>=0.000 < 0.05. Besides, there was no huge difference in the ultrasonic score among different time measurements (<i>t</i>â€‰=â€‰1.348 and <i>p</i>=0.128 > 0.05). The area under the ROC curve of the RRI for the diagnosis of AKI at the 2<sup>nd</sup> day, 4<sup>th</sup> day, and 6<sup>th</sup> day was 0.758, 0.841, and 0.856, respectively, which was all greater than 0.5 (<i>p</i> < 0.05). In conclusion, the proposed algorithm in this study could significantly enhance the amount of information in ultrasound images. In addition, the change of RRI values measured by ultrasound images based on the artificial intelligence PCNN was associated with AKI.",0,0
6853,"Value of Rehabilitation Training for Children with Cerebral Palsy Diagnosed and Analyzed by Computed Tomography Imaging Information Features under Deep Learning. To analyze the brain CT imaging data of children with cerebral palsy (CP), deep learning-based electronic computed tomography (CT) imaging information characteristics were used, thereby providing help for the rehabilitation analysis of children with CP and comorbid epilepsy. The brain CT imaging data of 73 children with CP were collected, who were outpatients or inpatients in our hospital. The images were randomly divided into two groups. One group was the artificial intelligence image group, and hybrid segmentation network (HSN) model was employed to analyze brain images to help the treatment. The other group was the control group, and original images were used to help diagnosis and treatment. The deep learning-based HSN was used to segment the CT image of the head of patients and was compared with other CNN methods. It was found that HSN had the highest Dice score (DSC) among all models. After treatment, six cases in the artificial intelligence image group returned to normal (20.7%), and the artificial intelligence image group was significantly higher than the control group (<i>X</i> <sup>2</sup>â€‰=â€‰335191, <i>P</i> < 0.001). The cerebral hemodynamic changes were obviously different in the two groups of children before and after treatment. The VP of the cerebral artery in the child was (139.68â€‰Â±â€‰15.66) cm/s after treatment, which was significantly faster than (131.84â€‰Â±â€‰15.93) cm/s before treatment, <i>P</i> < 0.05. To sum up, the deep learning model can effectively segment the CP area, which can measure and assist the diagnosis of future clinical cases of children with CP. It can also improve medical efficiency and accurately identify the patient's focus area, which had great application potential in helping to identify the rehabilitation training results of children with CP.",0,0
6854,"Effect of Interventional Therapy on Iliac Venous Compression Syndrome Evaluated and Diagnosed by Artificial Intelligence Algorithm-Based Ultrasound Images. In order to explore the efficacy of using artificial intelligence (AI) algorithm-based ultrasound images to diagnose iliac vein compression syndrome (IVCS) and assist clinicians in the diagnosis of diseases, the characteristics of vein imaging in patients with IVCS were summarized. After ultrasound image acquisition, the image data were preprocessed to construct a deep learning model to realize the position detection of venous compression and the recognition of benign and malignant lesions. In addition, a dataset was built for model evaluation. The data came from patients with thrombotic chronic venous disease (CVD) and deep vein thrombosis (DVT) in hospital. The image feature group of IVCS extracted by cavity convolution was the artificial intelligence algorithm imaging group, and the ultrasound images were directly taken as the control group without processing. Digital subtraction angiography (DSA) was performed to check the patient's veins one week in advance. Then, the patients were rolled into the AI algorithm imaging group and control group, and the correlation between May-Thurner syndrome (MTS) and AI algorithm imaging was analyzed based on DSA and ultrasound results. Satisfaction of intestinal venous stenosis (or occlusion) or formation of collateral circulation was used as a diagnostic index for MTS. Ultrasound showed that the AI algorithm imaging group had a higher percentage of good treatment effects than that of the control group. The call-up rate of the DMRF-convolutional neural network (CNN), precision, and accuracy were all superior to those of the control group. In addition, the degree of venous swelling of patients in the artificial intelligence algorithm imaging group was weak, the degree of pain relief was high after treatment, and the difference between the artificial intelligence algorithm imaging group and control group was statistically considerable (<i>p</i> < 0.005). Through grouped experiments, it was found that the construction of the AI imaging model was effective for the detection and recognition of lower extremity vein lesions in ultrasound images. To sum up, the ultrasound image evaluation and analysis using AI algorithm during MTS treatment was accurate and efficient, which laid a good foundation for future research, diagnosis, and treatment.",0,0
6855,"Computed Tomography Angiography under Deep Learning in the Treatment of Atherosclerosis with Rapamycin. The clinical characteristics and vascular computed tomography (CT) imaging characteristics of patients were explored so as to assist clinicians in diagnosing patients with atherosclerosis. 316 patients with atherosclerosis who were hospitalized for emergency treatment were treated with rapamycin (RAPA) in the hospital. A group of manually delineated left ventricular myocardia (LVM) on the patient's coronary computed tomography angiography (CCTA) were selected as the region of interest for imaging features extracted. The CCTA images of 80% of patients were randomly selected for training, and those of 20% of patients were used for verification. The correlation matrix method was used to remove redundant image omics features under different correlation thresholds. In the validation set, CCTA diagnostic parameters were about 40 times higher than the manually segmented data. The average dice similarity coefficient was 91.6%. The proposed method also produced a very small centroid distance (mean 1.058â€‰mm, standard deviation 1.245â€‰mm) and volume difference (mean 1.640), with a segmentation time of about 1.45â€‰Â±â€‰0.51â€‰s, compared to about 744.8â€‰Â±â€‰117.49â€‰s for physician manual segmentation. Therefore, the deep learning model effectively segmented the atherosclerotic lesion area, measured and assisted the diagnosis of future atherosclerosis clinical cases, improved medical efficiency, and accurately identified the patient's lesion area. It had great application potential in helping diagnosis and curative effect analysis of atherosclerosis.",0,0
6856,"Health Recognition Algorithm for Sports Training Based on Bi-GRU Neural Networks. The healthcare benefits associated with regular physical activity recognition and monitoring have been considered in several research studies. Regular recognition and monitoring of health status can potentially assist in managing and reducing the risk of many diseases such as cardiovascular disease, diabetes, and obesity. Using healthcare equipment in hospitals, people can conduct regular physical examinations to check their health status. However, most of the time, it is difficult to reach a specific medical environment and use special medical equipment. In this paper, a deep learning framework based on the bidirectional gated recurrent unit for health status recognition is implemented to improve the accuracy by making full use of the information provided by smartphone acceleration sensors. A model based on a bidirectional gated recurrent unit is constructed to describe the relationship between input acceleration signals and output information through a gating approach. Therefore, it can automatically detect the health status of the sportsman as healthy, subhealthy, and unhealthy. Finally, the practical data collected from an athlete have been used to evaluate the recognition performance of the system. Results show that the proposed methodology can predicate the sports health status accurately.",0,0
6858,"Use of Deep-Learning Genomics to Discriminate Healthy Individuals from Those with Alzheimer's Disease or Mild Cognitive Impairment. Alzheimer's disease (AD) is the most prevalent neurodegenerative disorder and the most common form of dementia in the elderly. Certain genes have been identified as important clinical risk factors for AD, and technological advances in genomic research, such as genome-wide association studies (GWAS), allow for analysis of polymorphisms and have been widely applied to studies of AD. However, shortcomings of GWAS include sensitivity to sample size and hereditary deletions, which result in low classification and predictive accuracy. Therefore, this paper proposes a novel deep-learning genomics approach and applies it to multitasking classification of AD progression, with the goal of identifying novel genetic biomarkers overlooked by traditional GWAS analysis.",0,0
6860,"A deep learning framework using CNN and stacked Bi-GRU for COVID-19 predictions in India. The novel coronavirus infection (COVID-19) first appeared in Wuhan, China, in December 2019. COVID-19 declared as a global pandemic by the WHO was the most rapidly spreading disease all across the world. India, the second most populated nation in the world, is still fighting it, when coronavirus reached the stage where community transmission takes place at an exponential rate. Therefore, it is crucial to examine the future trends of COVID-19 in India and anticipate how it will affect economic and social growth in a short run. In this paper, a new deep learning framework using CNN and stacked Bi-GRU has been developed for predicting and analyzing the COVID-19 cases in India. The proposed model can predict the next 30 days' new positive cases, new death cases, recovery rate and containment and health index values with high accuracy. The proposed method is compared against Gaussian process regression (GPR) model on COVID-19 datasets. The experimental result shows that the proposed framework is highly reliable for COVID-19 prediction over the GPR model.",0,0
6862,"Application of Data Mining Algorithms for Dementia in People with HIV/AIDS. Dementia interferes with the individual's motor, behavioural, and intellectual functions, causing him to be unable to perform instrumental activities of daily living. This study is aimed at identifying the best performing algorithm and the most relevant characteristics to categorise individuals with HIV/AIDS at high risk of dementia from the application of data mining. Principal component analysis (PCA) algorithm was used and tested comparatively between the following machine learning algorithms: logistic regression, decision tree, neural network, KNN, and random forest. The database used for this study was built from the data collection of 270 individuals infected with HIV/AIDS and followed up at the outpatient clinic of a reference hospital for infectious and parasitic diseases in the State of CearÃ¡, Brazil, from January to April 2019. Also, the performance of the algorithms was analysed for the 104 characteristics available in the database; then, with the reduction of dimensionality, there was an improvement in the quality of the machine learning algorithms and identified that during the tests, even losing about 30% of the variation. Besides, when considering only 23 characteristics, the precision of the algorithms was 86% in random forest, 56% logistic regression, 68% decision tree, 60% KNN, and 59% neural network. The random forest algorithm proved to be more effective than the others, obtaining 84% precision and 86% accuracy.",0,0
6864,"Identification of Potential lncRNAs and miRNAs as Diagnostic Biomarkers for Papillary Thyroid Carcinoma Based on Machine Learning. Papillary thyroid carcinoma (PTC) accounts for most of the proportion of thyroid cancer (TC). The objective of this study was to identify diagnostic, differentially expressed long noncoding RNAs (lncRNAs) and microRNAs (miRNAs), contributing to understanding the epigenetics mechanism of PTC.",0,0
6865,"A comparative study of multiple neural network for detection of COVID-19 on chest X-ray. Coronavirus disease of 2019 or COVID-19 is a rapidly spreading viral infection that has affected millions all over the world. With its rapid spread and increasing numbers, it is becoming overwhelming for the healthcare workers to rapidly diagnose the condition and contain it from spreading. Hence it has become a necessity to automate the diagnostic procedure. This will improve the work efficiency as well as keep the healthcare workers safe from getting exposed to the virus. Medical image analysis is one of the rising research areas that can tackle this issue with higher accuracy. This paper conducts a comparative study of the use of the recent deep learning models (VGG16, VGG19, DenseNet121, Inception-ResNet-V2, InceptionV3, Resnet50, and Xception) to deal with the detection and classification of coronavirus pneumonia from pneumonia cases. This study uses 7165 chest X-ray images of COVID-19 (1536) and pneumonia (5629) patients. Confusion metrics and performance metrics were used to analyze each model. Results show DenseNet121 (99.48% of accuracy) showed better performance when compared with the other models in this study.",0,0
6867,"Skin Cancer Detection Using Kernel Fuzzy C-Means and Improved Neural Network Optimization Algorithm. Early diagnosis of malignant skin cancer from images is a significant part of the cancer treatment process. One of the principal purposes of this research is to propose a pipeline methodology for an optimum computer-aided diagnosis of skin cancers. The method contains four main stages. The first stage is to perform a preprocessing based on noise reduction and contrast enhancement. The second stage is to segment the region of interest (ROI). This study uses kernel fuzzy C-means for ROI segmentation. Then, some features from the ROI are extracted, and then, a feature selection is used for selecting the best ones. The selected features are then injected into a support vector machine (SVM) for final identification. One important part of the contribution in this study is to propose a developed version of a new metaheuristic, named neural network optimization algorithm, to optimize both parts of feature selection and SVM classifier. Comparison results of the method with 5 state-of-the-art methods showed the approach's higher superiority toward the others.",0,0
6868,"Single and Combined Neuroimaging Techniques for Alzheimer's Disease Detection. Alzheimer's disease (AD) consists of the gradual process of decreasing volume and quality of neuron connection in the brain, which consists of gradual synaptic integrity and loss of cognitive functions. In recent years, there has been significant attention in AD classification and early detection with machine learning algorithms. There are different neuroimaging techniques for capturing data and using it for the classification task. Input data as images will help machine learning models to detect different biomarkers for AD classification. This marker has a more critical role for AD detection than other diseases because beta-amyloid can extract complex structures with some metal ions. Most researchers have focused on using 3D and 4D convolutional neural networks for AD classification due to reasonable amounts of data. Also, combination neuroimaging techniques like functional magnetic resonance imaging and positron emission tomography for AD detection have recently gathered much attention. However, gathering a combination of data can be expensive, complex, and tedious. For time consumption reasons, most patients prefer to throw one of the neuroimaging techniques. So, in this review article, we have surveyed different research studies with various neuroimaging techniques and ML methods to see the effect of using combined data as input. The result has shown that the use of the combination method would increase the accuracy of AD detection. Also, according to the sensitivity metrics from different machine learning methods, MRI and fMRI showed promising results.",0,0
6881,"Development of a Four-mRNA Expression-Based Prognostic Signature for Cutaneous Melanoma. We aim to find a biomarker that can effectively predict the prognosis of patients with cutaneous melanoma (CM). The RNA sequencing data of CM was downloaded from The Cancer Genome Atlas (TCGA) database and randomly divided into training group and test group. Survival statistical analysis and machine-learning approaches were performed on the RNA sequencing data of CM to develop a prognostic signature. Using univariable Cox proportional hazards regression, random survival forest algorithm, and receiver operating characteristic (ROC) in the training group, the four-mRNA signature including CD276, UQCRFS1, HAPLN3, and PIP4P1 was screened out. The four-mRNA signature could divide patients into low-risk and high-risk groups with different survival outcomes (log-rank <i>p</i> < 0.001). The predictive efficacy of the four-mRNA signature was confirmed in the test group, the whole TCGA group, and the independent GSE65904 (log-rank <i>p</i> < 0.05). The independence of the four-mRNA signature in prognostic prediction was demonstrated by multivariate Cox analysis. ROC and timeROC analyses showed that the efficiency of the signature in survival prediction was better than other clinical variables such as melanoma Clark level and tumor stage. This study highlights that the four-mRNA model could be used as a prognostic signature for CM patients with potential clinical application value.",0,0
6882,"Machine Learning to Identify Metabolic Subtypes of Obesity: A Multi-Center Study. Clinical characteristics of obesity are heterogenous, but current classification for diagnosis is simply based on BMI or metabolic healthiness. The purpose of this study was to use machine learning to explore a more precise classification of obesity subgroups towards informing individualized therapy.",0,0
6883,"Forecasting Seizure Likelihood With Wearable Technology. The unpredictability of epileptic seizures exposes people with epilepsy to potential physical harm, restricts day-to-day activities, and impacts mental well-being. Accurate seizure forecasters would reduce the uncertainty associated with seizures but need to be feasible and accessible in the long-term. Wearable devices are perfect candidates to develop non-invasive, accessible forecasts but are yet to be investigated in long-term studies. We hypothesized that machine learning models could utilize heart rate as a biomarker for well-established cycles of seizures and epileptic activity, in addition to other wearable signals, to forecast high and low risk seizure periods. This feasibility study tracked participants' (<i>n</i> = 11) heart rates, sleep, and step counts using wearable smartwatches and seizure occurrence using smartphone seizure diaries for at least 6 months (mean = 14.6 months, SD = 3.8 months). Eligible participants had a diagnosis of refractory epilepsy and reported at least 20 seizures (mean = 135, SD = 123) during the recording period. An ensembled machine learning and neural network model estimated seizure risk either daily or hourly, with retraining occurring on a weekly basis as additional data was collected. Performance was evaluated retrospectively against a rate-matched random forecast using the area under the receiver operating curve. A pseudo-prospective evaluation was also conducted on a held-out dataset. Of the 11 participants, seizures were predicted above chance in all (100%) participants using an hourly forecast and in ten (91%) participants using a daily forecast. The average time spent in high risk (prediction time) before a seizure occurred was 37 min in the hourly forecast and 3 days in the daily forecast. Cyclic features added the most predictive value to the forecasts, particularly circadian and multiday heart rate cycles. Wearable devices can be used to produce patient-specific seizure forecasts, particularly when biomarkers of seizure and epileptic activity cycles are utilized.",0,0
6884,"Functional Disruptions of the Brain in Low Back Pain: A Potential Imaging Biomarker of Functional Disability. Chronic low back pain (LBP) is one of the leading causes of disability worldwide. While LBP research has largely focused on the spine, many studies have demonstrated a restructuring of human brain architecture accompanying LBP and other chronic pain states. Brain imaging presents a promising source for discovering noninvasive biomarkers that can improve diagnostic and prognostication outcomes for chronic LBP. This study evaluated graph theory measures derived from brain resting-state functional connectivity (rsFC) as prospective noninvasive biomarkers of LBP. We also proposed and tested a hybrid feature selection method (Enet-subset) that combines Elastic Net and an optimal subset selection method. We collected resting-state functional MRI scans from 24 LBP patients and 27 age-matched healthy controls (HC). We then derived graph-theoretical features and trained a support vector machine (SVM) to classify patient group. The degree centrality (DC), clustering coefficient (CC), and betweenness centrality (BC) were found to be significant predictors of patient group. We achieved an average classification accuracy of 83.1% (<i>p</i> < 0.004) and AUC of 0.937 (<i>p</i> < 0.002), respectively. Similarly, we achieved a sensitivity and specificity of 87.0 and 79.7%. The classification results from this study suggest that graph matrices derived from rsFC can be used as biomarkers of LBP. In addition, our findings suggest that the proposed feature selection method, Enet-subset, might act as a better technique to remove redundant variables and improve the performance of the machine learning classifier.",0,0
6887,"Characterization of the Electrophysiologic Remodeling of Patients With Ischemic Cardiomyopathy by Clinical Measurements and Computer Simulations Coupled With Machine Learning. Patients with ischemic cardiomyopathy (ICMP) are at high risk for malignant arrhythmias, largely due to electrophysiological remodeling of the non-infarcted myocardium. The electrophysiological properties of the non-infarcted myocardium of patients with ICMP remain largely unknown.",0,0
6888,"A Large-Scale Open Motion Dataset (KFall) and Benchmark Algorithms for Detecting Pre-impact Fall of the Elderly Using Wearable Inertial Sensors. Research on pre-impact fall detection with wearable inertial sensors (detecting fall accidents prior to body-ground impacts) has grown rapidly in the past decade due to its great potential for developing an on-demand fall-related injury prevention system. However, most researchers use their own datasets to develop fall detection algorithms and rarely make these datasets publicly available, which poses a challenge to fairly evaluate the performance of different algorithms on a common basis. Even though some open datasets have been established recently, most of them are impractical for pre-impact fall detection due to the lack of temporal labels for fall time and limited types of motions. In order to overcome these limitations, in this study, we proposed and publicly provided a large-scale motion dataset called ""KFall,"" which was developed from 32 Korean participants while wearing an inertial sensor on the low back and performing 21 types of activities of daily living and 15 types of simulated falls. In addition, ready-to-use temporal labels of the fall time based on synchronized motion videos were published along with the dataset. Those enhancements make KFall the first public dataset suitable for pre-impact fall detection, not just for post-fall detection. Importantly, we have also developed three different types of latest algorithms (threshold based, support-vector machine, and deep learning), using the KFall dataset for pre-impact fall detection so that researchers and practitioners can flexibly choose the corresponding algorithm. Deep learning algorithm achieved both high overall accuracy and balanced sensitivity (99.32%) and specificity (99.01%) for pre-impact fall detection. Support vector machine also demonstrated a good performance with a sensitivity of 99.77% and specificity of 94.87%. However, the threshold-based algorithm showed relatively poor results, especially the specificity (83.43%) was much lower than the sensitivity (95.50%). The performance of these algorithms could be regarded as a benchmark for further development of better algorithms with this new dataset. This large-scale motion dataset and benchmark algorithms could provide researchers and practitioners with valuable data and references to develop new technologies and strategies for pre-impact fall detection and proactive injury prevention for the elderly.",0,0
6894,"A deep-learning-based framework for severity assessment of COVID-19 with CT images. Millions of positive COVID-19 patients are suffering from the pandemic around the world, a critical step in the management and treatment is severity assessment, which is quite challenging with the limited medical resources. Currently, several artificial intelligence systems have been developed for the severity assessment. However, imprecise severity assessment and insufficient data are still obstacles. To address these issues, we proposed a novel deep-learning-based framework for the fine-grained severity assessment using 3D CT scans, by jointly performing lung segmentation and lesion segmentation. The main innovations in the proposed framework include: 1) decomposing 3D CT scan into multi-view slices for reducing the complexity of 3D model, 2) integrating prior knowledge (dual-Siamese channels and clinical metadata) into our model for improving the model performance. We evaluated the proposed method on 1301 CT scans of 449 COVID-19 cases collected by us, our method achieved an accuracy of 86.7% for four-way classification, with the sensitivities of 92%, 78%, 95%, 89% for four stages. Moreover, ablation study demonstrated the effectiveness of the major components in our model. This indicates that our method may contribute a potential solution to severity assessment of COVID-19 patients using CT images and clinical metadata.",0,0
6895,"A CNN-based scheme for COVID-19 detection with emergency services provisions using an optimal path planning. Unmanned Air Vehicles (UAVs) are becoming popular in real-world scenarios due to current advances in sensor technology and hardware platform development. The applications of UAVs in the medical field are broad and may be shared worldwide. With the recent outbreak of COVID-19, fast diagnostic testing has become one of the challenges due to the lack of test kits. UAVs can help in tackling the COVID-19 by delivering medication to the hospital on time. In this paper, to detect the number of COVID-19 cases in a hospital, we propose a deep convolution neural architecture using transfer learning, classifying the patient into three categories as COVID-19 (positive) and normal (negative), and pneumonia based on given X-ray images. The proposed deep-learning architecture is compared with state-of-the-art models. The results show that the proposed model provides an accuracy of 94.92%. Further to offer time-bounded services to COVID-19 patients, we have proposed a scheme for delivering emergency kits to the hospitals in need using an optimal path planning approach for UAVs in the network.",0,0
6898,"The Aneurysm Occlusion Assistant, an AI platform for real time surgical guidance of intracranial aneurysms. In recent years, endovascular treatment has become the dominant approach to treat intracranial aneurysms (IAs). Despite tremendous improvement in surgical devices and techniques, 10-30% of these surgeries require retreatment. Previously, we developed a method which combines quantitative angiography with data-driven modeling to predict aneurysm occlusion within a fraction of a second. This is the first report on a semi-autonomous system, which can predict the surgical outcome of an IA immediately following device placement, allowing for therapy adjustment. Additionally, we previously reported various algorithms which can segment IAs, extract hemodynamic parameters via angiographic parametric imaging, and perform occlusion predictions.",0,0
6899,"Estimation of Patient Eye-Lens Dose During Neuro-Interventional Procedures using a Dense Neural Network (DNN). The patient's eye-lens dose changes for each projection view during fluoroscopically-guided neuro-interventional procedures. Monte-Carlo (MC) simulation can be done to estimate lens dose but MC cannot be done in real-time to give feedback to the interventionalist. Deep learning (DL) models were investigated to estimate patient-lens dose for given exposure conditions to give real-time updates. MC simulations were done using a Zubal computational phantom to create a dataset of eye-lens dose values for training the DL models. Six geometric parameters (entrance-field size, LAO gantry angulation, patient x, y, z head position relative to the beam isocenter, and whether patient's right or left eye) were varied for the simulations. The dose for each combination of parameters was expressed as lens dose per entrance air kerma (mGy/Gy). Geometric parameter combinations associated with high-dose values were sampled more finely to generate more high-dose values for training purposes. Additionally, dose at intermediate parameter values was calculated by MC in order to validate the interpolation capabilities of DL. Data was split into training, validation and testing sets. Stacked models and median algorithms were implemented to create more robust models. Model performance was evaluated using mean absolute percentage error (MAPE). The goal for this DL model is that it be implemented into the Dose Tracking System (DTS) developed by our group. This would allow the DTS to infer the patient's eye-lens dose for real-time feedback and eliminate the need for a large database of pre-calculated values with interpolation capabilities.",0,0
6902,"Editorial: The National COVID Cohort Collaborative Consortium Combines Population Data with Machine Learning to Evaluate and Predict Risk Factors for the Severity of COVID-19. Infection with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) that causes coronavirus disease 2019 (COVID-19) commonly presents with pneumonia. However, COVID-19 is now recognized to involve multiple organ systems with varying severity and duration. In July 2021, the findings from a retrospective population study from the National COVID Cohort Collaborative (N3C) Consortium were published that included analysis by machine learning methods of 174,568 adults with SARS-CoV-2 infection from 34 medical centers in the US. The study stratified patients for COVID-19 according to the World Health Organization (WHO) Clinical Progression Scale (CPS). Severe clinical outcomes were identified as the requirement for invasive ventilatory support, or extracorporeal membrane oxygenation (ECMO), and patient mortality. Machine learning analysis showed that the factor most strongly associated with severity of clinical course in patients with COVID-19 was pH. A separate multivariable logistic regression model showed that independent factors associated with more severe clinical outcomes included age, dementia, male gender, liver disease, and obesity. This Editorial aims to present the rationale and findings of the largest population cohort of adult patients with COVID-19 to date and highlights the importance of using large population studies with sophisticated analytical methods, including machine learning.",0,0
6903,"Naive Bayes Prediction of the Development of Cardiac Events in Heart Failure With Preserved Ejection Fraction in an Outpatient Clinicã€€- Beyond B-Type Natriuretic Peptide. The heterogeneity of B-type natriuretic peptide (BNP) levels among individuals with heart failure and preserved ejection fraction (HFpEF) makes predicting the development of cardiac events difficult. This study aimed at creating high-performance Naive Bayes (NB) classifiers, beyond BNP, to predict the development of cardiac events over a 3-year period in individual outpatients with HFpEF.Methodsâ€„andâ€„Results:We retrospectively enrolled 234 outpatients with HFpEF who were followed up for 3 years. Parameters with a coefficient of association â‰¥0.1 for cardiac events were applied as features of classifiers. We used the step forward method to find a high-performance model with the maximum area under the receiver operating characteristics curve (AUC). A 10-fold cross-validation method was used to validate the generalization performance of the classifiers. The mean kappa statistics, AUC, sensitivity, specificity, and accuracy were evaluated and compared between classifiers learning multiple factors and only the BNP. Kappa statistics, AUC, and sensitivity were significantly higher for NB classifiers learning 13 features than for those learning only BNP (0.69Â±0.14 vs. 0.54Â±0.12 P=0.024, 0.94Â±0.03 vs. 0.84Â±0.05 P<0.001, 85Â±8% vs. 64Â±20% P=0.006, respectively). The specificity and accuracy were similar.",0,0
6905,"An Artificial Intelligence-Assisted Method for Dementia Detection Using Images fromÂ the Clock Drawing Test. Widespread dementia detection could increase clinical trial candidates and enable appropriate interventions. Since the Clock Drawing Test (CDT) can be potentially used for diagnosing dementia-related disorders, it can be leveraged to develop a computer-aided screening tool.",0,0
6906,Discovery of Parkinson's disease states and disease progression modelling: a longitudinal data study using machine learning. Parkinson's disease is heterogeneous in symptom presentation and progression. Increased understanding of both aspects can enable better patient management and improve clinical trial design. Previous approaches to modelling Parkinson's disease progression assumed static progression trajectories within subgroups and have not adequately accounted for complex medication effects. Our objective was to develop a statistical progression model of Parkinson's disease that accounts for intra-individual and inter-individual variability and medication effects.,0,0
6907,"Early detection of COVID-19 in the UK using self-reported symptoms: a large-scale, prospective, epidemiological surveillance study. Self-reported symptoms during the COVID-19 pandemic have been used to train artificial intelligence models to identify possible infection foci. To date, these models have only considered the culmination or peak of symptoms, which is not suitable for the early detection of infection. We aimed to estimate the probability of an individual being infected with SARS-CoV-2 on the basis of early self-reported symptoms to enable timely self-isolation and urgent testing.",0,0
6912,The preoperative prognostic value of the radiomics nomogram based on CT combined with machine learning in patients with intrahepatic cholangiocarcinoma. Intrahepatic cholangiocarcinoma is an aggressive liver carcinoma with increasing incidence and mortality. A good auxiliary prognostic prediction tool is desperately needed for the development of treatment strategies. The purpose of this study was to explore the prognostic value of the radiomics nomogram based on enhanced CT in intrahepatic cholangiocarcinoma.,0,0
6914,Artificial neural network prediction of same-day discharge following primary total knee arthroplasty based on preoperative and intraoperative variables. This study used an artificial neural network (ANN) model to determine the most important pre- and perioperative variables to predict same-day discharge in patients undergoing total knee arthroplasty (TKA).,0,0
6919,A Machine Learning Approach to Liver Histological Evaluation Predicts Clinically Significant Portal Hypertension in NASH Cirrhosis. The hepatic venous pressure gradient (HVPG) is the standard for estimating portal pressure but requires expertise for interpretation. We hypothesized that HVPG could be extrapolated from liver histology using a machine learning (ML) algorithm.,0,0
6921,"Daily estimates of individual discharge likelihood with deep learning natural language processing in general medicine: a prospective and external validation study. Machine learning, in particular deep learning, may be able to assist in the prediction of the length of stay and timing of discharge for individual patients. Artificial neural networks applied to medical text have previously shown promise in this area. In this study, a previously derived artificial neural network was applied to prospective and external validation datasets. In the prediction of discharge within the next 2 days, when the algorithm was applied to prospective and external datasets, the area under the receiver operator curve for this task were 0.78 and 0.74, respectively. The performance in the prediction of discharge within the next 7 days was more limited (area under the receiver operator curve 0.68 and 0.67). This study has shown that in prospective and external validation datasets the previously derived deep learning algorithms have demonstrated moderate performance in the prediction of which patients will be discharged within the next 2 days. Future studies may seek to further refine or evaluate the effect of the implementation of such algorithms.",0,0
6922,"Machine learning for detection of stenoses and aneurysms: application in a physiologically realistic virtual patient database. This study presents an application of machine learning (ML) methods for detecting the presence of stenoses and aneurysms in the human arterial system. Four major forms of arterial disease-carotid artery stenosis (CAS), subclavian artery stenosis (SAS), peripheral arterial disease (PAD), and abdominal aortic aneurysms (AAA)-are considered. The ML methods are trained and tested on a physiologically realistic virtual patient database (VPD) containing 28,868 healthy subjects, adapted from the authors previous work and augmented to include disease. It is found that the tree-based methods of Random Forest and Gradient Boosting outperform other approaches. The performance of ML methods is quantified through the [Formula: see text] score and computation of sensitivities and specificities. When using six haemodynamic measurements (pressure in the common carotid, brachial, and radial arteries; and flow-rate in the common carotid, brachial, and femoral arteries), it is found that maximum [Formula: see text] scores larger than 0.9 are achieved for CAS and PAD, larger than 0.85 for SAS, and larger than 0.98 for both low- and high-severity AAAs. Corresponding sensitivities and specificities are larger than 90% for CAS and PAD, larger than 85% for SAS, and larger than 98% for both low- and high-severity AAAs. When reducing the number of measurements, performance is degraded by less than 5% when three measurements are used, and less than 10% when only two measurements are used for classification. For AAA, it is shown that [Formula: see text] scores larger than 0.85 and corresponding sensitivities and specificities larger than 85% are achievable when using only a single measurement. The results are encouraging to pursue AAA monitoring and screening through wearable devices which can reliably measure pressure or flow-rates.",0,0
6924,"Automated detection of substance use information from electronic health records for a pediatric population. Substance use screening in adolescence is unstandardized and often documented in clinical notes, rather than in structured electronic health records (EHRs). The objective of this study was to integrate logic rules with state-of-the-art natural language processing (NLP) and machine learning technologies to detect substance use information from both structured and unstructured EHR data.",0,0
6929,"Artificial intelligence predicts delirium following cardiac surgery: A case study. Delirium is a highly relevant complication of surgical interventions. Current research indicates that despite increased awareness for delirium, it is often overlooked. We implemented an AI-based tool to monitor delirium in cardiac surgery patients in our specialist clinic. This appears to be a promising approach to improve detection of delirium, especially for underrecognized forms and in peripheral wards without intensive screening. We present a case in which the AI identified delirium, confirmed by our routine screening and specialist evaluation.",0,0
6930,"Automated multiclass tissue segmentation of clinical brain MRIs with lesions. Delineation and quantification of normal and abnormal brain tissues on Magnetic Resonance Images is fundamental to the diagnosis and longitudinal assessment of neurological diseases. Here we sought to develop a convolutional neural network for automated multiclass tissue segmentation of brain MRIs that was robust at typical clinical resolutions and in the presence of a variety of lesions. We trained a 3D U-Net for full brain multiclass tissue segmentation from a prior atlas-based segmentation method on an internal dataset that consisted of 558 clinical T1-weighted brain MRIs (453/52/53; training/validation/test) of patients with one of 50 different diagnostic entities (nÂ =Â 362) or with a normal brain MRI (nÂ =Â 196). We then used transfer learning to refine our model on an external dataset that consisted of 7 patients with hand-labeled tissue types. We evaluated the tissue-wise and intra-lesion performance with different loss functions and spatial prior information in the validation set and applied the best performing model to the internal and external test sets. The network achieved an average overall Dice score of 0.87 and volume similarity of 0.97 in the internal test set. Further, the network achieved a median intra-lesion tissue segmentation accuracy of 0.85 inside lesions within white matter and 0.61 inside lesions within gray matter. After transfer learning, the network achieved an average overall Dice score of 0.77 and volume similarity of 0.96 in the external dataset compared to human raters. The network had equivalent or better performance than the original atlas-based method on which it was trained across all metrics and produced segmentations in a hundredth of the time. We anticipate that this pipeline will be a useful tool for clinical decision support and quantitative analysis of clinical brain MRIs in the presence of lesions.",1,1
6933,"Computer-aided diagnosis tool for cervical cancer screening with weakly supervised localization and detection of abnormalities using adaptable and explainable classifier. While pap test is the most common diagnosis methods for cervical cancer, their results are highly dependent on the ability of the cytotechnicians to detect abnormal cells on the smears using brightfield microscopy. In this paper, we propose an explainable region classifier in whole slide images that could be used by cyto-pathologists to handle efficiently these big images (100,000x100,000Â pixels). We create a dataset that simulates pap smears regions and uses a loss, we call classification under regression constraint, to train an efficient region classifier (about 66.8% accuracy on severity classification, 95.2% accuracy on normal/abnormal classification and 0.870 KAPPA score). We explain how we benefit from this loss to obtain a model focused on sensitivity and, then, we show that it can be used to perform weakly supervised localization (accuracy of 80.4%) of the cell that is mostly responsible for the malignancy of regions of whole slide images. We extend our method to perform a more general detection of abnormal cells (66.1% accuracy) and ensure that at least one abnormal cell will be detected if malignancy is present. Finally, we experiment our solution on a small real clinical slide dataset, highlighting the relevance of our proposed solution, adapting it to be as easily integrated in a pathology laboratory workflow as possible, and extending it to make a slide-level prediction.",0,0
6934,"Machine learning based natural language processing of radiology reports in orthopaedic trauma. To compare different Machine Learning (ML) Natural Language Processing (NLP) methods to classify radiology reports in orthopaedic trauma for the presence of injuries. Assessing NLP performance is a prerequisite for downstream tasks and therefore of importance from a clinical perspective (avoiding missed injuries, quality check, insight in diagnostic yield) as well as from a research perspective (identification of patient cohorts, annotation of radiographs).",0,0
6935,"xECGNet: Fine-tuning attention map within convolutional neural network to improve detection and explainability of concurrent cardiac arrhythmias. Background and objectiveDetecting abnormal patterns within an electrocardiogram (ECG) is crucial for diagnosing cardiovascular diseases. We start from two unresolved problems in applying deep-learning-based ECG classification models to clinical practice: first, although multiple cardiac arrhythmia (CA) types may co-occur in real life, the majority of previous detection methods have focused on one-to-one relationships between ECG and CA type, and second, it has been difficult to explain how neural-network-based CA classifiers make decisions. We hypothesize that fine-tuning attention maps with regard to all possible combinations of ground-truth (GT) labels will improve both the detection and interpretability of co-occurring CAs. Methods To test our hypothesis, we propose an end-to-end convolutional neural network (CNN), xECGNet, that fine-tunes the attention map to resemble the averaged response maps of GT labels. Fine-tuning is achieved by adding to the objective function a regularization loss between the attention map and the reference (averaged) map. Performance is assessed by F1 score and subset accuracy. Results The main experiment demonstrates that fine-tuning alone significantly improves a model's multilabel subset accuracy from 75.8% to 84.5% when compared with the baseline model. Also, xECGNet shows the highest F1 score of 0.812 and yields a more explainable map that encompasses multiple CA types, when compared to other baseline methods. Conclusions xECGNet has implications in that it tackles the two obstacles for the clinical application of CNN-based CA detection models with a simple solution of adding one additional term to the objective function.",0,0
6936,"Cross-Gram matrices and their use in transfer learning: Application to automatic REM detection using heart rate. while traditional sleep staging is achieved through the visualÂ -Â expert-basedÂ -Â annotation of a polysomnography, it has the disadvantages of being unpractical and expensive. Alternatives have been developed over the years to relieve sleep staging from its heavy requirements, through the collection of more easily assessable signals and its automation using machine learning. However, these alternatives have their limitations, some due to variabilities among and between subjects, other inherent to their use of sub-discriminative signals. Many new solutions rely on the evaluation of the Autonomic Nervous System (ANS) activation through the assessment of the heart-rate (HR); the latter is modulated by the aforementioned variabilities, which may result in data and concept shifts between what was learned and what we want to classify. Such adversary effects are usually tackled by Transfer Learning, dealing with problems where there are differences between what is known (source) and what we want to classify (target). In this paper, we propose two new kernel-based methods of transfer learning and assess their performances in Rapid-Eye-Movement (REM) sleep stage detection, using solely the heart rate.",0,0
6939,"The use of a next-generation sequencing-derived machine-learning risk-prediction model (OncoCast-MPM) for malignant pleural mesothelioma: a retrospective study. Current risk stratification for patients with malignant pleural mesothelioma based on disease stage and histology is inadequate. For some individuals with early-stage epithelioid tumours, a good prognosis by current guidelines can progress rapidly; for others with advanced sarcomatoid cancers, a poor prognosis can progress slowly. Therefore, we aimed to develop and validate a machine-learning tool-known as OncoCast-MPM-that could create a model for patient prognosis.",0,0
6941,Novel ECG features and machine learning to optimize culprit lesion detection in patients with suspected acute coronary syndrome. Novel temporal-spatial features of the 12â€‘lead ECG can conceptually optimize culprit lesions' detection beyond that of classical ST amplitude measurements. We sought to develop a data-driven approach for ECG feature selection to build a clinically relevant algorithm for real-time detection of culprit lesion.,0,0
6944,Use of machine learning techniques to identify HIV predictors for screening in sub-Saharan Africa. HIV prevention measures in sub-Saharan Africa are still short of attaining the UNAIDS 90-90-90 fast track targets set in 2014. Identifying predictors for HIV status may facilitate targeted screening interventions that improve health care. We aimed at identifying HIV predictors as well as predicting persons at high risk of the infection.,0,0
6947,"HVD-LSTM based recognition of epileptic seizures and normal human activity. In this paper, we detect the occurrence of epileptic seizures in patients as well as activities namely stand, walk, and exercise in healthy persons, leveraging EEG (electroencephalogram) signals. Using Hilbert vibration decomposition (HVD) on non-linear and non-stationary EEG signal, we obtain multiple monocomponents varying in terms of amplitude and frequency. After decomposition, we extract features from the monocomponent matrix of the EEG signals. The instantaneous amplitude of the HVD monocomponents varies because of the motion artifacts present in EEG signals. Hence, the acquired statistical features from the instantaneous amplitude help in identifying the epileptic seizures and the normal human activities. The features selected by correlation-based Q-score are classified using an LSTM (Long Short Term Memory) based deep learning model in which the feature-based weight update maximizes the classification accuracy. For epilepsy diagnosis using the Bonn dataset and activity recognition leveraging our Sensor Networks Research Lab (SNRL) data, we achieve testing classification accuracies of 96.00% and 83.30% respectively through our proposed method.",0,0
6948,"Automatic bone maturity grading from EOS radiographs in Adolescent Idiopathic Scoliosis. Adolescent Idiopathic Scoliosis (AIS) is a deformation of the spine and it is routinely diagnosed using posteroanterior and lateral radiographs. The Risser sign used in skeletal maturity assessment is commonly accepted in AIS patient's management. However, the Risser sign is subject to inter-observer variability and it relies mainly on the observation of ossification on the iliac crests. This study proposes a new machine-learning-based approach for Risser sign skeletal maturity assessment using EOS radiographs. Regions of interest including right and left humeral heads; left and right femoral heads; and pelvis are extracted from the radiographs. First, a total of 24 image features is extracted from EOS radiographs using a ResNet101-type convolutional neural network (CNN), pre-trained from the ImageNet database. Then, a support vector machine (SVM) algorithm is used for the final Risser sign classification. The experimental results demonstrate an overall accuracy of 84%, 78%, and 80% respectively for iliac crests, humeral heads, and femoral heads. Class activation maps using Grad-CAM were also investigated to understand the features of our model. In conclusion, our machine learning approach is promising to incorporate a large number of image features for different regions of interest to improve Risser grading for skeletal maturity. Automatic classification could contribute to the management of AIS patients.",0,0
6949,"DeepCervix: A deep learning-based framework for the classification of cervical cells using hybrid deep feature fusion techniques. Cervical cancer, one of the most common fatal cancers among women, can be prevented by regular screening to detect any precancerous lesions at early stages and treat them. Pap smear test is a widely performed screening technique for early detection of cervical cancer, whereas this manual screening method suffers from high false-positive results because of human errors. To improve the manual screening practice, machine learning (ML) and deep learning (DL) based computer-aided diagnostic (CAD) systems have been investigated widely to classify cervical Pap cells. Most of the existing studies require pre-segmented images to obtain good classification results. In contrast, accurate cervical cell segmentation is challenging because of cell clustering. Some studies rely on handcrafted features, which cannot guarantee the classification stage's optimality. Moreover, DL provides poor performance for a multiclass classification task when there is an uneven distribution of data, which is prevalent in the cervical cell dataset. This investigation has addressed those limitations by proposing DeepCervix, a hybrid deep feature fusion (HDFF) technique based on DL, to classify the cervical cells accurately. Our proposed method uses various DL models to capture more potential information to enhance classification performance. Our proposed HDFF method is tested on the publicly available SIPaKMeD dataset and compared the performance with base DL models and the late fusion (LF) method. For the SIPaKMeD dataset, we have obtained the state-of-the-art classification accuracy of 99.85%, 99.38%, and 99.14% for 2-class, 3-class, and 5-class classification. This method is also tested on the Herlev dataset and achieves an accuracy of 98.32% for 2-class and 90.32% for 7-class classification. The source code of the DeepCervix model is available at: https://github.com/Mamunur-20/DeepCervix.",0,0
6958,"Development and validation of a simplified risk score for the prediction of critical COVID-19 illness in newly diagnosed patients. Scores to identify patients at high risk of progression of coronavirus disease (COVID-19), caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), may become instrumental for clinical decision-making and patient management. We used patient data from the multicentre Lean European Open Survey on SARS-CoV-2-Infected Patients (LEOSS) and applied variable selection to develop a simplified scoring system to identify patients at increased risk of critical illness or death. A total of 1946 patients who tested positive for SARS-CoV-2 were included in the initial analysis and assigned to derivation and validation cohorts (nâ€‰=â€‰1297 and nâ€‰=â€‰649, respectively). Stability selection from over 100 baseline predictors for the combined endpoint of progression to the critical phase or COVID-19-related death enabled the development of a simplified score consisting of five predictors: C-reactive protein (CRP), age, clinical disease phase (uncomplicated vs. complicated), serum urea, and D-dimer (abbreviated as CAPS-D score). This score yielded an area under the curve (AUC) of 0.81 (95% confidence interval [CI]: 0.77-0.85) in the validation cohort for predicting the combined endpoint within 7 days of diagnosis and 0.81 (95% CI: 0.77-0.85) during full follow-up. We used an additional prospective cohort of 682 patients, diagnosed largely after the ""first wave"" of the pandemic to validate the predictive accuracy of the score and observed similar results (AUC for the event within 7 days: 0.83 [95% CI: 0.78-0.87]; for full follow-up: 0.82 [95% CI: 0.78-0.86]). An easily applicable score to calculate the risk of COVID-19 progression to critical illness or death was thus established and validated.",0,0
6973,"Using electronic health records to develop and validate a machine-learning tool to predict type 2 diabetes outcomes: a study protocol. Type 2 diabetes mellitus (T2DM) is a major cause of blindness, kidney failure, myocardial infarction, stroke and lower limb amputation. We are still unable, however, to accurately predict or identify which patients are at a higher risk of deterioration. Most risk stratification tools do not account for novel factors such as sociodemographic determinants, self-management ability or access to healthcare. Additionally, most tools are based in clinical trials, with limited external generalisability.",0,0
6985,"Quantum algorithm for quicker clinical prognostic analysis: an application and experimental study using CT scan images of COVID-19 patients. In medical diagnosis and clinical practice, diagnosing a disease early is crucial for accurate treatment, lessening the stress on the healthcare system. In medical imaging research, image processing techniques tend to be vital in analyzing and resolving diseases with a high degree of accuracy. This paper establishes a new image classification and segmentation method through simulation techniques, conducted over images of COVID-19 patients in India, introducing the use of Quantum Machine Learning (QML) in medical practice.",0,0
6986,"A novel deep learning approach to extract Chinese clinical entities for lung cancer screening and staging. Computed tomography (CT) reports record a large volume of valuable information about patients' conditions and the interpretations of radiology images from radiologists, which can be used for clinical decision-making and further academic study. However, the free-text nature of clinical reports is a critical barrier to use this data more effectively. In this study, we investigate a novel deep learning method to extract entities from Chinese CT reports for lung cancer screening and TNM staging.",0,0
6987,The 30-days hospital readmission risk in diabetic patients: predictive modeling with machine learning classifiers. Diabetes mellitus is a major chronic disease that results in readmissions due to poor disease control. Here we established and compared machine learning (ML)-based readmission prediction methods to predict readmission risks of diabetic patients.,0,0
6988,"A particle swarm optimization improved BP neural network intelligent model for electrocardiogram classification. As proven to reflect the work state of heart and physiological situation objectively, electrocardiogram (ECG) is widely used in the assessment of human health, especially the diagnosis of heart disease. The accuracy and reliability of abnormal ECG (AECG) decision depend to a large extent on the feature extraction. However, it is often uneasy or even impossible to obtain accurate features, as the detection process of ECG is easily disturbed by the external environment. And AECG got many species and great variation. What's more, the ECG result obtained after a long time past, which can not reach the purpose of early warning or real-time disease diagnosis. Therefore, developing an intelligent classification model with an accurate feature extraction method to identify AECG is of quite significance. This study aimed to explore an accurate feature extraction method of ECG and establish a suitable model for identifying AECG and the diagnosis of heart disease.",0,0
6989,"Learning rich features with hybrid loss for brain tumor segmentation. Accurately segment the tumor region of MRI images is important for brain tumor diagnosis and radiotherapy planning. At present, manual segmentation is wildly adopted in clinical and there is a strong need for an automatic and objective system to alleviate the workload of radiologists.",0,0
6995,"A deep semantic segmentation correction network for multi-model tiny lesion areas detection. Semantic segmentation of white matter hyperintensities related to focal cerebral ischemia (FCI) and lacunar infarction (LACI) is of significant importance for the automatic screening of tiny cerebral lesions and early prevention of LACI. However, existing studies on brain magnetic resonance imaging lesion segmentation focus on large lesions with obvious features, such as glioma and acute cerebral infarction. Owing to the multi-model tiny lesion areas of FCI and LACI, reliable and precise segmentation and/or detection of these lesion areas is still a significant challenge task.",0,0
6996,"Research on epileptic EEG recognition based on improved residual networks of 1-D CNN and indRNN. Epilepsy is one of the diseases of the nervous system, which has a large population in the world. Traditional diagnosis methods mostly depended on the professional neurologists' reading of the electroencephalogram (EEG), which was time-consuming, inefficient, and subjective. In recent years, automatic epilepsy diagnosis of EEG by deep learning had attracted more and more attention. But the potential of deep neural networks in seizure detection had not been fully developed.",0,0
6997,"Early warning of citric acid overdose and timely adjustment of regional citrate anticoagulation based on machine learning methods. Regional citrate anticoagulation (RCA) is an important local anticoagulation method during bedside continuous renal replacement therapy. To improve patient safety and achieve computer assisted dose monitoring and control, we took intensive care units patients into cohort and aiming at developing a data-driven machine learning model to give early warning of citric acid overdose and provide adjustment suggestions on citrate pumping rate and 10% calcium gluconate input rate for RCA treatment.",0,0
7002,"Prediction of breast cancer molecular subtypes using DCE-MRI based on CNNs combined with ensemble learning. To design an ensemble learning based prediction model using different breast DCE-MR post-contrast sequence images to distinguish two kinds of breast cancer subtypes (luminal and non-luminal). We retrospectively studied preoperative dynamic contrast enhanced-magnetic resonance imaging and molecular information of 266 breast cancer cases with either luminal subtype (luminal A and luminal B) or non-luminal subtype (human epidermal growth factor receptor 2 and triple negative). Then, multiple bounding boxes covering tumor lesions were acquired from three series of post-contrast DCE-MR sequence images which were determined by radiologists. Afterwards, three baseline convolutional neural networks (CNNs) with same architecture were concurrently trained, followed by preliminary prediction of probabilities from the testing database. Finally, the classification and evaluation of breast subtypes were realized by means of fusing predicted results from three CNNs employed via ensemble learning based on weighted voting. Taking advantage of 5-fold cross validation CV, the average prediction specificity, accuracy, precision and area under the ROC curve on testing dataset for the luminal versus non-luminal are 0.958, 0.852, 0.961, and 0.867, respectively, which empirically demonstrate that our proposed ensemble model has highly reliability and robustness. The breast DCE-MR post-contrast sequence image analysis utilizing the ensemble CNN model based on deep learning could show a valuable and extendible practical application on breast molecular subtype identification.",0,0
7003,"ARTS: A novel In-vivo classifier of arteriolosclerosis for the older adult brain. Brain arteriolosclerosis, one of the main pathologies of cerebral small vessel disease, is common in older adults and has been linked to lower cognitive and motor function and higher odds of dementia. In spite of its frequency and associated morbidity, arteriolosclerosis can only be diagnosed at autopsy. Therefore, the purpose of this work was to develop an in-vivo classifier of arteriolosclerosis based on brain MRI. First, an ex-vivo classifier of arteriolosclerosis was developed based on features related to white matter hyperintensities, diffusion anisotropy and demographics by applying machine learning to ex-vivo MRI and pathology data from 119 participants of the Rush Memory and Aging Project (MAP) and Religious Orders Study (ROS), two longitudinal cohort studies of aging that recruit non-demented older adults. The ex-vivo classifier showed good performance in predicting the presence of arteriolosclerosis, with an average area under the receiver operating characteristic curve AUCÂ =Â 0.78. The ex-vivo classifier was then translated to in-vivo based on available in-vivo and ex-vivo MRI data on the same participants. The in-vivo classifier was named ARTS (short for ARTerioloSclerosis), is fully automated, and provides a score linked to the likelihood a person suffers from arteriolosclerosis. The performance of ARTS in predicting the presence of arteriolosclerosis in-vivo was tested in a separate, 91% dementia-free group of 79 MAP/ROS participants and exhibited an AUCÂ =Â 0.79 in persons with antemortem intervals shorter than 2.4Â years. This level of performance in mostly non-demented older adults is notable considering that arteriolosclerosis can only be diagnosed at autopsy. The scan-rescan reproducibility of the ARTS score was excellent, with an intraclass correlation of 0.99, suggesting that application of ARTS in longitudinal studies may show high sensitivity in detecting small changes. Finally, higher ARTS scores in non-demented older adults were associated with greater decline in cognition two years after baseline MRI, especially in perceptual speed which has been linked to arteriolosclerosis and small vessel disease. This finding was shown in a separate group of 369 non-demented MAP/ROS participants and was validated in 72 non-demented Black participants of the Minority Aging Research Study (MARS) and also in 244 non-demented participants of the Alzheimer's Disease Neuroimaging Initiative 2 and 3. The results of this work suggest that ARTS may have broad implications in the advancement of diagnosis, prevention and treatment of arteriolosclerosis. ARTS is publicly available at https://www.nitrc.org/projects/arts/.",0,0
7006,"Design of intelligent diabetes mellitus detection system using hybrid feature selection based XGBoost classifier. In this work, a non-invasive diabetes mellitus detection system is proposed based on the wristband photoplethysmography (PPG) signal and basic physiological parameters (PhyP) to enable easy detection of diabetes mellitus (DM). A dataset of 217 participants with diabetes, prediabetes and normal conditions is used to develop the system. The Mel frequency cepstral coefficients (MFCC) extracted from 5s PPG signal segments and the PhyP are used as input for the machine learning algorithms. The K-nearest neighbors, support vector machine, random forest and extreme gradient boost (XGBoost) classifiers are used for classification. In addition, a hybrid feature selection method (Hybrid FS) is proposed to reduce the size of the input data. The Hybrid FS-based XGBoost system achieves a high accuracy of 99.93Â % for non-invasive diabetes detection with fewer features and less computational effort. The analysis suggests that the PPG signal from a wearable sensor is a good alternative for simple non-invasive blood glucose measurements in routine applications.",0,0
7008,"Multi-model and multi-slice ensemble learning architecture based on 2D convolutional neural networks for Alzheimer's disease diagnosis. Alzheimer's Disease (AD) is a chronic neurodegenerative disease without effective medications or supplemental treatments. Thus, predicting AD progression is crucial for clinical practice and medical research. Due to limited neuroimaging data, two-dimensional convolutional neural networks (2D CNNs) have been commonly adopted to differentiate among cognitively normal subjects (CN), people with mild cognitive impairment (MCI), and AD patients. Therefore, this paper proposes an ensemble learning (EL) architecture based on 2D CNNs, using a multi-model and multi-slice ensemble. First, the top 11 coronal slices of grey matter density maps for AD versus CN classifications were selected. Second, the discriminator of a generative adversarial network, VGG16, and ResNet50 were trained with the selected slices, and the majority voting scheme was used to merge the multi-slice decisions of each model. Afterwards, those three classifiers were used to construct an ensemble model. Multi-slice ensemble learning was designed to obtain spatial features, while multi-model integration reduced the prediction error rate. Finally, transfer learning was used in domain adaptation to refine those CNNs, moving them from working solely with AD versus CN classifications to being applicable to other tasks. This ensemble approach achieved accuracy values of 90.36%, 77.19%, and 72.36% when classifying AD versus CN, AD versus MCI, and MCI versus CN, respectively. Compared with other state-of-the-art 2D studies, the proposed approach provides an effective, accurate, automatic diagnosis along the AD continuum. This technique may enhance AD diagnostics when the sample size is limited.",0,0
7009,"Detection of segmented uterine cancer images by Hotspot Detection method using deep learning models, Pigeon-Inspired Optimization, types-based dominant activation selection approaches. Uterine cancer consists of cells of a layer that forms the inside of the uterus. Sometimes, as a result of abnormal growth of normal cells, it can damage the surrounding tissues and cause the formation of cancerous cells. In the USA, according to the projections for 2021, approximately 66 thousand new cases of uterine cancer will be detected and approximately 13 thousand of these cancer patients are expected to die from uterine cancer. Early diagnosis of cancer is important. Recently, artificial intelligence-based technologies have been used in the diagnosis and treatment processes of various diseases. In this study, five categories of datasets including normal, abnormal, and benign cells were used. The dataset consists of cellular images and is publicly available. The proposed approach consists of three steps. In the first step, the Hotspot method was used to detect the tumor cells in the images. In the second step, tumor cells that were brought to the fore by segmentation were trained by deep learning models, and activation sets of five types from each deep learning model were created. In the last step, the best activation sets were selected among the activation sets obtained by deep learning models of each type (for five dataset types). Pigeon-Inspired Optimization was used for this selection. Thus, the activation sets with the best performance of the five types were classified by the Softmax method. The overall accuracy success achieved with the approach suggested as a result of the classification was 99.65%.",0,0
7010,"Automatic identification of malaria and other red blood cell inclusions using convolutional neural networks. Malaria is a serious disease responsible for thousands of deaths each year. Many efforts have been made to aid in the diagnosis of malaria using machine learning techniques, but to date, the presence of other elements that may interfere with the recognition of malaria has not been considered. We have developed the first deep learning model using convolutional neural networks capable of differentiating malaria-infected red blood cells from not only normal erythrocytes but also erythrocytes with other types of inclusions. 6415 images of red blood cells were segmented from digital images of 53 peripheral blood smears using thresholding and watershed transformation techniques. These images were used to train a VGG-16 architecture using transfer learning. Using an independent test set of 23 smears, this model was 99.5% accurate in classifying malaria parasites and other red blood cell inclusions. This model also exhibited sensitivity and specificity values of 100% and 91.7%, respectively, classifying a complete smear as infected or not infected. Our model represents a promising advance for automation in the identification of malaria-infected patients. The differentiation between malaria parasites and other red blood cell inclusions demonstrates the potential utility of our model in a real work environment.",0,0
7012,Comparing Artificial Intelligence and Traditional Methods to Identify Factors Associated With Pediatric Asthma Readmission. To identify and contrast risk factors for six-month pediatric asthma readmissions using traditional models (Cox proportional-hazards and logistic regression) and artificial neural-network modeling.,0,0
7013,"Explainable deep learning predictions for illness risk of mental disorders in Nanjing, China. Epidemiological studies have revealed the associations of air pollutants and meteorological factors with a range of mental health conditions. However, little is known about local explanations and global understanding on the importance and effect of input features in the complex system of environmental stressors - mental disorders (MDs), especially for exposure to air pollution mixture. In this study, we combined deep learning neural networks (DLNNs) with SHapley Additive exPlanation (SHAP) to predict the illness risk of MDs on the population level, and then provided explanations for risk factors. The modeling system, which was trained on day-by-day hospital outpatient visits of two major hospitals in Nanjing, China from 2013/07/01 through 2019/02/28, visualized the time-varying prediction, contributing factors, and interaction effects of informative features. Our results suggested that NO<sub>2</sub>, SO<sub>2</sub>, and CO made outstanding contributions in magnitude of feature attributions under circumstances of mixed air pollutants. In particular, NO<sub>2</sub> at high concentration level was associated with an increase in illness risk of MDs, and the maximum and mean absolute SHAP value were approximated to 10 and 2 as a local and global measure of feature importance, respectively. It presented a marginally antagonistic effect for two pairs of gaseous pollutants, i.e., NO<sub>2</sub> vs. SO<sub>2</sub> and CO vs. NO<sub>2</sub>. In contrast, CO and SO<sub>2</sub> displayed the opposite direction of feature effects to the rise of observed concentrations, but an apparent synergistic effect was obviously captured. The primary risk factors driving a sharp increase in acute attack or exacerbation of MDs were also identified by depicting prediction paths of time-series samples. We believe that the significance of coupling accurate predictions from DLNNs with interpretable explanations of why a prediction is completed has broad applicability throughout the field of environmental health.",0,0
7021,"Deep learning with robustness to missing data: A novel approach to the detection of COVID-19. In the context of the current global pandemic and the limitations of the RT-PCR test, we propose a novel deep learning architecture, DFCN (Denoising Fully Connected Network). Since medical facilities around the world differ enormously in what laboratory tests or chest imaging may be available, DFCN is designed to be robust to missing input data. An ablation study extensively evaluates the performance benefits of the DFCN as well as its robustness to missing inputs. Data from 1088 patients with confirmed RT-PCR results are obtained from two independent medical facilities. The data includes results from 27 laboratory tests and a chest x-ray scored by a deep learning model. Training and test datasets are taken from different medical facilities. Data is made publicly available. The performance of DFCN in predicting the RT-PCR result is compared with 3 related architectures as well as a Random Forest baseline. All models are trained with varying levels of masked input data to encourage robustness to missing inputs. Missing data is simulated at test time by masking inputs randomly. DFCN outperforms all other models with statistical significance using random subsets of input data with 2-27 available inputs. When all 28 inputs are available DFCN obtains an AUC of 0.924, higher than any other model. Furthermore, with clinically meaningful subsets of parameters consisting of just 6 and 7 inputs respectively, DFCN achieves higher AUCs than any other model, with values of 0.909 and 0.919.",0,0
7022,"Rapid whole-brain electric field mapping in transcranial magnetic stimulation using deep learning. Transcranial magnetic stimulation (TMS) is a non-invasive neurostimulation technique that is increasingly used in the treatment of neuropsychiatric disorders and neuroscience research. Due to the complex structure of the brain and the electrical conductivity variation across subjects, identification of subject-specific brain regions for TMS is important to improve the treatment efficacy and understand the mechanism of treatment response. Numerical computations have been used to estimate the stimulated electric field (E-field) by TMS in brain tissue. But the relative long computation time limits the application of this approach. In this paper, we propose a deep-neural-network based approach to expedite the estimation of whole-brain E-field by using a neural network architecture, named 3D-MSResUnet and multimodal imaging data. The 3D-MSResUnet network integrates the 3D U-net architecture, residual modules and a mechanism to combine multi-scale feature maps. It is trained using a large dataset with finite element method (FEM) based E-field and diffusion magnetic resonance imaging (MRI) based anisotropic volume conductivity or anatomical images. The performance of 3D-MSResUnet is evaluated using several evaluation metrics and different combinations of imaging modalities and coils. The experimental results show that the output E-field of 3D-MSResUnet provides reliable estimation of the E-field estimated by the state-of-the-art FEM method with significant reduction in prediction time to about 0.24 second. Thus, this study demonstrates that neural networks are potentially useful tools to accelerate the prediction of E-field for TMS targeting.",0,0
7028,"Towards automated assessment of frailty status using a wrist-worn device. Wearable sensors potentially enable monitoring the users physical activity in daily life. Therefore, they are particularly appealing for the evaluation of older subjects in their environment, to capture early signs of frailty and mobility-related problems. This study explores the use of body-worn accelerometers for automated assessment of frailty during walking activity. Experiments involved 34 volunteers aged 70+, who were initially screened by geriatricians for the presence of frailty according to Frieds criteria. After screening, the volunteers were asked to walk 60 m at preferred speed, while wearing two accelerometers, one positioned on the lower back and the other on the wrist. Sensor-derived signals were analyzed independently to compare the ability of the two signals (wrist vs. lower back) in frailty status assessment. A gait detection technique was applied to identify segments made of four gait cycles. These segments were then used as input to compute 25 features in time and time-frequency domains, the latter by means of the Wavelet Transform. Finally, five machine learning models were trained and evaluated to classify subjects as robust or non-robust (i.e., pre-frail or frail). Gaussian naive Bayes applied to the features derived from the wrist sensor signal identified non-robust subjects with 91% sensitivity and 82% specificity, compared to 87% sensitivity and 64% specificity achieved with the lower back sensor. Results demonstrate that a wrist-worn accelerometer provides valuable information for the recognition of frailty in older adults, and could represent an effective tool to enable automated and unobtrusive assessment of frailty.",0,0
7029,"Multiparametric Quantitative US Examination of Liver Fibrosis: A Feature-engineering and Machine-learning Based Analysis. Quantitative ultrasound (QUS), which is commonly used to extract quantitative features from the ultrasound radiofrequency (RF) data or the RF envelope signals for tissue characterization, is becoming a promising technique for noninvasive assessments of liver fibrosis. However, the number of feature variables examined and finally used in the existing QUS methods is typically small, to some extent limiting the diagnostic performance. Therefore, this paper devises a new multiparametric QUS (MP-QUS) method which enables the extraction of a large number of feature variables from US RF signals and allows for the use of feature-engineering and machinelearning based algorithms for liver fibrosis assessment. In the MP-QUS, eighty-four feature variables were extracted from multiple QUS parametric maps derived from the RF signals and the envelope data. Afterwards, feature reduction and selection were performed in turn to remove the feature redundancy and identify the best combination of features in the reduced feature set. Finally, a variety of machine-learning algorithms were tested for classifying liver fibrosis with the selected features, based on the results of which the optimal classifier was established and used for final classification. The performance of the proposed MPQUS method for staging liver fibrosis was evaluated on an animal model, with histologic examination as the reference standard. The mean accuracy, sensitivity, specificity and area under the receiver-operating-characteristic curve achieved by MP-QUS are respectively 83.38%, 86.04%, 80.82% and 0.891 for recognizing significant liver fibrosis, and 85.50%, 88.92%, 85.24% and 0.924 for diagnosing liver cirrhosis. The proposed MP-QUS method paves a way for its future extension to assess liver fibrosis in human subjects.",0,0
7044,"SCU-Net: A deep learning method for segmentation and quantification of breast arterial calcifications on mammograms. Measurements of breast arterial calcifications (BAC) can offer a personalized, non-invasive approach to risk-stratify women for cardiovascular diseases such as heart attack and stroke. We aim to detect and segment breast arterial calcifications in mammograms accurately and suggest novel measurements to quantify detected BAC for future clinical applications.",0,0
7046,Application of deep-learning to the seronegative side of the NMO spectrum. To apply a deep-learning algorithm to brain MRIs of seronegative patients with neuromyelitis optica spectrum disorders (NMOSD) and NMOSD-like manifestations and assess whether their structural features are similar to aquaporin-4-seropositive NMOSD or multiple sclerosis (MS) patients.,0,0
7048,"A 3D deep learning model to predict the diagnosis of dementia with Lewy bodies, Alzheimer's disease, and mild cognitive impairment using brain 18F-FDG PET. The purpose of this study is to develop and validate a 3D deep learning model that predicts the final clinical diagnosis of Alzheimer's disease (AD), dementia with Lewy bodies (DLB), mild cognitive impairment due to Alzheimer's disease (MCI-AD), and cognitively normal (CN) using fluorine 18 fluorodeoxyglucose PET (18F-FDG PET) and compare model's performance to that of multiple expert nuclear medicine physicians' readers.",1,1
7049,"Co-clinical FDG-PET radiomic signature in predicting response to neoadjuvant chemotherapy in triple-negative breast cancer. We sought to exploit the heterogeneity afforded by patient-derived tumor xenografts (PDX) to first, optimize and identify robust radiomic features to predict response to therapy in subtype-matched triple negative breast cancer (TNBC) PDX, and second, to implement PDX-optimized image features in a TNBC co-clinical study to predict response to therapy using machine learning (ML) algorithms.",0,0
7052,"Predicting Depressive Symptom Severity Through Individuals' Nearby Bluetooth Device Count Data Collected by Mobile Phones: Preliminary Longitudinal Study. Research in mental health has found associations between depression and individuals' behaviors and statuses, such as social connections and interactions, working status, mobility, and social isolation and loneliness. These behaviors and statuses can be approximated by the nearby Bluetooth device count (NBDC) detected by Bluetooth sensors in mobile phones.",0,0
7064,"Artificial intelligence and polyp detection in colonoscopy: Use of a single neural network to achieve rapid polyp localization for clinical use. Artificial intelligence has been extensively studied to assist clinicians in polyp detection, but such systems usually require expansive processing power, making them prohibitively expensive and hindering wide adaption. The current study used a fast object detection algorithm, known as the YOLOv3 algorithm, to achieve real-time polyp detection on a laptop. In addition, we evaluated and classified the causes of false detections to further improve accuracy.",0,0
7067,"Multi-level Kronecker Convolutional Neural Network (ML-KCNN) for Glioma Segmentation from Multi-modal MRI Volumetric Data. The development of an automated glioma segmentation system from MRI volumes is a difficult task because of data imbalance problem. The ability of deep learning models to incorporate different layers for data representation assists medical experts like radiologists to recognize the condition of the patient and further make medical practices easier and automatic. State-of-the-art deep learning algorithms enable advancement in the medical image segmentation area, such a segmenting the volumes into sub-tumor classes. For this task, fully convolutional network (FCN)-based architectures are used to build end-to-end segmentation solutions. In this paper, we proposed a multi-level Kronecker convolutional neural network (MLKCNN) that captures information at different levels to have both local and global level contextual information. Our ML-KCNN uses Kronecker convolution, which overcomes the missing pixels problem by dilated convolution. Moreover, we used a post-processing technique to minimize false positive from segmented outputs, and the generalized dice loss (GDL) function handles the data-imbalance problem. Furthermore, the combination of connected component analysis (CCA) with conditional random fields (CRF) used as a post-processing technique achieves reduced Hausdorff distance (HD) score of 3.76 on enhancing tumor (ET), 4.88 on whole tumor (WT), and 5.85 on tumor core (TC). Dice similarity coefficient (DSC) of 0.74 on ET, 0.90 on WT, and 0.83 on TC. Qualitative and visual evaluation of our proposed method shown effectiveness of the proposed segmentation method can achieve performance that can compete with other brain tumor segmentation techniques.",0,0
7068,"Anatomic Point-Based Lung Region with Zone Identification for Radiologist Annotation and Machine Learning for Chest Radiographs. Our objective is to investigate the reliability and usefulness of anatomic point-based lung zone segmentation on chest radiographs (CXRs) as a reference standard framework and to evaluate the accuracy of automated point placement. Two hundred frontal CXRs were presented to two radiologists who identified five anatomic points: two at the lung apices, one at the top of the aortic arch, and two at the costophrenic angles. Of these 1000 anatomic points, 161 (16.1%) were obscured (mostly by pleural effusions). Observer variations were investigated. Eight anatomic zones then were automatically generated from the manually placed anatomic points, and a prototype algorithm was developed using the point-based lung zone segmentation to detect cardiomegaly and levels of diaphragm and pleural effusions. A trained U-Net neural network was used to automatically place these five points within 379 CXRs of an independent database. Intra- and inter-observer variation in mean distance between corresponding anatomic points was larger for obscured points (8.7Â mm and 20Â mm, respectively) than for visible points (4.3Â mm and 7.6Â mm, respectively). The computer algorithm using the point-based lung zone segmentation could diagnostically measure the cardiothoracic ratio and diaphragm position or pleural effusion. The mean distance between corresponding points placed by the radiologist and by the neural network was 6.2Â mm. The network identified 95% of the radiologist-indicated points with only 3% of network-identified points being false-positives. In conclusion, a reliable anatomic point-based lung segmentation method for CXRs has been developed with expected utility for establishing reference standards for machine learning applications.",1,1
7070,"CT-Based Hand-crafted Radiomic Signatures Can Predict PD-L1 Expression Levels in Non-small Cell Lung Cancer: a Two-Center Study. Here, we used pre-treatment CT images to develop and evaluate a radiomic signature that can predict the expression of programmed death ligand 1 (PD-L1) in non-small cell lung cancer (NSCLC). We then verified its predictive performance by cross-referencing its results with clinical characteristics. This two-center retrospective analysis included 125 patients with histologically confirmed NSCLC. A total of 1287 hand-crafted radiomic features were observed from manually determined tumor regions. Valuable features were then selected with a ridge regression-based recursive feature elimination approach. Machine learning-based prediction models were then built from this and compared each other. The final radiomic signature was built using logistic regression in the primary cohort, and then tested in a validation cohort. Finally, we compared the efficacy of the radiomic signature to the clinical model and the radiomic-clinical nomogram. Among the 125 patients, 89 were classified as having PD-L1 positive expression. However, there was no significant difference in PD-L1 expression levels determined by clinical characteristics (Pâ€‰=â€‰0.109-0.955). Upon selecting 9 radiomic features, we found that the logistic regression-based prediction model performed the best (AUCâ€‰=â€‰0.96, Pâ€‰<â€‰0.001). In the external cohort, our radiomic signature showed an AUC of 0.85, which outperformed both the clinical model (AUCâ€‰=â€‰0.38, Pâ€‰<â€‰0.001) and the radiomics-nomogram model (AUCâ€‰=â€‰0.61, Pâ€‰<â€‰0.001). Our CT-based hand-crafted radiomic signature model can effectively predict PD-L1 expression levels, providing a noninvasive means of better understanding PD-L1 expression in patients with NSCLC.",0,0
7075,"County-level phenomapping to identify disparities in cardiovascular outcomes: An unsupervised clustering analysis: Short title: Unsupervised clustering of counties and risk of cardiovascular mortality. Significant heterogeneity in cardiovascular disease (CVD) risk and healthcare resource allocation has been demonstrated in the United States, but optimal methods to capture heterogeneity in county-level characteristics that contribute to CVD mortality differences are unclear. We evaluated the feasibility of unsupervised machine learning (ML)-based phenomapping in identifying subgroups of county-level social and demographic risk factors with differential CVD outcomes.",0,0
7076,"Careful feature selection is key in classification of Alzheimer's disease patients based on whole-genome sequencing data. Despite great increase of the amount of data from genome-wide association studies (GWAS) and whole-genome sequencing (WGS), the genetic background of a partially heritable Alzheimer's disease (AD) is not fully understood yet. Machine learning methods are expected to help researchers in the analysis of the large number of SNPs possibly associated with the disease onset. To date, a number of such approaches were applied to genotype-based classification of AD patients and healthy controls using GWAS data and reported accuracy of 0.65-0.975. However, since the estimated influence of genotype on sporadic AD occurrence is lower than that, these very high classification accuracies may potentially be a result of overfitting. We have explored the possibilities of applying feature selection and classification using random forests to WGS and GWAS data from two datasets. Our results suggest that this approach is prone to overfitting if feature selection is performed before division of data into the training and testing set. Therefore, we recommend avoiding selection of features used to build the model based on data included in the testing set. We suggest that for currently available dataset sizes the expected classifier performance is between 0.55 and 0.7 (AUC) and higher accuracies reported in literature are likely a result of overfitting.",0,0
7079,"Development and Validation of a Magnetic Resonance Imaging-Based Machine Learning Model for TMJ Pathologies. The purpose of this study was to propose a machine learning model and assess its ability to classify TMJ pathologies on magnetic resonance (MR) images. This retrospective cohort study included 214 TMJs from 107 patients with TMJ signs and symptoms. A radiomics platform was used to extract (Huiying Medical Technology Co., Ltd., China) imaging features of TMJ pathologies, condylar bone changes, and disc displacements. Thereafter, different machine learning (ML) algorithms and logistic regression were implemented on radiomic features for feature selection, classification, and prediction. The following radiomic features included first-order statistics, shape, texture, gray-level cooccurrence matrix (GLCM), gray-level run length matrix (GLRLM), and gray-level size zone matrix (GLSZM). Six classifiers, including logistic regression (LR), random forest (RF), decision tree (DT), <i>k</i>-nearest neighbors (KNN), XGBoost, and support vector machine (SVM) were used for model building which could predict the TMJ pathologies. The performance of models was evaluated by sensitivity, specificity, and ROC curve. KNN and RF classifiers were found to be the most optimal machine learning model for the prediction of TMJ pathologies. The AUC, sensitivity, and specificity for the training set were 0.89 and 1, while those for the testing set were 0.77 and 0.74, respectively, for condylar changes and disc displacement, respectively. For TMJ condylar bone changes Large-Area High-Gray-Level Emphasis, Gray-Level Nonuniformity, Long-Run Emphasis Long-Run High-Gray-Level Emphasis, Flatness, and Volume features, while for TMJ disc displacements Average Intensity, Sum Average, Spherical Disproportion, and Entropy features, were selected. This study has proposed a machine learning model by KNN and RF analysis on TMJ MR images, which can be used to classify condylar changes and TMJ disc displacements.",0,0
7082,"Machine Learning Algorithm Using Electronic Chart-Derived Data to Predict Delirium After Elderly Hip Fracture Surgeries: A Retrospective Case-Control Study. <b>Background:</b> Elderly patients undergoing hip fracture repair surgery are at increased risk of delirium due to aging, comorbidities, and frailty. But current methods for identifying the high risk of delirium among hospitalized patients have moderate accuracy and require extra questionnaires. Artificial intelligence makes it possible to establish machine learning models that predict incident delirium risk based on electronic health data. <b>Methods:</b> We conducted a retrospective case-control study on elderly patients (â‰¥65 years of age) who received orthopedic repair with hip fracture under spinal or general anesthesia between June 1, 2018, and May 31, 2019. Anesthesia records and medical charts were reviewed to collect demographic, surgical, anesthetic features, and frailty index to explore potential risk factors for postoperative delirium. Delirium was assessed by trained nurses using the Confusion Assessment Method (CAM) every 12 h during the hospital stay. Four machine learning risk models were constructed to predict the incidence of postoperative delirium: random forest, eXtreme Gradient Boosting (XGBoosting), support vector machine (SVM), and multilayer perception (MLP). K-fold cross-validation was deployed to accomplish internal validation and performance evaluation. <b>Results:</b> About 245 patients were included and postoperative delirium affected 12.2% (30/245) of the patients. Multiple logistic regression revealed that dementia/history of stroke [OR 3.063, 95% CI (1.231, 7.624)], blood transfusion [OR 2.631, 95% CI (1.055, 6.559)], and preparation time [OR 1.476, 95% CI (1.170, 1.862)] were associated with postoperative delirium, achieving an area under receiver operating curve (AUC) of 0.779, 95% CI (0.703, 0.856). The accuracy of machine learning models for predicting the occurrence of postoperative delirium ranged from 83.67 to 87.75%. Machine learning methods detected 16 risk factors contributing to the development of delirium. Preparation time, frailty index uses of vasopressors during the surgery, dementia/history of stroke, duration of surgery, and anesthesia were the six most important risk factors of delirium. <b>Conclusion:</b> Electronic chart-derived machine learning models could generate hospital-specific delirium prediction models and calculate the contribution of risk factors to the occurrence of delirium. Further research is needed to evaluate the significance and applicability of electronic chart-derived machine learning models for the detection risk of delirium in elderly patients undergoing hip fracture repair surgeries.",0,0
7083,"Long-Term Mechanical Ventilation in Neonates: A 10-Year Overview and Predictive Model. <b>Objectives:</b> Significant resources are devoted to neonatal prolonged mechanical ventilation (NPMV), but little is known about the outcomes in those children. Our primary objective was to describe the NPMV respiratory, digestive, and neurological outcomes at 18 months corrected age. Our second objective was on the early identification of which patients, among the NPMV cohort, will need to be ventilated for â‰¥125 days, which corresponded to the 75th percentile in the preliminary data, and to describe that subgroup. <b>Methods:</b> In this retrospective cohort study, we included all children born between 2004 and 2013 who had a NPMV (â‰¥21 days of invasive or noninvasive respiratory support reached between 40 and 44 weeks of postconceptional age). We used random forests, logistic regression with penalization, naive Bayes, and XGBoost to predict which patients will need â‰¥125 days of ventilation. We used a Monte Carlo cross validation. <b>Results:</b> We included 164 patients. Of which, 40% (<i>n</i> = 66) were female, and the median gestational age was 29 weeks [interquartile range (IQR): 26-36 weeks] with a bimodal distribution. Median ventilation days were 104 (IQR: 66-139 days). The most frequently associated diagnoses were pulmonary hypertension (43%), early pulmonary dysplasia (41%), and lobar emphysema (37%). At 18 months corrected age, 29% (<i>n</i> = 47) had died, 59% (<i>n</i> = 97) were free of any respiratory support, and 45% (<i>n</i> = 74) were exclusively orally fed. A moderate area under the ROC curve of 0.65 (95% CI: 0.54-0.72) for identifying patients in need of â‰¥125 days of ventilation at inclusion was achieved by random forests classifiers. Among the 26 measured at inclusion, the most contributive ones were PCO<sub>2</sub>, inspired O<sub>2</sub> concentration, and gestational age. At 18 months corrected age, patients ventilated for â‰¥125 days had a lower respiratory weaning success (76 vs. 87%, <i>P</i> = 0.05), lower exclusive oral feeding proportion (51 vs. 84%, P < 0.001), and a higher neurological impairment (median Pediatric Cerebral Performance Category score 3 vs. 2, <i>P</i> = 0.008) than patients ventilated for < 125 days. <b>Conclusion:</b> NPMV is a severe condition with a high risk of mortality, neurological impairment, and oral feed delay at 18 months. Most survivors are weaned of any respiratory support. We identified the risk factors that allow for the early identification of the most at-risk children of long-term ventilation with a moderate discrimination.",0,0
7084,Preoperative Prediction of Cytokeratin 19 Expression for Hepatocellular Carcinoma with Deep Learning Radiomics Based on Gadoxetic Acid-Enhanced Magnetic Resonance Imaging. Cytokeratin 19 (CK19) expression is a proven independent prognostic predictor of hepatocellular carcinoma (HCC). This study aimed to develop and validate the performance of a deep learning radiomics (DLR) model for CK19 identification in HCC based on preoperative gadoxetic acid-enhanced magnetic resonance imaging (MRI).,0,0
7085,"Pyroptosis-Related Gene Signatures Can Robustly Diagnose Skin Cutaneous Melanoma and Predict the Prognosis. Skin cutaneous melanoma (SKCM) is a chronically malignant tumor with a high mortality rate. Pyroptosis, a kind of pro-inflammatory programmed cell death, has been linked to cancer in recent studies. However, the value of pyroptosis in the diagnosis and prognosis of SKCM is not clear. In this study, it was discovered that 20 pyroptosis-related genes (PRGs) differed in expression between SKCM and normal tissues, which were related to diagnosis and prognosis. Firstly, based on these genes, nine machine-learning algorithms were shown to perform well in constructing diagnostic classifiers, including K-Nearest Neighbor (KNN), logistic regression, Support Vector Machine (SVM), Artificial Neural Network (ANN), decision tree, random forest, XGBoost, LightGBM, and CatBoost. Secondly, the least absolute shrinkage and selection operator (LASSO) Cox regression analysis was applied and the prognostic model was constructed based on 9 PRGs. Subgroups in low and high risks determined by the prognostic model were shown to have different survival. Thirdly, functional enrichment analyses were performed by applying the gene set enrichment analysis (GSEA), and results suggested that the risk was related to immune response. In conclusion, the expression signatures of pyroptosis-related genes are effective and robust in the diagnosis and prognosis of SKCM, which is related to immunity.",0,0
7086,"Development of a Machine Learning Classifier Based on Radiomic Features Extracted From Post-Contrast 3D T1-Weighted MR Images to Distinguish Glioblastoma From Solitary Brain Metastasis. To differentiate Glioblastomas (GBM) and Brain Metastases (BM) using a radiomic features-based Machine Learning (ML) classifier trained from post-contrast three-dimensional T1-weighted (post-contrast 3DT1) MR imaging, and compare its performance in medical diagnosis <i>versus</i> human experts, on a testing cohort.",1,1
7089,"Using AMANHI-ACT cohorts for external validation of Iowa new-born metabolic profiles based models for postnatal gestational age estimation. Globally, 15 million infants are born preterm and another 23.2 million infants are born small for gestational age (SGA). Determining burden of preterm and SGA births, is essential for effective planning, modification of health policies and targeting interventions for reducing these outcomes for which accurate estimation of gestational age (GA) is crucial. Early pregnancy ultrasound measurements, last menstrual period and post-natal neonatal examinations have proven to be not feasible or inaccurate. Proposed algorithms for GA estimation in western populations, based on routine new-born screening, though promising, lack validation in developing country settings. We evaluated the hypothesis that models developed in USA, also predicted GA in cohorts of South Asia (575) and Sub-Saharan Africa (736) with same precision.",0,0
7090,"An Evolutionary Approach for the Enhancement of Dermatological Images and Their Classification Using Deep Learning Models. Dermatological problems are the most widely spread skin diseases amongst human beings. They can be infectious, chronic, and sometimes may also lead to serious health problems such as skin cancer. Generally, rural area clinics lack trained dermatologists and mostly rely on the analysis of remotely accessible experts through mobile-based networks for sharing the images and other related information. Under such circumstances, poor image quality introduced due to the capturing device results in misleading diagnosis. Here, a genetic-algorithm- (GA-) based approach used as an image enhancement technique has been explored to improve the low quality of the dermatological images received from the rural clinic. The diagnosis is performed on the enhanced images using convolutional neural network (CNN) classifier for the identification of the diseases. The scope of this paper is limited to only motion blurred images, which is the most prevalent problem in capturing of the images, specifically when any of the two (device or the object) may move unpredictably. Seven types of skin diseases, namely, melanoma, melanocytic nevus, basal cell carcinoma, actinic keratosis, benign keratosis, vascular lesion, and squamous cell carcinoma, have been investigated using ResNet-152 giving an overall accuracy of 87.40% for the blurred images. Use of GA-enhanced images increased the accuracy to 95.85%. The results were further analyzed using a confusion matrix and <i>t</i>-test-based statistical investigations. The advantage of the proposed technique is that it reduces the analysis time and errors due to manual diagnosis. Furthermore, speedy and reliable diagnosis at the earliest stage reduces the risk of developing more severe skin problems.",0,0
7093,"Lung Cancer Diagnosis Based on an ANN Optimized by Improved TEO Algorithm. A quarter of all cancer deaths are due to lung cancer. Studies show that early diagnosis and treatment of this disease are the most effective way to increase patient life expectancy. In this paper, automatic and optimized computer-aided detection is proposed for lung cancer. The method first applies a preprocessing step for normalizing and denoising the input images. Afterward, Kapur entropy maximization is performed along with mathematical morphology to lung area segmentation. Afterward, 19 GLCM features are extracted from the segmented images for the final evaluations. The higher priority images are then selected for decreasing the system complexity. The feature selection is based on a new optimization design, called Improved Thermal Exchange Optimization (ITEO), which is designed to improve the accuracy and convergence abilities. The images are finally classified into healthy or cancerous cases based on an optimized artificial neural network by ITEO. Simulation is compared with some well-known approaches and the results showed the superiority of the suggested method. The results showed that the proposed method with 92.27% accuracy provides the highest value among the compared methods.",0,0
7094,"Automatic Breast Tumor Diagnosis in MRI Based on a Hybrid CNN and Feature-Based Method Using Improved Deer Hunting Optimization Algorithm. Breast cancer is an unusual mass of the breast texture. It begins with an abnormal change in cell structure. This disease may increase uncontrollably and affects neighboring textures. Early diagnosis of this cancer (abnormal cell changes) can help definitively treat it. Also, prevention of this cancer can help to decrease the high cost of medical caring for breast cancer patients. In recent years, the computer-aided technique is an important active field for automatic cancer detection. In this study, an automatic breast tumor diagnosis system is introduced. An improved Deer Hunting Optimization Algorithm (DHOA) is used as the optimization algorithm. The presented method utilized a hybrid feature-based technique and a new optimized convolutional neural network (CNN). Simulations are applied to the DCE-MRI dataset based on some performance indexes. The novel contribution of this paper is to apply the preprocessing stage to simplifying the classification. Besides, we used a new metaheuristic algorithm. Also, the feature extraction by Haralick texture and local binary pattern (LBP) is recommended. Due to the obtained results, the accuracy of this method is 98.89%, which represents the high potential and efficiency of this method.",0,0
7098,"Prediction of 30-Day Readmission After Stroke Using Machine Learning and Natural Language Processing. <b>Background and Purpose:</b> This study aims to determine whether machine learning (ML) and natural language processing (NLP) from electronic health records (EHR) improve the prediction of 30-day readmission after stroke. <b>Methods:</b> Among index stroke admissions between 2011 and 2016 at an academic medical center, we abstracted discrete data from the EHR on demographics, risk factors, medications, hospital complications, and discharge destination and unstructured textual data from clinician notes. Readmission was defined as any unplanned hospital admission within 30 days of discharge. We developed models to predict two separate outcomes, as follows: (1) 30-day all-cause readmission and (2) 30-day stroke readmission. We compared the performance of logistic regression with advanced ML algorithms. We used several NLP methods to generate additional features from unstructured textual reports. We evaluated the performance of prediction models using a five-fold validation and tested the best model in a held-out test dataset. Areas under the curve (AUCs) were used to compare discrimination of each model. <b>Results:</b> In a held-out test dataset, advanced ML methods along with NLP features out performed logistic regression for all-cause readmission (AUC, 0.64 vs. 0.58; <i>p</i> < 0.001) and stroke readmission prediction (AUC, 0.62 vs. 0.52; <i>p</i> < 0.001). <b>Conclusion:</b> NLP-enhanced machine learning models potentially advance our ability to predict readmission after stroke. However, further improvement is necessary before being implemented in clinical practice given the weak discrimination.",0,0
7109,"Machine learning to predict distal caries in mandibular second molars associated with impacted third molars. Impacted mandibular third molars (M3M) are associated with the occurrence of distal caries on the adjacent mandibular second molars (DCM2M). In this study, we aimed to develop and validate five machine learning (ML) models designed to predict the occurrence of DCM2Ms due to the proximity with M3Ms and determine the relative importance of predictive variables for DCM2Ms that are important for clinical decision making. A total of 2642 mandibular second molars adjacent to M3Ms were analyzed and DCM2Ms were identified in 322 cases (12.2%). The models were trained using logistic regression, random forest, support vector machine, artificial neural network, and extreme gradient boosting ML methods and were subsequently validated using testing datasets. The performance of the ML models was significantly superior to that of single predictors. The area under the receiver operating characteristic curve of the machine learning models ranged from 0.88 to 0.89. Six features (sex, age, contact point at the cementoenamel junction, angulation of M3Ms, Winter's classification, and Pell and Gregory classification) were identified as relevant predictors. These prediction models could be used to detect patients at a high risk of developing DCM2M and ultimately contribute to caries prevention and treatment decision-making for impacted M3Ms.",0,0
7111,"Dialysis adequacy predictions using a machine learning method. Dialysis adequacy is an important survival indicator in patients with chronic hemodialysis. However, there are inconveniences and disadvantages to measuring dialysis adequacy by blood samples. This study used machine learning models to predict dialysis adequacy in chronic hemodialysis patients using repeatedly measured data during hemodialysis. This study included 1333 hemodialysis sessions corresponding to the monthly examination dates of 61 patients. Patient demographics and clinical parameters were continuously measured from the hemodialysis machine; 240 measurements were collected from each hemodialysis session. Machine learning models (random forest and extreme gradient boosting [XGBoost]) and deep learning models (convolutional neural network and gated recurrent unit) were compared with multivariable linear regression models. The mean absolute percentage error (MAPE), root mean square error (RMSE), and Spearman's rank correlation coefficient (Corr) for each model using fivefold cross-validation were calculated as performance measurements. The XGBoost model had the best performance among all methods (MAPEâ€‰=â€‰2.500; RMSEâ€‰=â€‰2.906; Corrâ€‰=â€‰0.873). The deep learning models with convolutional neural network (MAPEâ€‰=â€‰2.835; RMSEâ€‰=â€‰3.125; Corrâ€‰=â€‰0.833) and gated recurrent unit (MAPEâ€‰=â€‰2.974; RMSEâ€‰=â€‰3.230; Corrâ€‰=â€‰0.824) had similar performances. The linear regression models had the lowest performance (MAPEâ€‰=â€‰3.284; RMSEâ€‰=â€‰3.586; Corrâ€‰=â€‰0.770) compared with other models. Machine learning methods can accurately infer hemodialysis adequacy using continuously measured data from hemodialysis machines.",0,0
7122,"Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study. Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.",0,0
7130,Use of the Montreal Cognitive Assessment Thai Version to Discriminate Amnestic Mild Cognitive Impairment from Alzheimer's Disease and Healthy Controls: Machine Learning Results. The Montreal Cognitive Assessment (MoCA) is an effective and applicable screening instrument to confirm the diagnosis of amnestic mild cognitive impairment (aMCI) from patients with Alzheimer's disease (AD) and healthy controls (HCs).,0,0
7131,Cerebral aneurysm image segmentation based on multi-modal convolutional neural network. Accurate segmentation of cerebral aneurysms in computed tomography angiography (CTA) can provide an essential reference for diagnosis and treatment. This study aimed to evaluate a more helpful image segmentation method for cerebral aneurysms.,0,0
7132,"Automatic arteriosclerotic retinopathy grading using four-channel with image merging. Arteriosclerosis can reflect the severity of hypertension, which is one of the main diseases threatening human life safety. But Arteriosclerosis retinopathy detection involves costly and time-consuming manual assessment. To meet the urgent needs of automation, this paper developed a novel arteriosclerosis retinopathy grading method based on convolutional neural network.",0,0
7135,"Comparison of Supervised Machine Learning Algorithms for Classifying of Home Discharge Possibility in Convalescent Stroke Patients: A Secondary Analysis. Classifying the possibility of home discharge is important during stroke rehabilitation to support decision-making. There have been several studies on supervised machine learning algorithms, but only a few have compared the performance of different algorithms based on the same dataset for the classification of home discharge possibility. Therefore, we aimed to evaluate five supervised machine learning algorithms for the classification of home discharge possibility in stroke patients.",0,0
7137,"MSDS-UNet: A multi-scale deeply supervised 3D U-Net for automatic segmentation of lung tumor in CT. Lung cancer is one of the most common and deadly malignant cancers. Accurate lung tumor segmentation from CT is therefore very important for correct diagnosis and treatment planning. The automated lung tumor segmentation is challenging due to the high variance in appearance and shape of the targeting tumors. To overcome the challenge, we present an effective 3D U-Net equipped with ResNet architecture and a two-pathway deep supervision mechanism to increase the network's capacity for learning richer representations of lung tumors from global and local perspectives. Extensive experiments on two real medical datasets: the lung CT dataset from Liaoning Cancer Hospital in China with 220 cases and the public dataset of TCIA with 422 cases. Our experiments demonstrate that our model achieves an average dice score (0.675), sensitivity (0.731) and F1-score (0.682) on the dataset from Liaoning Cancer Hospital, and an average dice score (0.691), sensitivity (0.746) and F1-score (0.724) on the TCIA dataset, respectively. The results demonstrate that the proposed 3D MSDS-UNet outperforms the state-of-the-art segmentation models for segmenting all scales of tumors, especially for small tumors. Moreover, we evaluated our proposed MSDS-UNet on another challenging volumetric medical image segmentation task: COVID-19 lung infection segmentation, which shows consistent improvement in the segmentation performance.",0,0
7138,Predicting the risk of stroke in patients with late-onset epilepsy: A machine learning approach. The goal of this cohort study was to estimate the predictors for ischemic stroke in patients with epilepsy in a large database containing data from general practitioners in Germany using machine learning methods.,0,0
7140,"Triplanar ensemble U-Net model for white matter hyperintensities segmentation on MR images. White matter hyperintensities (WMHs) have been associated with various cerebrovascular and neurodegenerative diseases. Reliable quantification of WMHs is essential for understanding their clinical impact in normal and pathological populations. Automated segmentation of WMHs is highly challenging due to heterogeneity in WMH characteristics between deep and periventricular white matter, presence of artefacts and differences in the pathology and demographics of populations. In this work, we propose an ensemble triplanar network that combines the predictions from three different planes of brain MR images to provide an accurate WMH segmentation. In the loss functions the network uses anatomical information regarding WMH spatial distribution in loss functions, to improve the efficiency of segmentation and to overcome the contrast variations between deep and periventricular WMHs. We evaluated our method on 5 datasets, of which 3 are part of a publicly available dataset (training data for MICCAI WMH Segmentation Challenge 2017 - MWSC 2017) consisting of subjects from three different cohorts, and we also submitted our method to MWSC 2017 to be evaluated on the unseen test datasets. On evaluating our method separately in deep and periventricular regions, we observed robust and comparable performance in both regions. Our method performed better than most of the existing methods, including FSL BIANCA, and on par with the top ranking deep learning methods of MWSC 2017.",0,0
7141,"Variable length particle swarm optimization and multi-feature deep fusion for motor imagery EEG classification. Brain-computer interfaces are a new pathway for communication between human body and the external environment. High classification accuracy for motor imagery electroencephalogram (EEG) signals is desirable by improving the algorithm of feature extraction and classification. A novel algorithm (VLPSO-MFDF) based on the variable length particle swarm optimization (VLPSO) and multi-feature deep fusion (MFDF) is proposed. First, each layer of the deep forest is reconstructed into two same classification modules. Then, several different features are extracted for the motor imagery EEG signal to feed separately to the classification modules. The VLPSO is used to search for the optimal weights for the probability vectors output by each classification module, which can continuously optimize the classification performance. Experimental results demonstrate that the VLPSO-MFDF algorithm can achieve higher classification accuracy for four classifications of motor imagery EEG signals compared with the traditional deep forest algorithm. The proposed method fused multi-domain features and corrected the prediction difference. It was of great significance for improving the performance of the classifier.",0,0
7142,"Identification of Tissue of Origin and Guided Therapeutic Applications in Cancers of Unknown Primary Using Deep Learning and RNA Sequencing (TransCUPtomics). Cancers of unknown primary (CUP) are metastatic cancers for which the primary tumor is not found despite thorough diagnostic investigations. Multiple molecular assays have been proposed to identify the tissue of origin (TOO) and inform clinical care; however, none has been able to combine accuracy, interpretability, and easy access for routine use. We developed a classifier tool based on the training of a variational autoencoder to predict tissue of origin based on RNA-sequencing data. We used as training data 20,918 samples corresponding to 94 different categories, including 39 cancer types and 55 normal tissues. The TransCUPtomics classifier was applied to a retrospective cohort of 37 CUP patients and 11 prospective patients. TransCUPtomics exhibited an overall accuracy of 96% on reference data for TOO prediction. The TOO could be identified in 38 (79%) of 48 CUP patients. Eight of 11 prospective CUP patients (73%) could receive first-line therapy guided by TransCUPtomics prediction, with responses observed in most patients. The variational autoencoder added further utility by enabling prediction interpretability, and diagnostic predictions could be matched to detection of gene fusions and expressed variants. TransCUPtomics confidently predicted TOO for CUP and enabled tailored treatments leading to significant clinical responses. The interpretability of our approach is a powerful addition to improve the management of CUP patients.",0,0
7143,"Interpretability of time-series deep learning models: A study in cardiovascular patients admitted to Intensive care unit. Interpretability is fundamental in healthcare problems and the lack of it in deep learning models is currently the major barrier in the usage of such powerful algorithms in the field. The study describes the implementation of an attention layer for Long Short-Term Memory (LSTM) neural network that provides a useful picture on the influence of the several input variables included in the model. A cohort of 10,616 patients with cardiovascular diseases is selected from the MIMIC III dataset, an openly available database of electronic health records (EHRs) including all patients admitted to an ICU at Boston's Medical Centre. For each patient, we consider a 10-length sequence of 1-hour windows in which 48 clinical parameters are extracted to predict the occurrence of death in the next 7Â days. Inspired from the recent developments in the field of attention mechanisms for sequential data, we implement a recurrent neural network with LSTM cells incorporating an attention mechanism to identify features driving model's decisions over time. The performance of the LSTM model, measured in terms of AUC, is 0.790 (SDÂ =Â 0.015). Regard our primary objective, i.e. model interpretability, we investigate the role of attention weights. We find good correspondence with driving predictors of a transparent model (rÂ =Â 0.611, 95% CI [0.395, 0.763]). Moreover, most influential features identified at the cohort-level emerge as known risk factors in the clinical context. Despite the limitations of study dataset, this work brings further evidence of the potential of attention mechanisms in making deep learning model more interpretable and suggests the application of this strategy for the sequential analysis of EHRs.",0,0
7146,"Real-time interactive artificial intelligence of things-based prediction for adverse outcomes in adult patients with pneumonia in the emergency department. Artificial intelligence of things (AIoT) may be a solution for predicting adverse outcomes in emergency department (ED) patients with pneumonia; however, this issue remains unclear. Therefore, we conducted this study to clarify it.",0,0
7148,"Structuro-functional surrogates of response to subcallosal cingulate deep brain stimulation for depression. Subcallosal cingulate deep brain stimulation (SCC-DBS) produces long-term clinical improvement in approximately half of patients with severe treatment-resistant depression (TRD). We hypothesized that both structural and functional brain attributes may be important in determining responsiveness to this therapy. In a TRD SCC-DBS cohort, we retrospectively examined baseline and longitudinal differences in MRI-derived brain volume (nâ€‰=â€‰65) and 18F-fluorodeoxyglucose-PET glucose metabolism (nâ€‰=â€‰21) between responders and non-responders. Support-vector machines (SVMs) were subsequently trained to classify patients' response status based on extracted baseline imaging features. A machine learning model incorporating pre-operative frontopolar, precentral/frontal opercular, and orbitofrontal local volume values classified binary response status (12 months) with 83% accuracy (leave-one-out cross-validation (LOOCV): 80% accuracy) and explained 32% of the variance in continuous clinical improvement. It was also predictive in an out-of-sample SCC-DBS cohort (nâ€‰=â€‰21) with differing primary indications (bipolar disorder/anorexia nervosa) (76% accuracy). Adding pre-operative glucose metabolism information from rostral anterior cingulate cortex and temporal pole improved model performance, enabling it to predict response status in the TRD cohort with 86% accuracy (LOOCV: 81% accuracy) and explain 67% of clinical variance. Response-related patterns of metabolic and structural post-DBS change were also observed, especially in anterior cingulate cortex and neighbouring white matter. Areas where responders differed from non-responders - both at baseline and longitudinally - largely overlapped with depression-implicated white matter tracts, namely uncinate fasciculus, cingulum bundle, and forceps minor/rostrum of corpus callosum. The extent of patient-specific engagement of these same tracts (according to electrode location and stimulation parameters) also served as a predictor of TRD response status (72% accuracy; LOOCV: 70% accuracy) and augmented performance of the volume-based (88% accuracy; LOOCV: 82% accuracy) and combined volume/metabolism-based SVMs (100% accuracy; LOOCV: 94% accuracy). Taken together, these results indicate that responders and non-responders to SCC-DBS exhibit differences in brain volume and metabolism, both pre- and post-surgery. Baseline imaging features moreover predict response to treatment (particularly when combined with information about local tract engagement) and could inform future patient selection and other clinical decisions.",0,0
7151,"Predicting pain among female survivors of recent interpersonal violence: A proof-of-concept machine-learning approach. Interpersonal violence (IPV) is highly prevalent in the United States and is a major public health problem. The emergence and/or worsening of chronic pain are known sequelae of IPV; however, not all those who experience IPV develop chronic pain. To mitigate its development, it is critical to identify the factors that are associated with increased risk of pain after IPV. This proof-of-concept study used machine-learning strategies to predict pain severity and interference in 47 young women, ages 18 to 30, who experienced an incident of IPV (i.e., physical and/or sexual assault) within three months of their baseline assessment. Young women are more likely than men to experience IPV and to subsequently develop posttraumatic stress disorder (PTSD) and chronic pain. Women completed a comprehensive assessment of theory-driven cognitive and neurobiological predictors of pain severity and pain-related interference (e.g., pain, coping, disability, psychiatric diagnosis/symptoms, PTSD/trauma, executive function, neuroendocrine, and physiological stress response). Gradient boosting machine models were used to predict symptoms of pain severity and pain-related interference across time (Baseline, 1-,3-,6- follow-up assessments). Models showed excellent predictive performance for pain severity and adequate predictive performance for pain-related interference. This proof-of-concept study suggests that machine-learning approaches are a useful tool for identifying predictors of pain development in survivors of recent IPV. Baseline measures of pain, family life impairment, neuropsychological function, and trauma history were of greatest importance in predicting pain and pain-related interference across a 6-month follow-up period. Present findings support the use of machine-learning techniques in larger studies of post-IPV pain development and highlight theory-driven predictors that could inform the development of targeted early intervention programs. However, these results should be replicated in a larger dataset with lower levels of missing data.",0,0
7153,"Can Deep Learning Replace Gadolinium in Neuro-Oncology?: A Reader Study. This study proposes and evaluates a deep learning method that predicts surrogate images for contrast-enhanced T1 from multiparametric magnetic resonance imaging (MRI) acquired using only a quarter of the standard 0.1 mmol/kg dose of gadolinium-based contrast agent. In particular, the predicted images are quantitatively evaluated in terms of lesion detection performance.",0,0
7154,First Performance Evaluation of an Artificial Intelligence-Based Computer-Aided Detection System for Pulmonary Nodule Evaluation in Dual-Source Photon-Counting Detector CT at Different Low-Dose Levels. The aim of this study was to evaluate the image quality (IQ) and performance of an artificial intelligence (AI)-based computer-aided detection (CAD) system in photon-counting detector computed tomography (PCD-CT) for pulmonary nodule evaluation at different low-dose levels.,0,0
7157,"Brain tumor classification using fine-tuned GoogLeNet features and machine learning algorithms: IoMT enabled CAD system. In the healthcare research community, Internet of Medical Things (IoMT) is transforming the healthcare system into the world of the future internet. In IoMT enabled Computer aided diagnosis (CAD) system, the Health-related information is stored via the internet, and supportive data is provided to the patients. The development of various smart devices is interconnected via the internet, which helps the patient to communicate with a medical expert using IoMT based remote healthcare system for various life threatening diseases, e.g., brain tumors. The brain tumor is one of the most dreadful diseases ever known to human beings. Often, the tumors are predecessors to cancers. The survival rates for these diseases are very low. So, early detection and classification of tumors can save a lot of lives. IoMT enabled CAD system plays a vital role in solving these problems. Deep learning, a new domain in Machine Learning, has attracted a lot of attention in the last few years. The concept of Convolutional Neural Networks (CNNs) has been widely used in this field. In this paper, we have classified brain tumors into three classes, namely glioma, meningioma and pituitary, using transfer learning model. The features of the brain MRI images are extracted using a pre-trained CNN, i.e. GoogLeNet. The features are then classified using classifiers such as softmax, Support Vector Machine (SVM), and K-Nearest Neighbor (K-NN). The proposed model is trained and tested on CE-MRI Figshare dataset. Further, Harvard medical repository dataset images are also considered for the experimental purpose to classify four types of tumors, and the results are compared with the other state-of-the-art models. Performance measures such as accuracy, precision, recall, specificity, and F1 score are examined to evaluate the performances of the proposed model.",0,0
7162,"Deep learning-based segmentation of knee MRI for fully automatic subregional morphological assessment of cartilage tissues: Data from the Osteoarthritis Initiative. Morphological changes in knee cartilage subregions are valuable imaging-based biomarkers for understanding progression of osteoarthritis, and they are typically detected from magnetic resonance imaging (MRI). So far, accurate segmentation of cartilage has been done manually. Deep learning approaches show high promise in automating the task; however, they lack clinically relevant evaluation. We introduce a fully automatic method for segmentation and subregional assessment of articular cartilage, and evaluate its predictive power in context of radiographic osteoarthritis progression. Two data sets of 3D double-echo steady-state (DESS) MRI derived from the Osteoarthritis Initiative were used: first, nâ€‰=â€‰88; second, nâ€‰=â€‰600, 0-/12-/24-month visits. Our method performed deep learning-based segmentation of knee cartilage tissues, their subregional division via multi-atlas registration, and extraction of subregional volume and thickness. The segmentation model was developed and assessed on the first data set. Subsequently, on the second data set, the morphological measurements from our and the prior methods were analyzed in correlation and agreement, and, eventually, by their discriminative power of radiographic osteoarthritis progression over 12 and 24 months, retrospectively. The segmentation model showed very high correlation (râ€‰>â€‰0.934) and agreement (mean differenceâ€‰<â€‰116â€‰mm<sup>3</sup> ) in volumetric measurements with the reference segmentations. Comparison of our and manual segmentation methods yielded râ€‰=â€‰0.845-0.973 and mean differencesâ€‰=â€‰262-501â€‰mm<sup>3</sup> for weight-bearing cartilage volume, and râ€‰=â€‰0.770-0.962 and mean differencesâ€‰=â€‰0.513-1.138â€‰mm for subregional cartilage thickness. With regard to osteoarthritis progression, our method found most of the significant associations identified using the manual segmentation method, for both 12- and 24-month subregional cartilage changes. The method may be effectively applied in osteoarthritis progression studies to extract cartilage-related imaging biomarkers.",0,0
7163,Non-Contrast CT-Based Radiomics Score for Predicting Hematoma Enlargement in Spontaneous Intracerebral Hemorrhage. To develop aÂ non-contrast computed tomography-(CT)-based radiomics score for predicting the risk of hematoma early enlargement in spontaneous intracerebral hemorrhage.,0,0
7168,"Cross-validation of a machine learning algorithm that determines anterior cruciate ligament rehabilitation status and evaluation of its ability to predict future injury. Classification algorithms determine the similarity of an observation to defined classes, e.g., injured or healthy athletes, and can highlight treatment targets or assess progress of a treatment. The primary aim was to cross-validate a previously developed classification algorithm using a different sample, while a secondary aim was to examine its ability to predict future ACL injuries. The examined outcome measure was 'healthy-limb' class membership probability, which was compared between a cohort of athletes without previous or future (No Injury) previous (PACL) and future ACL injury (FACL). The No Injury group had significantly higher probabilities than the PACL (p < 0.001; medium effect) and FACL group (p â‰¤ 0.045; small effect). The ability to predict group membership was poor for the PACL (area under curve [AUC]; 0.61<AUC<0.62) and FACL group (0.57<AUC<0.59). The ACL injury incidence proportion was highest in athletes with probabilities below 0.20 (9.4%; +2.7% to baseline), while athletes with probabilities above 0.80 had an incidence proportion of 4.1% (-2.6%). While findings that a low probability might represent an increase in injury risk on a group level, it is not sensitive enough for injury screening to predict a future injury on the individual level.",0,0
7171,"Ultra-Fast Label-Free Serum Metabolic Diagnosis of Coronary Heart Disease via a Deep Stabilizer. Although mass spectrometry (MS) of metabolites has the potential to provide real-time monitoring of patient status for diagnostic purposes, the diagnostic application of MS is limited due to sample treatment and data quality/reproducibility. Here, the generation of a deep stabilizer for ultra-fast, label-free MS detection and the application of this method for serum metabolic diagnosis of coronary heart disease (CHD) are reported. Nanoparticle-assisted laser desorption/ionization-MS is used to achieve direct metabolic analysis of trace unprocessed serum in seconds. Furthermore, a deep stabilizer is constructed to map native MS results to high-quality results obtained by established methods. Finally, using the newly developed protocol and diagnosis variation characteristic surface to characterize sensitivity/specificity and variation, CHD is diagnosed with advanced accuracy in a high-throughput/speed manner. This work advances design of metabolic analysis tools for disease detection as it provides a direct label-free, ultra-fast, and stabilized platform for future protocol development in clinics.",0,0
7175,"[Application of Automated Machine Learning Based on Radiomics Features of T2WI and RS-EPI DWI to Predict Preoperative T Staging of Rectal Cancer]. To explore the radiomics features of T2 weighted image (T2WI) and readout-segmented echo-planar imaging (RS-EPI) plus difusion-weighted imaging (DWI), to develop an automated mahchine-learning model based on the said radiomics features, and to test the value of this model in predicting preoperative T staging of rectal cancer.",0,0
7176,[Application Test of the AI-Automatic Diagnostic System for Ki-67 in Breast Cancer]. To study the different methods of artificial intelligence (AI)-assisted Ki-67 scoring of clinical invasive ductal carcinoma (IDC) of the breast and to compare the results.,0,0
7177,[Identifying Molecular Subtypes of Whole-Slide Image in Colorectal Cancer via Deep Learning]. To establish an artificial intelligence-assisted diagnosis system for molecular subtyping of colorectal cancer (CRC).,0,0
7178,"Improving the predictive potential of diffusion MRI in schizophrenia using normative models-Towards subject-level classification. Diffusion MRI studies consistently report group differences in white matter between individuals diagnosed with schizophrenia and healthy controls. Nevertheless, the abnormalities found at the group-level are often not observed at the individual level. Among the different approaches aiming to study white matter abnormalities at the subject level, normative modeling analysis takes a step towards subject-level predictions by identifying affected brain locations in individual subjects based on extreme deviations from a normative range. Here, we leveraged a large harmonized diffusion MRI dataset from 512 healthy controls and 601 individuals diagnosed with schizophrenia, to study whether normative modeling can improve subject-level predictions from a binary classifier. To this aim, individual deviations from a normative model of standard (fractional anisotropy) and advanced (free-water) dMRI measures, were calculated by means of age and sex-adjusted z-scores relative to control data, in 18 white matter regions. Even though larger effect sizes are found when testing for group differences in z-scores than are found with raw values (pâ€‰<â€‰.001), predictions based on summary z-score measures achieved low predictive power (AUCâ€‰<â€‰0.63). Instead, we find that combining information from the different white matter tracts, while using multiple imaging measures simultaneously, improves prediction performance (the best predictor achieved AUCÂ =Â 0.726). Our findings suggest that extreme deviations from a normative model are not optimal features for prediction. However, including the complete distribution of deviations across multiple imaging measures improves prediction, and could aid in subject-level classification.",0,0
7179,Proposing an ensemble learning model based on neural network and fuzzy system for keratoconus diagnosis based on Pentacam measurements. The present study was done to evaluate efficiency of an ensemble learning structure for automatic keratoconus diagnosis and to categorize eyes into four different groups based on a combination of 19 parameters obtained from Pentacam measurements.,0,0
7184,"Measurement of Endotracheal Tube Positioning on Chest X-Ray Using Object Detection. Patients who are intubated with endotracheal tubes often receive chest x-ray (CXR) imaging to determine whether the tube is correctly positioned. When these CXRs are interpreted by a radiologist, they evaluate whether the tube needs to be repositioned and typically provide a measurement in centimeters between the endotracheal tube tip and carina. In this project, a large dataset of endotracheal tube and carina bounding boxes was annotated on CXRs, and a machine-learning model was trained to generate these boxes on new CXRs and to calculate a distance measurement between the tube and carina. This model was applied to a gold standard annotated dataset, as well as to all prospective data passing through our radiology system for two weeks. Inter-radiologist variability was also measured on a test dataset. The distance measurements for both the gold standard dataset (mean errorâ€‰=â€‰0.70Â cm) and prospective dataset (mean errorâ€‰=â€‰0.68Â cm) were noninferior to inter-radiologist variability (mean errorâ€‰=â€‰0.70Â cm) within an equivalence bound of 0.1Â cm. This suggests that this model performs at an accuracy similar to human measurements, and these distance calculations can be used for clinical report auto-population and/or worklist prioritization of severely malpositioned tubes.",1,1
7185,"Differential Role for Hippocampal Subfields in Alzheimer's Disease Progression Revealed with Deep Learning. Mild cognitive impairment (MCI) is often considered the precursor of Alzheimer's disease. However, MCI is associated with substantially variable progression rates, which are not well understood. Attempts to identify the mechanisms that underlie MCI progression have often focused on the hippocampus but have mostly overlooked its intricate structure and subdivisions. Here, we utilized deep learning to delineate the contribution of hippocampal subfields to MCI progression. We propose a dense convolutional neural network architecture that differentiates stable and progressive MCI based on hippocampal morphometry with an accuracy of 75.85%. A novel implementation of occlusion analysis revealed marked differences in the contribution of hippocampal subfields to the performance of the model, with presubiculum, CA1, subiculum, and molecular layer showing the most central role. Moreover, the analysis reveals that 10.5% of the volume of the hippocampus was redundant in the differentiation between stable and progressive MCI.",0,0
7187,"Deep learning for vessel-specific coronary artery calcium scoring: validation on a multi-centre dataset. To present and validate a fully automated, deep learning (DL)-based branch-wise coronary artery calcium (CAC) scoring algorithm on a multi-centre dataset.",0,0
7189,Prediction of Multiple sclerosis disease using machine learning classifiers: a comparative study. Hamedan Province is one of Iran's high-risk regions for Multiple Sclerosis (MS). Early diagnosis of MS based on an accurate system can control the disease. The aim of this study was to compare the performance of four machine learning techniques with traditional methods for predicting MS patients.,0,0
7191,"Predictive and discriminative localization of pathology using high resolution class activation maps with CNNs. Existing class activation mapping (CAM) techniques extract the feature maps only from a single layer of the convolutional neural net (CNN), generally from the final layer and then interpolate to upsample to the original image resolution to locate the discriminative regions. Consequently these provide a coarse localization that may not be able to capture subtle abnormalities in medical images. To alleviate this, our work proposes a technique called high resolution class activation mapping (HR-CAMs) that can provide enhanced visual explainability to the CNN models.",0,0
7195,"3D CNN classification model for accurate diagnosis of coronavirus disease 2019 using computed tomography images. <b>Purpose:</b> The coronavirus disease (COVID-19) has been spreading rapidly around the world. As of August 25, 2020, 23.719Â million people have been infected in many countries. The cumulative death toll exceeds 812,000. Early detection of COVID-19 is essential to provide patients with appropriate medical care and protecting uninfected people. <b>Approach:</b> Leveraging a large computed tomography (CT) database from 1112 patients provided by China Consortium of Chest CT Image Investigation (CC-CCII), we investigated multiple solutions in detecting COVID-19 and distinguished it from other common pneumonia (CP) and normal controls. We also compared the performance of different models for complete and segmented CT slices. In particular, we studied the effects of CT-superimposition depths into volumes on the performance of our models. <b>Results:</b> The results show that the optimal model can identify the COVID-19 slices with 99.76% accuracy (99.96% recall, 99.35% precision, and 99.65% <math xmlns=""http://www.w3.org/1998/Math/MathML""><mrow><mi>F</mi> <mn>1</mn></mrow> </math> -score). The overall performance for three-way classification obtained 99.24% accuracy and a macroaverage area under the receiver operating characteristic curve (macro-AUROC) of 0.9998. To the best of our knowledge, our method achieves the highest accuracy and recall with the largest public available COVID-19 CT dataset. <b>Conclusions:</b> Our model can help radiologists and physicians perform rapid diagnosis, especially when the healthcare system is overloaded.",0,0
7196,"Predicting Intensive Care Unit Length of Stay After Acute Type A Aortic Dissection Surgery Using Machine Learning. <b>Background:</b> Patients with acute type A aortic dissection are usually transferred to the intensive care unit (ICU) after surgery. Prolonged ICU length of stay (ICU-LOS) is associated with higher level of care and higher mortality. We aimed to develop and validate machine learning models for predicting ICU-LOS after acute type A aortic dissection surgery. <b>Methods:</b> A total of 353 patients with acute type A aortic dissection transferred to ICU after surgery from September 2016 to August 2019 were included. The patients were randomly divided into the training dataset (70%) and the validation dataset (30%). Eighty-four preoperative and intraoperative factors were collected for each patient. ICU-LOS was divided into four intervals (<4, 4-7, 7-10, and >10 days) according to interquartile range. Kendall correlation coefficient was used to identify factors associated with ICU-LOS. Five classic classifiers, Naive Bayes, Linear Regression, Decision Tree, Random Forest, and Gradient Boosting Decision Tree, were developed to predict ICU-LOS. Area under the curve (AUC) was used to evaluate the models' performance. <b>Results:</b> The mean age of patients was 51.0 Â± 10.9 years and 307 (87.0%) were males. Twelve predictors were identified for ICU-LOS, namely, D-dimer, serum creatinine, lactate dehydrogenase, cardiopulmonary bypass time, fasting blood glucose, white blood cell count, surgical time, aortic cross-clamping time, with Marfan's syndrome, without Marfan's syndrome, without aortic aneurysm, and platelet count. Random Forest yielded the highest performance, with an AUC of 0.991 (95% confidence interval [CI]: 0.978-1.000) and 0.837 (95% CI: 0.766-0.908) in the training and validation datasets, respectively. <b>Conclusions:</b> Machine learning has the potential to predict ICU-LOS for acute type A aortic dissection. This tool could improve the management of ICU resources and patient-throughput planning, and allow better communication with patients and their families.",0,0
7201,"Functional Connectivity Density for Radiation Encephalopathy Prediction in Nasopharyngeal Carcinoma. The diagnostic efficiency of radiation encephalopathy (RE) remains heterogeneous, and prediction of RE is difficult at the pre-symptomatic stage. We aimed to analyze the whole-brain resting-state functional connectivity density (FCD) of individuals with pre-symptomatic RE using multivariate pattern analysis (MVPA) and explore its prediction efficiency. Resting data from NPC patients with nasopharyngeal carcinoma (NPC; consisting of 20 pre-symptomatic RE subjects and 26 non-RE controls) were collected in this study. We used MVPA to classify pre-symptomatic RE subjects from non-RE controls based on FCD maps. Classifier performances were evaluated by accuracy, sensitivity, specificity, and area under the characteristic operator curve. Permutation tests and leave-one-out cross-validation were applied for assessing classifier performance. MVPA was able to differentiate pre-symptomatic RE subjects from non-RE controls using global FCD as a feature, with a total accuracy of 89.13%. The temporal lobe as well as regions involved in the visual processing system, the somatosensory system, and the default mode network (DMN) revealed robust discrimination during classification. Our findings suggest a good classification efficiency of global FCD for the individual prediction of RE at a pre-symptomatic stage. Moreover, the discriminating regions may contribute to the underlying mechanisms of sensory and cognitive disturbances in RE.",0,0
7203,"Diagnosis of Acute Central Dizziness With Simple Clinical Information Using Machine Learning. <b>Background:</b> Acute dizziness is a common symptom among patients visiting emergency medical centers. Extensive neurological examinations aimed at delineating the cause of dizziness often require experience and specialized training. We tried to diagnose central dizziness by machine learning using only basic clinical information. <b>Methods:</b> Patients were enrolled who had visited an emergency medical center with acute dizziness and underwent diffusion-weighted imaging. The enrolled patients were dichotomized as either having central (with a corresponding central lesion) or non-central dizziness. We obtained patient demographics, risk factors, vital signs, and presentation (non-whirling type dizziness or vertigo). Various machine learning algorithms were used to predict central dizziness. The area under the receiver operating characteristic curve (AUROC) was measured to evaluate diagnostic accuracy. The SHapley Additive exPlanations (SHAP) value was used to explain the importance of each factor. <b>Results:</b> Of the 4,481 visits, 414 (9.2%) were determined as central dizziness. Central dizziness patients were more often older and male and had more risk factors and higher systolic blood pressure. They also presented more frequently with non-whirling type dizziness (79 vs. 54.4%) than non-central dizziness. Catboost model showed the highest AUROC (0.738) with a 94.4% sensitivity and 31.9% specificity in the test set (<i>n</i> = 1,317). The SHAP value was highest for previous stroke presence (mean; 0.74), followed by male (0.33), presentation as non-whirling type dizziness (0.30), and age (0.25). <b>Conclusions:</b> Machine learning is feasible for classifying central dizziness using demographics, risk factors, vital signs, and clinical dizziness presentation, which are obtainable at the triage.",0,0
7204,"Connecting Social Psychology and Deep Reinforcement Learning: A Probabilistic Predictor on the Intention to Do Home-Based Physical Activity After Message Exposure. Previous research has shown that sending personalized messages consistent with the recipient's psychological profile is essential to activate the change toward a healthy lifestyle. In this paper we present an example of how artificial intelligence can support psychology in this process, illustrating the development of a probabilistic predictor in the form of a Dynamic Bayesian Network (DBN). The predictor regards the change in the intention to do home-based physical activity after message exposure. The data used to construct the predictor are those of a study on the effects of framing in communication to promote physical activity at home during the Covid-19 lockdown. The theoretical reference is that of psychosocial research on the effects of framing, according to which similar communicative contents formulated in different ways can be differently effective depending on the characteristics of the recipient. Study participants completed a first questionnaire aimed at measuring the psychosocial dimensions involved in doing physical activity at home. Next, they read recommendation messages formulated with one of four different frames (gain, non-loss, non-gain, and loss). Finally, they completed a second questionnaire measuring their perception of the messages and again the intention to exercise at home. The collected data were analyzed to elicit a DBN, i.e., a probabilistic structure representing the interrelationships between all the dimensions considered in the study. The adopted procedure was aimed to achieve a good balance between explainability and predictivity. The elicited DBN was found to be consistent with the psychosocial theories assumed as reference and able to predict the effectiveness of the different messages starting from the relevant psychosocial dimensions of the recipients. In the next steps of our project, the DBN will form the basis for the training of a Deep Reinforcement Learning (DRL) system for the synthesis of automatic interaction strategies. In turn, the DRL system will train a Deep Neural Network (DNN) that will guide the online interaction process. The discussion focuses on the advantages of the proposed procedure in terms of interpretability and effectiveness.",0,0
7207,"Predicting Age From Behavioral Test Performance for Screening Early Onset of Cognitive Decline. <b>Background:</b> Neuronal reactions and cognitive processes slow down during aging. The onset, rate, and extent of changes vary considerably from individual to individual. Assessing the changes throughout the lifespan is a challenging task. No existing test covers all domains, and batteries of tests are administered. The best strategy is to study each functional domain separately by applying different behavioral tasks whereby the tests reflect the conceptual structure of cognition. Such an approach has limitations that are described in the article. <b>Objective:</b> Our aim was to improve the diagnosis of early cognitive decline. We estimated the onset of cognitive decline in a healthy population, using behavioral tests, and predicted the age group of an individual. The comparison between the predicted (""cognitive"") and chronological age will contribute to the early diagnosis of accelerated aging. <b>Materials and Methods:</b> We used publicly available datasets (POBA, SSCT) and Pearson correlation coefficients to assess the relationship between age and tests results, Kruskal-Wallis test to compare distribution, clustering methods to find an onset of cognitive decline, feature selection to enhance performance of the clustering algorithms, and classification methods to predict an age group from cognitive tests results. <b>Results:</b> The major results of the psychophysiological tests followed a U-shape function across the lifespan, which reflected the known inverted function of white matter volume changes. Optimal values were observed in those aged over 35 years, with a period of stability and accelerated decline after 55-60 years of age. The shape of the age-related variance of the performance of major cognitive tests was linear, which followed the trend of lifespan gray matter volume changes starting from adolescence. There was no significant sex difference in lifelong dynamics of major tests estimates. The performance of the classification model for identifying subject age groups was high. <b>Conclusions:</b> ML models can be designed and utilized as computer-aided detectors of neurocognitive decline. Our study demonstrated great promise for the utility of classification models to predict age-related changes. These findings encourage further explorations combining several tests from the cognitive and psychophysiological test battery to derive the most reliable set of tests toward the development of a highly-accurate ML model.",0,0
7208,"MRI Radiomic Signature of White Matter Hyperintensities Is Associated With Clinical Phenotypes. Neuroimaging measurements of brain structural integrity are thought to be surrogates for brain health, but precise assessments require dedicated advanced image acquisitions. By means of quantitatively describing conventional images, radiomic analyses hold potential for evaluating brain health. We sought to: (1) evaluate radiomics to assess brain structural integrity by predicting white matter hyperintensities burdens (WMH) and (2) uncover associations between predictive radiomic features and clinical phenotypes.",0,0
7209,"EOGNET: A Novel Deep Learning Model for Sleep Stage Classification Based on Single-Channel EOG Signal. In recent years, automatic sleep staging methods have achieved competitive performance using electroencephalography (EEG) signals. However, the acquisition of EEG signals is cumbersome and inconvenient. Therefore, we propose a novel sleep staging approach using electrooculogram (EOG) signals, which are more convenient to acquire than the EEG. A two-scale convolutional neural network first extracts epoch-wise temporary-equivalent features from raw EOG signals. A recurrent neural network then captures the long-term sequential information. The proposed method was validated on 101 full-night sleep data from two open-access databases, the montreal archive of sleep studies and Sleep-EDF, achieving an overall accuracy of 81.2 and 76.3%, respectively. The results are comparable to those models trained with EEG signals. In addition, comparisons with six state-of-the-art methods further demonstrate the effectiveness of the proposed approach. Overall, this study provides a new avenue for sleep monitoring.",0,0
7216,"An ensemble learning approach to digital corona virus preliminary screening from cough sounds. This work develops a robust classifier for a COVID-19 pre-screening model from crowdsourced cough sound data. The crowdsourced cough recordings contain a variable number of coughs, with some input sound files more informative than the others. Accurate detection of COVID-19 from the sound datasets requires overcoming two main challenges (i) the variable number of coughs in each recording and (ii) the low number of COVID-positive cases compared to healthy coughs in the data. We use two open datasets of crowdsourced cough recordings and segment each cough recording into non-overlapping coughs. The segmentation enriches the original data without oversampling by splitting the original cough sound files into non-overlapping segments. Splitting the sound files enables us to increase the samples of the minority class (COVID-19) without changing the feature distribution of the COVID-19 samples resulted from applying oversampling techniques. Each cough sound segment is transformed into six image representations for further analyses. We conduct extensive experiments with shallow machine learning, Convolutional Neural Network (CNN), and pre-trained CNN models. The results of our models were compared to other recently published papers that apply machine learning to cough sound data for COVID-19 detection. Our method demonstrated a high performance using an ensemble model on the testing dataset with area under receiver operating characteristics curveâ€‰=â€‰0.77, precisionâ€‰=â€‰0.80, recallâ€‰=â€‰0.71, F1 measureâ€‰=â€‰0.75, and Kappaâ€‰=â€‰0.53. The results show an improvement in the prediction accuracy of our COVID-19 pre-screening model compared to the other models.",0,0
7217,"Prediction of treatment outcome in burning mouth syndrome patients using machine learning based on clinical data. The purpose of this study is to apply a machine learning approach to predict whether patients with burning mouth syndrome (BMS) respond to the initial approach and clonazepam therapy based on clinical data. Among the patients with the primary type of BMS who visited the clinic from 2006 to 2015, those treated with the initial approach of detailed explanation regarding home care instruction and use of oral topical lubricants, or who were prescribed clonazepam for a minimum of 1Â month were included in this study. The clinical data and treatment outcomes were collected from medical records. Extreme Gradient-Boosted Decision Trees was used for machine learning algorithms to construct prediction models. Accuracy of the prediction models was evaluated and feature importance calculated. The accuracy of the prediction models for the initial approach and clonazepam therapy was 67.6% and 67.4%, respectively. Aggravating factors and psychological distress were important features in the prediction model for the initial approach, and intensity of symptoms before administration was the important feature in the prediction model for clonazepam therapy. In conclusion, the analysis of treatment outcomes in patients with BMS using a machine learning approach showed meaningful results of clinical applicability.",0,0
7218,"Detecting suicidal risk using MMPI-2 based on machine learning algorithm. Minnesota Multiphasic Personality Inventory-2 (MMPI-2) is a widely used tool for early detection of psychological maladjustment and assessing the level of adaptation for a large group in clinical settings, schools, and corporations. This study aims to evaluate the utility of MMPI-2 in assessing suicidal risk using the results of MMPI-2 and suicidal risk evaluation. A total of 7,824 datasets collected from college students were analyzed. The MMPI-2-Resturcutred Clinical Scales (MMPI-2-RF) and the response results for each question of the Mini International Neuropsychiatric Interview (MINI) suicidality module were used. For statistical analysis, random forest and K-Nearest Neighbors (KNN) techniques were used with suicidal ideation and suicide attempt as dependent variables and 50 MMPI-2 scale scores as predictors. On applying the random forest method to suicidal ideation and suicidal attempts, the accuracy was 92.9% and 95%, respectively, and the Area Under the Curves (AUCs) were 0.844 and 0.851, respectively. When the KNN method was applied, the accuracy was 91.6% and 94.7%, respectively, and the AUCs were 0.722 and 0.639, respectively. The study confirmed that machine learning using MMPI-2 for a large group provides reliable accuracy in classifying and predicting the subject's suicidal ideation and past suicidal attempts.",0,0
7220,"Combining a convolutional neural network with autoencoders to predict the survival chance of COVID-19 patients. COVID-19 has caused many deaths worldwide. The automation of the diagnosis of this virus is highly desired. Convolutional neural networks (CNNs) have shown outstanding classification performance on image datasets. To date, it appears that COVID computer-aided diagnosis systems based on CNNs and clinical information have not yet been analysed or explored. We propose a novel method, named the CNN-AE, to predict the survival chance of COVID-19 patients using a CNN trained with clinical information. Notably, the required resources to prepare CT images are expensive and limited compared to those required to collect clinical data, such as blood pressure, liver disease, etc. We evaluated our method using a publicly available clinical dataset that we collected. The dataset properties were carefully analysed to extract important features and compute the correlations of features. A data augmentation procedure based on autoencoders (AEs) was proposed to balance the dataset. The experimental results revealed that the average accuracy of the CNN-AE (96.05%) was higher than that of the CNN (92.49%). To demonstrate the generality of our augmentation method, we trained some existing mortality risk prediction methods on our dataset (with and without data augmentation) and compared their performances. We also evaluated our method using another dataset for further generality verification. To show that clinical data can be used for COVID-19 survival chance prediction, the CNN-AE was compared with multiple pre-trained deep models that were tuned based on CT images.",0,0
7221,"Heatstroke predictions by machine learning, weather information, and an all-population registry for 12-hour heatstroke alerts. This study aims to develop and validate prediction models for the number of all heatstroke cases, and heatstrokes of hospital admission and death cases per city per 12â€‰h, using multiple weather information and a population-based database for heatstroke patients in 16 Japanese cities (corresponding to around a 10,000,000 population size). In the testing dataset, mean absolute percentage error of generalized linear models with wet bulb globe temperature as the only predictor and the optimal models, respectively, are 43.0% and 14.8% for spikes in the number of all heatstroke cases, and 37.7% and 10.6% for spikes in the number of heatstrokes of hospital admission and death cases. The optimal models predict the spikes in the number of heatstrokes well by machine learning methods including non-linear multivariable predictors and/or under-sampling and bagging. Here, we develop prediction models whose predictive performances are high enough to be implemented in public health settings.",0,0
7226,An explainable supervised machine learning predictor of acute kidney injury after adult deceased donor liver transplantation. Early prediction of acute kidney injury (AKI) after liver transplantation (LT) facilitates timely recognition and intervention. We aimed to build a risk predictor of post-LT AKI via supervised machine learning and visualize the mechanism driving within to assist clinical decision-making.,0,0
7227,"Classification of microcalcification clusters in digital breast tomosynthesis using ensemble convolutional neural network. The classification of benign and malignant microcalcification clusters (MCs) is an important task for computer-aided diagnosis (CAD) of digital breast tomosynthesis (DBT) images. Influenced by imaging method, DBT has the characteristic of anisotropic resolution, in which the resolution of intra-slice and inter-slice is quite different. In addition, the sharpness of MCs in different slices of DBT is quite different, among which the clearest slice is called focus slice. These characteristics limit the performance of CAD algorithms based on standard 3D convolution neural network (CNN).",0,0
7229,"Prediction of lymphovascular space invasion using a combination of tenascin-C, cox-2, and PET/CT radiomics in patients with early-stage cervical squamous cell carcinoma. Lymphovascular space invasion is an independent prognostic factor in early-stage cervical cancer. However, there is a lack of non-invasive methods to detect lymphovascular space invasion. Some researchers found that Tenascin-C and Cyclooxygenase-2 was correlated with lymphovascular space invasion. Radiomics has been studied as an emerging tool for distinguishing tumor pathology stage, evaluating treatment response, and predicting prognosis. This study aimed to establish a machine learning model that combines radiomics based on PET imaging with tenascin-C (TNC) and cyclooxygenase-2 (COX-2) for predicting lymphovascular space invasion (LVSI) in patients with early-stage cervical cancer.",0,0
7244,"Machine learning predicts treatment sensitivity in multiple myeloma based on molecular and clinical information coupled with drug response. Providing treatment sensitivity stratification at the time of cancer diagnosis allows better allocation of patients to alternative treatment options. Despite many clinical and biological risk markers having been associated with variable survival in cancer, assessing the interplay of these markers through Machine Learning (ML) algorithms still remains to be fully explored. Here, we present a Multi Learning Training approach (MuLT) combining supervised, unsupervised and self-supervised learning algorithms, to examine the predictive value of heterogeneous treatment outcomes for Multiple Myeloma (MM). We show that gene expression values improve the treatment sensitivity prediction and recapitulates genetic abnormalities detected by Fluorescence in situ hybridization (FISH) testing. MuLT performance was assessed by cross-validation experiments, in which it predicted treatment sensitivity with 68.70% of AUC. Finally, simulations showed numerical evidences that in average 17.07% of patients could get better response to a different treatment at the first line.",0,0
7251,"Deep Learning-Guided Fiberoptic Raman Spectroscopy Enables Real-Time <i>In Vivo</i> Diagnosis and Assessment of Nasopharyngeal Carcinoma and Post-treatment Efficacy during Endoscopy. In this work, we develop a deep learning-guided fiberoptic Raman diagnostic platform to assess its ability of real-time <i>in vivo</i> nasopharyngeal carcinoma (NPC) diagnosis and post-treatment follow-up of NPC patients. The robust Raman diagnostic platform is established using innovative multi-layer Raman-specified convolutional neural networks (RS-CNN) together with simultaneous fingerprint and high-wavenumber spectra acquired within sub-seconds using a fiberoptic Raman endoscopy system. We have acquired a total of 15,354 FP/HW <i>in vivo</i> Raman spectra (control: 1761; NPC: 4147; and post-treatment (PT): 9446) from 888 tissue sites of 418 subjects (healthy control: 85; NPC: 82; and PT: 251) during endoscopic examination. The optimized RS-CNN model provides an overall diagnostic accuracy of 82.09% (sensitivity of 92.18% and specificity of 73.99%) for identifying NPC from control and post-treatment patients, which is superior to the best diagnosis performance (accuracy of 73.57%; sensitivity of 89.74%; and specificity of 58.10%) using partial-least-squares linear-discriminate-analysis, proving the robustness and high spectral information sensitiveness of the RS-CNN model developed. We further investigate the saliency map of the best RS-CNN models using the correctly predicted Raman spectra. The specific Raman signatures that are related to the cancer-associated biomolecular variations (e.g., collagens, lipids, and nucleic acids) are uncovered in the map, validating the diagnostic capability of RS-CNN models to correlate with biomolecular signatures. Deep learning-based Raman spectroscopy is a powerful diagnostic tool for rapid screening and surveillance of NPC patients and can also be deployed for longitudinal follow-up monitoring of post-treatment NPC patients to detect early cancer recurrences in the head and neck.",0,0
7260,"Metabolic Profiling Revealed Prediction Biomarkers for Infantile Hemangioma in Umbilical Cord Blood Sera: A Prospective Study. Infantile hemangioma (IH), the most common benign tumor in infancy, mostly arises and has rapid growth before 3 months of age. Because irreversible skin changes occur in the early proliferative stage, early medical treatment is essential to reduce the permanent sequelae caused by IH. Yet there are still no early screening biomarkers for IH before its visible emergence. This study aimed to explore prediction biomarkers using noninvasive umbilical cord blood (UCB). A prospective study of the metabolic profiling approach was performed on UCB sera from 28 infants with IH and 132 matched healthy controls from a UCB population comprising over 1500 infants (PeptideAtlas: PASS01675) using liquid chromatography-mass spectrometry. The metabolic profiling results exhibited the characteristic metabolic aberrance of IH. Machine learning suggested a panel of biomarkers to predict the occurrence of IH, with the area under curve (AUC) values in the receiver operating characteristic analysis all >0.943. Phenylacetic acid had potential to predict infants with large IH (diameter >2 cm) from those with small IH (diameter <2 cm), with an AUC of 0.756. The novel biomarkers in noninvasive UCB sera for predicting IH before its emergence might lead to a revolutionary clinical utility.",0,0
7262,"Tumor Mutation Burden Prediction Model in Egyptian Breast Cancer patients based on Next Generation Sequencing. This study aimed to identify the tumor mutation burden (TMB) value in Egyptian breast cancer (BC) patients. Moreover, to find the best TMB prediction model based on the expression of estrogen (ER), progesterone (PR), human epidermal growth factor receptor 2 (HER-2), and proliferation index Ki-67.",0,0
7266,"Comparison among random forest, logistic regression, and existing clinical risk scores for predicting outcomes in patients with atrial fibrillation: A report from the J-RHYTHM registry. Machine learning (ML) has emerged as a promising tool for risk stratification. However, few studies have applied ML to risk assessment of patients with atrial fibrillation (AF).",0,0
7267,"MRI-based radiomics analysis for predicting the EGFR mutation based on thoracic spinal metastases in lung adenocarcinoma patients. This study aims to develop and evaluate multi-parametric MRI-based radiomics for preoperative identification of epidermal growth factor receptor (EGFR) mutation, which is important in treatment planning for patients with thoracic spinal metastases from primary lung adenocarcinoma.",0,0
7271,Image enhancement of whole-body oncology [<sup>18</sup>F]-FDG PET scans using deep neural networks to reduce noise. To enhance the image quality of oncology [<sup>18</sup>F]-FDG PET scans acquired in shorter times and reconstructed by faster algorithms using deep neural networks.,0,0
7272,"A Predictive Analysis of Wall Stress in Abdominal Aortic Aneurysms Using a Neural Network Model. Rupture risk assessment of abdominal aortic aneurysms (AAAs) by means of quantifying wall stress is a common biomechanical strategy. However, the clinical translation of this approach has been greatly limited due to the complexity associated with the computational tools required for its implementation. Thus, being able to estimate wall stress using nonbiomechanical markers that can be quantified as a direct outcome of clinical image segmentation would be advantageous in improving the potential implementation of said strategy. In the present work, we investigated the use of geometric indices to predict patient-specific AAA wall stress by means of a novel neural network (NN) modeling approach. We conducted a retrospective review of existing clinical images of two patient groups: 98 asymptomatic and 50 symptomatic AAAs. The images were subject to a protocol consisting of image segmentation, processing, volume meshing, finite element modeling, and geometry quantification, from which 53 geometric indices and the spatially averaged wall stress (SAWS) were calculated. SAWS estimated from finite element analysis was considered the gold standard for the predictions. We developed feed-forward NN models composed of an input layer, two dense layers, and an output layer using Keras, a deep learning library in python. The NN models were trained, tested, and validated independently for both AAA groups using all geometric indices, as well as a reduced set of indices resulting from a variable reduction procedure. We compared the performance of the NN models with two standard machine learning algorithms (MARS: multivariate adaptive regression splines and GAM: generalized additive model) and a linear regression model (GLM: generalized linear model). With the reduced sets of indices, the NN-based approach exhibited the highest mean goodness-of-fit (for the symptomatic group 0.71 and for the asymptomatic group 0.79) and lowest mean relative error (17% for both groups). In contrast, MARS yielded a mean goodness-of-fit of 0.59 for the symptomatic group and 0.77 for the asymptomatic group, with relative errors of 17% for the symptomatic group and 22% for the asymptomatic group. GAM had a mean goodness-of-fit of 0.70 for the symptomatic group and 0.80 for the asymptomatic group, with relative errors of 16% for the symptomatic group and 20% for the asymptomatic group. GLM did not perform as well as the other algorithms, with a mean goodness-of-fit of 0.53 for the symptomatic group and 0.70 for the asymptomatic group, with relative errors of 19% for the symptomatic group and 23% for the asymptomatic group. Nevertheless, the NN models required a reduced set of 15 and 13 geometric indices to predict SAWS for the symptomatic and asymptomatic AAA groups, respectively. This was in contrast to the reduced set of nine and eight geometric indices required to predict SAWS with the MARS and GAM algorithms for each AAA group, respectively. The use of NN modeling represents a promising alternative methodology for the estimation of AAA wall stress using geometric indices as surrogates, in lieu of finite element modeling. The performance metrics of NN models are expected to improve with significantly larger group sizes, given the suitability of NN modeling for ""big data"" applications.",0,0
7274,"Detection of Autism Spectrum Disorder in Children Using Machine Learning Techniques. Autism Spectrum Disorder (ASD) is a neurological disorder which might have a lifelong impact on the language learning, speech, cognitive, and social skills of an individual. Its symptoms usually show up in the developmental stages, i.e., within the first two years after birth, and it impacts around 1% of the population globally [https://www.autism-society.org/whatis/facts-and-statistics/. Accessed 25 Dec 2019]. ASD is mainly caused by genetics or by environmental factors; however, its conditions can be improved by detecting and treating it at earlier stages. In the current times, clinical standardized tests are the only methods which are being used, to diagnose ASD. This not only requires prolonged diagnostic time but also faces a steep increase in medical costs. To improve the precision and time required for diagnosis, machine learning techniques are being used to complement the conventional methods. We have applied models such as Support Vector Machines (SVM), Random Forest Classifier (RFC), NaÃ¯ve Bayes (NB), Logistic Regression (LR), and KNN to our dataset and constructed predictive models based on the outcome. The main objective of our paper is to thus determine if the child is susceptible to ASD in its nascent stages, which would help streamline the diagnosis process. Based on our results, Logistic Regression gives the highest accuracy for our selected dataset.",0,0
7278,"Explanatory Analysis of a Machine Learning Model to Identify Hypertrophic Cardiomyopathy Patients from EHR Using Diagnostic Codes. Hypertrophic cardiomyopathy (HCM) is a genetic heart disease that is the leading cause of sudden cardiac death (SCD) in young adults. Despite the well-known risk factors and existing clinical practice guidelines, HCM patients are underdiagnosed and sub-optimally managed. Developing machine learning models on electronic health record (EHR) data can help in better diagnosis of HCM and thus improve hundreds of patient lives. Automated phenotyping using HCM billing codes has received limited attention in the literature with a small number of prior publications. In this paper, we propose a novel predictive model that helps physicians in making diagnostic decisions, by means of information learned from historical data of similar patients. We assembled a cohort of 11,562 patients with known or suspected HCM who have visited Mayo Clinic between the years 1995 to 2019. All existing billing codes of these patients were extracted from the EHR data warehouse. Target ground truth labeling for training the machine learning model was provided by confirmed HCM diagnosis using the gold standard imaging tests for HCM diagnosis echocardiography (echo), or cardiac magnetic resonance (CMR) imaging. As the result, patients were labeled into three categories of ""yes definite HCM"", ""no HCM phenotype"", and ""possible HCM"" after a manual review of medical records and imaging tests. In this study, a random forest was adopted to investigate the predictive performance of billing codes for the identification of HCM patients due to its practical application and expected accuracy in a wide range of use cases. Our model performed well in finding patients with ""yes definite"", ""possible"" and ""no"" HCM with an accuracy of 71%, weighted recall of 70%, the precision of 75%, and weighted F1 score of 72%. Furthermore, we provided visualizations based on multidimensional scaling and the principal component analysis to provide insights for clinicians' interpretation. This model can be used for the identification of HCM patients using their EHR data, and help clinicians in their diagnosis decision making.",0,0
7279,"Automatic anatomical classification of colonoscopic images using deep convolutional neural networks. A colonoscopy can detect colorectal diseases, including cancers, polyps, and inflammatory bowel diseases. A computer-aided diagnosis (CAD) system using deep convolutional neural networks (CNNs) that can recognize anatomical locations during a colonoscopy could efficiently assist practitioners. We aimed to construct a CAD system using a CNN to distinguish colorectal images from parts of the cecum, ascending colon, transverse colon, descending colon, sigmoid colon, and rectum.",0,0
7281,"Identification of miR-203a, mir-10a, and miR-194 as predictors for risk of lymphovascular invasion in head and neck cancers. Lymphovascular invasion (LVI) is an important prognostic indicator of lymph node metastasis and disease aggressiveness but clear molecular mechanisms mediating this in head and neck cancers (HNSC) remain undefined. To identify important microRNAs (miRNAs) in HNSC that associate with and are also predictive of increased risk of LVI, we used a combination of clustering algorithms, multiple regression analyses and machine learning approaches and analyzed miRNA expression profiles in the TCGA HNSC database. As the first step, we identified miRNAs with increased association with LVI as a binary variable. In order to determine whether the identified miRNAs would show functional clusters that are also indicative of increased risk for LVI, we carried out unsupervised as well as supervised clustering. Our results identified distinct clusters of miRNAs that are predictive of increased LVI. We further refined these findings using a Random forest approach, and miR-203a-3p, mir-10a-5p, and miR-194-5p to be most strongly associated with LVI. Pathway enrichment analysis showed these miRNAs targeted genes involved in Hippo signaling and fatty acid oxidation pathways that are mediators of lymph node metastasis. Specific association was also identified between the miRNAs associated with LVI and expression of several lymphangiogenic genes that could be critical for determination of therapeutic strategies.",0,0
7283,"Assessment and Establishment of Correlation between Reactive Oxidation Species, Citric Acid, and Fructose Level in Infertile Male Individuals: A Machine-Learning Approach. Biochemical complexity of seminal plasma and obesity has an important role in male infertility (MI); so far, it has not been possible to provide evidence of clinical significance for all of them.",0,0
7289,"Uniqueness of gait kinematics in a cohort study. Gait, the style of human walking, has been studied as a behavioral characteristic of an individual. Several studies have utilized gait to identify individuals with the aid of machine learning and computer vision techniques. However, there is a lack of studies on the nature of gait, such as the identification power or the uniqueness. This study aims to quantify the uniqueness of gait in a cohort. Three-dimensional full-body joint kinematics were obtained during normal walking trials from 488 subjects using a motion capture system. The joint angles of the gait cycle were converted into gait vectors. Four gait vectors were obtained from each subject, and all the gait vectors were pooled together. Two gait vectors were randomly selected from the pool and tested if they could be accurately classified if they were from the same person or not. The gait from the cohort was classified with an accuracy of 99.71% using the support vector machine with a radial basis function kernel as a classifier. Gait of a person is as unique as his/her facial motion and finger impedance, but not as unique as fingerprints.",0,0
7290,"2D-3D reconstruction of distal forearm bone from actual X-ray images of the wrist using convolutional neural networks. The purpose of the study was to develop a deep learning network for estimating and constructing highly accurate 3D bone models directly from actual X-ray images and to verify its accuracy. The data used were 173 computed tomography (CT) images and 105 actual X-ray images of a healthy wrist joint. To compensate for the small size of the dataset, digitally reconstructed radiography (DRR) images generated from CT were used as training data instead of actual X-ray images. The DRR-like images were generated from actual X-ray images in the test and adapted to the network, and high-accuracy estimation of a 3D bone model from a small data set was possible. The 3D shape of the radius and ulna were estimated from actual X-ray images with accuracies of 1.05â€‰Â±â€‰0.36 and 1.45â€‰Â±â€‰0.41Â mm, respectively.",0,0
7294,"A Multitask Deep-Learning System to Classify Diabetic Macular Edema for Different Optical Coherence Tomography Devices: A Multicenter Analysis. Diabetic macular edema (DME) is the primary cause of vision loss among individuals with diabetes mellitus (DM). We developed, validated, and tested a deep learning (DL) system for classifying DME using images from three common commercially available optical coherence tomography (OCT) devices.",0,0
7295,Deep Learning Network for Segmentation of the Prostate Gland With Median Lobe Enlargement in T2-weighted MR Images: Comparison With Manual Segmentation Method. Aim of this study was to evaluate a fully automated deep learning network named Efficient Neural Network (ENet) for segmentation of prostate gland with median lobe enlargement compared to manual segmentation.,1,1
7296,"Artificial Intelligence-Enabled Electrocardiography to Screen Patients with Dilated Cardiomyopathy. Undiagnosed dilated cardiomyopathy (DC) can be asymptomatic or present as sudden cardiac death, therefore pre-emptively identifying and treating patients may be beneficial. Screening for DC with echocardiography is expensive and labor intensive and standard electrocardiography (ECG) is insensitive and non-specific. The performance and applicability of artificial intelligence-enabled electrocardiography (AI-ECG) for detection of DC is unknown. Diagnostic performance of an AI algorithm in determining reduced left ventricular ejection fraction (LVEF) was evaluated in a cohort that comprised of DC and normal LVEF control patients. DC patients and controls with 12-lead ECGs and a reference LVEF measured by echocardiography performed within 30 and 180 days of the ECG respectively were enrolled. The model was tested for its sensitivity, specificity, negative predictive (NPV) and positive predictive values (PPV) based on the prevalence of DC at 1% and 5%. The cohort consisted of 421 DC cases (60% males, 57Â±15 years, LVEF 28Â±11%) and 16,025 controls (49% males, age 69 Â±16 years, LVEF 62Â±5%). For detection of LVEFâ‰¤45%, the area under the curve (AUC) was 0.955 with a sensitivity of 98.8% and specificity 44.8%. The NPV and PPV were 100% and 1.8% at a DC prevalence of 1% and 99.9% and 8.6% at a prevalence of 5%, respectively. In conclusion AI-ECG demonstrated high sensitivity and negative predictive value for detection of DC and could be used as a simple and cost-effective screening tool with implications for screening first degree relatives of DC patients.",0,0
7297,"Automatic segmentation of brain metastases using T1 magnetic resonance and computed tomography images. An increasing number of patients with multiple brain metastases are being treated with stereotactic radiosurgery (SRS). Manually identifying and contouring all metastatic lesions is difficult and time-consuming, and a potential source of variability. Hence, we developed a 3D deep learning approach for segmenting brain metastases on MR and CT images. Five-hundred eleven patients treated with SRS were retrospectively identified for this study. Prior to radiotherapy, the patients were imaged with 3D T1 spoiled-gradient MR post-Gd (T1Â +Â C) and contrast-enhanced CT (CECT), which were co-registered by a treatment planner. The gross tumor volume contours, authored by the attending radiation oncologist, were taken as the ground truth. There were 3Â Â±Â 4 metastases per patient, with volume up to 57 ml. We produced a multi-stage model that automatically performs brain extraction, followed by detection and segmentation of brain metastases using co-registered T1Â +Â C and CECT. Augmented data from 80% of these patients were used to train modified 3D V-Net convolutional neural networks for this task. We combined a normalized boundary loss function with soft Dice loss to improve the model optimization, and employed gradient accumulation to stabilize the training. The average Dice similarity coefficient (DSC) for brain extraction was 0.975Â Â±Â 0.002 (95% CI). The detection sensitivity per metastasis was 90% (329/367), with moderate dependence on metastasis size. Averaged across 102 test patients, our approach had metastasis detection sensitivity 95Â Â±Â 3%, 2.4Â Â±Â 0.5 false positives, DSC of 0.76Â Â±Â 0.03, and 95th-percentile Hausdorff distance of 2.5Â Â±Â 0.3 mm (95% CIs). The volumes of automatic and manual segmentations were strongly correlated for metastases of volume up to 20 ml (r=0.97,p<0.001). This work expounds a fully 3D deep learning approach capable of automatically detecting and segmenting brain metastases using co-registered T1Â +Â C and CECT.",0,0
7300,"Quantitative analysis of EEG reactivity for neurological prognostication after cardiac arrest. To test whether 1) quantitative analysis of EEG reactivity (EEG-R) using machine learning (ML) is superior to visual analysis, and 2) combining quantitative analyses of EEG-R and EEG background pattern increases prognostic value for prediction of poor outcome after cardiac arrest (CA).",0,0
7303,"Heart disease prediction using supervised machine learning algorithms: Performance analysis and comparison. Machine learning and data mining-based approaches to prediction and detection of heart disease would be of great clinical utility, but are highly challenging to develop. In most countries there is a lack of cardiovascular expertise and a significant rate of incorrectly diagnosed cases which could be addressed by developing accurate and efficient early-stage heart disease prediction by analytical support of clinical decision-making with digital patient records. This study aimed to identify machine learning classifiers with the highest accuracy for such diagnostic purposes. Several supervised machine-learning algorithms were applied and compared for performance and accuracy in heart disease prediction. Feature importance scores for each feature were estimated for all applied algorithms except MLP and KNN. All the features were ranked based on the importance score to find those giving high heart disease predictions. This study found that using a heart disease dataset collected from Kaggle three-classification based on k-nearest neighbor (KNN), decision tree (DT) and random forests (RF) algorithms the RF method achieved 100% accuracy along with 100% sensitivity and specificity. Thus, we found that a relatively simple supervised machine learning algorithm can be used to make heart disease predictions with very high accuracy and excellent potential utility.",0,0
7311,Machine learning analysis of multispectral imaging and clinical risk factors to predict amputation wound healing. Prediction of amputation wound healing is challenging due to the multifactorial nature of critical limb ischemia and lack of objective assessment tools. Up to one-third of amputations require revision to a more proximal level within one year. We tested a novel wound imaging system to predict amputation wound healing at initial evaluation.,0,0
7312,Localization of cementoenamel junction in intraoral ultrasonographs with machine learning. Our goal was to automatically identify the cementoenamel junction (CEJ) location in ultrasound images using deep convolution neural networks (CNNs).,0,0
7314,"Data-driven identification of complex disease phenotypes. Disease interaction in multimorbid patients is relevant to treatment and prognosis, yet poorly understood. In the present work, we combine approaches from network science, machine learning and computational phenotyping to assess interactions between two or more diseases in a transparent way across the full diagnostic spectrum. We demonstrate that health states of hospitalized patients can be better characterized by including higher-order features capturing interactions between <i>more</i> than two diseases. We identify a meaningful set of higher-order diagnosis features that account for synergistic disease interactions in a population-wide (<i>N</i> = 9 M) medical claims dataset. We construct a <i>generalized disease network</i> where (higher-order) diagnosis features are linked if they predict similar diagnoses across the whole diagnostic spectrum. The fact that specific diagnoses are generally represented multiple times in the network allows for the identification of putatively different disease phenotypes that may reflect different disease aetiologies. At the example of obesity, we demonstrate the purely data-driven detection of two complex phenotypes of obesity. As indicated by a matched comparison between patients having these phenotypes, we show that these phenotypes show specific characteristics of what has been controversially discussed in the medical literature as metabolically healthy and unhealthy obesity, respectively. The findings also suggest that metabolically healthy patients show some progression towards more unhealthy obesity over time, a finding that is consistent with longitudinal studies indicating a transient nature of metabolically healthy obesity. The disease network is available for exploration at https://disease.network/.",0,0
7318,"A Multitask Learning Approach to Personalised Blood Glucose Prediction. Blood glucose prediction algorithms are key tools in the development of decision support systems and closed-loop insulin delivery systems for blood glucose control in diabetes. Deep learning models have provided leading results among machine learning algorithms to date in glucose prediction. However these models typically require large amounts of data to obtain best personalised glucose prediction results. Multitask learning facilitates an approach for leveraging data from multiple subjects while still learning accurate personalised models. In this work we present results comparing the effectiveness of multitask learning over sequential transfer learning, and learning only on subject-specific data with neural networks and support vector regression. The multitask learning approach shows consistent leading performance in predictive metrics at both short-term and long-term prediction horizons. We obtain a predictive accuracy (RMSE) of 18.8 2.3, 25.3 2.9, 31.8 3.9, 41.2 4.5, 47.2 4.6 mg/dL at 30, 45, 60, 90, and 120 min prediction horizons respectively, with at least 93\% clinically acceptable predictions using the Clarke Error Grid (EGA) at each prediction horizon. We also identify relevant prior information such as glycaemic variability that can be incorporated to improve predictive performance at long-term prediction horizons. Furthermore, we demonstrate consistent performance - 5% change in both RMSE and EGA (Zone A) - in rare cases of adverse glycaemic events with 1-6 weeks of training data. In conclusion, a multitask approach can allow for deploying personalised models even with significantly less subject-specific data without compromising performance.",0,0
7320,"Geometric Deep Learning for Subject-Independent Epileptic Seizure Prediction using Scalp EEG Signals. Recently, researchers in the biomedical community have introduced deep learning-based epileptic seizure prediction models using electroencephalograms (EEGs) that can anticipate an epileptic seizure by differentiating between the pre-ictal and interictal stages of the subjects brain. Despite having the appearance of a typical anomaly detection task, this problem is complicated by subject-specific characteristics in EEG data. Therefore, studies that investigate seizure prediction widely employ subject-specific models. However, this approach is not suitable in situations where a target subject has limited (or no) data for training. Subject-independent models can address this issue by learning to predict seizures from multiple subjects, and therefore are of greater value in practice. In this study, we propose a subject-independent seizure predictor using Geometric Deep Learning (GDL). In the first stage of our GDL-based method we use graphs derived from physical connections in the EEG grid. We subsequently seek to synthesize subject-specific graphs using deep learning. The models proposed in both stages achieve state-of-the-art performance using a one-hour early seizure prediction window on two benchmark datasets (CHB-MIT-EEG: 95.38% with 23 subjects and Siena-EEG: 96.05% with 15 subjects). To the best of our knowledge, this is the first study that proposes synthesizing subject-specific graphs for seizure prediction. Furthermore, through model interpretation we outline how this method can potentially contribute towards Scalp EEG-based seizure localization.",0,0
7321,"Deep Supervised Domain Adaptation for Pneumonia Diagnosis from Chest X-ray Images. Pneumonia is one of the most common treatable causes of death, and early diagnosis allows for early intervention. Automated diagnosis of pneumonia can therefore improve outcomes. However, it is challenging to develop high performance deep learning models due to the lack of well-annotated data for training. This paper proposes a novel method, called Deep Supervised Domain Adaptation (DSDA), to automatically diagnose pneumonia from chest X-ray images. Specifically, we propose to transfer the knowledge from a publicly available large-scale source dataset (ChestX-ray14) to a well-annotated but small-scale target dataset (the TTSH dataset). DSDA aligns the distributions of the source domain and the target domain according to the underlying semantics of the training samples. It includes two task-specific sub-networks for the source domain and the target domain, respectively. These two sub-networks share the feature extraction layers and are trained in an end-to-end manner. Unlike most existing domain adaptation approaches that perform the same tasks in the source domain and the target domain, we attempt to transfer the knowledge from a multi-label classification task in the source domain to a binary classification task in the target domain. To evaluate the effectiveness of our method, we compare it with several existing peer methods. The experimental results show that our method can achieve promising performance for automated pneumonia diagnosis.",0,0
7322,"Wrist-worn Hand Gesture Recognition while Walking via Transfer Learning. Walking, one of the most common daily activities, causes unwanted movement artifacts which can significantly deteriorate hand gesture recognition accuracy. However, traditional hand gesture recognition algorithms are typically developed and validated with wrist-worn devices only during static human poses, neglecting the critical importance of dynamic effects on gesture accuracy. Thus, we developed and validated a signal decomposition approach via empirical mode decomposition to accurately segment target gestures from coupled raw signals during dynamic walking and a transfer learning method based on distribution adaptation to enable gesture recognition through domain transfer between dynamic walking and static standing scenarios. Ten healthy subjects performed seven hand gestures during both walking and standing experiments while wearing an IMU wrist-worn device. Experimental results showed that the signal decomposition approach reduced the gesture detection error by 83.8%, and the transfer learning approach (20% transfer rate) improved hand gesture recognition accuracy by 15.1%. This ground-breaking work demonstrates the feasibility of hand gesture recognition while walking via wrist-worn sensing. These findings serve to inform real-life and ubiquitous adoption of wrist-worn hand gesture recognition for intuitive human-machine interaction in dynamic walking situations.",0,0
7324,Machine Learning Prediction of Kidney Stone Composition Using Electronic Health Record-Derived Features. Noninvasive prediction of kidney stone composition could direct dietary and pharmacologic preventative treatment without stone analysis. We aimed to assess the accuracy of machine learning models in predicting kidney stone composition using variables extracted from the electronic health record (EHR).,0,0
7329,"Automatic Detection of Covid-19 with Bidirectional LSTM Network Using Deep Features Extracted from Chest X-ray Images. Coronavirus disease, which comes up in China at the end of 2019 and showed different symptoms in people infected, affected millions of people. Computer-aided expert systems are needed due to the inadequacy of the reverse transcription-polymerase chain reaction kit, which is widely used in the diagnosis of this disease. Undoubtedly, expert systems that provide effective solutions to many problems will be very useful in the detection of Covid-19 disease, especially when unskilled personnel and financial deficiencies in underdeveloped countries are taken into consideration. In the literature, there are numerous machine learning approaches built with different classifiers in the detection of this disease. This paper proposes an approach based on deep learning which detects Covid-19 and no-finding cases using chest X-ray images. Here, the classification performance of the Bi-LSTM network on the deep features was compared with the Deep Neural Network within the frame of the fivefold cross-validation technique. Accuracy, sensitivity, specificity and precision metrics were used to evaluate the classification performance of the trained models. Bi-LSTM network presented better performance compare to DNN with 97.6% value of high accuracy despite the few numbers of Covid-19 images in the dataset. In addition, it is understood that concatenated deep features more meaningful than deep features obtained with pre-trained networks by one by, as well. Consequently, it is thought that the proposed study based on the Bi-LSTM network and concatenated deep features will be noteworthy in the design of highly sensitive automated Covid-19 monitoring systems.",0,0
7332,"Machine Learning Identifies Stool pH as Predictor of Bone Mineral Density in Healthy Multi-Ethnic U.S. Adults. A variety of modifiable and non-modifiable factors such as ethnicity, age, and diet have been shown to influence bone health. Previous studies are usually limited to analyses focused on the association of a few a priori variables or on a specific subset of the population.",0,0
7337,"Prediction Model of Anastomotic Leakage Among Esophageal Cancer Patients After Receiving an Esophagectomy: Machine Learning Approach. Anastomotic leakage (AL) is one of the severe postoperative adverse events (5%-30%), and it is related to increased medical costs in cancer patients who undergo esophagectomies. Machine learning (ML) methods show good performance at predicting risk for AL. However, AL risk prediction based on ML models among the Chinese population is unavailable.",0,0
7339,"A combination of fecal calprotectin and human beta-defensin 2 facilitates diagnosis and monitoring of inflammatory bowel disease. Inflammatory bowel disease (IBD) and irritable bowel syndrome (IBS) show a large overlap in clinical presentation, which presents diagnostic challenges. As a consequence, invasive and burdensome endoscopies are often used to distinguish between IBD and IBS. Here, we aimed to develop a noninvasive fecal test that can distinguish between IBD and IBS and reduce the number of endoscopies.We used shotgun metagenomic sequencing to analyze the composition and function of gut microbiota of 169 IBS patients, 447 IBD patients and 1044 population controls and measured fecal Calprotectin (FCal), human beta defensin 2 (HBD2), and chromogranin A (CgA) in these samples. These measurements were used to construct training sets (75% of data) for logistic regression and machine learning models to differentiate IBS from IBD and inactive from active IBD. The results were replicated on test sets (remaining 25% of the data) and microbiome data obtained using 16S sequencing.Fecal HBD2 showed high sensitivity and specificity for differentiating between IBD and IBS (sensitivityÂ =Â 0.89, specificityÂ =Â 0.76), while the inclusion of microbiome data with biomarkers (HBD2 and FCal) showed a potential for improvement in predictive power (optimal sensitivityÂ =Â 0.87, specificityÂ =Â 0.93). Shotgun sequencing-based models produced comparable results using 16S-sequencing data. HBD2 and FCal were found to have predictive power for IBD disease activity (AUC â‰ˆ 0.7).HBD2 is a novel biomarker for IBD in patients with gastro-intestinal complaints, especially when used in combination with FCal and potentially in combination with gut microbiome data.",0,0
7340,Radiomics and machine learning to predict aggressive type 2 endoleaks after endovascular aneurysm repair: a proof of concept. Persistent type 2 endoleaks (T2EL) require lifelong surveillance to avoid potentially life-threatening complications.,0,0
7349,Deep learning-based evaluation of the relationship between mandibular third molar and mandibular canal on CBCT. The objective of our study was to develop and validate a deep learning approach based on convolutional neural networks (CNNs) for automatic detection of the mandibular third molar (M3) and the mandibular canal (MC) and evaluation of the relationship between them on CBCT.,0,0
7354,"A Unified Hierarchical XGBoost model for classifying priorities for COVID-19 vaccination campaign. The current ML approaches do not fully focus to answer a still unresolved and topical challenge, namely the prediction of priorities of COVID-19 vaccine administration. Thus, our task includes some additional methodological challenges mainly related to avoiding unwanted bias while handling categorical and ordinal data with a highly imbalanced nature. Hence, the main contribution of this study is to propose a machine learning algorithm, namely Hierarchical Priority Classification eXtreme Gradient Boosting for priority classification for COVID-19 vaccine administration using the Italian Federation of General Practitioners dataset that contains Electronic Health Record data of 17k patients. We measured the effectiveness of the proposed methodology for classifying all the priority classes while demonstrating a significant improvement with respect to the state of the art. The proposed ML approach, which is integrated into a clinical decision support system, is currently supporting General Pracitioners in assigning COVID-19 vaccine administration priorities to their assistants.",0,0
7357,"Classification of glioblastoma versus primary central nervous system lymphoma using convolutional neural networks. A subset of primary central nervous system lymphomas (PCNSL) are difficult to distinguish from glioblastoma multiforme (GBM) on magnetic resonance imaging (MRI). We developed a convolutional neural network (CNN) to distinguish these tumors on contrast-enhanced T<sub>1</sub>-weighted images. Preoperative brain tumor MRIs were retrospectively collected among 320 patients with either GBM (nâ€‰=â€‰160) and PCNSL (nâ€‰=â€‰160) from two academic institutions. The individual images from these MRIs consisted of a training set (nâ€‰=â€‰1894 GBM and 1245 PCNSL), a validation set (nâ€‰=â€‰339 GBM; 202 PCNSL), and a testing set (99 GBM and 108 PCNSL). Three CNNs using the EfficientNetB4 architecture were evaluated. To increase the size of the training set and minimize overfitting, random flips and changes to color were performed on the training set. Our transfer learning approach (with image augmentation and 292 epochs) yielded an AUC of 0.94 (95% CI: 0.91-0.97) for GBM and an AUC of 0.95 (95% CI: 0.92-0.98) for PCNL. In the second case (not augmented and 137 epochs), the images were augmented prior to training. The area under the curve for GBM was 0.92 (95% CI: 0.88-0.96) for GBM and an AUC of 0.94 (95% CI: 0.91-0.97) for PCNSL. For the last case (augmented, Gaussian noise and 238 epochs) the AUC for GBM was 0.93 (95% CI: 0.89-0.96) and an AUC 0.93 (95% CIâ€‰=â€‰0.89-0.96) for PCNSL. Even with a relatively small dataset, our transfer learning approach demonstrated CNNs may provide accurate diagnostic information to assist radiologists in distinguishing PCNSL and GBM.",0,0
7366,"Self-supervised deep learning model for COVID-19 lung CT image segmentation highlighting putative causal relationship among age, underlying disease and COVID-19. Coronavirus disease 2019 (COVID-19) is very contagious. Cases appear faster than the available Polymerase Chain Reaction test kits in many countries. Recently, lung computerized tomography (CT) has been used as an auxiliary COVID-19 testing approach. Automatic analysis of the lung CT images is needed to increase the diagnostic efficiency and release the human participant. Deep learning is successful in automatically solving computer vision problems. Thus, it can be introduced to the automatic and rapid COVID-19 CT diagnosis. Many advanced deep learning-based computer vison techniques were developed to increase the model performance but have not been introduced to medical image analysis.",0,0
7367,"A new variant of deep belief network assisted with optimal feature selection for heart disease diagnosis using IoT wearable medical devices. In this paper, the information related to heart disease using IoT wearable devices is collected from any benchmark site, which is publicly available. With the collected data, feature extraction process is performed initially, in which heart rate, zero crossing rate, and higher order statistical features like standard deviation, median, skewness, kurtosis, variance, mean, peak amplitude, and entropy are extracted. For acquiring most significant features, the optimal feature selection process is implemented. As a novel contribution, the feature selection process is done by the hybrid optimization algorithm called PS-GWO by integrating GWO and PSO. Next, the extracted features are subjected to a famous deep learning algorithm named modified DBN, in which the activation function and number of hidden neurons is optimized using the same developed hybrid algorithm to improve the heart diagnosis accuracy. From the analysis, for the test case 1, the accuracy of the developed PS-GWO-DBN is 60%, 52.5%, 35% and 35% increased than NN, KNN, SVM, and DBN. For test case 2, the accuracy of the proposed PS-GWO-DBN is 26%, 24%, 21.6% and 17% increased than NN, KNN, SVM, and DBN, respectively. The accuracy of the designed PS-GWO-DBN is 26% advanced than NN, 24% advanced than KNN, 21.6% advanced than SVM and 17% advanced than DBN for test case 3. Thus, the proposed heart disease prediction model using PS-GWO-DBN performs better than other classifiers.",0,0
7369,"Deep Learning in the Detection of Rare Fractures - Development of a ""Deep Learning Convolutional Network"" Model for Detecting Acetabular Fractures. Fracture detection by artificial intelligence and especially Deep Convolutional Neural Networks (DCNN) is a topic of growing interest in current orthopaedic and radiological research. As learning a DCNN usually needs a large amount of training data, mostly frequent fractures as well as conventional X-ray are used. Therefore, less common fractures like acetabular fractures (AF) are underrepresented in the literature. The aim of this pilot study was to establish a DCNN for detection of AF using computer tomography (CT) scans.",0,0
7371,"Two-branch 3D convolutional neural network for motor imagery EEG decoding. <i>Objective.</i>The original motor imagery electroencephalography (MI-EEG) data contains not only temporal features but also a large number of spatial features related to the distribution of electrodes on the brain. However, in the process of MI-EEG decoding, most of the current convolutional neural network (CNN) based methods do not make the utmost of the spatial features related to electrode distribution.<i>Approach.</i>In this study, we adopt a concise 3D representation for the MI-EEG data to take full advantage of the spatial features and propose a two-branch 3D CNN (TB-3D CNN) for the 3D representation of MI-EEG data. First, the spatial and temporal features of the input 3D samples are extracted by the spatial and temporal feature learning branches, respectively, to avoid the mutual interference between the temporal and spatial features. Then, the central loss is introduced into the TB-3D CNN framework to further improve the MI-EEG decoding accuracy. And a 3D data augmentation method based on the cyclic translation of time dimension is proposed for the 3D representation method to alleviate the overfitting problem.<i>Main results.</i>Some experiments are conducted on the famous BCI competition IV 2a dataset to evaluate the effectiveness of the proposed MI-EEG decoding method. The experimental results comparison with some state-of-the-art methods demonstrates that the average accuracy of our method is 4.42% higher than that of the best of the comparative methods.<i>Significance.</i>The proposed MI-EEG decoding method has great promise to improve the performance of motor imagery brain-computer interface system.",0,0
7372,"Learning to synthesise the ageing brain without longitudinal data. How will my face look when I get older? Or, for a more challenging question: How will my brain look when I get older? To answer this question one must devise (and learn from data) a multivariate auto-regressive function which given an image and a desired target age generates an output image. While collecting data for faces may be easier, collecting longitudinal brain data is not trivial. We propose a deep learning-based method that learns to simulate subject-specific brain ageing trajectories without relying on longitudinal data. Our method synthesises images conditioned on two factors: age (a continuous variable), and status of Alzheimer's Disease (AD, an ordinal variable). With an adversarial formulation we learn the joint distribution of brain appearance, age and AD status, and define reconstruction losses to address the challenging problem of preserving subject identity. We compare with several benchmarks using two widely used datasets. We evaluate the quality and realism of synthesised images using ground-truth longitudinal data and a pre-trained age predictor. We show that, despite the use of cross-sectional data, our model learns patterns of gray matter atrophy in the middle temporal gyrus in patients with AD. To demonstrate generalisation ability, we train on one dataset and evaluate predictions on the other. In conclusion, our model shows an ability to separate age, disease influence and anatomy using only 2D cross-sectional data that should be useful in large studies into neurodegenerative disease, that aim to combine several data sources. To facilitate such future studies by the community at large our code is made available at https://github.com/xiat0616/BrainAgeing.",0,0
7379,"Differentiating ictal/subclinical spikes and waves in childhood absence epilepsy by spectral and network analyses: A pilot study. Childhood absence epilepsy (CAE) is a disease with distinct seizure semiology and electroencephalographic (EEG) features. Differentiating ictal and subclinical generalized spikes and waves discharges (GSWDs) in the EEG is challenging, since they appear to be identical upon visual inspection. Here, spectral and functional connectivity (FC) analyses were applied to routine EEG data of CAE patients, to differentiate ictal and subclinical GSWDs.",0,0
7386,"Improving accuracy of American Society of Anesthesiologists Physical Status using audit and feedback and artificial intelligence: a time-series analysis. While the American Society of Anesthesiologists (ASA) Physical Status (PS) is used to adjust for greater mortality risk with higher ASA PS classification, inaccurate classification can lead to an inaccurate comparison of institutions.",0,0
7395,"Individual versus Group Calibration of Machine Learning Models for Physical Activity Assessment Using Body-Worn Accelerometers. Modeling approaches for translating accelerometer data into physical activity metrics are often developed using a group calibration approach. However, it is unknown if models developed for specific individuals will improve measurement accuracy.",0,0
7400,"Multi-scale binary pattern encoding network for cancer classification in pathology images. Multi-scale approaches have been widely studied in pathology image analysis. These offer an ability to characterize tissues in an image at various scales, in which the tissues may appear differently. Many of such methods have focused on extracting multi-scale hand-crafted features and applied them to various tasks in pathology image analysis. Even, several deep learning methods explicitly adopt the multi-scale approaches. However, most of these methods simply merge the multi-scale features together or adopt the coarse-to-fine/fine-to-coarse strategy, which uses the features one at a time in a sequential manner. Utilizing the multi-scale features in a cooperative and discriminative fashion, the learning capabilities could be further improved. Herein, we propose a multi-scale approach that can identify and leverage the patterns of the multiple scales within a deep neural network and provide the superior capability of cancer classification. The patterns of the features across multiple scales are encoded as a binary pattern code and further converted to a decimal number, which can be easily embedded in the current framework of the deep neural networks. To evaluate the proposed method, multiple sets of pathology images are employed. Under the various experimental settings, the proposed method is systematically assessed and shows an improved classification performance in comparison to other competing methods.",0,0
7401,"Assessment of Parkinson's Disease Severity from Videos using Deep Architecture. Parkinson's disease (PD) diagnosis is based on clinical criteria, i.e., bradykinesia, rest tremor, rigidity, etc. Assessment of the severity of PD symptoms with clinical rating scales, however, is subject to inter-rater variability. In this paper, we propose a deep learning based automatic PD diagnosis method using videos to assist the diagnosis in clinical practices. We deploy a 3D Convolutional Neural Network (CNN) as the baseline approach for the PD severity classification and show the effectiveness. Due to the lack of data in clinical field, we explore the possibility of transfer learning from non-medical dataset and show that PD severity classification can benefit from it. To bridge the domain discrepancy between medical and non-medical datasets, we let the network focus more on the subtle temporal visual cues, i.e., the frequency of tremors, by designing a Temporal Self-Attention (TSA) mechanism. Seven tasks from the Movement Disorders Society - Unified PD rating scale (MDS-UPDRS) part III are investigated, which reveal the symptoms of bradykinesia and postural tremors. Furthermore, we propose a multi-domain learning method to predict the patient-level PD severity through task-assembling. We show the effectiveness of TSA and task-assembling method on our PD video dataset empirically. We achieve the best MCC of 0.55 on binary task-level and 0.39 on three-class patient-level classification.",0,0
7403,"Mixture Model Framework for Traumatic Brain Injury Prognosis Using Heterogeneous Clinical and Outcome Data. Prognoses of Traumatic Brain Injury (TBI) outcomes are neither easily nor accurately determined from clinical indicators. This is due in part to the heterogeneity of damage inflicted to the brain, ultimately resulting in diverse and complex outcomes. Using a data-driven approach on many distinct data elements may be necessary to describe this large set of outcomes and thereby robustly depict the nuanced differences among TBI patients recovery. In this work, we develop a method for modeling large heterogeneous data types relevant to TBI. Our approach is geared toward the probabilistic representation of mixed continuous and discrete variables with missing values. The model is trained on a dataset encompassing a variety of data types, including demographics, blood-based biomarkers, and imaging findings. In addition, it includes a set of clinical outcome assessments at 3, 6, and 12 months post-injury. The model is used to stratify patients into distinct groups in an unsupervised learning setting. We use the model to infer outcomes using input data, and show that the collection of input data reduces uncertainty of outcomes over a baseline approach. In addition, we quantify the performance of a likelihood scoring technique that can be used to self-evaluate the extrapolation risk of prognosis on unseen patients.",0,0
7404,"Wearable RF Near-Field Cough Monitoring by Frequency-Time Deep Learning. Coughing is a common symptom for many respiratory disorders, and can spread droplets of various sizes containing bacterial and viral pathogens. Mild coughs are usually overlooked in the early stage, not only because they are barely noticeable by the person and the people around, but also because the present recording method is not comfortable, private, or reliable for long-term monitoring. In this paper, a wearable radio-frequency (RF) sensor is presented to recognize the mild cough signal directly from the local trachea vibration characteristics, and can isolate interferences from nearby people. The sensor operates at the ultra-high-frequency band, and can couple the RF energy to the upper respiratory track by the near field of the sensing antenna. The retrieved tissue vibration caused by the cough airflow burst can then be analyzed by a convolutional neural network trained on the frequency-time spectra. The sensing antenna design is analyzed for performance improvement. During the human study of 5 participants over 100 minutes of prescribed routines, the overall recognition ratio is above 90% and the false positive ratio during other routines is below 2.09%.",0,0
7405,"Genetic analysis of coronary artery disease using tree-based automated machine learning informed by biology-based feature selection. Machine Learning (ML) approaches are increasingly being used in biomedical applications. Important challenges of ML include choosing the right algorithm and tuning the parameters for optimal performance. Automated ML (AutoML) methods, such as Tree-based Pipeline Optimization Tool (TPOT), have been developed to take some of the guesswork out of ML thus making this technology available to users from more diverse backgrounds. The goals of this study were to assess applicability of TPOT to genomics and to identify combinations of single nucleotide polymorphisms (SNPs) associated with coronary artery disease (CAD), with a focus on genes with high likelihood of being good CAD drug targets. We leveraged public functional genomic resources to group SNPs into biologically meaningful sets to be selected by TPOT. We applied this strategy to data from the UK Biobank, detecting a strikingly recurrent signal stemming from a group of 28 SNPs. Importance analysis of these SNPs uncovered functional relevance of the top SNPs to genes whose association with CAD is supported in the literature and other resources. Furthermore, we employed game-theory based metrics to study SNP contributions to individual-level TPOT predictions and discover distinct clusters of well-predicted CAD cases. The latter indicates a promising approach towards precision medicine.",0,0
7406,"A Temporal-Spectral-Based Squeeze-and- Excitation Feature Fusion Network for Motor Imagery EEG Decoding. Motor imagery (MI) electroencephalography (EEG) decoding plays an important role in brain-computer interface (BCI), which enables motor-disabled patients to communicate with the outside world via external devices. Recent deep learning methods, which fail to fully explore both deep-temporal characterizations in EEGs itself and multi-spectral information in different rhythms, generally ignore the temporal or spectral dependencies in MI-EEG. Also, the lack of effective feature fusion probably leads to redundant or irrelative information and thus fails to achieve the most discriminative features, resulting in the limited MI-EEG decoding performance. To address these issues, in this paper, a MI-EEG decoding framework is proposed, which uses a novel temporal-spectral-based squeeze-and-excitation feature fusion network (TS-SEFFNet). First, the deep-temporal convolution block (DT-Conv block) implements convolutions in a cascade architecture, which extracts high-dimension temporal representations from raw EEG signals. Second, the multi-spectral convolution block (MS-Conv block) is then conducted in parallel using multi-level wavelet convolutions to capture discriminative spectral features from corresponding clinical subbands. Finally, the proposed squeeze-and-excitation feature fusion block (SE-Feature-Fusion block) maps the deep-temporal and multi-spectral features into comprehensive fused feature maps, which highlights channel-wise feature responses by constructing interdependencies among different domain features. Competitive experimental results on two public datasets demonstrate that our method is able to achieve promising decoding performance compared with the state-of-the-art methods.",0,0
7418,"Comparing data-driven and hypothesis-driven MRI-based predictors of cognitive impairment in individuals from the Atherosclerosis Risk in Communities (ARIC) study. A data-driven index of dementia risk based on magnetic resonance imaging (MRI), the Alzheimer's Disease Pattern Similarity (AD-PS) score, was estimated for participants in the Atherosclerosis Risk in Communities (ARIC) study.",0,0
7421,A novel artificial intelligence approach for the automatic differentiation of fetal occiput anterior and non-occiput anterior positions during labor. The aim of this study is to develop a Machine Learning (ML) algorithm for an automatic classification of fetal occiput position at transperineal ultrasound (TPU) during the second stage of labor.,0,0
7425,"Classification of large-scale image database of various skin diseases using deep learning. The purpose of this study was to develop a deep learning-based computer-aided diagnosis system for skin disease classification using photographic images of patients. The targets are 59 skin diseases, including localized and diffuse diseases captured by photographic cameras, resulting in highly diverse images in terms of the appearance of the diseases or photographic conditions.",0,0
7426,"Candidemia Risk Prediction (CanDETEC) Model for Patients With Malignancy: Model Development and Validation in a Single-Center Retrospective Study. Appropriate empirical treatment for candidemia is associated with reduced mortality; however, the timely diagnosis of candidemia in patients with sepsis remains poor.",0,0
7427,"A Machine Learning-Based Algorithm for the Prediction of Intensive Care Unit Delirium (PRIDE): Retrospective Study. Delirium frequently occurs among patients admitted to the intensive care unit (ICU). There is limited evidence to support interventions to treat or resolve delirium in patients who have already developed delirium. Therefore, the early recognition and prevention of delirium are important in the management of critically ill patients.",0,0
7441,"Artificial Intelligence-Enabled Caregiving Walking Stick Powered by Ultra-Low-Frequency Human Motion. The increasing population of the elderly and motion-impaired people brings a huge challenge to our social system. However, the walking stick as their essential tool has rarely been investigated into its potential capabilities beyond basic physical support, such as activity monitoring, tracing, and accident alert. Here, we report a walking stick powered by ultra-low-frequency human motion and equipped with deep-learning-enabled advanced sensing features to provide a healthcare-monitoring platform for motion-impaired users. A linear-to-rotary structure is designed to achieve highly efficient energy harvesting from the linear motion of a walking stick with ultralow frequency. Besides, two kinds of self-powered triboelectric sensors are proposed and integrated to extract the motion features of the walking stick. Augmented sensing functionalities with high accuracies have been enabled by deep-learning-based data analysis, including identity recognition, disability evaluation, and motion status distinguishing. Furthermore, a self-sustainable Internet of Things (IoT) system with global positioning system tracing and environmental temperature and humidity amenity sensing functions is obtained. Combined with the aforementioned functionalities, this walking stick is demonstrated in various usage scenarios as a caregiver for real-time well-being status and activity monitoring. The caregiving walking stick shows the potential of being an intelligent aid for motion-impaired users to help them live life with adequate autonomy and safety.",0,0
7442,"Hold-out validation for the assessment of stability and reliability of multivariable regression demonstrated with magnetic resonance imaging of patients with schizophrenia. Neuroscience studies are very often tasked with identifying measurable differences between two groups of subjects, typically one group with a pathological condition and one group representing control subjects. It is often expected that the measurements acquired for comparing groups are also affected by a variety of additional patient characteristics such as sex, age, and comorbidities. Multivariable regression (MVR) is a statistical analysis technique commonly employed in neuroscience studies to ""control for"" or ""adjust for"" secondary effects (such as sex, age, and comorbidities) in order to ensure that the main study findings are focused on actual differences between the groups of interest associated with the condition under investigation. It is common practice in the neuroscience literature to utilize MVR to control for secondary effects; however, at present, it is not typically possible to assess whether the MVR adjustments correct for more error than they introduce. In common neuroscience practice, MVR models are not validated and no attempt to characterize deficiencies in the MVR model is made. In this article, we demonstrate how standard hold-out validation techniques (commonly used in machine learning analyses) that involve repeatedly randomly dividing datasets into training and testing samples can be adapted to the assessment of stability and reliability of MVR models with a publicly available neurological magnetic resonance imaging (MRI) dataset of patients with schizophrenia. Results demonstrate that MVR can introduce measurement error up to 30.06% and, on average across all considered measurements, introduce 9.84% error on this dataset. When hold-out validated MVR does not agree with the results of the standard use of MVR, the use of MVR in the given application is unstable. Thus, this paper helps evaluate the extent to which the simplistic use of MVR introduces study error in neuroscientific analyses with an analysis of patients with schizophrenia.",0,0
7443,A decision support system based on radiomics and machine learning to predict the risk of malignancy of ovarian masses from transvaginal ultrasonography and serum CA-125. To evaluate the performance of a decision support system (DSS) based on radiomics and machine learning in predicting the risk of malignancy of ovarian masses (OMs) from transvaginal ultrasonography (TUS) and serum CA-125.,0,0
7447,"Longitudinal metabolomics of human plasma reveals prognostic markers of COVID-19 disease severity. There is an urgent need to identify which COVID-19 patients will develop life-threatening illness so that medical resources can be optimally allocated and rapid treatment can be administered early in the disease course, when clinical management is most effective. To aid in the prognostic classification of disease severity, we perform untargeted metabolomics on plasma from 339 patients, with samples collected at six longitudinal time points. Using the temporal metabolic profiles and machine learning, we build a predictive model of disease severity. We discover that a panel of metabolites measured at the time of study entry successfully determines disease severity. Through analysis of longitudinal samples, we confirm that most of these markers are directly related to disease progression and that their levels return to baseline upon disease recovery. Finally, we validate that these metabolites are also altered in a hamster model of COVID-19.",0,0
7454,"Neural-ODE for pharmacokinetics modeling and its advantage to alternative machine learning models in predicting new dosing regimens. Forecasting pharmacokinetics (PK) for individual patients is a fundamental problem in clinical pharmacology. One key challenge is that PK models constructed using data from one dosing regimen must predict PK data for different dosing regimen(s). We propose a deep learning approach based on neural ordinary differential equations (neural-ODE) and tested its generalizability against a variety of alternative models. Specifically, we used the PK data from two different treatment regimens of trastuzumab emtansine. The models performed similarly when the training and the test sets come from the same dosing regimen. However, for predicting a new treatment regimen, the neural-ODE model showed substantially better performance. To date, neural-ODE is the most accurate PK model in predicting untested treatment regimens. This study represents the first time neural-ODE has been applied to PK modeling and the results suggest it is a widely applicable algorithm with the potential to impact future studies.",0,0
7455,"Random forest approach for determining risk prediction and predictive factors of type 2 diabetes: large-scale health check-up data in Japan. Early intervention in type 2 diabetes can prevent exacerbation of insulin resistance. More effective interventions can be implemented by early and precise prediction of the change in glycated haemoglobin A1c (HbA1c). Artificial intelligence (AI), which has been introduced into various medical fields, may be useful in predicting changes in HbA1c. However, the inability to explain the predictive factors has been a problem in the use of deep learning, the leading AI technology. Therefore, we applied a highly interpretable AI method, random forest (RF), to large-scale health check-up data and examined whether there was an advantage over a conventional prediction model.",0,0
7457,"Artificial Intelligence-Assisted Electrocardiography for Early Diagnosis of Thyrotoxic Periodic Paralysis. Thyrotoxic periodic paralysis (TPP) characterized by acute weakness, hypokalemia, and hyperthyroidism is a medical emergency with a great challenge in early diagnosis since most TPP patients do not have overt symptoms.",0,0
7460,Oropharyngeal primary tumor segmentation for radiotherapy planning on magnetic resonance imaging using deep learning. Segmentation of oropharyngeal squamous cell carcinoma (OPSCC) is needed for radiotherapy planning. We aimed to segment the primary tumor for OPSCC on MRI using convolutional neural networks (CNNs). We investigated the effect of multiple MRI sequences as input and we proposed a semi-automatic approach for tumor segmentation that is expected to save time in the clinic.,0,0
7462,"Computerized Assessment of Psychosis Risk. Early detection and intervention with young people at clinical high risk (CHR) for psychosis is critical for prevention efforts focused on altering the trajectory of psychosis. Early CHR research largely focused on validating clinical interviews for detecting at-risk individuals; however, this approach has limitations related to: (1) specificity (i.e., only 20% of CHR individuals convert to psychosis) and (2) the expertise and training needed to administer these interviews is limited. The purpose of our study is to develop the computerized assessment of psychosis risk (CAPR) battery, consisting of behavioral tasks that require minimal training to administer, can be administered online, and are tied to the neurobiological systems and computational mechanisms implicated in psychosis. The aims of our study are as follows: (1A) to develop a psychosis-risk calculator through the application of machine learning (ML) methods to the measures from the CAPR battery, (1B) evaluate group differences on the risk calculator score and test the hypothesis that the risk calculator score of the CHR group will differ from help-seeking and healthy controls, (1C) evaluate how baseline CAPR battery performance relates to symptomatic outcome two years later (i.e., conversion and symptomatic worsening). These aims will be explored in 500 CHR participants, 500 help-seeking individuals, and 500 healthy controls across the study sites. This project will provide a next-generation CHR battery, tied to illness mechanisms and powered by cutting-edge computational methods that can be used to facilitate the earliest possible detection of psychosis risk.",0,0
7465,"Chest X-ray pneumothorax segmentation using U-Net with EfficientNet and ResNet architectures. Medical imaging refers to visualization techniques to provide valuable information about the internal structures of the human body for clinical applications, diagnosis, treatment, and scientific research. Segmentation is one of the primary methods for analyzing and processing medical images, which helps doctors diagnose accurately by providing detailed information on the body's required part. However, segmenting medical images faces several challenges, such as requiring trained medical experts and being time-consuming and error-prone. Thus, it appears necessary for an automatic medical image segmentation system. Deep learning algorithms have recently shown outstanding performance for segmentation tasks, especially semantic segmentation networks that provide pixel-level image understanding. By introducing the first fully convolutional network (FCN) for semantic image segmentation, several segmentation networks have been proposed on its basis. One of the state-of-the-art convolutional networks in the medical image field is U-Net. This paper presents a novel end-to-end semantic segmentation model, named Ens4B-UNet, for medical images that ensembles four U-Net architectures with pre-trained backbone networks. Ens4B-UNet utilizes U-Net's success with several significant improvements by adapting powerful and robust convolutional neural networks (CNNs) as backbones for U-Nets encoders and using the nearest-neighbor up-sampling in the decoders. Ens4B-UNet is designed based on the weighted average ensemble of four encoder-decoder segmentation models. The backbone networks of all ensembled models are pre-trained on the ImageNet dataset to exploit the benefit of transfer learning. For improving our models, we apply several techniques for training and predicting, including stochastic weight averaging (SWA), data augmentation, test-time augmentation (TTA), and different types of optimal thresholds. We evaluate and test our models on the 2019 Pneumothorax Challenge dataset, which contains 12,047 training images with 12,954 masks and 3,205 test images. Our proposed segmentation network achieves a 0.8608 mean Dice similarity coefficient (DSC) on the test set, which is among the top one-percent systems in the Kaggle competition.",0,0
7469,"Identifying COVID-19-Specific Transcriptomic Biomarkers with Machine Learning Methods. COVID-19, a severe respiratory disease caused by a new type of coronavirus SARS-CoV-2, has been spreading all over the world. Patients infected with SARS-CoV-2 may have no pathogenic symptoms, i.e., presymptomatic patients and asymptomatic patients. Both patients could further spread the virus to other susceptible people, thereby making the control of COVID-19 difficult. The two major challenges for COVID-19 diagnosis at present are as follows: (1) patients could share similar symptoms with other respiratory infections, and (2) patients may not have any symptoms but could still spread the virus. Therefore, new biomarkers at different omics levels are required for the large-scale screening and diagnosis of COVID-19. Although some initial analyses could identify a group of candidate gene biomarkers for COVID-19, the previous work still could not identify biomarkers capable for clinical use in COVID-19, which requires disease-specific diagnosis compared with other multiple infectious diseases. As an extension of the previous study, optimized machine learning models were applied in the present study to identify some specific qualitative host biomarkers associated with COVID-19 infection on the basis of a publicly released transcriptomic dataset, which included healthy controls and patients with bacterial infection, influenza, COVID-19, and other kinds of coronavirus. This dataset was first analysed by Boruta, Max-Relevance and Min-Redundancy feature selection methods one by one, resulting in a feature list. This list was fed into the incremental feature selection method, incorporating one of the classification algorithms to extract essential biomarkers and build efficient classifiers and classification rules. The capacity of these findings to distinguish COVID-19 with other similar respiratory infectious diseases at the transcriptomic level was also validated, which may improve the efficacy and accuracy of COVID-19 diagnosis.",0,0
7474,"Automated Quality-Controlled Cardiovascular Magnetic Resonance Pericardial Fat Quantification Using a Convolutional Neural Network in the UK Biobank. <b>Background:</b> Pericardial adipose tissue (PAT) may represent a novel risk marker for cardiovascular disease. However, absence of rapid radiation-free PAT quantification methods has precluded its examination in large cohorts. <b>Objectives:</b> We developed a fully automated quality-controlled tool for cardiovascular magnetic resonance (CMR) PAT quantification in the UK Biobank (UKB). <b>Methods:</b> Image analysis comprised contouring an en-bloc PAT area on four-chamber cine images. We created a ground truth manual analysis dataset randomly split into training and test sets. We built a neural network for automated segmentation using a Multi-residual U-net architecture with incorporation of permanently active dropout layers to facilitate quality control of the model's output using Monte Carlo sampling. We developed an in-built quality control feature, which presents predicted Dice scores. We evaluated model performance against the test set (<i>n</i> = 87), the whole UKB Imaging cohort (<i>n</i> = 45,519), and an external dataset (<i>n</i> = 103). In an independent dataset, we compared automated CMR and cardiac computed tomography (CCT) PAT quantification. Finally, we tested association of CMR PAT with diabetes in the UKB (<i>n</i> = 42,928). <b>Results:</b> Agreement between automated and manual segmentations in the test set was almost identical to inter-observer variability (mean Dice score = 0.8). The quality control method predicted individual Dice scores with Pearson <i>r</i> = 0.75. Model performance remained high in the whole UKB Imaging cohort and in the external dataset, with medium-good quality segmentation in 94.3% (mean Dice score = 0.77) and 94.4% (mean Dice score = 0.78), respectively. There was high correlation between CMR and CCT PAT measures (Pearson <i>r</i> = 0.72, <i>p</i>-value 5.3 Ã—10<sup>-18</sup>). Larger CMR PAT area was associated with significantly greater odds of diabetes independent of age, sex, and body mass index. <b>Conclusions:</b> We present a novel fully automated method for CMR PAT quantification with good model performance on independent and external datasets, high correlation with reference standard CCT PAT measurement, and expected clinical associations with diabetes.",0,0
7480,"Predicting Colorectal Cancer Recurrence and Patient Survival Using Supervised Machine Learning Approach: A South African Population-Based Study. <b>Background:</b> South Africa (SA) has the highest incidence of colorectal cancer (CRC) in Sub-Saharan Africa (SSA). However, there is limited research on CRC recurrence and survival in SA. CRC recurrence and overall survival are highly variable across studies. Accurate prediction of patients at risk can enhance clinical expectations and decisions within the South African CRC patients population. We explored the feasibility of integrating statistical and machine learning (ML) algorithms to achieve higher predictive performance and interpretability in findings. <b>Methods:</b> We selected and compared six algorithms:- logistic regression (LR), naÃ¯ve Bayes (NB), C5.0, random forest (RF), support vector machine (SVM) and artificial neural network (ANN). Commonly selected features based on OneR and information gain, within 10-fold cross-validation, were used for model development. The validity and stability of the predictive models were further assessed using simulated datasets. <b>Results:</b> The six algorithms achieved high discriminative accuracies (AUC-ROC). ANN achieved the highest AUC-ROC for recurrence (87.0%) and survival (82.0%), and other models showed comparable performance with ANN. We observed no statistical difference in the performance of the models. Features including radiological stage and patient's age, histology, and race are risk factors of CRC recurrence and patient survival, respectively. <b>Conclusions:</b> Based on other studies and what is known in the field, we have affirmed important predictive factors for recurrence and survival using rigorous procedures. Outcomes of this study can be generalised to CRC patient population elsewhere in SA and other SSA countries with similar patient profiles.",0,0
7481,"Development of a Nomogram Based on Preoperative Bi-Parametric MRI and Blood Indices for the Differentiation Between Cystic-Solid Pituitary Adenoma and Craniopharyngioma. Given the similarities in clinical manifestations of cystic-solid pituitary adenomas (CS-PAs) and craniopharyngiomas (CPs), this study aims to establish and validate a nomogram based on preoperative imaging features and blood indices to differentiate between CS-PAs and CPs.",0,0
7482,Texture Analysis of DCE-MRI Intratumoral Subregions to Identify Benign and Malignant Breast Tumors. To evaluate the potential of the texture features extracted from dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) intratumoral subregions to distinguish benign from malignant breast tumors.,0,0
7483,"Predictive Radiomic Models for the Chemotherapy Response in Non-Small-Cell Lung Cancer based on Computerized-Tomography Images. The heterogeneity and complexity of non-small cell lung cancer (NSCLC) tumors mean that NSCLC patients at the same stage can have different chemotherapy prognoses. Accurate predictive models could recognize NSCLC patients likely to respond to chemotherapy so that they can be given personalized and effective treatment. We propose to identify predictive imaging biomarkers from pre-treatment CT images and construct a radiomic model that can predict the chemotherapy response in NSCLC. This single-center cohort study included 280 NSCLC patients who received first-line chemotherapy treatment. Non-contrast CT images were taken before and after the chemotherapy, and clinical information were collected. Based on the Response Evaluation Criteria in Solid Tumors and clinical criteria, the responses were classified into two categories: response (n = 145) and progression (n = 135), then all data were divided into two cohorts: training cohort (224 patients) and independent test cohort (56 patients). In total, 1629 features characterizing the tumor phenotype were extracted from a cube containing the tumor lesion cropped from the pre-chemotherapy CT images. After dimensionality reduction, predictive models of the chemotherapy response of NSCLC with different feature selection methods and different machine-learning classifiers (support vector machine, random forest, and logistic regression) were constructed. For the independent test cohort, the predictive model based on a random-forest classifier with 20 radiomic features achieved the best performance, with an accuracy of 85.7% and an area under the receiver operating characteristic curve of 0.941 (95% confidence interval, 0.898-0.982). Of the 20 selected features, four were first-order statistics of image intensity and the others were texture features. For nine features, there were significant differences between the response and progression groups (<i>p</i> < 0.001). In the response group, three features, indicating heterogeneity, were overrepresented and one feature indicating homogeneity was underrepresented. The proposed radiomic model with pre-chemotherapy CT features can predict the chemotherapy response of patients with non-small cell lung cancer. This radiomic model can help to stratify patients with NSCLC, thereby offering the prospect of better treatment.",0,0
7487,"A predictive model, and predictors of under-five child malaria prevalence in Ghana: How do LASSO, Ridge and Elastic net regression approaches compare? Malaria is among the leading causes of mortality and morbidity among children in Ghana. Therefore, identifying the predictors of malaria prevalence in children under-five is among the priorities of the global health agenda. In Ghana, the paradigm shifts from using traditional statistics to machine learning techniques to identifying predictors of malaria prevalence are scarce. Thus, the present study used machine learning techniques to identify variables to build the best fitting predictive model of malaria prevalence in Ghana. We analysed the data on 2867 under-five children with malaria RDT results from the 2019 Ghana Malaria Indicator Survey. LASSO, Ridge, and Elastic Net regression methods were used to select variables to build predictive models. The R freeware version 4.0.2 was used. One out of four children tested positive for malaria (25.04%). The logit models based on selected features by LASSO, Ridge, and Elastic Net contained eleven, fifteen, and thirteen features, respectively. The LASSO regression model is preferred because it contains the smallest number of predictors and the smallest prediction error. The significant predictors of malaria among children were being older than 24Â months, residing in the poorest household, being severely anaemic, residing in households without electricity, and residing in a rural area. The predictors identified in our study deserve policy attention and interventions to strengthen malaria control efforts in Ghana. The machine learning techniques employed in our study, especially the LASSO regression technique could be beneficial for identifying predictors of malaria prevalence in this group of children.",0,0
7491,"Automatic Prediction of Recurrence of Major Cardiovascular Events: A Text Mining Study Using Chest X-Ray Reports. We used EHR data of patients included in the Second Manifestations of ARTerial disease (SMART) study. We propose a deep learning-based multimodal architecture for our text mining pipeline that integrates neural text representation with preprocessed clinical predictors for the prediction of recurrence of major cardiovascular events in cardiovascular patients. Text preprocessing, including cleaning and stemming, was first applied to filter out the unwanted texts from X-ray radiology reports. Thereafter, text representation methods were used to numerically represent unstructured radiology reports with vectors. Subsequently, these text representation methods were added to prediction models to assess their clinical relevance. In this step, we applied logistic regression, support vector machine (SVM), multilayer perceptron neural network, convolutional neural network, long short-term memory (LSTM), and bidirectional LSTM deep neural network (BiLSTM).",0,0
7492,"Artificial Intelligence Analysis of EEG Amplitude in Intensive Heart Care. This article first studied the morphological characteristics of the EEG for intensive cardiac care; that is, based on the analysis of the mechanism of disease diagnosis and treatment, a signal processing and machine learning model was constructed. Then, the methods of signal preprocessing, signal feature extraction, new neural network model structure, training mechanism, optimization algorithm, and efficiency are studied, and experimental verification is carried out for public data sets and clinical big data. Then, the principle of intensive cardiac monitoring, the mechanism of disease diagnosis, the types of arrhythmia, and the characteristics of the typical signal are studied, and the rhythm performance, individual variability, and neurophysiological basis of electrical signals in intensive cardiac monitoring are researched. Finally, the automatic signal recognition technology is studied. In order to improve the training speed and generalization ability, a multiclassification model based on Least Squares Twin Support Vector Machine (LS-TWIN-SVM) is proposed. The computational complexity of the classification model algorithm is compared, and intelligence is adopted. The optimization algorithm selects the parameters of the classifier and uses the EEG signal to simulate the model. Support Vector Machines and their improved algorithms have achieved the ultimum in shallow neural networks and have achieved good results in the classification and recognition of bioelectric signals. The LS-TWIN-SVM algorithm proposed in this paper has achieved good results in the classification and recognition of bioelectric signals. It can perform bioinformatics processing on intensive cardiac care EEG signals, systematically biometric information, diagnose diseases, the real-time detection, auxiliary diagnosis, and rehabilitation of patients.",0,0
7494,"Deep Learning-Based Magnetic Resonance Imaging Image Features for Diagnosis of Anterior Cruciate Ligament Injury. To study and explore the adoption value of magnetic resonance imaging (MRI) in the diagnosis of anterior cruciate ligament (ACL) injuries, a multimodal feature fusion model based on deep learning was proposed for MRI diagnosis. After the related performance of the proposed algorithm was evaluated, it was utilized in the diagnosis of knee joint injuries. Thirty patients with knee joint injuries who came to our hospital for treatment were selected, and all patients were diagnosed with MRI based on deep learning multimodal feature fusion model (MRI group) and arthroscopy (arthroscopy group). The results showed that deep learning-based MRI sagittal plane detection had a great advantage and a high accuracy of 96.28% in the prediction task of ACL tearing. The sensitivity, specificity, and accuracy of MRI in the diagnosis of ACL injury was 96.78%, 90.62%, and 92.17%, respectively, and there was no considerable difference in contrast to the results obtained through arthroscopy (<i>P</i> > 0.05). The positive rate of acute ACL patients with bone contusion and medial collateral ligament injury was substantially superior to that of chronic injury. Moreover, the incidence of chronic injury ACL injury with meniscus tear and cartilage injury was notably higher than that of acute injury, with remarkable differences (<i>P</i> < 0.05). In summary, MRI images based on deep learning improved the sensitivity, specificity, and accuracy of ACL injury diagnosis and can accurately determined the type of ACL injury. In addition, it can provide reference information for clinical treatment plan selection and surgery and can be applied and promoted in clinical diagnosis.",0,0
7499,"Deep Learning-Based Approaches to Improve Classification Parameters for Diagnosing COVID-19 from CT Images. Patients infected with the COVID-19 virus develop severe pneumonia, which generally leads to death. Radiological evidence has demonstrated that the disease causes interstitial involvement in the lungs and lung opacities, as well as bilateral ground-glass opacities and patchy opacities. In this study, new pipeline suggestions are presented, and their performance is tested to decrease the number of false-negative (FN), false-positive (FP), and total misclassified images (FNâ€‰+â€‰FP) in the diagnosis of COVID-19 (COVID-19/non-COVID-19 and COVID-19 pneumonia/other pneumonia) from CT lung images. A total of 4320 CT lung images, of which 2554 were related to COVID-19 and 1766 to non-COVID-19, were used for the test procedures in COVID-19 and non-COVID-19 classifications. Similarly, a total of 3801 CT lung images, of which 2554 were related to COVID-19 pneumonia and 1247 to other pneumonia, were used for the test procedures in COVID-19 pneumonia and other pneumonia classifications. A 24-layer convolutional neural network (CNN) architecture was used for the classification processes. Within the scope of this study, the results of two experiments were obtained by using CT lung images with and without local binary pattern (LBP) application, and sub-band images were obtained by applying dual-tree complex wavelet transform (DT-CWT) to these images. Next, new classification results were calculated from these two results by using the five pipeline approaches presented in this study. For COVID-19 and non-COVID-19 classification, the highest sensitivity, specificity, accuracy, F-1, and AUC values obtained without using pipeline approaches were 0.9676, 0.9181, 0.9456, 0.9545, and 0.9890, respectively; using pipeline approaches, the values were 0.9832, 0.9622, 0.9577, 0.9642, and 0.9923, respectively. For COVID-19 pneumonia/other pneumonia classification, the highest sensitivity, specificity, accuracy, F-1, and AUC values obtained without using pipeline approaches were 0.9615, 0.7270, 0.8846, 0.9180, and 0.9370, respectively; using pipeline approaches, the values were 0.9915, 0.8140, 0.9071, 0.9327, and 0.9615, respectively. The results of this study show that classification success can be increased by reducing the time to obtain per-image results through using the proposed pipeline approaches.",0,0
7500,"A Computationally Virtual Histological Staining Method to Ovarian Cancer Tissue by Deep Generative Adversarial Networks. Histological analysis to tissue samples is elemental for diagnosing the risk and severity of ovarian cancer. The commonly used Hematoxylin and Eosin (H&E) staining method involves complex steps and strict requirements, which would seriously impact the research of histological analysis of the ovarian cancer. Virtual histological staining by the Generative Adversarial Network (GAN) provides a feasible way for these problems, yet it is still a challenge of using deep learning technology since the amounts of data available are quite limited for training. Based on the idea of GAN, we propose a weakly supervised learning method to generate autofluorescence images of unstained ovarian tissue sections corresponding to H&E staining sections of ovarian tissue. Using the above method, we constructed the supervision conditions for the virtual staining process, which makes the image quality synthesized in the subsequent virtual staining stage more perfect. Through the doctors' evaluation of our results, the accuracy of ovarian cancer unstained fluorescence image generated by our method reached 93%. At the same time, we evaluated the image quality of the generated images, where the FID reached 175.969, the IS score reached 1.311, and the MS reached 0.717. Based on the image-to-image translation method, we use the data set constructed in the previous step to implement a virtual staining method that is accurate to tissue cells. The accuracy of staining through the doctor's assessment reached 97%. At the same time, the accuracy of visual evaluation based on deep learning reached 95%.",0,0
7501,"Multiclassification of Endoscopic Colonoscopy Images Based on Deep Transfer Learning. With the continuous improvement of human living standards, dietary habits are constantly changing, which brings various bowel problems. Among them, the morbidity and mortality rates of colorectal cancer have maintained a significant upward trend. In recent years, the application of deep learning in the medical field has become increasingly spread aboard and deep. In a colonoscopy, Artificial Intelligence based on deep learning is mainly used to assist in the detection of colorectal polyps and the classification of colorectal lesions. But when it comes to classification, it can lead to confusion between polyps and other diseases. In order to accurately diagnose various diseases in the intestines and improve the classification accuracy of polyps, this work proposes a multiclassification method for medical colonoscopy images based on deep learning, which mainly classifies the four conditions of polyps, inflammation, tumor, and normal. In view of the relatively small number of data sets, the network firstly trained by transfer learning on ImageNet was used as the pretraining model, and the prior knowledge learned from the source domain learning task was applied to the classification task about intestinal illnesses. Then, we fine-tune the model to make it more suitable for the task of intestinal classification by our data sets. Finally, the model is applied to the multiclassification of medical colonoscopy images. Experimental results show that the method in this work can significantly improve the recognition rate of polyps while ensuring the classification accuracy of other categories, so as to assist the doctor in the diagnosis of surgical resection.",0,0
7506,"Prediction of Heart Disease Using a Combination of Machine Learning and Deep Learning. The correct prediction of heart disease can prevent life threats, and incorrect prediction can prove to be fatal at the same time. In this paper different machine learning algorithms and deep learning are applied to compare the results and analysis of the UCI Machine Learning Heart Disease dataset. The dataset consists of 14 main attributes used for performing the analysis. Various promising results are achieved and are validated using accuracy and confusion matrix. The dataset consists of some irrelevant features which are handled using Isolation Forest, and data are also normalized for getting better results. And how this study can be combined with some multimedia technology like mobile devices is also discussed. Using deep learning approach, 94.2% accuracy was obtained.",0,0
7516,"An Unbiased Machine Learning Exploration Reveals Gene Sets Predictive of Allograft Tolerance After Kidney Transplantation. Efforts at finding potential biomarkers of tolerance after kidney transplantation have been hindered by limited sample size, as well as the complicated mechanisms underlying tolerance and the potential risk of rejection after immunosuppressant withdrawal. In this work, three different publicly available genome-wide expression data sets of peripheral blood lymphocyte (PBL) from 63 tolerant patients were used to compare 14 different machine learning models for their ability to predict spontaneous kidney graft tolerance. We found that the Best Subset Selection (BSS) regression approach was the most powerful with a sensitivity of 91.7% and a specificity of 93.8% in the test group, and a specificity of 86.1% and a sensitivity of 80% in the validation group. A feature set with five genes (HLA-DOA, TCL1A, EBF1, CD79B, and PNOC) was identified using the BSS model. EBF1 downregulation was also an independent factor predictive of graft rejection and graft loss. An AUC value of 84.4% was achieved using the two-gene signature (EBF1 and HLA-DOA) as an input to our classifier. Overall, our systematic machine learning exploration suggests novel biological targets that might affect tolerance to renal allografts, and provides clinical insights that can potentially guide patient selection for immunosuppressant withdrawal.",0,0
7519,"Identification of Microbiota Biomarkers With Orthologous Gene Annotation for Type 2 Diabetes. Type 2 diabetes (T2D) is a systematic chronic metabolic condition with abnormal sugar metabolism dysfunction, and its complications are the most harmful to human beings and may be life-threatening after long-term durations. Considering the high incidence and severity at late stage, researchers have been focusing on the identification of specific biomarkers and potential drug targets for T2D at the genomic, epigenomic, and transcriptomic levels. Microbes participate in the pathogenesis of multiple metabolic diseases including diabetes. However, the related studies are still non-systematic and lack the functional exploration on identified microbes. To fill this gap between gut microbiome and diabetes study, we first introduced eggNOG database and KEGG ORTHOLOGY (KO) database for orthologous (protein/gene) annotation of microbiota. Two datasets with these annotations were employed, which were analyzed by multiple machine-learning models for identifying significant microbiota biomarkers of T2D. The powerful feature selection method, Max-Relevance and Min-Redundancy (mRMR), was first applied to the datasets, resulting in a feature list for each dataset. Then, the list was fed into the incremental feature selection (IFS), incorporating support vector machine (SVM) as the classification algorithm, to extract essential annotations and build efficient classifiers. This study not only revealed potential pathological factors for diabetes at the microbiome level but also provided us new candidates for drug development against diabetes.",0,0
7520,"Preoperative Heart Rate Variability During Sleep Predicts Vagus Nerve Stimulation Outcome Better in Patients With Drug-Resistant Epilepsy. <b>Objective:</b> Vagus nerve stimulation (VNS) is an adjunctive and well-established treatment for patients with drug-resistant epilepsy (DRE). However, it is still difficult to identify patients who may benefit from VNS surgery. Our study aims to propose a VNS outcome prediction model based on machine learning with multidimensional preoperative heart rate variability (HRV) indices. <b>Methods:</b> The preoperative electrocardiography (ECG) of 59 patients with DRE and of 50 healthy controls were analyzed. Responders were defined as having at least 50% average monthly seizure frequency reduction at 1-year follow-up. Time domain, frequency domain, and non-linear indices of HRV were compared between 30 responders and 29 non-responders in awake and sleep states, respectively. For feature selection, univariate filter and recursive feature elimination (RFE) algorithms were performed to assess the importance of different HRV indices to VNS outcome prediction and improve the classification performance. Random forest (RF) was used to train the classifier, and leave-one-out (LOO) cross-validation was performed to evaluate the prediction model. <b>Results:</b> Among 52 HRV indices, 49 showed significant differences between DRE patients and healthy controls. In sleep state, 35 HRV indices of responders were significantly higher than those of non-responders, while 16 of them showed the same differences in awake state. Low-frequency power (LF) ranked first in the importance ranking results by univariate filter and RFE methods, respectively. With HRV indices in sleep state, our model achieved 74.6% accuracy, 80% precision, 70.6% recall, and 75% F1 for VNS outcome prediction, which was better than the optimal performance in awake state (65.3% accuracy, 66.4% precision, 70.5% recall, and 68.4% F1). <b>Significance:</b> With the ECG during sleep state and machine learning techniques, the statistical model based on preoperative HRV could achieve a better performance of VNS outcome prediction and, therefore, help patients who are not suitable for VNS to avoid the high cost of surgery and possible risks of long-term stimulation.",0,0
7521,"Deep Learning-Based Localization of EEG Electrodes Within MRI Acquisitions. The simultaneous acquisition of electroencephalographic (EEG) signals and functional magnetic resonance images (fMRI) aims to measure brain activity with good spatial and temporal resolution. This bimodal neuroimaging can bring complementary and very relevant information in many cases and in particular for epilepsy. Indeed, it has been shown that it can facilitate the localization of epileptic networks. Regarding the EEG, source localization requires the resolution of a complex inverse problem that depends on several parameters, one of the most important of which is the position of the EEG electrodes on the scalp. These positions are often roughly estimated using fiducial points. In simultaneous EEG-fMRI acquisitions, specific MRI sequences can provide valuable spatial information. In this work, we propose a new fully automatic method based on neural networks to segment an ultra-short echo-time MR volume in order to retrieve the coordinates and labels of the EEG electrodes. It consists of two steps: a segmentation of the images by a neural network, followed by the registration of an EEG template on the obtained detections. We trained the neural network using 37 MR volumes and then we tested our method on 23 new volumes. The results show an average detection accuracy of 99.7% with an average position error of 2.24 mm, as well as 100% accuracy in the labeling.",0,0
7527,"A Deep Learning Algorithm to Predict Hazardous Drinkers and the Severity of Alcohol-Related Problems Using K-NHANES. <b>Purpose:</b> The number of patients with alcohol-related problems is steadily increasing. A large-scale survey of alcohol-related problems has been conducted. However, studies that predict hazardous drinkers and identify which factors contribute to the prediction are limited. Thus, the purpose of this study was to predict hazardous drinkers and the severity of alcohol-related problems of patients using a deep learning algorithm based on a large-scale survey data. <b>Materials and Methods:</b> Datasets of National Health and Nutrition Examination Survey of South Korea (K-NHANES), a nationally representative survey for the entire South Korean population, were used to train deep learning and conventional machine learning algorithms. Datasets from 69,187 and 45,672 participants were used to predict hazardous drinkers and the severity of alcohol-related problems, respectively. Based on the degree of contribution of each variable to deep learning, it was possible to determine which variable contributed significantly to the prediction of hazardous drinkers. <b>Results:</b> Deep learning showed the higher performance than conventional machine learning algorithms. It predicted hazardous drinkers with an AUC (Area under the receiver operating characteristic curve) of 0.870 (Logistic regression: 0.858, Linear SVM: 0.849, Random forest classifier: 0.810, K-nearest neighbors: 0.740). Among 325 variables for predicting hazardous drinkers, energy intake was a factor showing the greatest contribution to the prediction, followed by carbohydrate intake. Participants were classified into Zone I, Zone II, Zone III, and Zone IV based on the degree of alcohol-related problems, showing AUCs of 0.881, 0.774, 0.853, and 0.879, respectively. <b>Conclusion:</b> Hazardous drinking groups could be effectively predicted and individuals could be classified according to the degree of alcohol-related problems using a deep learning algorithm. This algorithm could be used to screen people who need treatment for alcohol-related problems among the general population or hospital visitors.",0,0
7533,"Three-Dimensional Convolutional Autoencoder Extracts Features of Structural Brain Images With a ""Diagnostic Label-Free"" Approach: Application to Schizophrenia Datasets. There has been increasing interest in performing psychiatric brain imaging studies using deep learning. However, most studies in this field disregard three-dimensional (3D) spatial information and targeted disease discrimination, without considering the genetic and clinical heterogeneity of psychiatric disorders. The purpose of this study was to investigate the efficacy of a 3D convolutional autoencoder (3D-CAE) for extracting features related to psychiatric disorders without diagnostic labels. The network was trained using a Kyoto University dataset including 82 patients with schizophrenia (SZ) and 90 healthy subjects (HS) and was evaluated using Center for Biomedical Research Excellence (COBRE) datasets, including 71 SZ patients and 71 HS. We created 16 3D-CAE models with different channels and convolutions to explore the effective range of hyperparameters for psychiatric brain imaging. The number of blocks containing two convolutional layers and one pooling layer was set, ranging from 1 block to 4 blocks. The number of channels in the extraction layer varied from 1, 4, 16, and 32 channels. The proposed 3D-CAEs were successfully reproduced into 3D structural magnetic resonance imaging (MRI) scans with sufficiently low errors. In addition, the features extracted using 3D-CAE retained the relation to clinical information. We explored the appropriate hyperparameter range of 3D-CAE, and it was suggested that a model with 3 blocks may be related to extracting features for predicting the dose of medication and symptom severity in schizophrenia.",0,0
7536,"Deep learning based detection of COVID-19 from chest X-ray images. The whole world is facing a health crisis, that is unique in its kind, due to the COVID-19 pandemic. As the coronavirus continues spreading, researchers are concerned by providing or help provide solutions to save lives and to stop the pandemic outbreak. Among others, artificial intelligence (AI) has been adapted to address the challenges caused by pandemic. In this article, we design a deep learning system to extract features and detect COVID-19 from chest X-ray images. Three powerful networks, namely ResNet50, InceptionV3, and VGG16, have been fine-tuned on an enhanced dataset, which was constructed by collecting COVID-19 and normal chest X-ray images from different public databases. We applied data augmentation techniques to artificially generate a large number of chest X-ray images: Random Rotation with an angle between -â€‰10 and 10 degrees, random noise, and horizontal flips. Experimental results are encouraging: the proposed models reached an accuracy of 97.20â€‰% for Resnet50, 98.10â€‰% for InceptionV3, and 98.30â€‰% for VGG16 in classifying chest X-ray images as Normal or COVID-19. The results show that transfer learning is proven to be effective, showing strong performance and easy-to-deploy COVID-19 detection methods. This enables automatizing the process of analyzing X-ray images with high accuracy and it can also be used in cases where the materials and RT-PCR tests are limited.",0,0
7537,"<math xmlns=""http://www.w3.org/1998/Math/MathML""><mover><mtext>pin</mtext> <mo>Â¯</mo></mover> </math> -TSVM: A Robust Transductive Support Vector Machine and its Application to the Detection of COVID-19 Infected Patients. Training a machine learning model on the data sets with missing labels is a challenging task. Not all models can handle the problem of missing labels. However, if these data sets are further corrupted with label noise, it becomes even more challenging to train a machine learning model on such data sets. We propose to use a transductive support vector machine (TSVM) for semi-supervised learning in this situation. We make this model robust to label noise by using a truncated pinball loss function with it. We name our approach, <math xmlns=""http://www.w3.org/1998/Math/MathML""><mover><mtext>pin</mtext> <mo>Â¯</mo></mover> </math> -TSVM. We provide both the primal and the dual formulations of the obtained robust TSVM for linear and non-linear kernels. We also perform experiments on synthetic and real-world data sets to prove the superior robustness of our model as compared to the existing approaches. To this end, we use small as well as large-scale data sets to perform the experiments. We show that the model is capable of training in the presence of label noise and finding the missing labels of the data samples. We use this property of <math xmlns=""http://www.w3.org/1998/Math/MathML""><mover><mtext>pin</mtext> <mo>Â¯</mo></mover> </math> -TSVM to detect the coronavirus patients based on their chest X-ray images.",0,0
7540,"Applying deep learning-based multi-modal for detection of coronavirus. Amidst the global pandemic and catastrophe created by 'COVID-19', every research institution and scientist are doing their best efforts to invent or find the vaccine or medicine for the disease. The objective of this research is to design and develop a deep learning-based multi-modal for the screening of COVID-19 using chest radiographs and genomic sequences. The modal is also effective in finding the degree of genomic similarity among the Severe Acute Respiratory Syndrome-Coronavirus 2 and other prevalent viruses such asÂ Severe Acute Respiratory Syndrome-Coronavirus,Â Middle East Respiratory Syndrome-Coronavirus,Â Human Immunodeficiency Virus, and Human T-cell Leukaemia Virus. The experimental results on the datasets available atÂ National Centre for Biotechnology Information, GitHub, and Kaggle repositories show that it is successful in detecting the genome of 'SARS-CoV-2' in the host genome with an accuracy of 99.27% and screening of chest radiographs into COVID-19, non-COVID pneumonia and healthy with a sensitivity of 95.47%. Thus, it may prove a useful tool for doctors to quickly classify the infected and non-infected genomes. It can also be useful in finding the most effective drug from the available drugs for the treatment of 'COVID-19'.",0,0
7543,"Machine learning-based heart disease prediction system for Indian population: An exploratory study done in South India. In India, huge mortality occurs due to cardiovascular diseases (CVDs) as these diseases are not diagnosed in early stages. Machine learning (ML) algorithms can be used to build efficient and economical prediction system for early diagnosis of CVDs in India.",0,0
7552,"RCTE: A reliable and consistent temporal-ensembling framework for semi-supervised segmentation of COVID-19 lesions. The segmentation of COVID-19 lesions from computed tomography (CT) scans is crucial to develop an efficient automated diagnosis system. Deep learning (DL) has shown success in different segmentation tasks. However, an efficient DL approach requires a large amount of accurately annotated data, which is difficult to aggregate owing to the urgent situation of COVID-19. Inaccurate annotation can easily occur without experts, and segmentation performance is substantially worsened by noisy annotations. Therefore, this study presents a reliable and consistent temporal-ensembling (RCTE) framework for semi-supervised lesion segmentation. A segmentation network is integrated into a teacher-student architecture to segment infection regions from a limited number of annotated CT scans and a large number of unannotated CT scans. The network generates reliable and unreliable targets, and to evenly handle these targets potentially degrades performance. To address this, a reliable teacher-student architecture is introduced, where a reliable teacher network is the exponential moving average (EMA) of a reliable student network that is reliably renovated by restraining the student involvement to EMA when its loss is larger. We also present a noise-aware loss based on improvements to generalized cross-entropy loss to lead the segmentation performance toward noisy annotations. Comprehensive analysis validates the robustness of RCTE over recent cutting-edge semi-supervised segmentation techniques, with a 65.87% Dice score.",0,0
7553,"Deep Learning-Based Nuclear Lobe Count Method for Differential Count of Neutrophils. Differentiating neutrophils based on the count of nuclear lobulation is useful for diagnosing various hematological disorders, including megaloblastic anemia, myelodysplastic syndrome, and sepsis. It has been reported that one-fifth of sepsis-infected patients worldwide died between 1990 and 2017. Notably, fewer nuclear-lobed and stab-formed neutrophils develop in the peripheral blood during sepsis. This abnormality can serve as an early diagnostic criterion. However, testing this feature is a complex and time-consuming task that is rife with human error. For this reason, we apply deep learning to automatically differentiate neutrophil and nuclear lobulation counts and report the world's first small-scale pilot. Blood films are prepared using venous peripheral blood taken from four healthy volunteers and are stained with May-GrÃ¼nwald Giemsa stain. Six-hundred 360 Ã— 363-pixel images of neutrophils having five different nuclear lobulations are automatically captured by Cellavision DM-96, an automatic digital microscope camera. Images are input to an original architecture with five convolutional layers built on a deep learning neural-network platform by Sony, Neural Network Console. The deep learning system distinguishes the four groups (i.e., band-formed, two-, three-, and four- and five- segmented) of neutrophils with up to 99% accuracy, suggesting that neutrophils can be automatically differentiated based on their count of segmented nuclei using deep learning.",0,0
7560,"A random forest model predicts responses to infliximab in Crohn's disease based on clinical and serological parameters. Infliximab (IFX) has revolutionised the treatment for Crohn's disease (CD) recently, while a part of patients show no response to it at the end of the induction period. We developed a random forest-based prediction tool to predict the response to IFX in CD patients.",0,0
7561,"Payer budget impact of an artificial intelligence <i>inÂ vitro</i> diagnostic to modify diabetic kidney disease progression. To evaluate the U.S. payer budget-impact of KidneyIntelX, an artificial intelligence-enabled <i>inÂ vitro</i> diagnostic to predict kidney function decline in Type 2 Diabetic Kidney Disease (T2DKD) patients, stages 1-3b.",0,0
7565,"Segmentation of dermoscopy images based on deformable 3D convolution and ResU-NeXt +. Melanoma is one of the most dangerous skin cancers. The current melanoma segmentation is mainly based on FCNs (fully connected networks) and U-Net. Nevertheless, these two kinds of neural networks are prone to parameter redundancy, and the gradient of neural networks disappears that occurs when the neural network backpropagates as the neural network gets deeper, which will reduce the Jaccard index of the skin lesion image segmentation model. To solve the above problems and improve the survival rate of melanoma patients, an improved skin lesion segmentation model based on deformable 3D convolution and ResU-NeXt++ (D3DC- ResU-NeXt++) is proposed in this paper. The new modules in D3DC-ResU-NeXt++ can replace ordinary modules in the existing 2D convolutional neural networks (CNNs) that can be trained efficiently through standard backpropagation with high segmentation accuracy. In particular, we introduce a new data preprocessing method with dilation, crop operation, resizing, and hair removal (DCRH), which improves the Jaccard index of skin lesion image segmentation. Because rectified Adam (RAdam) does not easily fall into a local optimal solution and can converge quickly in segmentation model training, we also introduce RAdam as the training optimizer. The experiments show that our model has excellent performance on the segmentation of the ISIC2018 Task I dataset, and the Jaccard index achieves 86.84%. The proposed method improves the Jaccard index of segmentation of skin lesion images and can also assist dermatological doctors in determining and diagnosing the types of skin lesions and the boundary between lesions and normal skin, so as to improve the survival rate of skin cancer patients. Overview of the proposed model. An improved skin lesion segmentation model based on deformable 3D convolution and ResU-NeXt++ (D3DC- ResU-NeXt++) is proposed in this paper. D3DC-ResU-NeXt++ has strong spatial geometry processing capabilities, it is used to segment the skin lesion sample image; DCRH and transfer learning are used to preprocess the data set and D3DC-ResU-NeXt++ respectively, which can highlight the difference between the lesion area and the normal skin, and enhance the segmentation efficiency and robustness of the neural network; RAdam is used to speed up the convergence speed of neural network and improve the efficiency of segmentation.",0,0
7569,"Effectiveness of Kanna photoscreener in detecting amblyopia risk factors. Amblyopia is a significant public health problem. Photoscreeners have been shown to have significant potential for screening; however, most are limited by cost and display low accuracy. The purpose of this study was validate a novel artificial intelligence (AI) and machine learning-based facial photoscreener ""Kanna,"" and to determine its effectiveness in detecting amblyopia risk factors.",0,0
7574,"Dynamics of data-driven microstates in bipolar disorder. Many of the existing models of mood in bipolar disorder can largely be divided into two camps, tracking mood as either a discrete or continuous variable. Both groups rely upon certain assumptions, with most considering only aggregate scores on clinical instruments. In this study, we propose a novel framework that combines elements from both discrete and continuous mood models, using a machine learning pipeline to detect subtle patterns across individuals. Latent factors are constructed from assessments at the item level, then clustered into groups referred to as microstates. Transitions between microstates are captured via a discrete-time Markov chain, allowing for characterization of mood's dynamic nature. Key findings include a factor mapping heavily onto irritability and aggression, as well as a hierarchical pattern of microstates within depression and mania. Validity of these results is confirmed by reproduction in an unseen data set from a separate subject cohort.",0,0
7577,"Artificial Intelligence-Enabled ECG to Identify Silent Atrial Fibrillation in Embolic Stroke of Unknown Source. Embolic strokes of unknown source (ESUS) are common and often suspected to be caused by unrecognized paroxysmal atrial fibrillation (AF). An AI-enabled ECG (AI-ECG) during sinus rhythm has been shown to identify patients with unrecognized AF. We pursued this study to determine if the AI-ECG model differentiates between patients with ESUS and those with known causes of stroke, and to evaluate whether the AF prediction by AI-ECG among patients with ESUS was associated with the results of prolonged ambulatory cardiac rhythm monitoring.",0,0
7578,"Association between childhood trauma, parental bonding and antisocial personality disorder in adulthood: A machine learning approach. Childhood trauma (CT) and parental bonding (PB) have been correlated with later antisocial personality disorder (ASPD). Aiming to better understand this complex interaction we analyzed the data from a cross-sectional study that evaluated 346 male inpatient cocaine users, using both traditional statistical analysis and machine learning (ML) approaches. Childhood Trauma Questionnaire (CTQ), Parental Bonding Instrument (PBI), and Mini International Neuropsychiatric Interview (MINI) were applied. We found a markedly higher prevalence of mental illness in the ASPD group. The ML method and the traditional analysis showed that emotional and physical abuse were the factors with the strongest relationship with ASPD. Also, there were discrepancies between the findings of both methods regarding physical neglect and paternal care. Although this study does not allow definitive answers in this matter, we do propose that these two methods can aid in better comprehending how multiple variables interact with each other in the development of psychological disorders.",0,0
7579,"Weakly unsupervised conditional generative adversarial network for image-based prognostic prediction for COVID-19 patients based on chest CT. Because of the rapid spread and wide range of the clinical manifestations of the coronavirus disease 2019 (COVID-19), fast and accurate estimation of the disease progression and mortality is vital for the management of the patients. Currently available image-based prognostic predictors for patients with COVID-19 are largely limited to semi-automated schemes with manually designed features and supervised learning, and the survival analysis is largely limited to logistic regression. We developed a weakly unsupervised conditional generative adversarial network, called pix2surv, which can be trained to estimate the time-to-event information for survival analysis directly from the chest computed tomography (CT) images of a patient. We show that the performance of pix2surv based on CT images significantly outperforms those of existing laboratory tests and image-based visual and quantitative predictors in estimating the disease progression and mortality of COVID-19 patients. Thus, pix2surv is a promising approach for performing image-based prognostic predictions.",0,0
7580,"Motion-based camera localization system in colonoscopy videos. Optical colonoscopy is an essential diagnostic and prognostic tool for many gastrointestinal diseases, including cancer screening and staging, intestinal bleeding, diarrhea, abdominal symptom evaluation, and inflammatory bowel disease assessment. However, the evaluation, classification, and quantification of findings from colonoscopy are subject to inter-observer variation. Automated assessment of colonoscopy is of interest considering the subjectivity present in qualitative human interpretations of colonoscopy findings. Localization of the camera is essential to interpreting the meaning and context of findings for diseases evaluated by colonoscopy. In this study, we propose a camera localization system to estimate the relative location of the camera and classify the colon into anatomical segments. The camera localization system begins with non-informative frame detection and removal. Then a self-training end-to-end convolutional neural network is built to estimate the camera motion, where several strategies are proposed to improve its robustness and generalization on endoscopic videos. Using the estimated camera motion a camera trajectory can be derived and a relative location index calculated. Based on the estimated location index, anatomical colon segment classification is performed by constructing a colon template. The proposed motion estimation algorithm was evaluated on an external dataset containing the ground truth for camera pose. The experimental results show that the performance of the proposed method is superior to other published methods. The relative location index estimation and anatomical region classification were further validated using colonoscopy videos collected from routine clinical practice. This validation yielded an average accuracy in classification of 0.754, which is substantially higher than the performances obtained using location indices built from other methods.",0,0
7586,"A neural network-based method for polypharmacy side effects prediction. Polypharmacy is a type of treatment that involves the concurrent use of multiple medications. Drugs may interact when they are used simultaneously. So, understanding and mitigating polypharmacy side effects are critical for patient safety and health. Since the known polypharmacy side effects are rare and they are not detected in clinical trials, computational methods are developed to model polypharmacy side effects.",0,0
7591,"Predicting subclinical psychotic-like experiences on a continuum using machine learning. Previous studies applying machine learning methods to psychosis have primarily been concerned with the binary classification of chronic schizophrenia patients and healthy controls. The aim of this study was to use electroencephalographic (EEG) data and pattern recognition to predict subclinical psychotic-like experiences on a continuum between these two extremes in otherwise healthy people. We applied two different approaches to an auditory oddball regularity learning task obtained from NÂ =Â 73 participants: A feature extraction and selection routine incorporating behavioural measures, event-related potential components and effective connectivity parameters; Regularisation of spatiotemporal maps of event-related potentials. Using the latter approach, optimal performance was achieved using the response to frequent, predictable sounds. Features within the P50 and P200 time windows had the greatest contribution toward lower Prodromal Questionnaire (PQ) scores and the N100 time window contributed most to higher PQ scores. As a proof-of-concept, these findings demonstrate that EEG data alone are predictive of individual psychotic-like experiences in healthy people. Our findings are in keeping with the mounting evidence for altered sensory responses in schizophrenia, as well as the notion that psychosis may exist on a continuum expanding into the non-clinical population.",0,0
7592,"Prediction of large-for-gestational age infants in relation to hyperglycemia in pregnancy - A comparison of statistical models. Using data from a large multi-centre cohort, we aimed to create a risk prediction model for large-for-gestational age (LGA) infants, using both logistic regression and naÃ¯ve Bayes approaches, and compare the utility of these two approaches.",0,0
7602,"An SVM approach towards breast cancer classification from H&E-stained histopathology images based on integrated features. Breast cancer is one among the most frequent reasons of women's death worldwide. Nowadays, healthcare informatics is mainly focussing on the classification of breast cancer images, due to the lethal nature of this cancer. There are chances of inter- and intra-observer variability that may lead to misdiagnosis in the detection of cancer. This study proposed an automatic breast cancer classification system that uses support vector machine (SVM) classifier based on integrated features (texture, geometrical, and color). The University of California Santa Barbara (UCSB) dataset and BreakHis dataset, which are available in public domain, were used. A classification comparison module which involves SVM, k-nearest neighbor (k-NN), random forest (RF), and artificial neural network (ANN) was also proposed to determine the classifier that best suits for the application of breast cancer detection from histopathology images. The performance of these classifiers was analyzed against metrics like accuracy, specificity, sensitivity, balanced accuracy, and F-score. Results showed that among the classifiers, the SVM classifier performed better with a test accuracy of approximately 90% on both the datasets. Additionally, the significance of the proposed integrated SVM model was statistically analyzed against other classifier models.",0,0
7605,"Automated machine learning optimizes and accelerates predictive modeling from COVID-19 high throughput datasets. COVID-19 outbreak brings intense pressure on healthcare systems, with an urgent demand for effective diagnostic, prognostic and therapeutic procedures. Here, we employed Automated Machine Learning (AutoML) to analyze three publicly available high throughput COVID-19 datasets, including proteomic, metabolomic and transcriptomic measurements. Pathway analysis of the selected features was also performed. Analysis of a combined proteomic and metabolomic dataset led to 10 equivalent signatures of two features each, with AUC 0.840 (CI 0.723-0.941) in discriminating severe from non-severe COVID-19 patients. A transcriptomic dataset led to two equivalent signatures of eight features each, with AUC 0.914 (CI 0.865-0.955) in identifying COVID-19 patients from those with a different acute respiratory illness. Another transcriptomic dataset led to two equivalent signatures of nine features each, with AUC 0.967 (CI 0.899-0.996) in identifying COVID-19 patients from virus-free individuals. Signature predictive performance remained high upon validation. Multiple new features emerged and pathway analysis revealed biological relevance by implication in Viral mRNA Translation, Interferon gamma signaling and Innate Immune System pathways. In conclusion, AutoML analysis led to multiple biosignatures of high predictive performance, with reduced features and large choice of alternative predictors. These favorable characteristics are eminent for development of cost-effective assays to contribute to better disease management.",0,0
7607,"QCBCT-NET for direct measurement of bone mineral density from quantitative cone-beam CT: a human skull phantom study. The purpose of this study was to directly and quantitatively measure BMD from Cone-beam CT (CBCT) images by enhancing the linearity and uniformity of the bone intensities based on a hybrid deep-learning model (QCBCT-NET) of combining the generative adversarial network (Cycle-GAN) and U-Net, and to compare the bone images enhanced by the QCBCT-NET with those by Cycle-GAN and U-Net. We used two phantoms of human skulls encased in acrylic, one for the training and validation datasets, and the other for the test dataset. We proposed the QCBCT-NET consisting of Cycle-GAN with residual blocks and a multi-channel U-Net using paired training data of quantitative CT (QCT) and CBCT images. The BMD images produced by QCBCT-NET significantly outperformed the images produced by the Cycle-GAN or the U-Net in mean absolute difference (MAD), peak signal to noise ratio (PSNR), normalized cross-correlation (NCC), structural similarity (SSIM), and linearity when compared to the original QCT image. The QCBCT-NET improved the contrast of the bone images by reflecting the original BMD distribution of the QCT image locally using the Cycle-GAN, and also spatial uniformity of the bone images by globally suppressing image artifacts and noise using the two-channel U-Net. The QCBCT-NET substantially enhanced the linearity, uniformity, and contrast as well as the anatomical and quantitative accuracy of the bone images, and demonstrated more accuracy than the Cycle-GAN and the U-Net for quantitatively measuring BMD in CBCT.",0,0
7608,"Deep-learning framework and computer assisted fatty infiltration analysis for the supraspinatus muscle in MRI. Occupation ratio and fatty infiltration are important parameters for evaluating patients with rotator cuff tears. We analyzed the occupation ratio using a deep-learning framework and studied the fatty infiltration of the supraspinatus muscle using an automated region-based Otsu thresholding technique. To calculate the amount of fatty infiltration of the supraspinatus muscle using an automated region-based Otsu thresholding technique. The mean Dice similarity coefficient, accuracy, sensitivity, specificity, and relative area difference for the segmented lesion, measuring the similarity of clinician assessment and that of a deep neural network, were 0.97, 99.84, 96.89, 99.92, and 0.07, respectively, for the supraspinatus fossa and 0.94, 99.89, 93.34, 99.95, and 2.03, respectively, for the supraspinatus muscle. The fatty infiltration measure using the Otsu thresholding method significantly differed among the Goutallier grades (Grade 0; 0.06, Grade 1; 4.68, Grade 2; 20.10, Grade 3; 42.86, Grade 4; 55.79, pâ€‰<â€‰0.0001). The occupation ratio and fatty infiltration using Otsu thresholding demonstrated a moderate negative correlation (Ïâ€‰=â€‰-â€‰0.75, pâ€‰<â€‰0.0001). This study included 240 randomly selected patients who underwent shoulder magnetic resonance imaging (MRI) from January 2015 to December 2016. We used a fully convolutional deep-learning algorithm to quantitatively detect the fossa and muscle regions by measuring the occupation ratio of the supraspinatus muscle. Fatty infiltration was objectively evaluated using the Otsu thresholding method. The proposed convolutional neural network exhibited fast and accurate segmentation of the supraspinatus muscle and fossa from shoulder MRI, allowing automatic calculation of the occupation ratio. Quantitative evaluation using a modified Otsu thresholding method can be used to calculate the proportion of fatty infiltration in the supraspinatus muscle. We expect that this will improve the efficiency and objectivity of diagnoses by quantifying the index used for shoulder MRI.",0,0
7610,"Using 2D video-based pose estimation for automated prediction of autism spectrum disorders in young children. Clinical research in autism has recently witnessed promising digital phenotyping results, mainly focused on single feature extraction, such as gaze, head turn on name-calling or visual tracking of the moving object. The main drawback of these studies is the focus on relatively isolated behaviors elicited by largely controlled prompts. We recognize that while the diagnosis process understands the indexing of the specific behaviors, ASD also comes with broad impairments that often transcend single behavioral acts. For instance, the atypical nonverbal behaviors manifest through global patterns of atypical postures and movements, fewer gestures used and often decoupled from visual contact, facial affect, speech. Here, we tested the hypothesis that a deep neural network trained on the non-verbal aspects of social interaction can effectively differentiate between children with ASD and their typically developing peers. Our model achieves an accuracy of 80.9% (F1 score: 0.818; precision: 0.784; recall: 0.854) with the prediction probability positively correlated to the overall level of symptoms of autism in social affect and repetitive and restricted behaviors domain. Provided the non-invasive and affordable nature of computer vision, our approach carries reasonable promises that a reliable machine-learning-based ASD screening may become a reality not too far in the future.",0,0
7612,"Evaluation of Deep Learning-based Approaches to Segment Bowel Air Pockets and Generate Pelvis Attenuation Maps from CAIPIRINHA-accelerated Dixon MR Images. Attenuation correction (AC) remains a challenge in pelvis PET/MR imaging. In addition to the segmentation/model-based approaches, deep learning methods have shown promise in synthesizing accurate pelvis attenuation maps (Î¼-maps). However, these methods often misclassify air pockets in the digestive tract, which can introduce bias in the reconstructed PET images. The aims of this work were to develop deep learning-based methods to automatically segment air pockets and generate pseudo-CT images from CAIPIRINHA-accelerated MR Dixon images. <b>Methods:</b> A convolutional neural network (CNN) was trained to segment air pockets using 3D CAIPIRINHA-accelerated MR Dixon datasets from 35 subjects and was evaluated against semi-automated segmentations. A separate CNN was trained to synthesize pseudo-CT Î¼-maps from the Dixon images. Its accuracy was evaluated by comparing the deep learning-, model- and CT-based Î¼-maps using data from 30 of the subjects. Finally, the impact of different Î¼-maps and air pocket segmentation methods on the PET quantification was investigated. <b>Results:</b> Air pockets segmented using the CNN agreed well with semi-automated segmentations, with a mean Dice similarity coefficient of 0.75. Volumetric similarity score between two segmentations was 0.85 Â± 0.14. The mean absolute relative change (RCs) with respect to the CT-based Î¼-maps were 2.6% and 5.1% in the whole pelvis for the deep learning and model-based Î¼-maps, respectively. The average RC between PET images reconstructed with deep learning and CT-based Î¼-maps was 2.6%. <b>Conclusion:</b> We presented a deep learning-based method to automatically segment air pockets from CAIPIRINHA-accelerated Dixon images with comparable accuracy to semi-automatic segmentations. We also showed that the Î¼-maps synthesized using a deep learning-based method from CAIPIRINHA-accelerated Dixon images are more accurate than those generated with the model-based approach available on integrated PET/MRI scanner.",0,0
7615,"Prediction model of in-hospital mortality in intensive care unit patients with heart failure: machine learning-based, retrospective analysis of the MIMIC-III database. The predictors of in-hospital mortality for intensive care units (ICUs)-admitted heart failure (HF) patients remain poorly characterised. We aimed to develop and validate a prediction model for all-cause in-hospital mortality among ICU-admitted HF patients.",0,0
7617,"Machine learning algorithm improves accuracy of ortho-K lens fitting in vision shaping treatment. To construct a machine learning (ML)-based model for estimating the alignment curve (AC) curvature in orthokeratology lens fitting for vision shaping treatment (VST), which can minimize the number of lens trials, improving efficiency while maintaining accuracy, with regards to its improvement over a previous calculation method.",0,0
7619,"Biological knowledge-slanted random forest approach for the classification of calcified aortic valve stenosis. Calcific aortic valve stenosis (CAVS) is a fatal disease and there is no pharmacological treatment to prevent the progression of CAVS. This study aims to identify genes potentially implicated with CAVS in patients with congenital bicuspid aortic valve (BAV) and tricuspid aortic valve (TAV) in comparison with patients having normal valves, using a knowledge-slanted random forest (RF).",0,0
7622,"neoDL: a novel neoantigen intrinsic feature-based deep learning model identifies IDH wild-type glioblastomas with the longest survival. Neoantigen based personalized immune therapies achieve promising results in melanoma and lung cancer, but few neoantigen based models perform well in IDH wild-type GBM, and the association between neoantigen intrinsic features and prognosis remain unclear in IDH wild-type GBM. We presented a novel neoantigen intrinsic feature-based deep learning model (neoDL) to stratify IDH wild-type GBMs into subgroups with different survivals.",0,0
7635,"Learning Carbohydrate Digestion and Insulin Absorption Curves Using Blood Glucose Level Prediction and Deep Learning Models. Type 1 diabetes is a chronic disease caused by the inability of the pancreas to produce insulin. Patients suffering type 1 diabetes depend on the appropriate estimation of the units of insulin they have to use in order to keep blood glucose levels in range (considering the calories taken and the physical exercise carried out). In recent years, machine learning models have been developed in order to help type 1 diabetes patients with their blood glucose control. These models tend to receive the insulin units used and the carbohydrate taken as inputs and generate optimal estimations for future blood glucose levels over a prediction horizon. The body glucose kinetics is a complex user-dependent process, and learning patient-specific blood glucose patterns from insulin units and carbohydrate content is a difficult task even for deep learning-based models. This paper proposes a novel mechanism to increase the accuracy of blood glucose predictions from deep learning models based on the estimation of carbohydrate digestion and insulin absorption curves for a particular patient. This manuscript proposes a method to estimate absorption curves by using a simplified model with two parameters which are fitted to each patient by using a genetic algorithm. Using simulated data, the results show the ability of the proposed model to estimate absorption curves with mean absolute errors below 0.1 for normalized fast insulin curves having a maximum value of 1 unit.",0,0
7637,"A Comprehensive Computer-Assisted Diagnosis System for Early Assessment of Renal Cancer Tumors. Renal cell carcinoma (RCC) is the most common and a highly aggressive type of malignant renal tumor. In this manuscript, we aim to identify and integrate the optimal discriminating morphological, textural, and functional features that best describe the malignancy status of a given renal tumor. The integrated discriminating features may lead to the development of a novel comprehensive renal cancer computer-assisted diagnosis (RC-CAD) system with the ability to discriminate between benign and malignant renal tumors and specify the malignancy subtypes for optimal medical management. Informed consent was obtained from a total of 140 biopsy-proven patients to participate in the study (male = 72 and female = 68, age range = 15 to 87 years). There were 70 patients who had RCC (40 clear cell RCC (ccRCC), 30 nonclear cell RCC (nccRCC)), while the other 70 had benign angiomyolipoma tumors. Contrast-enhanced computed tomography (CE-CT) images were acquired, and renal tumors were segmented for all patients to allow the extraction of discriminating imaging features. The RC-CAD system incorporates the following major steps: (i) applying a new parametric spherical harmonic technique to estimate the morphological features, (ii) modeling a novel angular invariant gray-level co-occurrence matrix to estimate the textural features, and (iii) constructing wash-in/wash-out slopes to estimate the functional features by quantifying enhancement variations across different CE-CT phases. These features were subsequently combined and processed using a two-stage multilayer perceptron artificial neural network (MLP-ANN) classifier to classify the renal tumor as benign or malignant and identify the malignancy subtype as well. Using the combined features and a leave-one-subject-out cross-validation approach, the developed RC-CAD system achieved a sensitivity of 95.3%Â±2.0%, a specificity of 99.9%Â±0.4%, and Dice similarity coefficient of 0.98Â±0.01 in differentiating malignant from benign tumors, as well as an overall accuracy of 89.6%Â±5.0% in discriminating ccRCC from nccRCC. The diagnostic abilities of the developed RC-CAD system were further validated using a randomly stratified 10-fold cross-validation approach. The obtained results using the proposed MLP-ANN classification model outperformed other machine learning classifiers (e.g., support vector machine, random forests, relational functional gradient boosting, etc.). Hence, integrating morphological, textural, and functional features enhances the diagnostic performance, making the proposal a reliable noninvasive diagnostic tool for renal tumors.",0,0
7652,"Computer Vision-Based Microcalcification Detection in Digital Mammograms Using Fully Connected Depthwise Separable Convolutional Neural Network. Microcalcification clusters in mammograms are one of the major signs of breast cancer. However, the detection of microcalcifications from mammograms is a challenging task for radiologists due to their tiny size and scattered location inside a denser breast composition. Automatic CAD systems need to predict breast cancer at the early stages to support clinical work. The intercluster gap, noise between individual MCs, and individual object's location can affect the classification performance, which may reduce the true-positive rate. In this study, we propose a computer-vision-based FC-DSCNN CAD system for the detection of microcalcification clusters from mammograms and classification into malignant and benign classes. The computer vision method automatically controls the noise and background color contrast and directly detects the MC object from mammograms, which increases the classification performance of the neural network. The breast cancer classification framework has four steps: image preprocessing and augmentation, RGB to grayscale channel transformation, microcalcification region segmentation, and MC ROI classification using FC-DSCNN to predict malignant and benign cases. The proposed method was evaluated on 3568 DDSM and 2885 PINUM mammogram images with automatic feature extraction, obtaining a score of 0.97 with a 2.35 and 0.99 true-positive ratio with 2.45 false positives per image, respectively. Experimental results demonstrated that the performance of the proposed method remains higher than the traditional and previous approaches.",0,0
7654,"Affective State during Physiotherapy and Its Analysis Using Machine Learning Methods. Invasive or uncomfortable procedures especially during healthcare trigger emotions. Technological development of the equipment and systems for monitoring and recording psychophysiological functions enables continuous observation of changes to a situation responding to a situation. The presented study aimed to focus on the analysis of the individual's affective state. The results reflect the excitation expressed by the subjects' statements collected with psychological questionnaires. The research group consisted of 49 participants (22 women and 25 men). The measurement protocol included acquiring the electrodermal activity signal, cardiac signals, and accelerometric signals in three axes. Subjective measurements were acquired for affective state using the JAWS questionnaires, for cognitive skills the DST, and for verbal fluency the VFT. The physiological and psychological data were subjected to statistical analysis and then to a machine learning process using different features selection methods (JMI or PCA). The highest accuracy of the kNN classifier was achieved in combination with the JMI method (81.63%) concerning the division complying with the JAWS test results. The classification sensitivity and specificity were 85.71% and 71.43%.",0,0
7658,"Comparison of Feature Extraction Methods for Physiological Signals for Heat-Based Pain Recognition. While even the most common definition of pain is under debate, pain assessment has remained the same for decades. But the paramount importance of precise pain management for successful healthcare has encouraged initiatives to improve the way pain is assessed. Recent approaches have proposed automatic pain evaluation systems using machine learning models trained with data coming from behavioural or physiological sensors. Although yielding promising results, machine learning studies for sensor-based pain recognition remain scattered and not necessarily easy to compare to each other. In particular, the important process of extracting features is usually optimised towards specific datasets. We thus introduce a comparison of feature extraction methods for pain recognition based on physiological sensors in this paper. In addition, the PainMonit Database (PMDB), a new dataset including both objective and subjective annotations for heat-induced pain in 52 subjects, is introduced. In total, five different approaches including techniques based on feature engineering and feature learning with deep learning are evaluated on the BioVid and PMDB datasets. Our studies highlight the following insights: (1) Simple feature engineering approaches can still compete with deep learning approaches in terms of performance. (2) More complex deep learning architectures do not yield better performance compared to simpler ones. (3) Subjective self-reports by subjects can be used instead of objective temperature-based annotations to build a robust pain recognition system.",0,0
7662,"Non-Invasive Driver Drowsiness Detection System. Drowsiness when in command of a vehicle leads to a decline in cognitive performance that affects driver behavior, potentially causing accidents. Drowsiness-related road accidents lead to severe trauma, economic consequences, impact on others, physical injury and/or even death. Real-time and accurate driver drowsiness detection and warnings systems are necessary schemes to reduce tiredness-related driving accident rates. The research presented here aims at the classification of drowsy and non-drowsy driver states based on respiration rate detection by non-invasive, non-touch, impulsive radio ultra-wideband (IR-UWB) radar. Chest movements of 40 subjects were acquired for 5 m using a lab-placed IR-UWB radar system, and respiration per minute was extracted from the resulting signals. A structured dataset was obtained comprising respiration per minute, age and label (drowsy/non-drowsy). Different machine learning models, namely, Support Vector Machine, Decision Tree, Logistic regression, Gradient Boosting Machine, Extra Tree Classifier and Multilayer Perceptron were trained on the dataset, amongst which the Support Vector Machine shows the best accuracy of 87%. This research provides a ground truth for verification and assessment of UWB to be used effectively for driver drowsiness detection based on respiration.",0,0
7674,"Combining Genetic Algorithms and SVM for Breast Cancer Diagnosis Using Infrared Thermography. Breast cancer is one of the leading causes of mortality globally, but early diagnosis and treatment can increase the cancer survival rate. In this context, thermography is a suitable approach to help early diagnosis due to the temperature difference between cancerous tissues and healthy neighboring tissues. This work proposes an ensemble method for selecting models and features by combining a Genetic Algorithm (GA) and the Support Vector Machine (SVM) classifier to diagnose breast cancer. Our evaluation demonstrates that the approach presents a significant contribution to the early diagnosis of breast cancer, presenting results with 94.79% Area Under the Receiver Operating Characteristic Curve and 97.18% of Accuracy.",0,0
7677,"Gender and Age Estimation Methods Based on Speech Using Deep Neural Networks. The speech signal contains a vast spectrum of information about the speaker such as speakers' gender, age, accent, or health state. In this paper, we explored different approaches to automatic speaker's gender classification and age estimation system using speech signals. We applied various Deep Neural Network-based embedder architectures such as x-vector and d-vector to age estimation and gender classification tasks. Furthermore, we have applied a transfer learning-based training scheme with pre-training the embedder network for a speaker recognition task using the Vox-Celeb1 dataset and then fine-tuning it for the joint age estimation and gender classification task. The best performing system achieves new state-of-the-art results on the age estimation task using popular TIMIT dataset with a mean absolute error (MAE) of 5.12 years for male and 5.29 years for female speakers and a root-mean square error (RMSE) of 7.24 and 8.12 years for male and female speakers, respectively, and an overall gender recognition accuracy of 99.60%.",0,0
7685,"Unsupervised Assessment of Balance and Falls Risk Using a Smartphone and Machine Learning. Assessment of health and physical function using smartphones (mHealth) has enormous potential due to the ubiquity of smartphones and their potential to provide low cost, scalable access to care as well as frequent, objective measurements, outside of clinical environments. Validation of the algorithms and outcome measures used by mHealth apps is of paramount importance, as poorly validated apps have been found to be harmful to patients. Falls are a complex, common and costly problem in the older adult population. Deficits in balance and postural control are strongly associated with falls risk. Assessment of balance and falls risk using a validated smartphone app may lessen the need for clinical assessments which can be expensive, requiring non-portable equipment and specialist expertise. This study reports results for the real-world deployment of a smartphone app for self-directed, unsupervised assessment of balance and falls risk. The app relies on a previously validated algorithm for assessment of balance and falls risk; the outcome measures employed were trained prior to deployment on an independent data set. Results for a sample of 594 smartphone assessments from 147 unique phones show a strong association between self-reported falls history and the falls risk and balance impairment scores produced by the app, suggesting they may be clinically useful outcome measures. In addition, analysis of the quantitative balance features produced seems to suggest that unsupervised, self-directed assessment of balance in the home is feasible.",0,0
7686,"Multi-Modal Adaptive Fusion Transformer Network for the Estimation of Depression Level. Depression is a severe psychological condition that affects millions of people worldwide. As depression has received more attention in recent years, it has become imperative to develop automatic methods for detecting depression. Although numerous machine learning methods have been proposed for estimating the levels of depression via audio, visual, and audiovisual emotion sensing, several challenges still exist. For example, it is difficult to extract long-term temporal context information from long sequences of audio and visual data, and it is also difficult to select and fuse useful multi-modal information or features effectively. In addition, how to include other information or tasks to enhance the estimation accuracy is also one of the challenges. In this study, we propose a multi-modal adaptive fusion transformer network for estimating the levels of depression. Transformer-based models have achieved state-of-the-art performance in language understanding and sequence modeling. Thus, the proposed transformer-based network is utilized to extract long-term temporal context information from uni-modal audio and visual data in our work. This is the first transformer-based approach for depression detection. We also propose an adaptive fusion method for adaptively fusing useful multi-modal features. Furthermore, inspired by current multi-task learning work, we also incorporate an auxiliary task (depression classification) to enhance the main task of depression level regression (estimation). The effectiveness of the proposed method has been validated on a public dataset (AVEC 2019 Detecting Depression with AI Sub-challenge) in terms of the PHQ-8 scores. Experimental results indicate that the proposed method achieves better performance compared with currently state-of-the-art methods. Our proposed method achieves a concordance correlation coefficient (CCC) of 0.733 on AVEC 2019 which is 6.2% higher than the accuracy (CCC = 0.696) of the state-of-the-art method.",0,0
7687,"AIoT-Enabled Rehabilitation Recognition System-Exemplified by Hybrid Lower-Limb Exercises. Ubiquitous health management (UHM) is vital in the aging society. The UHM services with artificial intelligence of things (AIoT) can assist home-isolated healthcare in tracking rehabilitation exercises for clinical diagnosis. This study combined a personalized rehabilitation recognition (PRR) system with the AIoT for the UHM of lower-limb rehabilitation exercises. The three-tier infrastructure integrated the recognition pattern bank with the sensor, network, and application layers. The wearable sensor collected and uploaded the rehab data to the network layer for AI-based modeling, including the data preprocessing, featuring, machine learning (ML), and evaluation, to build the recognition pattern. We employed the SVM and ANFIS methods in the ML process to evaluate 63 features in the time and frequency domains for multiclass recognition. The Hilbert-Huang transform (HHT) process was applied to derive the frequency-domain features. As a result, the patterns combining the time- and frequency-domain features, such as relative motion angles in y- and z-axis, and the HHT-based frequency and energy, could achieve successful recognition. Finally, the suggestive patterns stored in the AIoT-PRR system enabled the ML models for intelligent computation. The PRR system can incorporate the proposed modeling with the UHM service to track the rehabilitation program in the future.",0,0
7699,"Physical Activity Recognition Based on a Parallel Approach for an Ensemble of Machine Learning and Deep Learning Classifiers. Human activity recognition (HAR) by wearable sensor devices embedded in the Internet of things (IOT) can play a significant role in remote health monitoring and emergency notification to provide healthcare of higher standards. The purpose of this study is to investigate a human activity recognition method of accrued decision accuracy and speed of execution to be applicable in healthcare. This method classifies wearable sensor acceleration time series data of human movement using an efficient classifier combination of feature engineering-based and feature learning-based data representation. Leave-one-subject-out cross-validation of the method with data acquired from 44 subjects wearing a single waist-worn accelerometer on a smart textile, and engaged in a variety of 10 activities, yielded an average recognition rate of 90%, performing significantly better than individual classifiers. The method easily accommodates functional and computational parallelization to bring execution time significantly down.",0,0
7710,"Classical Machine Learning Versus Deep Learning for the Older Adults Free-Living Activity Classification. Physical activity has a strong influence on mental and physical health and is essential in healthy ageing and wellbeing for the ever-growing elderly population. Wearable sensors can provide a reliable and economical measure of activities of daily living (ADLs) by capturing movements through, e.g., accelerometers and gyroscopes. This study explores the potential of using classical machine learning and deep learning approaches to classify the most common ADLs: walking, sitting, standing, and lying. We validate the results on the ADAPT dataset, the most detailed dataset to date of inertial sensor data, synchronised with high frame-rate video labelled data recorded in a free-living environment from older adults living independently. The findings suggest that both approaches can accurately classify ADLs, showing high potential in profiling ADL patterns of the elderly population in free-living conditions. In particular, both long short-term memory (LSTM) networks and Support Vector Machines combined with ReliefF feature selection performed equally well, achieving around 97% F-score in profiling ADLs.",0,0
7714,"Automated Loss-of-Balance Event Identification in Older Adults at Risk of Falls during Real-World Walking Using Wearable Inertial Measurement Units. Loss-of-balance (LOB) events, such as trips and slips, are frequent among community-dwelling older adults and are an indicator of increased fall risk. In a preliminary study, eight community-dwelling older adults with a history of falls were asked to perform everyday tasks in the real world while donning a set of three inertial measurement sensors (IMUs) and report LOB events via a voice-recording device. Over 290 h of real-world kinematic data were collected and used to build and evaluate classification models to detect the occurrence of LOB events. Spatiotemporal gait metrics were calculated, and time stamps for when LOB events occurred were identified. Using these data and machine learning approaches, we built classifiers to detect LOB events. Through a leave-one-participant-out validation scheme, performance was assessed in terms of the area under the receiver operating characteristic curve (AUROC) and the area under the precision recall curve (AUPR). The best model achieved an AUROC â‰¥0.87 for every held-out participant and an AUPR 4-20 times the incidence rate of LOB events. Such models could be used to filter large datasets prior to manual classification by a trained healthcare provider. In this context, the models filtered out at least 65.7% of the data, while detecting â‰¥87.0% of events on average. Based on the demonstrated discriminative ability to separate LOBs and normal walking segments, such models could be applied retrospectively to track the occurrence of LOBs over an extended period of time.",0,0
7719,"Classification of Motor Imagery Electroencephalography Signals Based on Image Processing Method. In recent years, more and more frameworks have been applied to brain-computer interface technology, and electroencephalogram-based motor imagery (MI-EEG) is developing rapidly. However, it is still a challenge to improve the accuracy of MI-EEG classification. A deep learning framework termed IS-CBAM-convolutional neural network (CNN) is proposed to address the non-stationary nature, the temporal localization of excitation occurrence, and the frequency band distribution characteristics of the MI-EEG signal in this paper. First, according to the logically symmetrical relationship between the C3 and C4 channels, the result of the time-frequency image subtraction (IS) for the MI-EEG signal is used as the input of the classifier. It both reduces the redundancy and increases the feature differences of the input data. Second, the attention module is added to the classifier. A convolutional neural network is built as the base classifier, and information on the temporal location and frequency distribution of MI-EEG signal occurrences are adaptively extracted by introducing the Convolutional Block Attention Module (CBAM). This approach reduces irrelevant noise interference while increasing the robustness of the pattern. The performance of the framework was evaluated on BCI competition IV dataset 2b, where the mean accuracy reached 79.6%, and the average kappa value reached 0.592. The experimental results validate the feasibility of the framework and show the performance improvement of MI-EEG signal classification.",0,0
7720,"The Performance of Post-Fall Detection Using the Cross-Dataset: Feature Vectors, Classifiers and Processing Conditions. In this study, algorithms to detect post-falls were evaluated using the cross-dataset according to feature vectors (time-series and discrete data), classifiers (ANN and SVM), and four different processing conditions (normalization, equalization, increase in the number of training data, and additional training with external data). Three-axis acceleration and angular velocity data were obtained from 30 healthy male subjects by attaching an IMU to the middle of the left and right anterior superior iliac spines (ASIS). Internal and external tests were performed using our lab dataset and SisFall public dataset, respectively. The results showed that ANN and SVM were suitable for the time-series and discrete data, respectively. The classification performance generally decreased, and thus, specific feature vectors from the raw data were necessary when untrained motions were tested using a public dataset. Normalization made SVM and ANN more and less effective, respectively. Equalization increased the sensitivity, even though it did not improve the overall performance. The increase in the number of training data also improved the classification performance. Machine learning was vulnerable to untrained motions, and data of various movements were needed for the training.",0,0
7726,"Impartially Validated Multiple Deep-Chain Models to Detect COVID-19 in Chest X-ray Using Latent Space Radiomics. The COVID-19 pandemic continues to spread globally at a rapid pace, and its rapid detection remains a challenge due to its rapid infectivity and limited testing availability. One of the simply available imaging modalities in clinical routine involves chest X-ray (CXR), which is often used for diagnostic purposes. Here, we proposed a computer-aided detection of COVID-19 in CXR imaging using deep and conventional radiomic features. First, we used a 2D U-Net model to segment the lung lobes. Then, we extracted deep latent space radiomics by applying deep convolutional autoencoder (ConvAE) with internal dense layers to extract low-dimensional deep radiomics. We used Johnson-Lindenstrauss (JL) lemma, Laplacian scoring (LS), and principal component analysis (PCA) to reduce dimensionality in conventional radiomics. The generated low-dimensional deep and conventional radiomics were integrated to classify COVID-19 from pneumonia and healthy patients. We used 704 CXR images for training the entire model (i.e., U-Net, ConvAE, and feature selection in conventional radiomics). Afterward, we independently validated the whole system using a study cohort of 1597 cases. We trained and tested a random forest model for detecting COVID-19 cases through multivariate binary-class and multiclass classification. The maximal (full multivariate) model using a combination of the two radiomic groups yields performance in classification cross-validated accuracy of 72.6% (69.4-74.4%) for multiclass and 89.6% (88.4-90.7%) for binary-class classification.",0,0
7727,"Detection of Minor and Major Depression through Voice as a Biomarker Using Machine Learning. Both minor and major depression have high prevalence and are important causes of social burden worldwide; however, there is still no objective indicator to detect minor depression. This study aimed to examine if voice could be used as a biomarker to detect minor and major depression. Ninety-three subjects were classified into three groups: the not depressed group (<i>n</i> = 33), the minor depressive episode group (<i>n</i> = 26), and the major depressive episode group (<i>n</i> = 34), based on current depressive status as a dimension. Twenty-one voice features were extracted from semi-structured interview recordings. A three-group comparison was performed through analysis of variance. Seven voice indicators showed differences between the three groups, even after adjusting for age, BMI, and drugs taken for non-psychiatric disorders. Among the machine learning methods, the best performance was obtained using the multi-layer processing method, and an AUC of 65.9%, sensitivity of 65.6%, and specificity of 66.2% were shown. This study further revealed voice differences in depressive episodes and confirmed that not depressed groups and participants with minor and major depression could be accurately distinguished through machine learning. Although this study is limited by a small sample size, it is the first study on voice change in minor depression and suggests the possibility of detecting minor depression through voice.",0,0
7730,"Development of Machine Learning Models for Prediction of Osteoporosis from Clinical Health Examination Data. Osteoporosis is treatable but often overlooked in clinical practice. We aimed to construct prediction models with machine learning algorithms to serve as screening tools for osteoporosis in adults over fifty years old. Additionally, we also compared the performance of newly developed models with traditional prediction models. Data were acquired from community-dwelling participants enrolled in health checkup programs at a medical center in Taiwan. A total of 3053 men and 2929 women were included. Models were constructed for men and women separately with artificial neural network (ANN), support vector machine (SVM), random forest (RF), k-nearest neighbor (KNN), and logistic regression (LoR) to predict the presence of osteoporosis. Area under receiver operating characteristic curve (AUROC) was used to compare the performance of the models. We achieved AUROC of 0.837, 0.840, 0.843, 0.821, 0.827 in men, and 0.781, 0.807, 0.811, 0.767, 0.772 in women, for ANN, SVM, RF, KNN, and LoR models, respectively. The ANN, SVM, RF, and LoR models in men, and the ANN, SVM, and RF models in women performed significantly better than the traditional Osteoporosis Self-Assessment Tool for Asians (OSTA) model. We have demonstrated that machine learning algorithms improve the performance of screening for osteoporosis. By incorporating the models in clinical practice, patients could potentially benefit from earlier diagnosis and treatment of osteoporosis.",0,0
7731,"Exploring Factors for Predicting Anxiety Disorders of the Elderly Living Alone in South Korea Using Interpretable Machine Learning: A Population-Based Study. This epidemiological study aimed to develop an X-AI that could explain groups with a high anxiety disorder risk in old age. To achieve this objective, (1) this study explored the predictors of senile anxiety using base models and meta models. (2) This study presented decision tree visualization that could help psychiatric consultants and primary physicians easily interpret the path of predicting high-risk groups based on major predictors derived from final machine learning models with the best performance. This study analyzed 1558 elderly (695 males and 863 females) who were 60 years or older and completed the Zung's Self-Rating Anxiety Scale (SAS). We used support vector machine (SVM), random forest, LightGBM, and Adaboost for the base model, a single predictive model, while using XGBoost algorithm for the meta model. The analysis results confirmed that the predictive performance of the ""SVM + Random forest + LightGBM + AdaBoost + XGBoost model (stacking ensemble: accuracy 87.4%, precision 85.1%, recall 87.4%, and F1-score 85.5%)"" was the best. Also, the results of this study showed that the elderly who often (or mostly) felt subjective loneliness, had a Self Esteem Scale score of 26 or less, and had a subjective communication with their family of 4 or less (on a 10-point scale) were the group with the highest risk anxiety disorder. The results of this study imply that it is necessary to establish a community-based mental health policy that can identify elderly groups with high anxiety risks based on multiple risk factors and manage them constantly.",0,0
7736,"Predicting Type 2 Diabetes Using Logistic Regression and Machine Learning Approaches. Diabetes mellitus is one of the most common human diseases worldwide and may cause several health-related complications. It is responsible for considerable morbidity, mortality, and economic loss. A timely diagnosis and prediction of this disease could provide patients with an opportunity to take the appropriate preventive and treatment strategies. To improve the understanding of risk factors, we predict type 2 diabetes for Pima Indian women utilizing a logistic regression model and decision tree-a machine learning algorithm. Our analysis finds five main predictors of type 2 diabetes: glucose, pregnancy, body mass index (BMI), diabetes pedigree function, and age. We further explore a classification tree to complement and validate our analysis. The six-fold classification tree indicates glucose, BMI, and age are important factors, while the ten-node tree implies glucose, BMI, pregnancy, diabetes pedigree function, and age as the significant predictors. Our preferred specification yields a prediction accuracy of 78.26% and a cross-validation error rate of 21.74%. We argue that our model can be applied to make a reasonable prediction of type 2 diabetes, and could potentially be used to complement existing preventive measures to curb the incidence of diabetes and reduce associated costs.",0,0
7749,"Risk Score Generated from CT-Based Radiomics Signatures for Overall Survival Prediction in Non-Small Cell Lung Cancer. This study aimed to create a risk score generated from CT-based radiomics signatures that could be used to predict overall survival in patients with non-small cell lung cancer (NSCLC). We retrospectively enrolled three sets of NSCLC patients (including 336, 84, and 157 patients for training, testing, and validation set, respectively). A total of 851 radiomics features for each patient from CT images were extracted for further analyses. The most important features (strongly linked with overall survival) were chosen by pairwise correlation analysis, Least Absolute Shrinkage and Selection Operator (LASSO) regression model, and univariate Cox proportional hazard regression. Multivariate Cox proportional hazard model survival analysis was used to create risk scores for each patient, and Kaplan-Meier was used to separate patients into two groups: high-risk and low-risk, respectively. ROC curve assessed the prediction ability of the risk score model for overall survival compared to clinical parameters. The risk score, which developed from ten radiomics signatures model, was found to be independent of age, gender, and stage for predicting overall survival in NSCLC patients (HR, 2.99; 95% CI, 2.27-3.93; <i>p</i> < 0.001) and overall survival prediction ability was 0.696 (95% CI, 0.635-0.758), 0.705 (95% CI, 0.649-0.762), 0.657 (95% CI, 0.589-0.726) (AUC) for 1, 3, and 5 years, respectively, in the training set. The risk score is more likely to have a better accuracy in predicting survival at 1, 3, and 5 years than clinical parameters, such as age 0.57 (95% CI, 0.499-0.64), 0.552 (95% CI, 0.489-0.616), 0.621 (95% CI, 0.544-0.689) (AUC); gender 0.554, 0.546, 0.566 (AUC); stage 0.527, 0.501, 0.459 (AUC), respectively, in 1, 3 and 5 years in the training set. In the training set, the Kaplan-Meier curve revealed that NSCLC patients in the high-risk group had a lower overall survival time than the low-risk group (<i>p</i> < 0.001). We also had similar results that were statistically significant in the testing and validation set. In conclusion, risk scores developed from ten radiomics signatures models have great potential to predict overall survival in NSCLC patients compared to the clinical parameters. This model was able to stratify NSCLC patients into high-risk and low-risk groups regarding the overall survival prediction.",0,0
7750,"Assessing Versatile Machine Learning Models for Glioma Radiogenomic Studies across Hospitals. Radiogenomics use non-invasively obtained imaging data, such as magnetic resonance imaging (MRI), to predict critical biomarkers of patients. Developing an accurate machine learning (ML) technique for MRI requires data from hundreds of patients, which cannot be gathered from any single local hospital. Hence, a model universally applicable to multiple cohorts/hospitals is required. We applied various ML and image pre-processing procedures on a glioma dataset from The Cancer Image Archive (TCIA, <i>n</i> = 159). The models that showed a high level of accuracy in predicting glioblastoma or WHO Grade II and III glioma using the TCIA dataset, were then tested for the data from the National Cancer Center Hospital, Japan (NCC, <i>n</i> = 166) whether they could maintain similar levels of high accuracy. Results: we confirmed that our ML procedure achieved a level of accuracy (AUROC = 0.904) comparable to that shown previously by the deep-learning methods using TCIA. However, when we directly applied the model to the NCC dataset, its AUROC dropped to 0.383. Introduction of standardization and dimension reduction procedures before classification without re-training improved the prediction accuracy obtained using NCC (0.804) without a loss in prediction accuracy for the TCIA dataset. Furthermore, we confirmed the same tendency in a model for IDH1/2 mutation prediction with standardization and application of dimension reduction that was also applicable to multiple hospitals. Our results demonstrated that overfitting may occur when an ML method providing the highest accuracy in a small training dataset is used for different heterogeneous data sets, and suggested a promising process for developing an ML method applicable to multiple cohorts.",0,0
7752,"Accelerated T2-Weighted TSE Imaging of the Prostate Using Deep Learning Image Reconstruction: A Prospective Comparison with Standard T2-Weighted TSE Imaging. Multiparametric MRI (mpMRI) of the prostate has become the standard of care in prostate cancer evaluation. Recently, deep learning image reconstruction (DLR) methods have been introduced with promising results regarding scan acceleration. Therefore, the aim of this study was to investigate the impact of deep learning image reconstruction (DLR) in a shortened acquisition process of T2-weighted TSE imaging, regarding the image quality and diagnostic confidence, as well as PI-RADS and T2 scoring, as compared to standard T2 TSE imaging. Sixty patients undergoing 3T mpMRI for the evaluation of prostate cancer were prospectively enrolled in this institutional review board-approved study between October 2020 and March 2021. After the acquisition of standard T2 TSE imaging (T2<sub>S</sub>), the novel T2 TSE sequence with DLR (T2<sub>DLR</sub>) was applied in three planes. Overall, the acquisition time for T2<sub>S</sub> resulted in 10:21 min versus 3:50 min for T2<sub>DLR</sub>. The image evaluation was performed by two radiologists independently using a Likert scale ranging from 1-4 (4 best) applying the following criteria: noise levels, artifacts, overall image quality, diagnostic confidence, and lesion conspicuity. Additionally, T2 and PI-RADS scoring were performed. The mean patient age was 69 Â± 9 years (range, 49-85 years). The noise levels and the extent of the artifacts were evaluated to be significantly improved in T2<sub>DLR</sub> versus T2<sub>S</sub> by both readers (<i>p</i> < 0.05). Overall image quality was also evaluated to be superior in T2<sub>DLR</sub> versus T2<sub>S</sub> in all three acquisition planes (<i>p</i> = 0.005-<0.001). Both readers evaluated the item lesion conspicuity to be superior in T2<sub>DLR</sub> with a median of 4 versus a median of 3 in T2<sub>S</sub> (<i>p</i> = 0.001 and <0.001, respectively). T2-weighted TSE imaging of the prostate in three planes with an acquisition time reduction of more than 60% including DLR is feasible with a significant improvement of image quality.",1,1
7753,"Validation of a Point-of-Care Optical Coherence Tomography Device with Machine Learning Algorithm for Detection of Oral Potentially Malignant and Malignant Lesions. Non-invasive strategies that can identify oral malignant and dysplastic oral potentially-malignant lesions (OPML) are necessary in cancer screening and long-term surveillance. Optical coherence tomography (OCT) can be a rapid, real time and non-invasive imaging method for frequent patient surveillance. Here, we report the validation of a portable, robust OCT device in 232 patients (lesions: 347) in different clinical settings. The device deployed with algorithm-based automated diagnosis, showed efficacy in delineation of oral benign and normal (<i>n</i> = 151), OPML (<i>n</i> = 121), and malignant lesions (<i>n</i> = 75) in community and tertiary care settings. This study showed that OCT images analyzed by automated image processing algorithm could distinguish the dysplastic-OPML and malignant lesions with a sensitivity of 95% and 93%, respectively. Furthermore, we explored the ability of multiple (<i>n</i> = 14) artificial neural network (ANN) based feature extraction techniques for delineation high grade-OPML (moderate/severe dysplasia). The support vector machine (SVM) model built over ANN, delineated high-grade dysplasia with sensitivity of 83%, which in turn, can be employed to triage patients for tertiary care. The study provides evidence towards the utility of the robust and low-cost OCT instrument as a point-of-care device in resource-constrained settings and the potential clinical application of device in screening and surveillance of oral cancer.",0,0
7755,"Explainable Artificial Intelligence Reveals Novel Insight into Tumor Microenvironment Conditions Linked with Better Prognosis in Patients with Breast Cancer. We investigated the data-driven relationship between immune cell composition in the tumor microenvironment (TME) and the â‰¥5-year survival rates of breast cancer patients using explainable artificial intelligence (XAI) models. We acquired TCGA breast invasive carcinoma data from the cbioPortal and retrieved immune cell composition estimates from bulk RNA sequencing data from TIMER2.0 based on EPIC, CIBERSORT, TIMER, and xCell computational methods. Novel insights derived from our XAI model showed that B cells, CD8<sup>+</sup> T cells, M0 macrophages, and NK T cells are the most critical TME features for enhanced prognosis of breast cancer patients. Our XAI model also revealed the inflection points of these critical TME features, above or below which â‰¥5-year survival rates improve. Subsequently, we ascertained the conditional probabilities of â‰¥5-year survival under specific conditions inferred from the inflection points. In particular, the XAI models revealed that the B cell fraction (relative to all cells in a sample) exceeding 0.025, M0 macrophage fraction (relative to the total immune cell content) below 0.05, and NK T cell and CD8<sup>+</sup> T cell fractions (based on cancer type-specific arbitrary units) above 0.075 and 0.25, respectively, in the TME could enhance the â‰¥5-year survival in breast cancer patients. The findings could lead to accurate clinical predictions and enhanced immunotherapies, and to the design of innovative strategies to reprogram the breast TME.",0,0
7757,"Saliency-guided deep learning network for automatic tumor bed volume delineation in post-operative breast irradiation. Efficient, reliable and reproducible target volume delineation is a key step in the effective planning of breast radiotherapy. However, post-operative breast target delineation is challenging as the contrast between the tumor bed volume (TBV) and normal breast tissue is relatively low in CT images. In this study, we propose to mimic the marker-guidance procedure in manual target delineation. We developed a saliency-based deep learning segmentation (SDL-Seg) algorithm for accurate TBV segmentation in post-operative breast irradiation. The SDL-Seg algorithm incorporates saliency information in the form of markers' location cues into a U-Net model. The design forces the model to encode the location-related features, which underscores regions with high saliency levels and suppresses low saliency regions. The saliency maps were generated by identifying markers on CT images. Markers' location were then converted to probability maps using a distance transformation coupled with a Gaussian filter. Subsequently, the CT images and the corresponding saliency maps formed a multi-channel input for the SDL-Seg network. Our in-house dataset was comprised of 145 prone CT images from 29 post-operative breast cancer patients, who received 5-fraction partial breast irradiation (PBI) regimen on GammaPod. The 29 patients were randomly split into training (19), validation (5) and test (5) sets. The performance of the proposed method was compared against basic U-Net. Our model achieved mean (standard deviation) of 76.4(Â±2.7) %, 6.76(Â±1.83) mm, and 1.9(Â±0.66) mm for Dice similarity coefficient, 95 percentile Hausdorff distance, and average symmetric surface distance respectively on the test set with computation time of below 11 seconds per one CT volume. SDL-Seg showed superior performance relative to basic U-Net for all the evaluation metrics while preserving low computation cost. The findings demonstrate that SDL-Seg is a promising approach for improving the efficiency and accuracy of the on-line treatment planning procedure of PBI, such as GammaPod based PBI.",0,0
7759,"Reaction-diffusion informed approach to determine myocardial ischemia using stochastic in-silico ECGs and CNNs. Every year, nine million people die globally from ischemic heart disease (IHD). There are many methods of early detection of IHD which can help prevent death, but few are able to determine the configuration and severity of this disease. Our study aims to determine the severity and configuration of ischemic zones by implementing the reaction-diffusion analysis of cardiac excitation in a model of the left ventricle of the human heart. Initially, this model is applied to compute twenty thousand in-silico ECG signals with stochastic distribution of ischemic parameters. Furthermore, generated data is effectively (r<sup>2</sup>=0.85) implemented for training a one-dimensional convolutional neural network to determine the severity and configuration of ischemia using only two lead surface ECG. Our results readily demonstrate that using a minimally configured portable ECG system can be instrumental for monitoring IHD and allowing early tracking of acute ischemic events.",0,0
7760,"ECG quality assessment based on hand-crafted statistics and deep-learned S-transform spectrogram features. Background and Objective Electrocardiogram (ECG) quality assessment is significant for automatic diagnosis of cardiovascular disease and reducing the massive workload of reviewing continuous ECGs. Hence, how to design an appropriate algorithm for objectively evaluating the multi-lead ECG recordings is particularly important. Despite the deep learning methods performing well in many fields, as a data-driven method, it may not be entirely suitable for ECG analysis due to the difficulty in obtaining sufficient data and the low signal-to-noise ratio of ECG recordings. In this study, with the aim of providing an accurate and automatic ECG quality assessment scheme, we propose an innovative ECG quality assessment algorithm based on hand-crafted statistical features and deep-learned spectral features. Methods In this paper, a novel approach, combining the deep-learned Stockwell transform (S-Transform) spectrogram features and hand-crafted statistical features, is proposed for ECG quality assessment. Firstly, a double-input convolutional neural network (CNN) is established. Then, the S-Transform with a novel online augmentation scheme is performed on the multi-lead raw ECG signal received from one input layer to obtain proper time-frequency representation. After that, the CNN with three convolutional layers is employed to extract robust deep-learned features automatically. Simultaneously, the hand-crafted statistical features, including lead-fall, baseline drift, and R peak features, are calculated and fed into another input layer for feature fusion training. Finally, the deep-learned and hand-crafted features are concatenated and further fused by a fully connected layer for quality classification. Furthermore, a log-odds analysis scheme combining with a gradient-based method can localize the abnormal zone in time, frequency, and spatial domains. Results and Conclusion Our proposed method is evaluated on a publicly available database with 10-fold cross-validation. The experimental results demonstrate that the proposed assessment algorithm reached a mean accuracy of 93.09%, a mean F1-score of 0.8472, and a sensitivity of 0.9767. Moreover, comprehensive experiments indicate that the fusion of CNN features and statistical features has complementary advantages and ideal interpretability, achieving end-to-end multi-lead ECG assessment with satisfying performance.",0,0
7761,"Deep learning approach to predict sentinel lymph node status directly from routine histology of primary melanoma tumours. Sentinel lymph node status is a central prognostic factor for melanomas. However, the surgical excision involves some risks for affected patients. In this study, we therefore aimed to develop a digital biomarker that can predict lymph node metastasis non-invasively from digitised H&E slides of primary melanoma tumours.",0,0
7764,"Clinical predictors of treatment response towards exposure therapy in virtuo in spider phobia: A machine learning and external cross-validation approach. While being highly effective on average, exposure-based treatments are not equally effective in all patients. The a priori identification of patients with a poor prognosis may enable the application of more personalized psychotherapeutic interventions. We aimed at identifying sociodemographic and clinical pre-treatment predictors for treatment response in spider phobia (SP). N = 174 patients with SP underwent a highly standardized virtual reality exposure therapy (VRET) at two independent sites. Analyses on group-level were used to test the efficacy. We applied a state-of-the-art machine learning protocol (Random Forests) to evaluate the predictive utility of clinical and sociodemographic predictors for a priori identification of individual treatment response assessed directly after treatment and at 6-month follow-up. The reliability and generalizability of predictive models was tested via external cross-validation. Our study shows that one session of VRET is highly effective on a group-level and is among the first to reveal long-term stability of this treatment effect. Individual short-term symptom reductions could be predicted above chance, but accuracies dropped to non-significance in our between-site prediction and for predictions of long-term outcomes. With performance metrics hardly exceeding chance level and the lack of generalizability in the employed between-site replication approach, our study suggests limited clinical utility of clinical and sociodemographic predictors. Predictive models including multimodal predictors may be more promising.",0,0
7765,"Machine learning for holistic visualization of STEMI registry data. Widespread adoption of evidence-based guidelines and treatment pathways in ST-Elevation Myocardial Infarction (STEMI) patients has considerably improved cardiac survival and decreased the risk of recurrent myocardial infarction. However, survival outcomes appear to have plateaued over the last decade. The hope underpinning the current study is to engage data visualization to develop a more holistic understanding of the patient space, supported by principles and techniques borrowed from traditionally disparate disciplines, like cartography and machine learning.",0,0
7768,"Effect of a deep learning-based system on the miss rate of gastric neoplasms during upper gastrointestinal endoscopy: a single-centre, tandem, randomised controlled trial. White light endoscopy is a pivotal first-line tool for the detection of gastric neoplasms. However, gastric neoplasms can be missed during upper gastrointestinal endoscopy due to the subtle nature of these lesions and varying skill among endoscopists. Here, we aimed to evaluate the effect of an artificial intelligence (AI) system designed to detect focal lesions and diagnose gastric neoplasms on reducing the miss rate of gastric neoplasms in clinical practice.",0,0
7772,Prediction of long-term survival after gastrectomy using random survival forests. No well validated and contemporaneous tools for personalized prognostication of gastric adenocarcinoma exist. This study aimed to derive and validate a prognostic model for overall survival after surgery for gastric adenocarcinoma using a large national dataset.,0,0
7784,"Information extraction for prognostic stage prediction from breast cancer medical records using NLP and ML. For cancer prediction, the prognostic stage is the main factor that helps medical experts to decide the optimal treatment for a patient. Specialists study prognostic stage information from medical reports, often in an unstructured form, and take a larger review time. The main objective of this study is to suggest a generic clinical decision-unifying staging method to extract the most reliable prognostic stage information of breast cancer from medical records of various health institutions. Additional prognostic elements should be extracted from medical reports to identify the cancer stage for getting an exact measure of cancer and improving care quality. This study has collected 465 pathological and clinical reports of breast cancer sufferers from India's reputed medical institutions. The unstructured records were found distinct from each institute. Anatomic and biologic factors are extracted from medical records using the natural language processing, machine learning and rule-based method for prognostic stage detection. This study has extracted anatomic stage, grade, estrogen receptor (ER), progesterone receptor (PR), and human epidermal growth factor receptor 2 (HER2) from medical reports with high accuracy and predicted prognostic stage for both regions. The prognostic stage prediction's average accuracy is found 92% and 82% in rural and urban areas, respectively. It was essential to combine biological and anatomical elements under a single prognostic staging method. A generic clinical decision-unifying staging method for prognostic stage detection with great accuracy in various institutions of different regional areas suggests that the proposed research improves the prognosis of breast cancer.",0,0
7792,"Combining MRI and Histologic Imaging Features for Predicting Overall Survival in Patients with Glioma. Purpose To test the hypothesis that combined features from MR and digital histopathologic images more accurately predict overall survival (OS) in patients with glioma compared with MRI or histopathologic features alone. Materials and Methods Multiparametric MR and histopathologic images in patients with a diagnosis of glioma (high- or low-grade glioma [HGG or LGG]) were obtained from The Cancer Imaging Archive (original images acquired 1983-2008). An extensive set of engineered features such as intensity, histogram, and texture were extracted from delineated tumor regions in MR and histopathologic images. Cox proportional hazard regression and support vector machine classification (SVC) models were applied to <i>(a)</i> MRI features only (MRI<sub>cox</sub>/svc), histopathologic features only (HistoPath<sub>cox</sub>/svc), and <i>(c)</i> combined MRI and histopathologic features (MRI+HistoPath<sub>cox</sub>/svc) and evaluated in a split train-test configuration. Results A total of 171 patients (mean age, 51 years Â± 15; 91 men) were included with HGG (<i>n</i> = 75) and LGG (<i>n</i> = 96). Median OS was 467 days (range, 3-4752 days) for all patients, 350 days (range, 15-1561 days) for HGG, and 595 days (range, 3-4752 days) for LGG. The MRI+HistoPath<sub>cox</sub> model demonstrated higher concordance index (C-index) compared with MRI<sub>cox</sub> and HistoPath<sub>cox</sub> models on all patients (C-index, 0.79 vs 0.70 [<i>P</i> = .02; MRI<sub>cox</sub>] and 0.67 [<i>P</i> = .01; HistoPath<sub>cox</sub>]), patients with HGG (C-index, 0.78 vs 0.68 [<i>P</i> = .03; MRI<sub>cox</sub>] and 0.64 [<i>P</i> = .01; HistoPath<sub>cox</sub>]), and patients with LGG (C-index, 0.88 vs 0.62 [P = .008; MRI<sub>cox</sub>] and 0.62 [P = .006; HistoPath<sub>cox</sub>]). In binary classification, the MRI+HistoPath<sub>svc</sub> model (area under the receiver operating characteristic curve [AUC], 0.86 [95% CI: 0.80, 0.95]) had higher performance than the MRI<sub>svc</sub> model (AUC, 0.68 [95% CI: 0.50, 0.81]; <i>P</i> = .01) and the HistoPath<sub>svc</sub> model (AUC, 0.72 [95% CI: 0.60, 0.85]; <i>P</i> = .04). Conclusion The model combining features from MR and histopathologic images had higher accuracy in predicting OS compared with the models with MR or histopathologic images alone. <b>Keywords:</b> Survival Prediction, Gliomas, Digital Pathology Imaging, MR Imaging, Machine Learning <i>Supplemental material is available for this article.</i>",0,0
7794,Improving the Efficiency of Clinical Trial Recruitment Using an Ensemble Machine Learning to Assist With Eligibility Screening. Efficiently identifying eligible patients is a crucial first step for a successful clinical trial. The objective of this study was to test whether an approach using electronic health record (EHR) data and an ensemble machine learning algorithm incorporating billing codes and data from clinical notes processed by natural language processing (NLP) can improve the efficiency of eligibility screening.,0,0
7803,Machine learning for prediction of diabetes risk in middle-aged Swedish people. To study if machine learning methodology can be used to detect persons with increased type 2 diabetes or prediabetes risk among people without known abnormal glucose regulation.,0,0
7807,"Prediction of Tumor Shrinkage Pattern to Neoadjuvant Chemotherapy Using a Multiparametric MRI-Based Machine Learning Model in Patients With Breast Cancer. <b>Aim:</b> After neoadjuvant chemotherapy (NACT), tumor shrinkage pattern is a more reasonable outcome to decide a possible breast-conserving surgery (BCS) than pathological complete response (pCR). The aim of this article was to establish a machine learning model combining radiomics features from multiparametric MRI (mpMRI) and clinicopathologic characteristics, for early prediction of tumor shrinkage pattern prior to NACT in breast cancer. <b>Materials and Methods:</b> This study included 199 patients with breast cancer who successfully completed NACT and underwent following breast surgery. For each patient, 4,198 radiomics features were extracted from the segmented 3D regions of interest (ROI) in mpMRI sequences such as T1-weighted dynamic contrast-enhanced imaging (T1-DCE), fat-suppressed T2-weighted imaging (T2WI), and apparent diffusion coefficient (ADC) map. The feature selection and supervised machine learning algorithms were used to identify the predictors correlated with tumor shrinkage pattern as follows: (1) reducing the feature dimension by using ANOVA and the least absolute shrinkage and selection operator (LASSO) with 10-fold cross-validation, (2) splitting the dataset into a training dataset and testing dataset, and constructing prediction models using 12 classification algorithms, and (3) assessing the model performance through an area under the curve (AUC), accuracy, sensitivity, and specificity. We also compared the most discriminative model in different molecular subtypes of breast cancer. <b>Results:</b> The Multilayer Perception (MLP) neural network achieved higher AUC and accuracy than other classifiers. The radiomics model achieved a mean AUC of 0.975 (accuracy = 0.912) on the training dataset and 0.900 (accuracy = 0.828) on the testing dataset with 30-round 6-fold cross-validation. When incorporating clinicopathologic characteristics, the mean AUC was 0.985 (accuracy = 0.930) on the training dataset and 0.939 (accuracy = 0.870) on the testing dataset. The model further achieved good AUC on the testing dataset with 30-round 5-fold cross-validation in three molecular subtypes of breast cancer as following: (1) HR+/HER2-: 0.901 (accuracy = 0.816), (2) HER2+: 0.940 (accuracy = 0.865), and (3) TN: 0.837 (accuracy = 0.811). <b>Conclusions:</b> It is feasible that our machine learning model combining radiomics features and clinical characteristics could provide a potential tool to predict tumor shrinkage patterns prior to NACT. Our prediction model will be valuable in guiding NACT and surgical treatment in breast cancer.",0,0
7810,"Efficacy of Location-Based Features for Survival Prediction of Patients With Glioblastoma Depending on Resection Status. Cancer stands out as one of the fatal diseases people are facing all the time. Each year, a countless number of people die because of the late diagnosis of cancer or wrong treatments. Glioma, one of the most common primary brain tumors, has different aggressiveness and sub-regions, which can affect the risk of disease. Although prediction of overall survival based on multimodal magnetic resonance imaging (MRI) is challenging, in this study, we assess if and how location-based features of tumors can affect overall survival prediction. This approach is evaluated independently and in combination with radiomic features. The process is carried out on a data set entailing MRI images of patients with glioblastoma. To assess the impact of resection status, the data set is divided into two groups, patients were reported as gross total resection and unknown resection status. Then, different machine learning algorithms were used to evaluate how location features are linked with overall survival. Results from regression models indicate that location-based features have considerable effects on the patients' overall survival independently. Additionally, classifier models show an improvement in prediction accuracy by the addition of location-based features to radiomic features.",0,0
7811,Preoperative Radiomics Analysis of 1p/19q Status in WHO Grade II Gliomas. The present study aimed to preoperatively predict the status of 1p/19q based on radiomics analysis in patients with World Health Organization (WHO) grade II gliomas.,0,0
7812,Development and Validation of a Radiomic Nomogram for Predicting the Prognosis of Kidney Renal Clear Cell Carcinoma. The present study aims to comprehensively investigate the prognostic value of a radiomic nomogram that integrates contrast-enhanced computed tomography (CECT) radiomic signature and clinicopathological parameters in kidney renal clear cell carcinoma (KIRC).,0,0
7813,"Early recognition of necrotizing pneumonia in children based on non-contrast-enhanced computed tomography radiomics signatures. Necrotizing pneumonia (NP) is an infrequent but severe complication of pneumonia in children. In the early stages of NP, CT imaging shows lung consolidation, which cannot be detected in time. This study aimed to explore the ability of non-contrast-enhanced CT radiomics features to recognize NP in early stage.",0,0
7815,"Machine learning-based long-term outcome prediction in patients undergoing percutaneous coronary intervention. Traditional prognostic risk assessment in patients with coronary artery disease undergoing percutaneous coronary intervention (PCI) is based on a limited selection of clinical and imaging findings. Machine learning (ML) can consider a higher number and complexity of variables and may be useful for characterising cardiovascular risk, predicting outcomes, and identifying biomarkers in large population studies.",0,0
7816,Artificial intelligence-based analysis for immunohistochemistry staining of immune checkpoints to predict resected non-small cell lung cancer survival and relapse. Conventional analysis of single-plex chromogenic immunohistochemistry (IHC) focused on quantitative but spatial analysis. How immune checkpoints localization related to non-small cell lung cancer (NSCLC) prognosis remained unclear.,0,0
7817,"Machine learning-based random forest predicts anastomotic leakage after anterior resection for rectal cancer. Anastomotic leakage (AL) is one of the commonest and most serious complications after rectal cancer surgery. The previous analyses on predictors for AL included small-scale patients, and their prediction models performed unsatisfactorily.",0,0
7826,"Diagnosis of Alzheimer's disease using laser-induced breakdown spectroscopy and machine learning. Alzheimer's disease (AD) is a progressive incurable neurodegenerative disease and a major health problem in aging population. We show that the combined use of Laser-Induced Breakdown Spectroscopy (LIBS) and machine learning applied for the analysis of micro-drops of plasma samples of AD and healthy controls (HC) yields robust classification. Following the acquisition of LIBS spectra of 67 plasma samples from a cohort of 31 AD patients and 36 healthy controls (HC), we successfully diagnose late-onset AD (> 65 years old), with a total classification accuracy of 80%, a specificity of 75% and a sensitivity of 85%.",0,0
7830,"Quantification of tumor microenvironment acidity in glioblastoma using principal component analysis of dynamic susceptibility contrast enhanced MR imaging. Glioblastoma (GBM) has high metabolic demands, which can lead to acidification of the tumor microenvironment. We hypothesize that a machine learning model built on temporal principal component analysis (PCA) of dynamic susceptibility contrast-enhanced (DSC) perfusion MRI can be used to estimate tumor acidity in GBM, as estimated by pH-sensitive amine chemical exchange saturation transfer echo-planar imaging (CEST-EPI). We analyzed 78 MRI scans in 32 treatment naÃ¯ve and post-treatment GBM patients. All patients were imaged with DSC-MRI, and pH-weighting that was quantified from CEST-EPI estimation of the magnetization transfer ratio asymmetry (MTR<sub>asym</sub>) at 3Â ppm. Enhancing tumor (ET), non-enhancing core (NC), and peritumoral T2 hyperintensity (namely, edema, ED) were used to extract principal components (PCs) and to build support vector machines regression (SVR) models to predict MTR<sub>asym</sub> values using PCs. Our predicted map correlated with MTR<sub>asym</sub> values with Spearman's r equal to 0.66, 0.47, 0.67, 0.71, in NC, ET, ED, and overall, respectively (pâ€‰<â€‰0.006). The results of this study demonstrates that PCA analysis of DSC imaging data can provide information about tumor pH in GBM patients, with the strongest association within the peritumoral regions.",0,0
7832,"A novel framework for designing a multi-DoF prosthetic wrist control using machine learning. Prosthetic arms can significantly increase the upper limb function of individuals with upper limb loss, however despite the development of various multi-DoF prosthetic arms the rate of prosthesis abandonment is still high. One of the major challenges is to design a multi-DoF controller that has high precision, robustness, and intuitiveness for daily use. The present study demonstrates a novel framework for developing a controller leveraging machine learning algorithms and movement synergies to implement natural control of a 2-DoF prosthetic wrist for activities of daily living (ADL). The data was collected during ADL tasks of ten individuals with a wrist brace emulating the absence of wrist function. Using this data, the neural network classifies the movement and then random forest regression computes the desired velocity of the prosthetic wrist. The models were trained/tested with ADLs where their robustness was tested using cross-validation and holdout data sets. The proposed framework demonstrated high accuracy (F-1 score of 99% for the classifier and Pearson's correlation of 0.98 for the regression). Additionally, the interpretable nature of random forest regression was used to verify the targeted movement synergies. The present work provides a novel and effective framework to develop an intuitive control for multi-DoF prosthetic devices.",0,0
7833,"Clinically applicable artificial intelligence system for dental diagnosis with CBCT. In this study, a novel AI system based on deep learning methods was evaluated to determine its real-time performance of CBCT imaging diagnosis of anatomical landmarks, pathologies, clinical effectiveness, and safety when used by dentists in a clinical setting. The system consists of 5 modules: ROI-localization-module (segmentation of teeth and jaws), tooth-localization and numeration-module, periodontitis-module, caries-localization-module, and periapical-lesion-localization-module. These modules use CNN based on state-of-the-art architectures. In total, 1346 CBCT scans were used to train the modules. After annotation and model development, the AI system was tested for diagnostic capabilities of the Diagnocat AI system. 24 dentists participated in the clinical evaluation of the system. 30 CBCT scans were examined by two groups of dentists, where one group was aided by Diagnocat and the other was unaided. The results for the overall sensitivity and specificity for aided and unaided groups were calculated as an aggregate of all conditions. The sensitivity values for aided and unaided groups were 0.8537 and 0.7672 while specificity was 0.9672 and 0.9616 respectively. There was a statistically significant difference between the groups (pâ€‰=â€‰0.032). This study showed that the proposed AI system significantly improved the diagnostic capabilities of dentists.",1,1
7839,"A Deep Learning-Based Approach for Glomeruli Instance Segmentation from Multistained Renal Biopsy Pathologic Images. Glomeruli instance segmentation from pathologic images is a fundamental step in the automatic analysis of renal biopsies. Glomerular histologic manifestations vary widely among diseases and cases, and several special staining methods are necessary for pathologic diagnosis. A robust model is needed to segment and classify glomeruli with different staining methods and apply in cases with various glomerular pathologic changes. Herein, pathologic images from renal biopsy slides stained with three basic special staining methods were used to build the data sets. The snapshot group included 1970 glomeruli from 516 patients, and the whole-slide image group included 8665 glomeruli from 148 patients. Cascade Mask region-based convolutional neural net architecture was trained to detect, classify, and segment glomeruli into three categories: i) GN, structural normal; ii) global sclerosis; and iii) glomerular with other lesions. In the snapshot group, total glomeruli, GN, global sclerosis, and glomerular with other lesions achieved an F1 score of 0.914, 0.896, 0.681, and 0.756, respectively, which were comparable with those in the whole-slide image group (0.940, 0.839, 0.806, and 0.753, respectively). Among the three categories, GN achieved the best instance segmentation effect in both groups, as determined by average precision, average recall, F1 score, and Mask mean Intersection over Union. The present model segments and classifies multistained glomeruli with efficiency and robustness. It can be applied as the first step for more detailed glomerular histologic analysis.",0,0
7845,"Diagnostic accuracy of a novel artificial intelligence system for adenoma detection in daily practice: a prospective nonrandomized comparative study. â€‚Adenoma detection rate (ADR) varies significantly between endoscopists, with adenoma miss rates (AMRs) up to 26â€Š%. Artificial intelligence (AI) systems may improve endoscopy quality and reduce the rate of interval cancer. We evaluated the efficacy of an AI system in real-time colonoscopy and its influence on AMR and ADR.",1,1
7847,"Synthetic pulmonary perfusion images from 4DCT for functional avoidance using deep learning. <i>Purpose.</i>To develop and evaluate the performance of a deep learning model to generate synthetic pulmonary perfusion images from clinical 4DCT images for patients undergoing radiotherapy for lung cancer.<i>Methods</i>. A clinical data set of 58 pre- and post-radiotherapy<sup>99m</sup>Tc-labeled MAA-SPECT perfusion studies (32 patients) each with contemporaneous 4DCT studies was collected. Using the inhale and exhale phases of the 4DCT, a 3D-residual network was trained to create synthetic perfusion images utilizing the MAA-SPECT as ground truth. The training process was repeated for a 50-imaging study, five-fold validation with twenty model instances trained per fold. The highest performing model instance from each fold was selected for inference upon the eight-study test set. A manual lung segmentation was used to compute correlation metrics constrained to the voxels within the lungs. From the pre-treatment test cases (<i>N</i>Â =Â 5), 50th percentile contours of well-perfused lung were generated from both the clinical and synthetic perfusion images and the agreement was quantified.<i>Results</i>. Across the hold-out test set, our deep learning model predicted perfusion with a Spearman correlation coefficient of 0.70 (IQR: 0.61-0.76) and a Pearson correlation coefficient of 0.66 (IQR: 0.49-0.73). The agreement of the functional avoidance contour pairs was Dice of 0.803 (IQR: 0.750-0.810) and average surface distance of 5.92 mm (IQR: 5.68-7.55).<i>Conclusion</i>. We demonstrate that from 4DCT alone, a deep learning model can generate synthetic perfusion images with potential application in functional avoidance treatment planning.",0,0
7848,"Prediction of chemotherapy response in breast cancer patients at pre-treatment using second derivative texture of CT images and machine learning. Although neoadjuvant chemotherapy (NAC) is a crucial component of treatment for locally advanced breast cancer (LABC), only about 70% of patients respond to it. Effective adjustment of NAC for individual patients can significantly improve survival rates of those resistant to standard regimens. Thus, the early prediction of NAC outcome is of great importance in facilitating a personalized paradigm for breast cancer therapeutics. In this study, quantitative computed tomography (qCT) parametric imaging in conjunction with machine learning techniques were investigated to predict LABC tumor response to NAC. Textural and second derivative textural (SDT) features of CT images of 72 patients diagnosed with LABC were analysed before the initiation of NAC to quantify intra-tumor heterogeneity. These quantitative features were processed through a correlation-based feature reduction followed by a sequential feature selection with a bootstrap 0.632+ area under the receiver operating characteristic (ROC) curve (AUC<sub>0.632+</sub>) criterion. The best feature subset consisted of a combination of one textural and three SDT features. Using these features, an AdaBoost decision tree could predict the patient response with a cross-validated AUC<sub>0.632+</sub> accuracy, sensitivity and specificity of 0.88, 85%, 88% and 75%, respectively. This study demonstrates, for the first time, that a combination of textural and SDT features of CT images can be used to predict breast cancer response NAC prior to the start of treatment which can potentially facilitate early therapy adjustments.",0,0
7855,"Deep learning for sex classification in resting-state and task functional brain networks from the UK Biobank. Classification of whole-brain functional connectivity MRI data with convolutional neural networks (CNNs) has shown promise, but the complexity of these models impedes understanding of which aspects of brain activity contribute to classification. While visualization techniques have been developed to interpret CNNs, bias inherent in the method of encoding abstract input data, as well as the natural variance of deep learning models, detract from the accuracy of these techniques. We introduce a stochastic encoding method in an ensemble of CNNs to classify functional connectomes by sex. We applied our method to resting-state and task data from the UK BioBank, using two visualization techniques to measure the salience of three brain networks involved in task- and resting-states, and their interaction. To regress confounding factors such as head motion, age, and intracranial volume, we introduced a multivariate balancing algorithm to ensure equal distributions of such covariates between classes in our data. We achieved a final AUROC of 0.8459. We found that resting-state data classifies more accurately than task data, with the inner salience network playing the most important role of the three networks overall in classification of resting-state data and connections to the central executive network in task data.",0,0
7862,Individualized Glaucoma Change Detection Using Deep Learning Auto Encoder-Based Regions of Interest. To compare change over time in eye-specific optical coherence tomography (OCT) retinal nerve fiber layer (RNFL)-based region-of-interest (ROI) maps developed using unsupervised deep-learning auto-encoders (DL-AE) to circumpapillary RNFL (cpRNFL) thickness for the detection of glaucomatous progression.,0,0
7867,A machine learning analysis of risk and protective factors of suicidal thoughts and behaviors in college students. To identify robust and reproducible factors associated with suicidal thoughts and behaviors (STBs) in college students.,0,0
7871,Using Deep Learning Segmentation for Endotracheal Tube Position Assessment. The purpose of this study was to determine the efficacy of using deep learning segmentation for endotracheal tube (ETT) position on frontal chest x-rays (CXRs).,0,0
7884,Automated detection and segmentation of sclerotic spinal lesions on body CTs using a deep convolutional neural network. To develop a deep convolutional neural network capable of detecting spinal sclerotic metastases on body CTs.,0,0
7889,"Early Prediction of Mortality, Severity, and Length of Stay in the Intensive Care Unit of Sepsis Patients Based on Sepsis 3.0 by Machine Learning Models. <b>Background:</b> Early prediction of the clinical outcome of patients with sepsis is of great significance and can guide treatment and reduce the mortality of patients. However, it is clinically difficult for clinicians. <b>Methods:</b> A total of 2,224 patients with sepsis were involved over a 3-year period (2016-2018) in the intensive care unit (ICU) of Peking Union Medical College Hospital. With all the key medical data from the first 6 h in the ICU, three machine learning models, logistic regression, random forest, and XGBoost, were used to predict mortality, severity (sepsis/septic shock), and length of ICU stay (LOS) (>6 days, â‰¤ 6 days). Missing data imputation and oversampling were completed on the dataset before introduction into the models. <b>Results:</b> Compared to the mortality and LOS predictions, the severity prediction achieved the best classification results, based on the area under the operating receiver characteristics (AUC), with the random forest classifier (sensitivity = 0.65, specificity = 0.73, F1 score = 0.72, AUC = 0.79). The random forest model also showed the best overall performance (mortality prediction: sensitivity = 0.50, specificity = 0.84, F1 score = 0.66, AUC = 0.74; LOS prediction: sensitivity = 0.79, specificity = 0.66, F1 score = 0.69, AUC = 0.76) among the three models. The predictive ability of the SOFA score itself was inferior to that of the above three models. <b>Conclusions:</b> Using the random forest classifier in the first 6 h of ICU admission can provide a comprehensive early warning of sepsis, which will contribute to the formulation and management of clinical decisions and the allocation and management of resources.",0,0
7890,"An Optimization Algorithm for Computer-Aided Diagnosis of Breast Cancer Based on Support Vector Machine. As one of the most vulnerable cancers of women, the incidence rate of breast cancer in China is increasing at an annual rate of 3%, and the incidence is younger. Therefore, it is necessary to conduct research on the risk of breast cancer, including the cause of disease and the prediction of breast cancer risk based on historical data. Data based statistical learning is an important branch of modern computational intelligence technology. Using machine learning method to predict and judge unknown data provides a new idea for breast cancer diagnosis. In this paper, an improved optimization algorithm (GSP_SVM) is proposed by combining genetic algorithm, particle swarm optimization and simulated annealing with support vector machine algorithm. The results show that the classification accuracy, MCC, AUC and other indicators have reached a very high level. By comparing with other optimization algorithms, it can be seen that this method can provide effective support for decision-making of breast cancer auxiliary diagnosis, thus significantly improving the diagnosis efficiency of medical institutions. Finally, this paper also preliminarily explores the effect of applying this algorithm in detecting and classifying breast cancer in different periods, and discusses the application of this algorithm to multiple classifications by comparing it with other algorithms.",0,0
7893,"DeepCUBIT: Predicting Lymphovascular Invasion or Pathological Lymph Node Involvement of Clinical T1 Stage Non-Small Cell Lung Cancer on Chest CT Scan Using Deep Cubical Nodule Transfer Learning Algorithm. The prediction of lymphovascular invasion (LVI) or pathological nodal involvement of tumor cells is critical for successful treatment in early stage non-small cell lung cancer (NSCLC). We developed and validated a Deep Cubical Nodule Transfer Learning Algorithm (DeepCUBIT) using transfer learning and 3D Convolutional Neural Network (CNN) to predict LVI or pathological nodal involvement on chest CT images. A total of 695 preoperative CT images of resected NSCLC with tumor size of less than or equal to 3Â cm from 2008 to 2015 were used to train and validate the DeepCUBIT model using five-fold cross-validation method. We also used tumor size and consolidation to tumor ratio (C/T ratio) to build a support vector machine (SVM) classifier. Two-hundred and fifty-four out of 695 samples (36.5%) had LVI or nodal involvement. An integrated model (3D CNN + Tumor size + C/T ratio) showed sensitivity of 31.8%, specificity of 89.8%, accuracy of 76.4%, and AUC of 0.759 on external validation cohort. Three single SVM models, using 3D CNN (DeepCUBIT), tumor size or C/T ratio, showed AUCs of 0.717, 0.630 and 0.683, respectively on external validation cohort. DeepCUBIT showed the best single model compared to the models using only C/T ratio or tumor size. In addition, the DeepCUBIT model could significantly identify the prognosis of resected NSCLC patients even in stage I. DeepCUBIT using transfer learning and 3D CNN can accurately predict LVI or nodal involvement in cT1 size NSCLC on CT images. Thus, it can provide a more accurate selection of candidates who will benefit from limited surgery without increasing the risk of recurrence.",0,0
7894,"An immune-based risk-stratification system for predicting prognosis in pulmonary sarcomatoid carcinoma (PSC). Pulmonary sarcomatoid carcinoma (PSC) is an uncommon subtype of lung cancer, and immune checkpoint blockade promises in clinical benefit. However, virtually nothing is known about the expression of common immune checkpoints in PSC. Here, we performed immunohistochemistry (IHC) to detect nine immune-related proteins in 97 PSC patients. Based on the univariable Cox regression, random forests were used to establish risk models for OS and DFS. Moreover, we used the GSEA, CIBERSORT, and ImmuCellAI to analyze the enriched pathways and microenvironment. Univariable analysis revealed that CD4 (<i>P</i> = 0.008), programmed cell death protein 1 (PD-1; <i>P</i> = 0.003), galectin-9 (Gal-9) on tumor cells (TCs; <i>P</i> = 0.021) were independent for DFS, while CD4 (<i>P</i> = 0.020), PD-1 (<i>P</i> = 0.004), Gal-9 (<i>P</i> = 0.033), and HLA on TILs (<i>P</i> = 0.031) were significant for OS. Meanwhile, the expression level of CD8 played a marginable role in DFS (<i>P</i> = 0.061), limited by the number of patients. The combination of Gal-9 on TC with CD4 and PD-1 on TILs demonstrated the most accurate prediction for DFS (AUC: 0.636-0.791, F1-score: 0.635-0.799), and a dramatic improvement to TNM-stage (<i>P</i> < 0.001 for F1-score of 1-y, 3-y, and 5-yDFS). A similar finding was also observed in the predictive ability of CD4 for OS (AUC: 0.602-0.678, F1-score: 0.635-0.679). CD4 was negatively associated with the infiltration of neutrophils (<i>P</i> = 0.015). PDCD1 (coding gene of PD-1) was positively correlated to the number of exhausted T cells (Texs; <i>P</i> = 0.020) and induced regulatory T cells (iTregs; <i>P</i> = 0.021), and LGALS9 (coding gene of Gal-9) was positively related to the level of dendritic cells (DCs; <i>P</i> = 0.021). Further, a higher combinational level of CD4, PDCD1 on TILs, and LAGLS9 on TCs were proved to be infiltrated with more M1-type macrophages (<i>P</i> < 0.05). We confirmed the expression status of nine immune-related proteins and established a TNM-Immune system for OS and DFS in PSC to assist clinical risk-stratification.",0,0
7897,"Using Machine Learning to Characterize Atrial Fibrotic Substrate From Intracardiac Signals With a Hybrid <i>in silico</i> and <i>in vivo</i> Dataset. In patients with atrial fibrillation, intracardiac electrogram signal amplitude is known to decrease with increased structural tissue remodeling, referred to as fibrosis. In addition to the isolation of the pulmonary veins, fibrotic sites are considered a suitable target for catheter ablation. However, it remains an open challenge to find fibrotic areas and to differentiate their density and transmurality. This study aims to identify the volume fraction and transmurality of fibrosis in the atrial substrate. Simulated cardiac electrograms, combined with a generalized model of clinical noise, reproduce clinically measured signals. Our hybrid dataset approach combines <i>in silico</i> and clinical electrograms to train a decision tree classifier to characterize the fibrotic atrial substrate. This approach captures different <i>in vivo</i> dynamics of the electrical propagation reflected on healthy electrogram morphology and synergistically combines it with synthetic fibrotic electrograms from <i>in silico</i> experiments. The machine learning algorithm was tested on five patients and compared against clinical voltage maps as a proof of concept, distinguishing non-fibrotic from fibrotic tissue and characterizing the patient's fibrotic tissue in terms of density and transmurality. The proposed approach can be used to overcome a single voltage cut-off value to identify fibrotic tissue and guide ablation targeting fibrotic areas.",0,0
7898,"HADLN: Hybrid Attention-Based Deep Learning Network for Automated Arrhythmia Classification. In recent years, with the development of artificial intelligence, deep learning model has achieved initial success in ECG data analysis, especially the detection of atrial fibrillation. In order to solve the problems of ignoring the correlation between contexts and gradient dispersion in traditional deep convolution neural network model, the hybrid attention-based deep learning network (HADLN) method is proposed to implement arrhythmia classification. The HADLN can make full use of the advantages of residual network (ResNet) and bidirectional long-short-term memory (Bi-LSTM) architecture to obtain fusion features containing local and global information and improve the interpretability of the model through the attention mechanism. The method is trained and verified by using the PhysioNet 2017 challenge dataset. Without loss of generality, the ECG signal is classified into four categories, including atrial fibrillation, noise, other, and normal signals. By combining the fusion features and the attention mechanism, the learned model has a great improvement in classification performance and certain interpretability. The experimental results show that the proposed HADLN method can achieve precision of 0.866, recall of 0.859, accuracy of 0.867, and F1-score of 0.880 on 10-fold cross-validation.",0,0
7900,"Thalamus Radiomics-Based Disease Identification and Prediction of Early Treatment Response for Schizophrenia. Emerging evidence suggests structural and functional disruptions of the thalamus in schizophrenia, but whether thalamus abnormalities are able to be used for disease identification and prediction of early treatment response in schizophrenia remains to be determined. This study aims at developing and validating a method of disease identification and prediction of treatment response by multi-dimensional thalamic features derived from magnetic resonance imaging in schizophrenia patients using radiomics approaches.",0,0
7902,"Automated cortical thickness measurement of the mandibular condyle head on CBCT images using a deep learning method. This study proposes a deep learning model for cortical bone segmentation in the mandibular condyle head using cone-beam computed tomography (CBCT) and an automated method for measuring cortical thickness with a color display based on the segmentation results. In total, 12,800 CBCT images from 25 normal subjects, manually labeled by an oral radiologist, served as the gold-standard. The segmentation model combined a modified U-Net and a convolutional neural network for target region classification. Model performance was evaluated using intersection over union (IoU) and the Hausdorff distance in comparison with the gold standard. The second automated model measured the cortical thickness based on a three-dimensional (3D) model rendered from the segmentation results and presented a color visualization of the measurements. The IoU and Hausdorff distance showed high accuracy (0.870 and 0.928 for marrow bone and 0.734 and 1.247 for cortical bone, respectively). A visual comparison of the 3D color maps showed a similar trend to the gold standard. This algorithm for automatic segmentation of the mandibular condyle head and visualization of the measured cortical thickness as a 3D-rendered model with a color map may contribute to the automated quantification of bone thickness changes of the temporomandibular joint complex on CBCT.",0,0
7903,"Machine learning-based preoperative datamining can predict the therapeutic outcome of sleep surgery in OSA subjects. Increasing recognition of anatomical obstruction has resulted in a large variety of sleep surgeries to improve anatomic collapse of obstructive sleep apnea (OSA) and the prediction of whether sleep surgery will have successful outcome is very important. The aim of this study is to assess a machine learning-based clinical model that predict the success rate of sleep surgery in OSA subjects. The predicted success rate from machine learning and the predicted subjective surgical outcome from the physician were compared with the actual success rate in 163 male dominated-OSA subjects. Predicted success rate of sleep surgery from machine learning models based on sleep parameters and endoscopic findings of upper airway demonstrated higher accuracy than subjective predicted value of sleep surgeon. The gradient boosting model showed the best performance to predict the surgical success that is evaluated by pre- and post-operative polysomnography or home sleep apnea testing among the logistic regression and three machine learning models, and the accuracy of gradient boosting model (0.708) was significantly higher than logistic regression model (0.542). Our data demonstrate that the data mining-driven prediction such as gradient boosting exhibited higher accuracy for prediction of surgical outcome and we can provide accurate information on surgical outcomes before surgery to OSA subjects using machine learning models.",1,1
7906,"Integrating ensemble systems biology feature selection and bimodal deep neural network for breast cancer prognosis prediction. Breast cancer is a heterogeneous disease. To guide proper treatment decisions for each patient, robust prognostic biomarkers, which allow reliable prognosis prediction, are necessary. Gene feature selection based on microarray data is an approach to discover potential biomarkers systematically. However, standard pure-statistical feature selection approaches often fail to incorporate prior biological knowledge and select genes that lack biological insights. Besides, due to the high dimensionality and low sample size properties of microarray data, selecting robust gene features is an intrinsically challenging problem. We hence combined systems biology feature selection with ensemble learning in this study, aiming to select genes with biological insights and robust prognostic predictive power. Moreover, to capture breast cancer's complex molecular processes, we adopted a multi-gene approach to predict the prognosis status using deep learning classifiers. We found that all ensemble approaches could improve feature selection robustness, wherein the hybrid ensemble approach led to the most robust result. Among all prognosis prediction models, the bimodal deep neural network (DNN)Â achieved the highest test performance, further verified by survival analysis. In summary, this study demonstrated the potential of combining ensemble learning and bimodal DNN in guiding precision medicine.",0,0
7907,"Characterizing intra-tumor regions on quantitative ultrasound parametric images to predict breast cancer response to chemotherapy at pre-treatment. The efficacy of quantitative ultrasound (QUS) multi-parametric imaging in conjunction with unsupervised classification algorithms was investigated for the first time in characterizing intra-tumor regions to predict breast tumor response to chemotherapy before the start of treatment. QUS multi-parametric images of breast tumors were generated using the ultrasound radiofrequency data acquired from 181 patients diagnosed with locally advanced breast cancer and planned for neo-adjuvant chemotherapy followed by surgery. A hidden Markov random field (HMRF) expectation maximization (EM) algorithm was applied to identify distinct intra-tumor regions on QUS multi-parametric images. Several features were extracted from the segmented intra-tumor regions and tumor margin on different parametric images. A multi-step feature selection procedure was applied to construct a QUS biomarker consisting of four features for response prediction. Evaluation results on an independent test set indicated that the developed biomarker coupled with a decision tree model with adaptive boosting (AdaBoost) as the classifier could predict the treatment response of patient at pre-treatment with an accuracy of 85.4% and an area under the receiver operating characteristic (ROC) curve (AUC) of 0.89. In comparison, the biomarkers consisted of the features derived from the entire tumor core (without consideration of the intra-tumor regions), and the entire tumor core and the tumor margin could predict the treatment response of patients with an accuracy of 74.5% and 76.4%, and an AUC of 0.79 and 0.76, respectively. Standard clinical features could predict the therapy response with an accuracy of 69.1% and an AUC of 0.6. Long-term survival analyses indicated that the patients predicted by the developed model as responders had a significantly better survival compared to the non-responders. Similar findings were observed for the two response cohorts identified at post-treatment based on standard clinical and pathological criteria. The results obtained in this study demonstrated the potential of QUS multi-parametric imaging integrated with unsupervised learning methods in identifying distinct intra-tumor regions in breast cancer to characterize its responsiveness to chemotherapy prior to the start of treatment.",0,0
7915,Neonatal mortality prediction with routinely collected data: a machine learning approach. Recent decreases in neonatal mortality have been slower than expected for most countries. This study aims to predict the risk of neonatal mortality using only data routinely available from birth records in the largest city of the Americas.,0,0
7917,"Automated detection of muscle fatigue conditions from cyclostationary based geometric features of surface electromyography signals. In this study, an attempt has been made to develop an automated muscle fatigue detection system using cyclostationary based geometric features of surface electromyography (sEMG) signals. For this purpose, signals are acquired from fifty-eight healthy volunteers under dynamic muscle fatiguing contractions. The sEMG signals are preprocessed and the epochs of signals under nonfatigue and fatigue conditions are considered for the analysis. A computationally effective Fast Fourier transform based accumulation algorithm is adapted to compute the spectral correlation density coefficients. The boundary of spectral density coefficients in the complex plane is obtained using alpha shape method. The geometric features, namely, perimeter, area, circularity, bending energy, eccentricity and inertia are extracted from the shape and the machine learning models based on multilayer perceptron (MLP) and extreme learning machine (ELM) are developed using these biomarkers. The results show that the cyclostationarity increases in fatigue condition. All the extracted features are found to have significant difference in the two conditions. It is found that the ELM model based on prominent features classifies the sEMG signals with a maximum accuracy of 94.09% and F-score of 93.75%. Therefore, the proposed approach appears to be useful for analysing the fatiguing contractions in neuromuscular conditions.",0,0
7927,"Automatic cell counting from stimulated Raman imaging using deep learning. In this paper, we propose an automatic cell counting framework for stimulated Raman scattering (SRS) images, which can assist tumor tissue characteristic analysis, cancer diagnosis, and surgery planning processes. SRS microscopy has promoted tumor diagnosis and surgery by mapping lipids and proteins from fresh specimens and conducting a fast disclose of fundamental diagnostic hallmarks of tumors with a high resolution. However, cell counting from label-free SRS images has been challenging due to the limited contrast of cells and tissue, along with the heterogeneity of tissue morphology and biochemical compositions. To this end, a deep learning-based cell counting scheme is proposed by modifying and applying U-Net, an effective medical image semantic segmentation model that uses a small number of training samples. The distance transform and watershed segmentation algorithms are also implemented to yield the cell instance segmentation and cell counting results. By performing cell counting on SRS images of real human brain tumor specimens, promising cell counting results are obtained with > 98% of area under the curve (AUC) and R = 0.97 in terms of cell counting correlation between SRS and histological images with hematoxylin and eosin (H&E) staining. The proposed cell counting scheme illustrates the possibility and potential of performing cell counting automatically in near real time and encourages the study of applying deep learning techniques in biomedical and pathological image analyses.",0,0
7928,"Survival prognostic factors in patients with acute myeloid leukemia using machine learning techniques. This paper identifies prognosis factors for survival in patients with acute myeloid leukemia (AML) using machine learning techniques. We have integrated machine learning with feature selection methods and have compared their performances to identify the most suitable factors in assessing the survival of AML patients. Here, six data mining algorithms including Decision Tree, Random Forrest, Logistic Regression, Naive Bayes, W-Bayes Net, and Gradient Boosted Tree (GBT) are employed for the detection model and implemented using the common data mining tool RapidMiner and open-source R package. To improve the predictive ability of our model, a set of features were selected by employing multiple feature selection methods. The accuracy of classification was obtained using 10-fold cross-validation for the various combinations of the feature selection methods and machine learning algorithms. The performance of the models was assessed by various measurement indexes including accuracy, kappa, sensitivity, specificity, positive predictive value, negative predictive value, and area under the ROC curve (AUC). Our results showed that GBT with an accuracy of 85.17%, AUC of 0.930, and the feature selection via the Relief algorithm has the best performance in predicting the survival rate of AML patients.",0,0
7929,"Cost-effectiveness of artificial intelligence monitoring for active tuberculosis treatment: A modeling study. Tuberculosis (TB) incidence in Los Angeles County, California, USA (5.7 per 100,000) is significantly higher than the U.S. national average (2.9 per 100,000). Directly observed therapy (DOT) is the preferred strategy for active TB treatment but requires substantial resources. We partnered with the Los Angeles County Department of Public Health (LACDPH) to evaluate the cost-effectiveness of AiCure, an artificial intelligence (AI) platform that allows for automated treatment monitoring.",0,0
7931,"PEDF, a pleiotropic WTC-LI biomarker: Machine learning biomarker identification and validation. Biomarkers predict World Trade Center-Lung Injury (WTC-LI); however, there remains unaddressed multicollinearity in our serum cytokines, chemokines, and high-throughput platform datasets used to phenotype WTC-disease. To address this concern, we used automated, machine-learning, high-dimensional data pruning, and validated identified biomarkers. The parent cohort consisted of male, never-smoking firefighters with WTC-LI (FEV1, %Pred< lower limit of normal (LLN); n = 100) and controls (n = 127) and had their biomarkers assessed. Cases and controls (n = 15/group) underwent untargeted metabolomics, then feature selection performed on metabolites, cytokines, chemokines, and clinical data. Cytokines, chemokines, and clinical biomarkers were validated in the non-overlapping parent-cohort via binary logistic regression with 5-fold cross validation. Random forests of metabolites (n = 580), clinical biomarkers (n = 5), and previously assayed cytokines, chemokines (n = 106) identified that the top 5% of biomarkers important to class separation included pigment epithelium-derived factor (PEDF), macrophage derived chemokine (MDC), systolic blood pressure, macrophage inflammatory protein-4 (MIP-4), growth-regulated oncogene protein (GRO), monocyte chemoattractant protein-1 (MCP-1), apolipoprotein-AII (Apo-AII), cell membrane metabolites (sphingolipids, phospholipids), and branched-chain amino acids. Validated models via confounder-adjusted (age on 9/11, BMI, exposure, and pre-9/11 FEV1, %Pred) binary logistic regression had AUCROC [0.90(0.84-0.96)]. Decreased PEDF and MIP-4, and increased Apo-AII were associated with increased odds of WTC-LI. Increased GRO, MCP-1, and simultaneously decreased MDC were associated with decreased odds of WTC-LI. In conclusion, automated data pruning identified novel WTC-LI biomarkers; performance was validated in an independent cohort. One biomarker-PEDF, an antiangiogenic agent-is a novel, predictive biomarker of particulate-matter-related lung disease. Other biomarkers-GRO, MCP-1, MDC, MIP-4-reveal immune cell involvement in WTC-LI pathogenesis. Findings of our automated biomarker identification warrant further investigation into these potential pharmacotherapy targets.",0,0
7932,"Sequence to Sequence ECG Cardiac Rhythm Classification using Convolutional Recurrent Neural Networks. This paper proposes a novel deep learning architecture involving combinations of Convolutional Neural Networks (CNN) layers and Recurrent neural networks (RNN) layers that can be used to perform segmentation and classification of 5 cardiac rhythms based on ECG recordings. The algorithm is developed in a sequence to sequence setting where the input is a sequence of five second ECG signal sliding windows and the output is a sequence of cardiac rhythm labels. The novel architecture processes as input both the spectrograms of the ECG signal as well as the heartbeats' signal waveform. Additionally, we are able to train the model in the presence of label noise. The model's performance and generalizability is verified on an external database different from the one we used to train. Experimental result shows this approach can achieve an average F1 scores of 0.89 (averaged across 5 classes). The proposed model also achieves comparable classification performance to existing state-of-the-art approach with considerably less number of training parameters.",0,0
7933,"Proximity of Cellular and Physiological Response Failures in Sepsis. Sepsis is a devastating multi-stage health condition with a high mortality rate. Its complexity, prevalence, and dependency of its outcomes on early detection have attracted substantial attention from data science and machine learning communities. Previous studies rely on individual cellular and physiological responses representing organ system failures to predict health outcomes or the onset of different sepsis stages. However, it is known that organ systems' failures and dynamics are not independent events. In this study, we identify the dependency patterns of significant proximate sepsis-related failures of cellular and physiological responses using data from 12,223 adult patients hospitalized between July 2013 and December 2015. The results show that proximate failures of cellular and physiological responses create better feature sets for outcome prediction than individual responses. Our findings reveal the few significant proximate failures that play the major roles in predicting patients' outcomes. This study's results can be simply translated into clinical practices and inform the prediction and improvement of patients' conditions and outcomes.",0,0
7934,"Respiratory Event Detection during Sleep Using Electrocardiogram and Respiratory Related Signals: Using Polysomnogram and Patch-Type Wearable Device Data. This paper presents an automatic algorithm for the detection of respiratory events in patients using electrocardiogram (ECG) and respiratory signals. The proposed method was developed using data of polysomnogram (PSG) and those recorded from a patch-type device. In total, data of 1,285 subjects were used for algorithm development and evaluation. The proposed method involved respiratory event detection and apnea-hypopnea index (AHI) estimation. Handcrafted features from the ECG and respiratory signals were applied to machine learning algorithms including linear discriminant analysis, quadratic discriminant analysis, random forest, multi-layer perceptron, and the support vector machine (SVM). High performance was demonstrated when using SVM, where the overall accuracy achieved was 83% and the Cohens kappa was 0.53 for the minute-by-minute respiratory event detection. The correlation coefficient between the reference AHI obtained using the PSG and estimated AHI as per the proposed method was 0.87. Furthermore, patient classification based on an AHI cutoff of 15 showed an accuracy of 87% and a Cohens kappa of 0.72. The proposed method increases performance result, as it records the ECG and respiratory signals simultaneously. Overall, it can be used to lower the development cost of commercial software owing to the use of open datasets.",0,0
7936,"RobustSleepNet: Transfer Learning for Automated Sleep Staging at Scale. Sleep disorder diagnosis relies on the analysis of polysomnography (PSG) records. As a preliminary step of this examination, sleep stages are systematically determined. In practice, sleep stage classification relies on the visual inspection of 30-second epochs of polysomnography signals. Numerous automatic approaches have been developed to replace this tedious and expensive task. Although these methods demonstrated better performance than human sleep experts on specific datasets, they remain largely unused in sleep clinics. The main reason is that each sleep clinic uses a specific PSG montage that most automatic approaches cannot handle out-of-the-box. Moreover, even when the PSG montage is compatible, publications have shown that automatic approaches perform poorly on unseen data with different demographics. To address these issues, we introduce RobustSleepNet, a deep learning model for automatic sleep stage classification able to handle arbitrary PSG montages. We trained and evaluated this model in a leave-one-out-dataset fashion on a large corpus of 8 heterogeneous sleep staging datasets to make it robust to demographic changes. When evaluated on an unseen dataset, RobustSleepNet reaches 97% of the F1 of a model explicitly trained on this dataset. Hence, RobustSleepNet unlocks the possibility to perform high-quality out-of-the-box automatic sleep staging with any clinical setup. We further show that finetuning RobustSleepNet, using a part of the unseen dataset, increases the F1 by 2% when compared to a model trained specifically for this dataset. Therefore, finetuning might be used to reach a state-of-the-art level of performance on a specific population.",0,0
7939,"Lab-on-Eyeglasses to Monitor Kidneys and Strengthen Vulnerable Populations in Pandemics: Machine Learning in Predicting Serum Creatinine Using Tear Creatinine. The serum creatinine level is commonly recognized as a measure of glomerular filtration rate (GFR) and is defined as an indicator of overall renal health. A typical procedure in determining kidney performance is venipuncture to obtain serum creatinine in the blood, which requires a skilled technician to perform on a laboratory basis and multiple clinical steps to acquire a meaningful result. Recently, wearable sensors have undergone immense development, especially for noninvasive health monitoring without a need for a blood sample. This article addresses a fiber-based sensing device selective for tear creatinine, which was fabricated using a copper-containing benzenedicarboxylate (BDC) metal-organic framework (MOF) bound with graphene oxide-Cu(II) and hybridized with Cu<sub>2</sub>O nanoparticles (NPs). Density functional theory (DFT) was employed to study the binding energies of creatinine toward the ternary hybrid materials that irreversibly occurred at pendant copper ions attached with the BDC segments. Electrochemical impedance spectroscopy (EIS) was utilized to probe the unique charge-transfer resistances of the derived sensing materials. The single-use modified sensor achieved 95.1% selectivity efficiency toward the determination of tear creatinine contents from 1.6 to 2400 Î¼M of 10 repeated measurements in the presence of interfering species of dopamine, urea, and uric acid. The machine learning with the supervised training estimated 83.3% algorithm accuracy to distinguish among low, moderate, and high normal serum creatinine by evaluating tear creatinine. With only one step of collecting tears, this lab-on-eyeglasses with disposable hybrid textile electrodes selective for tear creatinine may be greatly beneficial for point-of-care (POC) kidney monitoring for vulnerable populations remotely, especially during pandemics.",0,0
7946,"Facial recognition accuracy in photographs of Thai neonates with Down syndrome among physicians and the Face2Gene application. Down syndrome (DS) is typically recognizable in those who present with multiple dysmorphism, especially in regard to facial phenotypes. However, as the presentation of DS in neonates is less obvious, a phenotype-based presumptive diagnosis is more challenging. Recently, an artificial intelligence (AI) application, Face2Gene, was developed to help physicians recognize specific genetic syndromes by using two-dimensional facial photos. As of yet, there has not been any study comparing accuracy among physicians or applications. Our objective was to compare the facial recognition accuracy of DS in Thai neonates, using facial photographs, among physicians and the Face2Gene. Sixty-four Thai neonates at Thammasat University Hospital, with genetic testing and signed parental consent, were divided into a DS group (25) and non-DS group (39). Non-DS was further divided into unaffected (19) and those affected with other syndromes (20). Our results revealed physician accuracy (89%) was higher than the Face2Gene (81%); however, the application was higher in sensitivity (100%) than physicians (86%). While this application can serve as a helpful assistant in facilitating any genetic syndrome such as DS, to aid clinicians in recognizing DS facial features in neonates, it is not a replacement for well-trained doctors.",1,1
7948,"Classification of focal liver lesions in CT images using convolutional neural networks with lesion information augmented patches and synthetic data augmentation. We propose a deep learning method that classifies focal liver lesions (FLLs) into cysts, hemangiomas, and metastases from portal phase abdominal CT images. We propose a synthetic data augmentation process to alleviate the class imbalance and the Lesion INformation Augmented (LINA) patch to improve the learning efficiency.",0,0
7950,"Comparison of convolutional neural networks for detecting large vessel occlusion on computed tomography angiography. Artificial intelligence diagnosis and triage of large vessel occlusion may quicken clinical response for a subset of time-sensitive acute ischemic stroke patients, improving outcomes. Differences in architectural elements within data-driven convolutional neural network (CNN) models impact performance. Foreknowledge of effective model architectural elements for domain-specific problems can narrow the search for candidate models and inform strategic model design and adaptation to optimize performance on available data. Here, we study CNN architectures with a range of learnable parameters and which span the inclusion of architectural elements, such as parallel processing branches and residual connections with varying methods of recombining residual information.",0,0
7955,"Automatic Extraction of Lung Cancer Staging Information From Computed Tomography Reports: Deep Learning Approach. Lung cancer is the leading cause of cancer deaths worldwide. Clinical staging of lung cancer plays a crucial role in making treatment decisions and evaluating prognosis. However, in clinical practice, approximately one-half of the clinical stages of lung cancer patients are inconsistent with their pathological stages. As one of the most important diagnostic modalities for staging, chest computed tomography (CT) provides a wealth of information about cancer staging, but the free-text nature of the CT reports obstructs their computerization.",0,0
7965,"Deep learning to automate the labelling of head MRI datasets for computer vision applications. The purpose of this study was to build a deep learning model to derive labels from neuroradiology reports and assign these to the corresponding examinations, overcoming a bottleneck to computer vision model development.",0,0
7966,"Performance of automatic machine learning versus radiologists in the evaluation of endometrium on computed tomography. In this study, we developed radiomic models that utilize a combination of imaging features and clinical variables to distinguish endometrial cancer (EC) from normal endometrium on routine computed tomography (CT).",1,1
7973,"A machine learning framework to optimize optic nerve electrical stimulation for vision restoration. Optic nerve electrical stimulation is a promising technique to restore vision in blind subjects. Machine learning methods can be used to select effective stimulation protocols, but they require a model of the stimulated system to generate enough training data. Here, we use a convolutional neural network (CNN) as a model of the ventral visual stream. A genetic algorithm drives the activation of the units in a layer of the CNN representing a cortical region toward a desired pattern, by refining the activation imposed at a layer representing the optic nerve. To simulate the pattern of activation elicited by the sites of an electrode array, a simple point-source model was introduced and its optimization process was investigated for static and dynamic scenes. Psychophysical data confirm that our stimulation evolution framework produces results compatible with natural vision. Machine learning approaches could become a very powerful tool to optimize and personalize neuroprosthetic systems.",0,0
7979,"Machine learning identifies novel markers predicting functional decline in older adults. The ability to carry out instrumental activities of daily living, such as paying bills, remembering appointments and shopping alone decreases with age, yet there are remarkable individual differences in the rate of decline among older adults. Understanding variables associated with a decline in instrumental activities of daily living is critical to providing appropriate intervention to prolong independence. Prior research suggests that cognitive measures, neuroimaging and fluid-based biomarkers predict functional decline. However, <i>a priori</i> selection of variables can lead to the over-valuation of certain variables and exclusion of others that may be predictive. In this study, we used machine learning techniques to select a wide range of baseline variables that best predicted functional decline in two years in individuals from the Alzheimer's Disease Neuroimaging Initiative dataset. The sample included 398 individuals characterized as cognitively normal or mild cognitive impairment. Support vector machine classification algorithms were used to identify the most predictive modality from five different data modality types (demographics, structural MRI, fluorodeoxyglucose-PET, neurocognitive and genetic/fluid-based biomarkers). In addition, variable selection identified individual variables across all modalities that best predicted functional decline in a testing sample. Of the five modalities examined, neurocognitive measures demonstrated the best accuracy in predicting functional decline (accuracy = 74.2%; area under the curve = 0.77), followed by fluorodeoxyglucose-PET (accuracy = 70.8%; area under the curve = 0.66). The individual variables with the greatest discriminatory ability for predicting functional decline included partner report of language in the Everyday Cognition questionnaire, the ADAS13, and activity of the left angular gyrus using fluorodeoxyglucose-PET. These three variables collectively explained 32% of the total variance in functional decline. Taken together, the machine learning model identified novel biomarkers that may be involved in the processing, retrieval, and conceptual integration of semantic information and which predict functional decline two years after assessment. These findings may be used to explore the clinical utility of the Everyday Cognition as a non-invasive, cost and time effective tool to predict future functional decline.",0,0
7990,"Clinical Feature-Based Machine Learning Model for 1-Year Mortality Risk Prediction of ST-Segment Elevation Myocardial Infarction in Patients with Hyperuricemia: A Retrospective Study. Accurate risk assessment of high-risk patients is essential in clinical practice. However, there is no practical method to predict or monitor the prognosis of patients with ST-segment elevation myocardial infarction (STEMI) complicated by hyperuricemia. We aimed to evaluate the performance of different machine learning models for the prediction of 1-year mortality in STEMI patients with hyperuricemia. We compared five machine learning models (logistic regression, <i>k</i>-nearest neighbor, CatBoost, random forest, and XGBoost) with the traditional global (GRACE) risk score for acute coronary event registrations. We registered patients aged >18 years diagnosed with STEMI and hyperuricemia at the Affiliated Hospital of Zunyi Medical University between January 2016 and January 2020. Overall, 656 patients were enrolled (average age, 62.5 Â± 13.6â€‰years; 83.6%, male). All patients underwent emergency percutaneous coronary intervention. We evaluated the performance of five machine learning classifiers and the GRACE risk model in predicting 1-year mortality. The area under the curve (AUC) of the six models, including the GRACE risk model, ranged from 0.75 to 0.88. Among all the models, CatBoost had the highest predictive accuracy (0.89), AUC (0.87), precision (0.84), and F1 value (0.44). After hybrid sampling technique optimization, CatBoost had the highest accuracy (0.96), AUC (0.99), precision (0.95), and F1 value (0.97). Machine learning algorithms, especially the CatBoost model, can accurately predict the mortality associated with STEMI complicated by hyperuricemia after a 1-year follow-up.",0,0
7994,"Development of a system to support warfarin dose decisions using deep neural networks. The first aim of this study was to develop a prothrombin time international normalized ratio (PT INR) prediction model. The second aim was to develop a warfarin maintenance dose decision support system as a precise warfarin dosing platform. Data of 19,719 inpatients from three institutions was analyzed. The PT INR prediction algorithm included dense and recurrent neural networks, and was designed to predict the 5th-day PT INR from data of days 1-4. Data from patients in one hospital (nâ€‰=â€‰22,314) was used to train the algorithm which was tested with the datasets from the other two hospitals (nâ€‰=â€‰12,673). The performance of 5th-day PT INR prediction was compared with 2000 predictions made by 10 expert physicians. A generator of individualized warfarin dose-PT INR tables which simulated the repeated administration of varying doses of warfarin was developed based on the prediction model. The algorithm outperformed humans with accuracy terms of withinâ€‰Â±â€‰0.3 of the actual value (machine learning algorithm: 10,650/12,673 cases (84.0%), expert physicians: 1647/2000 cases (81.9%), Pâ€‰=â€‰0.014). In the individualized warfarin dose-PT INR tables generated by the algorithm, the 8th-day PT INR predictions were within 0.3 of actual value in 450/842 cases (53.4%). An artificial intelligence-based warfarin dosing algorithm using a recurrent neural network outperformed expert physicians in predicting future PT INRs. An individualized warfarin dose-PT INR table generator which was constructed based on this algorithm was acceptable.",1,1
8003,"Application of machine learning to predict the outcome of pediatric traumatic brain injury. Traumatic brain injury (TBI) generally causes mortality and disability, particularly in children. Machine learning (ML) is a computer algorithm, applied as a clinical prediction tool. The present study aims to assess the predictability of ML for the functional outcomes of pediatric TBI.",0,0
8004,"Exploring polypharmacy with artificial intelligence: data analysis protocol. Polypharmacy is common among older adults and it represents a public health concern, due to the negative health impacts potentially associated with the use of several medications. However, the large number of medication combinations and sequences of use makes it complicated for traditional statistical methods to predict which therapy is genuinely associated with health outcomes. The project aims to use artificial intelligence (AI) to determine the quality of polypharmacy among older adults with chronic diseases in the province of QuÃ©bec, Canada.",0,0
8007,"A deep learning method for single-trial EEG classification in RSVP task based on spatiotemporal features of ERPs. <i>Objective</i>. Single-trial electroencephalography (EEG) classification is of great importance in the rapid serial visual presentation (RSVP) task. Convolutional neural networks (CNNs), as one of the mainstream deep learning methods, have been proven to be effective in extracting RSVP EEG features. However, most existing CNN models for EEG classification do not consider the phase-locked characteristic of event-related potential (ERP) components very well in the architecture design. Here, we propose a novel CNN model to make better use of the phase-locked characteristic to extract spatiotemporal features for single-trial RSVP EEG classification. Based on the phase-locked characteristic, the spatial distributions of the main ERP component in different periods can be learned separately.<i>Approach.</i>In this work, we propose a novel CNN model to achieve superior performance on single-trial RSVP EEG classification. We introduce the combination of the standard convolutional layer, the permute layer and the depthwise convolutional layer to separately operate the spatial convolution in different periods, which more fully utilizes the phase-locked characteristic of ERPs for classification. We compare our model with several traditional and deep-learning methods in the classification performance. Moreover, we use spatial topography and saliency map to visually analyze the ERP features extracted by our model.<i>Main results</i>. The results show that our model obtains better classification performance than those of reference methods. The spatial topographies of each subject exhibit the typical ERP spatial distribution in different time periods. And the saliency map of each subject illustrates the discriminant electrodes and the meaningful temporal features.<i>Significance</i>. Our model is designed with better consideration of the phase-locked ERP characteristic and reaches excellent performance on single-trial RSVP EEG classification.",0,0
8013,"Pixel-wise body composition prediction with a multi-task conditional generative adversarial network. The analysis of human body composition plays a critical role in health management and disease prevention. However, current medical technologies to accurately assess body composition such as dual energy X-ray absorptiometry, computed tomography, and magnetic resonance imaging have the disadvantages of prohibitive cost or ionizing radiation. Recently, body shape based techniques using body scanners and depth cameras, have brought new opportunities for improving body composition estimation by intelligently analyzing body shape descriptors. In this paper, we present a multi-task deep neural network method utilizing a conditional generative adversarial network to predict the pixel level body composition using only 3D body surfaces. The proposed method can predict 2D subcutaneous and visceral fat maps in a single network with a high accuracy. We further introduce an interpreted patch discriminator which optimizes the texture accuracy of the 2D fat maps. The validity and effectiveness of our new method are demonstrated experimentally on TCIA and LiTS datasets. Our proposed approach outperforms competitive methods by at least 41.3% for the whole body fat percentage, 33.1% for the subcutaneous and visceral fat percentage, and 4.1% for the regional fat predictions.",0,0
8015,Can artificial intelligence predict glaucomatous visual field progression?: A spatial-ordinal convolutional neural network model. To develop an artificial neural network model incorporating both spatial and ordinal approaches to predict glaucomatous visual field (VF) progression.,0,0
8017,"Deep learning neural networks to differentiate Stafne's bone cavity from pathological radiolucent lesions of the mandible in heterogeneous panoramic radiography. This study aimed to develop a high-performance deep learning algorithm to differentiate Stafne's bone cavity (SBC) from cysts and tumors of the jaw based on images acquired from various panoramic radiographic systems. Data sets included 176 Stafne's bone cavities and 282 odontogenic cysts and tumors of the mandible (98 dentigerous cysts, 91 odontogenic keratocysts, and 93 ameloblastomas) that required surgical removal. Panoramic radiographs were obtained using three different imaging systems. The trained model showed 99.25% accuracy, 98.08% sensitivity, and 100% specificity for SBC classification and resulted in one misclassified SBC case. The algorithm was approved to recognize the typical imaging features of SBC in panoramic radiography regardless of the imaging system when traced back with Grad-Cam and Guided Grad-Cam methods. The deep learning model for SBC differentiating from odontogenic cysts and tumors showed high performance with images obtained from multiple panoramic systems. The present algorithm is expected to be a useful tool for clinicians, as it diagnoses SBCs in panoramic radiography to prevent unnecessary examinations for patients. Additionally, it would provide support for clinicians to determine further examinations or referrals to surgeons for cases where even experts are unsure of diagnosis using panoramic radiography alone.",0,0
8024,"Continuous Gait Phase Estimation Using LSTM for Robotic Transfemoral Prosthesis Across Walking Speeds. User gait phase estimation plays a key role for the seamless control of the lower-limb robotic assistive devices (e.g., exoskeletons or prostheses) during ambulation. To achieve this, several studies have attempted to estimate the gait phase using a thigh or shank angle. However, their estimation resulted in some deviation from the actual walking and varied across the walking speeds. In this study, we investigated the different setups using for the machine learning approach to obtain more accurate and consistent gait phase estimation for the robotic transfemoral prosthesis over different walking speeds. Considering the transfemoral prosthetic application, we proposed two different sensor setups: i) the angular positions and velocities of both thigh and torso (S1) and ii) the angular positions and velocities of both thigh and torso, and heel force data (S2). The proposed setups and method are experimentally evaluated with three healthy young subjects at four different walking speeds: 0.5, 1.0, 1.5, and 2.0 m/s. Both results showed robust and accurate gait phase estimation with respect to the ground truth (loss value of S1: 4.54e-03 Vs. S2: 4.70e-03). S1 had the advantage of a simple equipment setup using only two IMUs, while S2 had the advantage of estimating more accurate heel-strikes than S1 by using additional heel force data. The choice between the two sensor setups can depend on the researchers' preference in consideration of the device setup or the focus of the interest.",0,0
8028,"Caries and Restoration Detection Using Bitewing Film Based on Transfer Learning with CNNs. Caries is a dental disease caused by bacterial infection. If the cause of the caries is detected early, the treatment will be relatively easy, which in turn prevents caries from spreading. The current common procedure of dentists is to first perform radiographic examination on the patient and mark the lesions manually. However, the work of judging lesions and markings requires professional experience and is very time-consuming and repetitive. Taking advantage of the rapid development of artificial intelligence imaging research and technical methods will help dentists make accurate markings and improve medical treatments. It can also shorten the judgment time of professionals. In addition to the use of Gaussian high-pass filter and Otsu's threshold image enhancement technology, this research solves the problem that the original cutting technology cannot extract certain single teeth, and it proposes a caries and lesions area analysis model based on convolutional neural networks (CNN), which can identify caries and restorations from the bitewing images. Moreover, it provides dentists with more accurate objective judgment data to achieve the purpose of automatic diagnosis and treatment planning as a technology for assisting precision medicine. A standardized database established following a defined set of steps is also proposed in this study. There are three main steps to generate the image of a single tooth from a bitewing image, which can increase the accuracy of the analysis model. The steps include (1) preprocessing of the dental image to obtain a high-quality binarization, (2) a dental image cropping procedure to obtain individually separated tooth samples, and (3) a dental image masking step which masks the fine broken teeth from the sample and enhances the quality of the training. Among the current four common neural networks, namely, AlexNet, GoogleNet, Vgg19, and ResNet50, experimental results show that the proposed AlexNet model in this study for restoration and caries judgments has an accuracy as high as 95.56% and 90.30%, respectively. These are promising results that lead to the possibility of developing an automatic judgment method of bitewing film.",0,0
8049,"Deep-Learning-Driven Full-Waveform Inversion for Ultrasound Breast Imaging. Ultrasound breast imaging is a promising alternative to conventional mammography because it does not expose women to harmful ionising radiation and it can successfully image dense breast tissue. However, conventional ultrasound imaging only provides morphological information with limited diagnostic value. Ultrasound computed tomography (USCT) uses energy in both transmission and reflection when imaging the breast to provide more diagnostically relevant quantitative tissue properties, but it is often based on time-of-flight tomography or similar ray approximations of the wave equation, resulting in reconstructed images with low resolution. Full-waveform inversion (FWI) is based on a more accurate approximation of wave-propagation phenomena and can consequently produce very high resolution images using frequencies below 1 megahertz. These low frequencies, however, are not available in most USCT acquisition systems, as they use transducers with central frequencies well above those required in FWI. To circumvent this problem, we designed, trained, and implemented a two-dimensional convolutional neural network to artificially generate missing low frequencies in USCT data. Our results show that FWI reconstructions using experiment data after the application of the proposed method successfully converged, showing good agreement with X-ray CT and reflection ultrasound-tomography images.",0,0
8058,"A Comparison of Three Neural Network Approaches for Estimating Joint Angles and Moments from Inertial Measurement Units. The application of artificial intelligence techniques to wearable sensor data may facilitate accurate analysis outside of controlled laboratory settings-the holy grail for gait clinicians and sports scientists looking to bridge the lab to field divide. Using these techniques, parameters that are difficult to directly measure in-the-wild, may be predicted using surrogate lower resolution inputs. One example is the prediction of joint kinematics and kinetics based on inputs from inertial measurement unit (IMU) sensors. Despite increased research, there is a paucity of information examining the most suitable artificial neural network (ANN) for predicting gait kinematics and kinetics from IMUs. This paper compares the performance of three commonly employed ANNs used to predict gait kinematics and kinetics: multilayer perceptron (MLP); long short-term memory (LSTM); and convolutional neural networks (CNN). Overall high correlations between ground truth and predicted kinematic and kinetic data were found across all investigated ANNs. However, the optimal ANN should be based on the prediction task and the intended use-case application. For the prediction of joint angles, CNNs appear favourable, however these ANNs do not show an advantage over an MLP network for the prediction of joint moments. If real-time joint angle and joint moment prediction is desirable an LSTM network should be utilised.",0,0
8061,"Predicting Antituberculosis Drug-Induced Liver Injury Using an Interpretable Machine Learning Method: Model Development and Validation Study. Tuberculosis (TB) is a pandemic, being one of the top 10 causes of death and the main cause of death from a single source of infection. Drug-induced liver injury (DILI) is the most common and serious side effect during the treatment of TB.",0,0
8064,"Multivariate Machine Learning Analyses in Identification of Major Depressive Disorder Using Resting-State Functional Connectivity: A Multicentral Study. Diagnosis of major depressive disorder (MDD) using resting-state functional connectivity (rs-FC) data faces many challenges, such as the high dimensionality, small samples, and individual difference. To assess the clinical value of rs-FC in MDD and identify the potential rs-FC machine learning (ML) model for the individualized diagnosis of MDD, based on the rs-FC data, a progressive three-step ML analysis was performed, including six different ML algorithms and two dimension reduction methods, to investigate the classification performance of ML model in a multicentral, large sample dataset [1021 MDD patients and 1100 normal controls (NCs)]. Furthermore, the linear least-squares fitted regression model was used to assess the relationships between rs-FC features and the severity of clinical symptoms in MDD patients. Among used ML methods, the rs-FC model constructed by the eXtreme Gradient Boosting (XGBoost) method showed the optimal classification performance for distinguishing MDD patients from NCs at the individual level (accuracy = 0.728, sensitivity = 0.720, specificity = 0.739, area under the curve = 0.831). Meanwhile, identified rs-FCs by the XGBoost model were primarily distributed within and between the default mode network, limbic network, and visual network. More importantly, the 17 item individual Hamilton Depression Scale scores of MDD patients can be accurately predicted using rs-FC features identified by the XGBoost model (adjusted <i>R</i><sup>2</sup> = 0.180, root mean squared error = 0.946). The XGBoost model using rs-FCs showed the optimal classification performance between MDD patients and HCs, with the good generalization and neuroscientifical interpretability.",0,0
8072,"Machine Learning Methods for Fear Classification Based on Physiological Features. This paper focuses on the binary classification of the emotion of fear, based on the physiological data and subjective responses stored in the DEAP dataset. We performed a mapping between the discrete and dimensional emotional information considering the participants' ratings and extracted a substantial set of 40 types of features from the physiological data, which represented the input to various machine learning algorithms-Decision Trees, k-Nearest Neighbors, Support Vector Machine and artificial networks-accompanied by dimensionality reduction, feature selection and the tuning of the most relevant hyperparameters, boosting classification accuracy. The methodology we approached included tackling different situations, such as resolving the problem of having an imbalanced dataset through data augmentation, reducing overfitting, computing various metrics in order to obtain the most reliable classification scores and applying the Local Interpretable Model-Agnostic Explanations method for interpretation and for explaining predictions in a human-understandable manner. The results show that fear can be predicted very well (accuracies ranging from 91.7% using Gradient Boosting Trees to 93.5% using dimensionality reduction and Support Vector Machine) by extracting the most relevant features from the physiological data and by searching for the best parameters which maximize the machine learning algorithms' classification scores.",0,0
8073,"DeepRePath: Identifying the Prognostic Features of Early-Stage Lung Adenocarcinoma Using Multi-Scale Pathology Images and Deep Convolutional Neural Networks. The prognosis of patients with lung adenocarcinoma (LUAD), especially early-stage LUAD, is dependent on clinicopathological features. However, its predictive utility is limited. In this study, we developed and trained a DeepRePath model based on a deep convolutional neural network (CNN) using multi-scale pathology images to predict the prognosis of patients with early-stage LUAD. DeepRePath was pre-trained with 1067 hematoxylin and eosin-stained whole-slide images of LUAD from the Cancer Genome Atlas. DeepRePath was further trained and validated using two separate CNNs and multi-scale pathology images of 393 resected lung cancer specimens from patients with stage I and II LUAD. Of the 393 patients, 95 patients developed recurrence after surgical resection. The DeepRePath model showed average area under the curve (AUC) scores of 0.77 and 0.76 in cohort I and cohort II (external validation set), respectively. Owing to low performance, DeepRePath cannot be used as an automated tool in a clinical setting. When gradient-weighted class activation mapping was used, DeepRePath indicated the association between atypical nuclei, discohesive tumor cells, and tumor necrosis in pathology images showing recurrence. Despite the limitations associated with a relatively small number of patients, the DeepRePath model based on CNNs with transfer learning could predict recurrence after the curative resection of early-stage LUAD using multi-scale pathology images.",0,0
8074,"Development of a Deep-Learning Pipeline to Recognize and Characterize Macrophages in Colo-Rectal Liver Metastasis. Quantitative analysis of Tumor Microenvironment (TME) provides prognostic and predictive information in several human cancers but, with few exceptions, it is not performed in daily clinical practice since it is extremely time-consuming. We recently showed that the morphology of Tumor Associated Macrophages (TAMs) correlates with outcome in patients with Colo-Rectal Liver Metastases (CLM). However, as for other TME components, recognizing and characterizing hundreds of TAMs in a single histopathological slide is unfeasible. To fasten this process, we explored a deep-learning based solution. We tested three Convolutional Neural Networks (CNNs), namely UNet, SegNet and DeepLab-v3, with three different segmentation strategies, semantic segmentation, pixel penalties and instance segmentation. The different experiments are compared according to the Intersection over Union (IoU), a metric describing the similarity between what CNN predicts as TAM and the ground truth, and the Symmetric Best Dice (SBD), which indicates the ability of CNN to separate different TAMs. UNet and SegNet showed intrinsic limitations in discriminating single TAMs (highest SBD 61.34Â±2.21), whereas DeepLab-v3 accurately recognized TAMs from the background (IoU 89.13Â±3.85) and separated different TAMs (SBD 79.00Â±3.72). This deep-learning pipeline to recognize TAMs in digital slides will allow the characterization of TAM-related metrics in the daily clinical practice, allowing the implementation of prognostic tools.",0,0
8075,"Analysis of Periodontal Conditions in the Provinces of Vietnam: Results From the National Dental Survey. Nationwide dental health surveys are crucial for providing essential information on dental health and dental condition-related problems in the community. However, the relationship between periodontal conditions and sociodemographic data has not been well investigated in Vietnam. With data from the National Oral Health Survey in 2019, we performed several machine learning methods on this dataset to investigate the impacts of sociodemographic features on gingival bleeding, periodontal pockets, and Community Periodontal Index. From the experiments, LightGBM produced a maximum AUC (area under the curve) value of 0.744. The other models in descending order were logistic regression (0.705), logiboost (0.704), and random forest (0.684). All methods resulted in significantly high overall accuracies, all exceeding 90%. The results show that the gradient boosting model can predict well the relationship between periodontal conditions and sociodemographic data. The investigated model also reveals that the geographic region has the most significant influence on dental health, while the consumption of sweet foods/drinks is the second most crucial. These findings advocate for a region-specific approach for the dental care program and the implementation of a sugar-risk food reduction program.",0,0
8076,Prediction of Neurological Outcomes in Out-of-hospital Cardiac Arrest Survivors Immediately after Return of Spontaneous Circulation: Ensemble Technique with Four Machine Learning Models. We performed this study to establish a prediction model for 1-year neurological outcomes in out-of-hospital cardiac arrest (OHCA) patients who achieved return of spontaneous circulation (ROSC) immediately after ROSC using machine learning methods.,0,0
8078,Improving detection accuracy of perfusion defect in standard dose SPECT-myocardial perfusion imaging by deep-learning denoising. We previously developed a deep-learning (DL) network for image denoising in SPECT-myocardial perfusion imaging (MPI). Here we investigate whether this DL network can be utilized for improving detection of perfusion defects in standard-dose clinical acquisitions.,0,0
8089,"Accurate prediction of breast cancer survival through coherent voting networks with gene expression profiling. For a patient affected by breast cancer, after tumor removal, it is necessary to decide which adjuvant therapy is able to prevent tumor relapse and formation of metastases. A prediction of the outcome of adjuvant therapy tailored for the patient is hard, due to the heterogeneous nature of the disease. We devised a methodology for predicting 5-years survival based on the new machine learning paradigm of coherent voting networks, with improved accuracy over state-of-the-art prediction methods. The 'coherent voting communities' metaphor provides a certificate justifying the survival prediction for an individual patient, thus facilitating its acceptability in practice, in the vein of explainable Artificial Intelligence. The method we propose is quite flexible and applicable to other types of cancer.",0,0
8090,"An integrated machine learning framework for a discriminative analysis of schizophrenia using multi-biological data. Finding effective and objective biomarkers to inform the diagnosis of schizophrenia is of great importance yet remains challenging. Relatively little work has been conducted on multi-biological data for the diagnosis of schizophrenia. In this cross-sectional study, we extracted multiple features from three types of biological data, including gut microbiota data, blood data, and electroencephalogram data. Then, an integrated framework of machine learning consisting of five classifiers, three feature selection algorithms, and four cross validation methods was used to discriminate patients with schizophrenia from healthy controls. Our results show that the support vector machine classifier without feature selection using the input features of multi-biological data achieved the best performance, with an accuracy of 91.7% and an AUC of 96.5% (pâ€‰<â€‰0.05). These results indicate that multi-biological data showed better discriminative capacity for patients with schizophrenia than single biological data. The top 5% discriminative features selected from the optimal model include the gut microbiota features (Lactobacillus, Haemophilus, and Prevotella), the blood features (superoxide dismutase level, monocyte-lymphocyte ratio, and neutrophil count), and the electroencephalogram features (nodal local efficiency, nodal efficiency, and nodal shortest path length in the temporal and frontal-parietal brain areas). The proposed integrated framework may be helpful for understanding the pathophysiology of schizophrenia and developing biomarkers for schizophrenia using multi-biological data.",0,0
8092,"Deep learning for abdominal ultrasound: A computer-aided diagnostic system for the severity of fatty liver. The prevalence of nonalcoholic fatty liver disease is increasing over time worldwide, with similar trends to those of diabetes and obesity. A liver biopsy, the gold standard of diagnosis, is not favored due to its invasiveness. Meanwhile, noninvasive evaluation methods of fatty liver are still either very expensive or demonstrate poor diagnostic performances, thus, limiting their applications. We developed neural network-based models to assess fatty liver and classify the severity using B-mode ultrasound (US) images.",0,0
8095,"DNA methylation-based prediction of response to immune checkpoint inhibition in metastatic melanoma. Therapies based on targeting immune checkpoints have revolutionized the treatment of metastatic melanoma in recent years. Still, biomarkers predicting long-term therapy responses are lacking.",0,0
8097,Radiogenomic and Deep Learning Network Approaches to Predict <i>KRAS</i> Mutation from Radiotherapy Plan CT. We aimed to investigate the role of radiogenomic and deep learning approaches in predicting the KRAS mutation status of a tumor using radiotherapy planning computed tomography (CT) images in patients with locally advanced rectal cancer.,0,0
8109,"A Machine Learning Approach for Investigating Delirium as a Multifactorial Syndrome. Delirium is a psycho-organic syndrome common in hospitalized patients, especially the elderly, and is associated with poor clinical outcomes. This study aims to identify the predictors that are mostly associated with the risk of delirium episodes using a machine learning technique (MLT). A random forest (RF) algorithm was used to evaluate the association between the subject's characteristics and the 4AT (the 4 A's test) score screening tool for delirium. RF algorithm was implemented using information based on demographic characteristics, comorbidities, drugs and procedures. Of the 78 patients enrolled in the study, 49 (63%) were at risk for delirium, 32 (41%) had at least one episode of delirium during the hospitalization (38% in orthopedics and 31% both in internal medicine and in the geriatric ward). The model explained 75.8% of the variability of the 4AT score with a root mean squared error of 3.29. Higher age, the presence of dementia, physical restraint, diabetes and a lower degree are the variables associated with an increase of the 4AT score. Random forest is a valid method for investigating the patients' characteristics associated with delirium onset also in small case-series. The use of this model may allow for early detection of delirium onset to plan the proper adjustment in healthcare assistance.",0,0
8116,"A Computational Tumor-Infiltrating Lymphocyte Assessment Method Comparable with Visual Reporting Guidelines for Triple-Negative Breast Cancer. Tumor-infiltrating lymphocytes (TILs) are clinically significant in triple-negative breast cancer (TNBC). Although a standardized methodology for visual TILs assessment (VTA) exists, it has several inherent limitations. We established a deep learning-based computational TIL assessment (CTA) method broadly following VTA guideline and compared it with VTA for TNBC to determine the prognostic value of the CTA and a reasonable CTA workflow for clinical practice.",1,1
8117,"A machine learning-based risk stratification model for ventricular tachycardia and heart failure in hypertrophic cardiomyopathy. Machine learning (ML) and artificial intelligence are emerging as important components of precision medicine that enhance diagnosis and risk stratification. Risk stratification tools for hypertrophic cardiomyopathy (HCM) exist, but they are based on traditional statistical methods. The aim was to develop a novel machine learning risk stratification tool for the prediction of 5-year risk in HCM. The goal was to determine if its predictive accuracy is higher than the accuracy of the state-of-the-art tools.",0,0
8123,"BrcaSeg: A Deep Learning Approach for Tissue Quantification and Genomic Correlations of Histopathological Images. Epithelial and stromal tissues are components of the tumor microenvironment and play a major role in tumor initiation and progression. Distinguishing stroma from epithelial tissues is critically important for spatial characterization of the tumor microenvironment. We propose BrcaSeg, an image analysis pipeline based on a convolutional neural network (CNN) model to classify epithelial and stromal regions in whole-slide hematoxylin and eosin (H&E) stained histopathological images. The CNN model was trained using well-annotated breast cancer tissue microarrays and validated with images from The Cancer Genome Atlas (TCGA) Program. BrcaSeg achieves a classification accuracy of 91.02%, which outperforms other state-of-the-art methods. Using this model, we generated pixel-level epithelial/stromal tissue maps for 1000 TCGA breast cancer slide images that are paired with gene expression data. We subsequently estimated the epithelial and stromal ratios and performed correlation analysis to model the relationship between gene expression and tissue ratios. Gene Ontology (GO) enrichment analyses of genes that were highly correlated with tissue ratios suggest that the same tissue was associated with similar biological processes in different breast cancer subtypes, whereas each subtype also had its own idiosyncratic biological processes governing the development of these tissues. Taken all together, our approach can lead to new insights in exploring relationships between image-based phenotypes and their underlying genomic events and biological processes for all types of solid tumors. BrcaSeg can be accessed at https://github.com/Serian1992/ImgBio.",0,0
8124,"Generalizability of heterogeneous treatment effects based on causal forests applied to two randomized clinical trials of intensive glycemic control. Purpose Machine learning is an attractive tool for identifying heterogeneous treatment effects (HTE) of interventions but generalizability of machine learning derived HTE remains unclear. We examined generalizability of HTE detected using causal forests in two similarly designed randomized trials in type II diabetes patients. Methods We evaluated published HTE of intensive versus standard glycemic control on all-cause mortality from the Action to Control Cardiovascular Risk in Diabetes study (ACCORD) in a second trial, the Veterans Affairs Diabetes Trial (VADT). We then applied causal forests to VADT, ACCORD, and pooled data from both studies and compared variable importance and subgroup effects across samples. Results HTE in ACCORD did not replicate in similar subgroups in VADT, but variable importance was correlated between VADT and ACCORD (Kendall's tau-b 0.75). Applying causal forests to pooled individual-level data yielded seven subgroups with similar HTE across both studies, ranging from risk difference of all-cause mortality of -3.9% (95% CI -7.0, -0.8) to 4.7% (95% CI 1.8, 7.5). Conclusions Machine learning detection of HTE subgroups from randomized trials may not generalize across study samples even when variable importance is correlated. Pooling individual-level data may overcome differences in study populations and/or differences in interventions that limit HTE generalizability.",0,0
8132,Fully automated waist circumference measurement on abdominal CT: Comparison with manual measurements and potential value for identifying overweight and obesity as an adjunct output of CT scan. Waist circumference (WC) is a widely accepted anthropometric parameter of central obesity. We investigated a fully automated body segmentation algorithm for measuring WC on abdominal computed tomography (CT) in comparison to manual WC measurements (WC-manual) and evaluated the performance of CT-measured WC for identifying overweight/obesity.,1,1
8137,"Task-induced Pyramid and Attention GAN for Multimodal Brain Image Imputation and Classification in Alzheimers disease. With the advance of medical imaging technologies, multimodal images such as magnetic resonance images (MRI) and positron emission tomography (PET) can capture subtle structural and functional changes of brain, facilating the diagnosis of brain diseases such as Alzheimers disease (AD). In practice, multimodal images may be incomplete since PET is often missing due to high financial cost or availability. Most of existing methods simply excluded subjects with missing data, which unfortunately reduced sample size. In addition, how to extract and combine multimodal features is still challenging. To address these problems, we propose a deep learning framework to integrate a task-induced pyramid and attention generative adversarial network (TPA-GAN) with a pathwise transfer dense convolution network (PT-DCN) for imputation and also classification of multimodal brain images. First, we propose a TPA-GAN to integrate pyramid convolution and attention module as well as disease classification task into GAN for generating the missing PET data with their MRI. Then, with the imputed multimodal brain images, we build a dense convolution network with pathwise transfer blocks to gradually learn and combine multimodal features for final disease classification. Experiments are performed on ADNI-1 and ADNI-2 datasets to evaluate our proposed method, achiving superior performance in image imputation and brain disease diagnosis compared to state-of-the-art methods.",0,0
8142,"Deep Learning Analysis in Prediction of COVID-19 Infection Status Using Chest CT Scan Features. Background and aims Non-contrast chest computed tomography (CT) scanning is one of the important tools for evaluating of lung lesions. The aim of this study was to use a deep learning approach for predicting the outcome of patients with COVID-19 into two groups of critical and non-critical according to their CT features. Methods This was carried out as a retrospective study from March to April 2020 in Baqiyatallah Hospital, Tehran, Iran. From total of 1078 patients with COVID-19 pneumonia who underwent chest CT, 169 were critical cases and 909 were non-critical. Deep learning neural networks were used to classify samples into critical or non-critical ones according to the chest CT results. Results The best accuracy of prediction was seen by the presence of diffuse opacities and lesion distribution (both=0.91, 95% CI: 0.83-0.99). The largest sensitivity was achieved using lesion distribution (0.74, 95% CI: 0.55-0.93), and the largest specificity was for presence of diffuse opacities (0.95, 95% CI: 0.9-1). The total model showed an accuracy of 0.89 (95% CI: 0.79-0.99), and the corresponding sensitivity and specificity were 0.71 (95% CI: 0.51-0.91) and 0.93 (95% CI: 0.87-0.96), respectively. Conclusions The results showed that CT scan can accurately classify and predict critical and non-critical COVID-19 cases.",0,0
8143,"Prediction of COVID-19 deterioration in high-risk patients at diagnosis: an early warning score for advanced COVID-19 developed by machine learning. While more advanced COVID-19 necessitates medical interventions and hospitalization, patients with mild COVID-19 do not require this. Identifying patients at risk of progressing to advanced COVID-19 might guide treatment decisions, particularly for better prioritizing patients in need for hospitalization.",0,0
8144,"Can AI-assisted microscope facilitate breast HER2 interpretation? A multi-institutional ring study. The level of human epidermal growth factor receptor-2 (HER2) protein and gene expression in breast cancer is an essential factor in judging the prognosis of breast cancer patients. Several investigations have shown high intraobserver and interobserver variability in the evaluation of HER2 staining by visual examination. In this study, we aim to propose an artificial intelligence (AI)-assisted microscope to improve the HER2 assessment accuracy and reliability. Our AI-assisted microscope was equipped with a conventional microscope with a cell-level classification-based HER2 scoring algorithm and an augmented reality module to enable pathologists to obtain AI results in real time. We organized a three-round ring study of 50 infiltrating duct carcinoma not otherwise specified (NOS) cases without neoadjuvant treatment, and recruited 33 pathologists from 6 hospitals. In the first ring study (RS1), the pathologists read 50 HER2 whole-slide images (WSIs) through an online system. After a 2-week washout period, they read the HER2 slides using a conventional microscope in RS2. After another 2-week washout period, the pathologists used our AI microscope for assisted interpretation in RS3. The consistency and accuracy of HER2 assessment by the AI-assisted microscope were significantly improved (pâ€‰<â€‰0.001) over those obtained using a conventional microscope and online WSI. Specifically, our AI-assisted microscope improved the precision of immunohistochemistry (IHC) 3â€‰+â€‰and 2â€‰+â€‰scoring while ensuring the recall of fluorescent in situ hybridization (FISH)-positive results in IHC 2â€‰+â€‰. Also, the average acceptance rate of AI for all pathologists was 0.90, demonstrating that the pathologists agreed with most AI scoring results.",1,1
8146,"Towards automatic diagnosis of rheumatic heart disease on echocardiographic exams through video-based deep learning. Rheumatic heart disease (RHD) affects an estimated 39 million people worldwide and is the most common acquired heart disease in children and young adults. Echocardiograms are the gold standard for diagnosis of RHD, but there is a shortage of skilled experts to allow widespread screenings for early detection and prevention of the disease progress. We propose an automated RHD diagnosis system that can help bridge this gap.",0,0
8147,Machine learning for initial insulin estimation in hospitalized patients. The study sought to determine whether machine learning can predict initial inpatient total daily dose (TDD) of insulin from electronic health records more accurately than existing guideline-based dosing recommendations.,0,0
8156,"Time-Frequency Decomposition of Scalp Electroencephalograms Improves Deep Learning-Based Epilepsy Diagnosis. Epilepsy diagnosis based on Interictal Epileptiform Discharges (IEDs) in scalp electroencephalograms (EEGs) is laborious and often subjective. Therefore, it is necessary to build an effective IED detector and an automatic method to classify IED-free versus IED EEGs. In this study, we evaluate features that may provide reliable IED detection and EEG classification. Specifically, we investigate the IED detector based on convolutional neural network (ConvNet) with different input features (temporal, spectral, and wavelet features). We explore different ConvNet architectures and types, including 1D (one-dimensional) ConvNet, 2D (two-dimensional) ConvNet, and noise injection at various layers. We evaluate the EEG classification performance on five independent datasets. The 1D ConvNet with preprocessed full-frequency EEG signal and frequency bands (delta, theta, alpha, beta) with Gaussian additive noise at the output layer achieved the best IED detection results with a false detection rate of 0.23/min at 90% sensitivity. The EEG classification system obtained a mean EEG classification Leave-One-Institution-Out (LOIO) cross-validation (CV) balanced accuracy (BAC) of 78.1% (area under the curve (AUC) of 0.839) and Leave-One-Subject-Out (LOSO) CV BAC of 79.5% (AUC of 0.856). Since the proposed classification system only takes a few seconds to analyze a 30-min routine EEG, it may help in reducing the human effort required for epilepsy diagnosis.",0,0
8161,"A Supervised Image Registration Approach for Late Gadolinium Enhanced MRI and Cine Cardiac MRI Using Convolutional Neural Networks. Late gadolinium enhanced (LGE) cardiac magnetic resonance (CMR) imaging is the current gold standard for assessing myocardium viability for patients diagnosed with myocardial infarction, myocarditis or cardiomyopathy. This imaging method enables the identification and quantification of myocardial tissue regions that appear hyper-enhanced. However, the delineation of the myocardium is hampered by the reduced contrast between the myocardium and the left ventricle (LV) blood-pool due to the gadolinium-based contrast agent. The balanced-Steady State Free Precession (bSSFP) cine CMR imaging provides high resolution images with superior contrast between the myocardium and the LV blood-pool. Hence, the registration of the LGE CMR images and the bSSFP cine CMR images is a vital step for accurate localization and quantification of the compromised myocardial tissue. Here, we propose a Spatial Transformer Network (STN) inspired convolutional neural network (CNN) architecture to perform supervised registration of bSSFP cine CMR and LGE CMR images. We evaluate our proposed method on the 2019 Multi-Sequence Cardiac Magnetic Resonance Segmentation Challenge (MS-CMRSeg) dataset and use several evaluation metrics, including the center-to-center LV and right ventricle (RV) blood-pool distance, and the contour-to-contour blood-pool and myocardium distance between the LGE and bSSFP CMR images. Specifically, we showed that our registration method reduced the bSSFP to LGE LV blood-pool center distance from 3.28mm before registration to 2.27mm post registration and RV blood-pool center distance from 4.35mm before registration to 2.52mm post registration. We also show that the average surface distance (ASD) between bSSFP and LGE is reduced from 2.53mm to 2.09mm, 1.78mm to 1.40mm and 2.42mm to 1.73mm for LV blood-pool, LV myocardium and RV blood-pool, respectively.",0,0
8162,"Detection of Junctional Ectopic Tachycardia by Central Venous Pressure. Central venous pressure (CVP) is the blood pressure in the venae cavae, near the right atrium of the heart. This signal waveform is commonly collected in clinical settings, and yet there has been limited discussion of using this data for detecting arrhythmia and other cardiac events. In this paper, we develop a signal processing and feature engineering pipeline for CVP waveform analysis. Through a case study on pediatric junctional ectopic tachycardia (JET), we show that our extracted CVP features reliably detect JET with comparable results to the more commonly used electrocardiogram (ECG) features. This machine learning pipeline can thus improve the clinical diagnosis and ICU monitoring of arrhythmia. It also corroborates and complements the ECG-based diagnosis, especially when the ECG measurements are unavailable or corrupted.",0,0
8165,"A Full-Stack Application for Detecting Seizures and Reducing Data During Continuous Electroencephalogram Monitoring. Continuous electroencephalogram monitoring is associated with lower mortality in critically ill patients; however, it is underused due to the resource-intensive nature of manually interpreting prolonged streams of continuous electroencephalogram data. Here, we present a novel real-time, machine learning-based alerting and monitoring system for epilepsy and seizures that dramatically reduces the amount of manual electroencephalogram review.",0,0
8173,"Predictive modelling of hypoxic ischaemic encephalopathy risk following perinatal asphyxia. Hypoxic Ischemic Encephalopathy (HIE) remains a major cause of neurological disability. Early intervention with therapeutic hypothermia improves outcome, but prediction of HIE is difficult and no single clinical marker is reliable. Machine learning algorithms may allow identification of patterns in clinical data to improve prognostic power. Here we examine the use of a Random Forest machine learning algorithm and five-fold cross-validation to predict the occurrence of HIE in a prospective cohort of infants with perinatal asphyxia. Infants with perinatal asphyxia were recruited at birth and neonatal course was followed for the development of HIE. Clinical variables were recorded for each infant including maternal demographics, delivery details and infant's condition at birth. We found that the strongest predictors of HIE were the infant's condition at birth (as expressed by Apgar score), need for resuscitation, and the first postnatal measures of pH, lactate, and base deficit. Random Forest models combining features including Apgar score, most intensive resuscitation, maternal age and infant birth weight both with and without biochemical markers of pH, lactate, and base deficit resulted in a sensitivity of 56-100% and a specificity of 78-99%. This study presents a dynamic method of rapid classification that has the potential to be easily adapted and implemented in a clinical setting, with and without the availability of blood gas analysis. Our results demonstrate that applying machine learning algorithms to readily available clinical data may support clinicians in the early and accurate identification of infants who will develop HIE. We anticipate our models to be a starting point for the development of a more sophisticated clinical decision support system to help identify which infants will benefit from early therapeutic hypothermia.",0,0
8176,Deep Learning Based Prediction of Atrial Fibrillation Disease Progression with Endocardial Electrograms in a Canine Model. We sought to determine whether electrical patterns in endocardial wavefronts contained elements specific to atrial fibrillation (AF) disease progression.,0,0
8177,"The use of explainable artificial intelligence to explore types of fenestral otosclerosis misdiagnosed when using temporal bone high-resolution computed tomography. The purpose of this study was to explore the common characteristics of fenestral otosclerosis (OS) which are misdiagnosed, and develop a deep learning model for the diagnosis of fenestral OS based on temporal bone high-resolution computed tomography scans.",0,0
8178,"Automated Left Ventricle Ischemic Scar Detection in CT Using Deep Neural Networks. <b>Objectives:</b> The aim of this study is to develop a scar detection method for routine computed tomography angiography (CTA) imaging using deep convolutional neural networks (CNN), which relies solely on anatomical information as input and is compatible with existing clinical workflows. <b>Background:</b> Identifying cardiac patients with scar tissue is important for assisting diagnosis and guiding interventions. Late gadolinium enhancement (LGE) magnetic resonance imaging (MRI) is the gold standard for scar imaging; however, there are common instances where it is contraindicated. CTA is an alternative imaging modality that has fewer contraindications and is faster than Cardiovascular magnetic resonance imaging but is unable to reliably image scar. <b>Methods:</b> A dataset of LGE MRI (200 patients, 83 with scar) was used to train and validate a CNN to detect ischemic scar slices using segmentation masks as input to the network. MRIs were segmented to produce 3D left ventricle meshes, which were sampled at points along the short axis to extract anatomical masks, with scar labels from LGE as ground truth. The trained CNN was tested with an independent CTA dataset (25 patients, with ground truth established with paired LGE MRI). Automated segmentation was performed to provide the same input format of anatomical masks for the network. The CNN was compared against manual reading of the CTA dataset by 3 experts. <b>Results:</b> Note that 84.7% cross-validated accuracy (AUC: 0.896) for detecting scar slices in the left ventricle on the MRI data was achieved. The trained network was tested against the CTA-derived data, with no further training, where it achieved an 88.3% accuracy (AUC: 0.901). The automated pipeline outperformed the manual reading by clinicians. <b>Conclusion:</b> Automatic ischemic scar detection can be performed from a routine cardiac CTA, without any scar-specific imaging or contrast agents. This requires only a single acquisition in the cardiac cycle. In a clinical setting, with near zero additional cost, scar presence could be detected to triage images, reduce reading times, and guide clinical decision-making.",1,1
8181,"Machine Learning Prediction Models for Mechanically Ventilated Patients: Analyses of the MIMIC-III Database. <b>Background:</b> Mechanically ventilated patients in the intensive care unit (ICU) have high mortality rates. There are multiple prediction scores, such as the Simplified Acute Physiology Score II (SAPS II), Oxford Acute Severity of Illness Score (OASIS), and Sequential Organ Failure Assessment (SOFA), widely used in the general ICU population. We aimed to establish prediction scores on mechanically ventilated patients with the combination of these disease severity scores and other features available on the first day of admission. <b>Methods:</b> A retrospective administrative database study from the Medical Information Mart for Intensive Care (MIMIC-III) database was conducted. The exposures of interest consisted of the demographics, pre-ICU comorbidity, ICU diagnosis, disease severity scores, vital signs, and laboratory test results on the first day of ICU admission. Hospital mortality was used as the outcome. We used the machine learning methods of <i>k</i>-nearest neighbors (KNN), logistic regression, bagging, decision tree, random forest, Extreme Gradient Boosting (XGBoost), and neural network for model establishment. A sample of 70% of the cohort was used for the training set; the remaining 30% was applied for testing. Areas under the receiver operating characteristic curves (AUCs) and calibration plots would be constructed for the evaluation and comparison of the models' performance. The significance of the risk factors was identified through models and the top factors were reported. <b>Results:</b> A total of 28,530 subjects were enrolled through the screening of the MIMIC-III database. After data preprocessing, 25,659 adult patients with 66 predictors were included in the model analyses. With the training set, the models of KNN, logistic regression, decision tree, random forest, neural network, bagging, and XGBoost were established and the testing set obtained AUCs of 0.806, 0.818, 0.743, 0.819, 0.780, 0.803, and 0.821, respectively. The calibration curves of all the models, except for the neural network, performed well. The XGBoost model performed best among the seven models. The top five predictors were age, respiratory dysfunction, SAPS II score, maximum hemoglobin, and minimum lactate. <b>Conclusion:</b> The current study indicates that models with the risk of factors on the first day could be successfully established for predicting mortality in ventilated patients. The XGBoost model performs best among the seven machine learning models.",0,0
8185,"Deep Neural Network Analysis of Pathology Images With Integrated Molecular Data for Enhanced Glioma Classification and Grading. Gliomas are primary brain tumors that originate from glial cells. Classification and grading of these tumors is critical to prognosis and treatment planning. The current criteria for glioma classification in central nervous system (CNS) was introduced by World Health Organization (WHO) in 2016. This criteria for glioma classification requires the integration of histology with genomics. In 2017, the Consortium to Inform Molecular and Practical Approaches to CNS Tumor Taxonomy (cIMPACT-NOW) was established to provide up-to-date recommendations for CNS tumor classification, which in turn the WHO is expected to adopt in its upcoming edition. In this work, we propose a novel glioma analytical method that, for the first time in the literature, integrates a cellularity feature derived from the digital analysis of brain histopathology images integrated with molecular features following the latest WHO criteria. We first propose a novel over-segmentation strategy for region-of-interest (ROI) selection in large histopathology whole slide images (WSIs). A Deep Neural Network (DNN)-based classification method then fuses molecular features with cellularity features to improve tumor classification performance. We evaluate the proposed method with 549 patient cases from The Cancer Genome Atlas (TCGA) dataset for evaluation. The cross validated classification accuracies are 93.81% for lower-grade glioma (LGG) and high-grade glioma (HGG) using a regular DNN, and 73.95% for LGG II and LGG III using a residual neural network (ResNet) DNN, respectively. Our experiments suggest that the type of deep learning has a significant impact on tumor subtype discrimination between LGG II <i>vs</i>. LGG III. These results outperform state-of-the-art methods in classifying LGG II <i>vs</i>. LGG III and offer competitive performance in distinguishing LGG <i>vs</i>. HGG in the literature. In addition, we also investigate molecular subtype classification using pathology images and cellularity information. Finally, for the first time in literature this work shows promise for cellularity quantification to predict brain tumor grading for LGGs with <i>IDH</i> mutations.",0,0
8186,"Easily Created Prediction Model Using Automated Artificial Intelligence Framework (Prediction One, Sony Network Communications Inc., Tokyo, Japan) for Subarachnoid Hemorrhage Outcomes Treated by Coiling and Delayed Cerebral Ischemia. Introduction Reliable prediction models of subarachnoid hemorrhage (SAH) outcomes and delayed cerebral ischemia (DCI) are needed to decide the treatment strategy. Automated artificial intelligence (AutoAI) is attractive, but there are few reports on AutoAI-based models for SAH functional outcomes and DCI. We herein made models using an AutoAI framework, Prediction One (Sony Network Communications Inc., Tokyo, Japan), and compared it to other previous statistical prediction scores. Methods We used an open dataset of 298 SAH patients, who were with non-severe neurological grade and treated by coiling. Modified Rankin Scale 0-3 at six months was defined as a favorable functional outcome and DCI occurrence as another outcome. We randomly divided them into a 248-patient training dataset and a 50-patient test dataset. Prediction One made the model using training dataset with 5-fold cross-validation. We evaluated the model using the test dataset and compared the area under the curves (AUCs) of the created models. Those of the modified SAFIRE score and the Fisher computed tomography (CT) scale to predict the outcomes. Results The AUCs of the AutoAI-based models for functional outcome in the training and test dataset were 0.994 and 0.801, and those for the DCI occurrence were 0.969 and 0.650. AUCs for functional outcome calculated using modified SAFIRE score were 0.844 and 0.892. Those for the DCI occurrence calculated using the Fisher CT scale were 0.577 and 0.544. Conclusions We easily and quickly made AutoAI-based prediction models. The models' AUCs were not inferior to the previous prediction models despite the easiness.",0,0
8187,"Hand tremor detection in videos with cluttered background using neural network based approaches. With the increasing prevalence of neurodegenerative diseases, including Parkinson's disease, hand tremor detection has become a popular research topic because it helps with the diagnosis and tracking of disease progression. Conventional hand tremor detection algorithms involved wearable sensors. A non-invasive hand tremor detection algorithm using videos as input is desirable but the existing video-based algorithms are sensitive to environmental conditions. An algorithm, with the capability of detecting hand tremor from videos with a cluttered background, would allow the videos recorded in a non-research environment to be used. Clinicians and researchers could use videos collected from patients and participants in their own home environment or standard clinical settings. Neural network based machine learning architectures provide high accuracy classification results in related fields including hand gesture recognition and body movement detection systems. We thus investigated the accuracy of advanced neural network architectures to automatically detect hand tremor in videos with a cluttered background. We examined configurations with different sets of features and neural network based classification models. We compared the performance of different combinations of features and classification models and then selected the combination which provided the highest accuracy of hand tremor detection. We used cross validation to test the accuracy of the trained model predictions. The highest classification accuracy for automatically detecting tremor (vs non tremor) was 80.6% and this was obtained using Convolutional Neural Network-Long Short-Term Memory and features based on measures of frequency and amplitude change.",0,0
8191,Bronchopulmonary Dysplasia Predicted by Developing a Machine Learning Model of Genetic and Clinical Information. An early and accurate evaluation of the risk of bronchopulmonary dysplasia (BPD) in premature infants is pivotal in implementing preventive strategies. The risk prediction models nowadays for BPD risk that included only clinical factors but without genetic factors are either too complex without practicability or provide poor-to-moderate discrimination. We aim to identify the role of genetic factors in BPD risk prediction early and accurately.,0,0
8196,"LSTM Neural Network for Inferring Conduction Velocity Distribution in Demyelinating Neuropathies. Waveform analysis of compound muscle action potential (CMAP) is important in the detailed analysis of conduction velocities of each axon as seen in temporal dispersion. This understanding is limited because conduction velocity distribution cannot be easily available from a CMAP waveform. Given the recent advent of artificial intelligence, this study aimed to assess whether conduction velocity (CV) distribution can be inferred from CMAP by the use of deep learning algorithms. Simulated CMAP waveforms were constructed from a single motor unit potential and randomly created CV histograms (<i>n</i> = 12,000). After training the data with various recurrent neural networks (RNNs), CV inference was tested by the network. Among simple RNNs, long short-term memory (LSTM) and gated recurrent unit, the best accuracy and loss profiles, were shown by two-layer bidirectional LSTM, with training and validation accuracies of 0.954 and 0.975, respectively. Training with the use of a recurrent neural network can accurately infer conduction velocity distribution in a wide variety of simulated demyelinating neuropathies. Using deep learning techniques, CV distribution can be assessed in a non-invasive manner.",0,0
8197,"Left Atrial Wall Stress and the Long-Term Outcome of Catheter Ablation of Atrial Fibrillation: An Artificial Intelligence-Based Prediction of Atrial Wall Stress. Atrial stretch may contribute to the mechanism of atrial fibrillation (AF) recurrence after atrial fibrillation catheter ablation (AFCA). We tested whether the left atrial (LA) wall stress (LAW-stress<sub>[<i>measured</i>]</sub>) could be predicted by artificial intelligence (AI) using non-invasive parameters (LAW-stress<sub>[AI]</sub>) and whether rhythm outcome after AFCA could be predicted by LAW-stress<sub>[AI]</sub> in an independent cohort. Cohort 1 included 2223 patients, and cohort 2 included 658 patients who underwent AFCA. LAW-stress<sub>[<i>measured</i>]</sub> was calculated using the Law of Laplace using LA diameter by echocardiography, peak LA pressure measured during procedure, and LA wall thickness measured by customized software (AMBER) using computed tomography. The highest quartile (Q4) LAW-stress<sub>[<i>measured</i>]</sub> was predicted and validated by AI using non-invasive clinical parameters, including non-paroxysmal type of AF, age, presence of hypertension, diabetes, vascular disease, and heart failure, left ventricular ejection fraction, and the ratio of the peak mitral flow velocity of the early rapid filling to the early diastolic velocity of the mitral annulus (E/Em). We tested the AF/atrial tachycardia recurrence 3 months after the blanking period after AFCA using the LAW-stress<sub>[<i>measured</i>]</sub> and LAW-stress<sub>[AI]</sub> in cohort 1 and LAW-stress<sub>[AI]</sub> in cohort 2. LAW-stress<sub>[<i>measured</i>]</sub> was independently associated with non-paroxysmal AF (<i>p</i> < 0.001), diabetes (<i>p</i> = 0.012), vascular disease (<i>p</i> = 0.002), body mass index (<i>p</i> < 0.001), E/Em (<i>p</i> < 0.001), and mean LA voltage measured by electrogram voltage mapping (<i>p</i> < 0.001). The best-performing AI model had acceptable prediction power for predicting Q4-LAW-stress<sub>[<i>measured</i>]</sub> (area under the receiver operating characteristic curve 0.734). During 26.0 (12.0-52.0) months of follow-up, AF recurrence was significantly higher in the Q4-LAW-stress<sub>[<i>measured</i>]</sub> group [log-rank <i>p</i> = 0.001, hazard ratio 2.43 (1.21-4.90), <i>p</i> = 0.013] and Q4-LAW-stress<sub>[AI]</sub> group (log-rank <i>p</i> = 0.039) in cohort 1. In cohort 2, the Q4-LAW-stress<sub>[AI]</sub> group consistently showed worse rhythm outcomes (log-rank <i>p</i> < 0.001). A higher LAW-stress was associated with poorer rhythm outcomes after AFCA. AI was able to predict this complex but useful prognostic parameter using non-invasive parameters with moderate accuracy.",0,0
8198,"Automated Localization of Focal Ventricular Tachycardia From Simulated Implanted Device Electrograms: A Combined Physics-AI Approach. <b>Background:</b> Focal ventricular tachycardia (VT) is a life-threating arrhythmia, responsible for high morbidity rates and sudden cardiac death (SCD). Radiofrequency ablation is the only curative therapy against incessant VT; however, its success is dependent on accurate localization of its source, which is highly invasive and time-consuming. <b>Objective:</b> The goal of our study is, as a proof of concept, to demonstrate the possibility of utilizing electrogram (EGM) recordings from cardiac implantable electronic devices (CIEDs). To achieve this, we utilize fast and accurate whole torso electrophysiological (EP) simulations in conjunction with convolutional neural networks (CNNs) to automate the localization of focal VTs using simulated EGMs. <b>Materials and Methods:</b> A highly detailed 3D torso model was used to simulate âˆ¼4000 focal VTs, evenly distributed across the left ventricle (LV), utilizing a rapid reaction-eikonal environment. Solutions were subsequently combined with lead field computations on the torso to derive accurate electrocardiograms (ECGs) and EGM traces, which were used as inputs to CNNs to localize focal sources. We compared the localization performance of a previously developed CNN architecture (Cartesian probability-based) with our novel CNN algorithm utilizing universal ventricular coordinates (UVCs). <b>Results:</b> Implanted device EGMs successfully localized VT sources with localization error (8.74 mm) comparable to ECG-based localization (6.69 mm). Our novel UVC CNN architecture outperformed the existing Cartesian probability-based algorithm (errors = 4.06 mm and 8.07 mm for ECGs and EGMs, respectively). Overall, localization was relatively insensitive to noise and changes in body compositions; however, displacements in ECG electrodes and CIED leads caused performance to decrease (errors 16-25 mm). <b>Conclusion:</b> EGM recordings from implanted devices may be used to successfully, and robustly, localize focal VT sources, and aid ablation planning.",0,0
8199,"Deep Shape Features for Predicting Future Intracranial Aneurysm Growth. <b>Introduction:</b> Intracranial aneurysms (IAs) are a common vascular pathology and are associated with a risk of rupture, which is often fatal. Aneurysm growth is considered a surrogate of rupture risk; therefore, the study aimed to develop and evaluate prediction models of future artificial intelligence (AI) growth based on baseline aneurysm morphology as a computer-aided treatment decision support. <b>Materials and methods:</b> Follow-up CT angiography (CTA) and magnetic resonance angiography (MRA) angiograms of 39 patients with 44 IAs were classified by an expert as growing and stable (25/19). From the angiograms vascular surface meshes were extracted and the aneurysm shape was characterized by established morphologic features and novel deep shape features. The features corresponding to the baseline aneurysms were used to predict future aneurysm growth using univariate thresholding, multivariate random forest and multi-layer perceptron (MLP) learning, and deep shape learning based on the PointNet++ model. <b>Results:</b> The proposed deep shape feature learning method achieved an accuracy of 0.82 (sensitivity = 0.96, specificity = 0.63), while the multivariate learning and univariate thresholding methods were inferior with an accuracy of up to 0.68 and 0.63, respectively. <b>Conclusion:</b> High-performing classification of future growing IAs renders the proposed deep shape features learning approach as the key enabling tool to manage rupture risk in the ""no treatment"" paradigm of patient follow-up imaging.",0,0
8202,"Possibilistic Clustering-Promoting Semi-Supervised Learning for EEG-Based Emotion Recognition. The purpose of the latest brain computer interface is to perform accurate emotion recognition through the customization of their recognizers to each subject. In the field of machine learning, graph-based semi-supervised learning (GSSL) has attracted more and more attention due to its intuitive and good learning performance for emotion recognition. However, the existing GSSL methods are sensitive or not robust enough to noise or outlier electroencephalogram (EEG)-based data since each individual subject may present noise or outlier EEG patterns in the same scenario. To address the problem, in this paper, we invent a Possibilistic Clustering-Promoting semi-supervised learning method for EEG-based Emotion Recognition. Specifically, it constrains each instance to have the same label membership value with its local weighted mean to improve the reliability of the recognition method. In addition, a regularization term about fuzzy entropy is introduced into the objective function, and the generalization ability of membership function is enhanced by increasing the amount of sample discrimination information, which improves the robustness of the method to noise and the outlier. A large number of experimental results on the three real datasets (i.e., DEAP, SEED, and SEED-IV) show that the proposed method improves the reliability and robustness of the EEG-based emotion recognition.",0,0
8204,"Correcting data imbalance for semi-supervised COVID-19 detection using X-ray chest images. A key factor in the fight against viral diseases such as the coronavirus (COVID-19) is the identification of virus carriers as early and quickly as possible, in a cheap and efficient manner. The application of deep learning for image classification of chest X-ray images of COVID-19 patients could become a useful pre-diagnostic detection methodology. However, deep learning architectures require large labelled datasets. This is often a limitation when the subject of research is relatively new as in the case of the virus outbreak, where dealing with small labelled datasets is a challenge. Moreover, in such context, the datasets are also highly imbalanced, with few observations from positive cases of the new disease. In this work we evaluate the performance of the semi-supervised deep learning architecture known as MixMatch with a very limited number of labelled observations and highly imbalanced labelled datasets. We demonstrate the critical impact of data imbalance to the model's accuracy. Therefore, we propose a simple approach for correcting data imbalance, by re-weighting each observation in the loss function, giving a higher weight to the observations corresponding to the under-represented class. For unlabelled observations, we use the pseudo and augmented labels calculated by MixMatch to choose the appropriate weight. The proposed method improved classification accuracy by up to 18%, with respect to the non balanced MixMatch algorithm. We tested our proposed approach with several available datasets using 10, 15 and 20 labelled observations, for binary classification (COVID-19 positive and normal cases). For multi-class classification (COVID-19 positive, pneumonia and normal cases), we tested 30, 50, 70 and 90 labelled observations. Additionally, a new dataset is included among the tested datasets, composed of chest X-ray images of Costa Rican adult patients.",0,0
8209,MIDCAN: A multiple input deep convolutional attention network for Covid-19 diagnosis based on chest CT and chest X-ray. COVID-19 has caused 3.34m deaths till 13/May/2021. It is now still causing confirmed cases and ongoing deaths every day.,0,0
8214,"Using deep learning convolutional neural networks to automatically perform cerebral aqueduct CSF flow analysis. Since the development of phase-contrast magnetic resonance imaging (PC-MRI), quantification of cerebrospinal fluid (CSF) flow across the cerebral aqueduct has been utilized for diagnosis of conditions such as normal pressure hydrocephalus (NPH). This study aims to develop an automated method of aqueduct CSF flow analysis using convolution neural networks (CNNs), which can replace the current standard involving manual segmentation of aqueduct region of interest (ROI). Retrospective analysis was performed on 333 patients who underwent PC-MRI, totaling 353 imaging studies. Aqueduct flow measurements using manual ROI placement was performed independently by two radiologists. Two types of CNNs, MultiResUNet and UNet, were trained using ROI data from the senior radiologist, with PC-MRI studies being randomly divided into training (80%) and validation (20%) datasets. Segmentation performance was assessed using Dice similarity coefficient (DSC), and CSF flow parameters were calculated from both manual and CNN-derived ROIs. MultiResUNet, UNet and second radiologist (Rater 2) had DSCs of 0.933, 0.928, and 0.867, respectively, with pÂ <Â 0.001 between CNNs and Rater 2. Comparison of CSF flow parameters showed excellent intraclass correlation coefficients (ICCs) for MultiResUNet, with lowest correlation being 0.67. For UNet, lower ICCs of -0.01 to 0.56 were observed. Only 3/353 (0.8%) studies failed to have appropriate ROIs placed by MultiResUNet, compared to 12/353 (3.4%) failed cases for UNet. In conclusion, CNNs were able to measure aqueductal CSF flow with similar performance to a senior neuroradiologist. MultiResUNet demonstrated fewer cases of segmentation failure and more consistent flow measurements compared to the widely adopted UNet.",1,1
8215,"Accurate assessment of low-function autistic children based on EEG feature fusion. Autism spectrum disorder (ASD) is a very serious neurodevelopmental disorder and diagnosis mainly depends on the clinical scale, which has a certain degree of subjectivity. It is necessary to make accurate evaluation by objective indicators. In this study, we enrolled 96 children aged from 3 to 6Â years: 48 low-function autistic children (38 males and 10 females; meanÂ±SD age: 4.9Â±1.1Â years) and 48 typically developing (TD) children (38 males and 10 females; meanÂ±SD age: 4.9Â Â±Â 1.2Â years) to participate in our experiment. We investigated to fuse multi-features (entropy, relative power, coherence and bicoherence) to distinguish low-function autistic children and TD children accurately. Minimum redundancy maximum correlation algorithm was used to choose the features and support vector machine was used for classification. Ten-fold cross validation was used to test the accuracy of the model. Better classification result was obtained. We tried to provide a reliable basis for clinical evaluation and diagnosis for ASD.",0,0
8218,"Machine-learning based feature selection for a non-invasive breathing change detection. Chronic Obstructive Pulmonary Disease (COPD) is one of the top 10 causes of death worldwide, representing a major public health problem. Researchers have been looking for new technologies and methods for patient monitoring with the intention of an early identification of acute exacerbation events. Many of these works have been focusing in breathing rate variation, while achieving unsatisfactory sensitivity and/or specificity. This study aims to identify breathing features that better describe respiratory pattern changes in a short-term adjustment of the load-capacity-drive balance, using exercising data.",0,0
8219,"[Deep learning-based dental plaque detection on permanent teeth and the influenced factors]. <b>Objective:</b> To develop an artificial intelligence system for detecting dental plaque on permanent teeth and find the influenced factors. <b>Methods:</b> Photos of the labial or buccal surfaces of the permanent teeth were taken by using an intraoral camera (1 280Ã—960 pixels; TPC Ligang, Shenzhen, China) before and after applying the plaque-disclosing agent (Cimedical, Japan) in 25 volunteers [12 males, 13 femals, aged (23Â±3) years] recruided in accordance with the inclusion criteria from the students of Peking University School of Stomatology from October 2018 to June 2019. A total of 549 groups of photos were captured and then divided into a training dataset containing 440 groups of photos and a test dataset including 109 groups of photos. The scopes of teeth and dental plaque on photos were labeled using LabelMe (Windows 3.2.1, MIT, U S A). A DeepLab based deep learning system was designed for the intelligent detection of dental plaque on permanent teeth. The mean intersection over union (MIoU) was employed to indicate the detection accuracy. Matlab (Windows R2017a, MathWorks, U S A) was used to extract the plaque edge line of 109 groups of photos and to calculate the number of pixels for the measurement of the complexity of the plaque edge line. The percentage of dental plaque area was calculated. Multivariate linear regression was used to explore whether tooth site, plaque percentage, number of plaque edge line pixels and lens light spot location would influence the detection accuracy, of which <i>P</i><0.05 was considered statistically significant. <b>Results:</b> The MIoU of the permanent tooth model was 0.700Â±0.191 when 440 photos were used for training and 109 photos were used for testing. In the regression model of significance test (<i>P</i><0.05), the percentage of plaque and the number of pixels on the edge of plaque had significant influence on the accuracy of dental plaque detection. The standardized coefficient of the number of pixels of the plaque edge line is -0.289, and the standardized coefficient of the percentage of plaque is -0.551. <b>Conclusions:</b> In the present study, an artificial intelligence system was built to detect dental plaque area on tooth photos collected by family intraoral camera. The system showed the ability to detect the dental plaque of permanent teeth. The more complex the marginal line of dental plaque and higher the percentage of dental plaque are, the lower the accuracy of plaque recognition is.",0,0
8220,"White blood cell evaluation in haematological malignancies using a web-based digital microscopy platform. Digital microscopy systems are beginning to replace traditional light microscopes for morphologic analysis of blood films, but these are geographically restricted to individual computers and technically limited by manufacturer's constraints. We explored the use of a scanner-agnostic web-based artificial intelligence (AI) system to assess the accuracy of white blood cell (WBC) differentials and blast identification in haematological malignancies.",0,0
8222,"Development of machine learning algorithms to predict achievement of minimal clinically important difference for the KOOS-PS following total knee arthroplasty. As cost-effective measures become increasingly implemented in the US healthcare system, changes in patient-reported outcome measure (PROM) scores can be utilized to indicate patient satisfaction following procedures including total knee arthroplasty (TKA). The primary aim of this study was to develop and evaluate machine learning algorithms to predict achievement of the minimal clinically important difference (MCID) for the Knee Injury and Osteoarthritis Outcome Score-Physical Function Short Form (KOOS-PS) at 1-year following TKA. A retrospective review of primary TKA patients between 2016 and 2018 was performed. Variables considered for prediction included demographics and preoperative PROMs. The KOOS-PS MCID was calculated via a distribution-based method. Five machine learning algorithms were developed and tested by discrimination, calibration, Brier score, and decision curve analysis. Among the 744 patients who met the inclusion criteria, 385 (72.8%) patients achieved the MCID. The elastic-net penalized logistic regression model was selected as the best performing model (c-statistic 0.77, calibration intercept -0.02, calibration slope 1.15, and Brier score 0.14). The most important variables for MCID achievement were preoperative KOOS-PS score, preoperative VAS Pain, preoperative opioid use, preoperative PROMIS global mental health score, age, and sex. Algorithms were incorporated into an open-access digital application available at https://sorg-apps.shinyapps.io/tka_koos_mcid/. This study is the first to predict the probability of achieving the KOOS-PS MCID following TKA using a machine learning-based approach. The results were used to develop a clinical decision aid based on commonly collected predictive variables to preoperatively predict an individual patient's likelihood of attaining an acceptable outcome following TKA.",0,0
8223,"Patient specific prediction of temporal lobe epilepsy surgical outcomes. Drug-resistant temporal lobe epilepsy (TLE) is the most common type of epilepsy for which patients undergo surgery. Despite the best clinical judgment and currently available prediction algorithms, surgical outcomes remain variable. We aimed to build and to evaluate the performance of multidimensional Bayesian network classifiers (MBCs), a type of probabilistic graphical model, at predicting probability of seizure freedom after TLE surgery.",0,0
8226,"Deep-LIBRA: An artificial-intelligence method for robust quantification of breast density with independent validation in breast cancer risk assessment. Breast density is an important risk factor for breast cancer that also affects the specificity and sensitivity of screening mammography. Current federal legislation mandates reporting of breast density for all women undergoing breast cancer screening. Clinically, breast density is assessed visually using the American College of Radiology Breast Imaging Reporting And Data System (BI-RADS) scale. Here, we introduce an artificial intelligence (AI) method to estimate breast density from digital mammograms. Our method leverages deep learning using two convolutional neural network architectures to accurately segment the breast area. An AI algorithm combining superpixel generation and radiomic machine learning is then applied to differentiate dense from non-dense tissue regions within the breast, from which breast density is estimated. Our method was trained and validated on a multi-racial, multi-institutional dataset of 15,661 images (4,437 women), and then tested on an independent matched case-control dataset of 6368 digital mammograms (414 cases; 1178 controls) for both breast density estimation and case-control discrimination. On the independent dataset, breast percent density (PD) estimates from Deep-LIBRA and an expert reader were strongly correlated (Spearman correlation coefficient = 0.90). Moreover, in a model adjusted for age and BMI, Deep-LIBRA yielded a higher case-control discrimination performance (area under the ROC curve, AUC = 0.612 [95% confidence interval (CI): 0.584, 0.640]) compared to four other widely-used research and commercial breast density assessment methods (AUCs = 0.528 to 0.599). Our results suggest a strong agreement of breast density estimates between Deep-LIBRA and gold-standard assessment by an expert reader, as well as improved performance in breast cancer risk assessment over state-of-the-art open-source and commercial methods.",1,1
8232,"Automatic left ventricle volume calculation with explainability through a deep learning weak-supervision methodology. Magnetic resonance imaging is the most reliable imaging technique to assess the heart. More specifically there is great importance in the analysis of the left ventricle, as the main pathologies directly affect this region. In order to characterize the left ventricle, it is necessary to extract its volume. In this work we present a neural network architecture that is capable of directly estimating the left ventricle volume in short axis cine Magnetic Resonance Imaging in the end-diastolic frame and provide a segmentation of the region which is the basis of the volume calculation, thus offering explainability to the estimated value.",0,0
8233,"A smart LED therapy device with an automatic facial acne vulgaris diagnosis based on deep learning and internet of things application. In low-level laser therapy, providing an optimal dosage and proposing a proper diagnosis before dermatological treatment are essential to reduce the side effects and potential dangers. In this article, a smart LED therapy system for automatic facial acne vulgaris diagnosis based on deep learning and Internet of Things application is proposed. The main goals of this study were to (1) develop an LED therapy device with different power densities and LED grid control; (2) propose a deep learning model based on modified ResNet50 and YOLOv2 for an automatic acne diagnosis; and (3) develop a smartphone application for facial photography image capture and LED therapy parameter configuration. Furthermore, a healthcare Internet of Things (H-IoT) platform for the connectivity between smartphone apps, the cloud server, and the LED therapy device is proposed to improve the efficiency of the treatment process. Experiments were conducted on test data sets divided by a cross-validation method to verify the feasibility of the proposed LED therapy system with automatic facial acne detection. The obtained results evidenced the practical application of the proposed LED therapy system for automatic acne diagnosis and H-IoT-based solutions.",0,0
8240,"A machine learning model for the prediction of down syndrome in second trimester antenatal screening. Down syndrome (DS) is the most common human chromosomal abnormality. About 1200 laboratories carry out antenatal screening for DS in second trimester pregnancies in China. Their prenatal assessment of DS pregnancy risk is based on biometric calculations conducted on maternal serum biochemical markers and ultrasonic markers of fetal growth. However, the performance of this triple test for DS in second trimester pregnancies has a false positive rate of 5%, and a detection rate of about 60%âˆ¼65%.",0,0
8243,"Clinical Deployment of Explainable Artificial Intelligence of SPECT for Diagnosis of Coronary Artery Disease. This study sought to develop and evaluate a novel, general purpose, explainable deep learning model (coronary artery disease-deep learning [CAD-DL]) for the detection of obstructive CAD following single-photon emission computed tomography (SPECT) myocardial perfusion imaging (MPI).",0,0
8252,"Bayesian convolutional neural network estimation for pediatric pneumonia detection and diagnosis. Pneumonia is a disease that affects the lungs, making breathing difficult. Nowadays, pneumonia is the disease that kills the most children under the age of five in the world, and if no action is taken, pneumonia is estimated to kill 11 million children by the year 2030. Knowing that rapid and accurate diagnosis of pneumonia is a significant factor in reducing mortality, acceleration, or automation of the diagnostic process is highly desirable. The use of computational methods can decrease specialists' workload and even offer a second opinion, increasing the number of accurate diagnostics.",0,0
8258,Utilisation of machine learning to predict surgical candidates for the treatment of childhood upper airway obstruction. To investigate the effect of adenotonsillectomy on OSAS symptoms based on a data-driven approach and thereby identify criteria that may help avoid unnecessary surgery in children with OSAS.,0,0
8259,"B-Map: a fuzzy-based model to detect foreign objects in a brain. To cope up with the medical complications, scientists and physicians rely more on digitized historical evidence. It helps them to identify the disease and to develop new drugs and strategies. The authors have designed a model called B-Map. It can detect and segmenting any foreign object in the brain using fuzzy rules. The model can detect objects such as cancer and brain tumor. The proposed work aims at designing a classifier. The classifier would help to detect all possible foreign objects using one application. B-Map has been compared with benchmark algorithms such as K-means and ANN. It was found that the proposed model performs significantly better than the current techniques. Original patients' sample reports are taken from various medical laboratories. The figure numbers are retained as in the paper. The proposed model is able to find the edges and segment different types of foreign objects or one can say unexpected developments. Figure 12 shows the outer edges of a section of a brain MRI. The patient's MRI very clearly shows Hydrocephalus. The same is segmented and shown in Fig. 13. Figure 14 shows a segment of benign development and 15 shows a cancerous development which are again successfully segmented by the proposed model. The data on whichÂ testing is done is clinical data ofÂ the original patients. As the patient's details and data cannot be shared the author's cannot upload the data in the repository. As soon as the research completes, a benchmark dataset will be created and uploaded in public domain so that researchers can access it.",0,0
8261,"Wireless Soft Scalp Electronics and Virtual Reality System for Motor Imagery-Based Brain-Machine Interfaces. Motor imagery offers an excellent opportunity as a stimulus-free paradigm for brain-machine interfaces. Conventional electroencephalography (EEG) for motor imagery requires a hair cap with multiple wired electrodes and messy gels, causing motion artifacts. Here, a wireless scalp electronic system with virtual reality for real-time, continuous classification of motor imagery brain signals is introduced. This low-profile, portable system integrates imperceptible microneedle electrodes and soft wireless circuits. Virtual reality addresses subject variance in detectable EEG response to motor imagery by providing clear, consistent visuals and instant biofeedback. The wearable soft system offers advantageous contact surface area and reduced electrode impedance density, resulting in significantly enhanced EEG signals and classification accuracy. The combination with convolutional neural network-machine learning provides a real-time, continuous motor imagery-based brain-machine interface. With four human subjects, the scalp electronic system offers a high classification accuracy (93.22 Â± 1.33% for four classes), allowing wireless, real-time control of a virtual reality game.",0,0
8285,"Realistic preterm prediction based on optimized synthetic sampling of EHG signal. Preterm labor is the leading cause of neonatal morbidity and mortality in newborns and has attracted significant research attention from many scientific areas. The relationship between uterine contraction and the underlying electrical activities makes uterine electrohysterogram (EHG) a promising direction for detecting and predicting preterm births. However, due to the scarcity of EHG signals, especially those leading to preterm births, synthetic algorithms have been used to generate artificial samples of preterm birth type in order to eliminate bias in the prediction towards normal delivery, at the expense of reducing the feature effectiveness in automatic preterm detection based on machine learning. To address this problem, we quantify the effect of synthetic samples (balance coefficient) on the effectiveness of features and form a general performance metric by using several feature scores with relevant weights that describe their contributions to class segregation. In combination with the activation/inactivation functions that characterize the effect of the abundance of training samples on the accuracy of the prediction of preterm and normal birth delivery, we obtained an optimal sample balance coefficient that compromises the effect of synthetic samples in removing bias toward the majority group (i.e., normal delivery and the side effect of reducing the importance of features). A more realistic predictive accuracy was achieved through a series of numerical tests on the publicly available TPEHG database, therefore demonstrating the effectiveness of the proposed method.",0,0
8288,Prediction of 1-year mortality after heart transplantation using machine learning approaches: A single-center study from China. Heart transplantation (HTx) remains the gold-standard treatment for end-stage heart failure. The aim of this study was to establish a risk-prediction model for assessing prognosis of HTx using machine-learning approach.,0,0
8296,"Distinct Phenotypes of Hospitalized Patients with Hyperkalemia by Machine Learning Consensus Clustering and Associated Mortality Risks. Hospitalized patients with hyperkalemia are heterogeneous, and cluster approaches may identify specific homogenous groups. This study aimed to cluster patients with hyperkalemia on admission using unsupervised machine learning consensus clustering approach, and to compare characteristics and outcomes among these distinct clusters.",0,0
8298,Utilizing timestamps of longitudinal electronic health record data to classify clinical deterioration events. To propose an algorithm that utilizes only timestamps of longitudinal electronic health record data to classify clinical deterioration events.,0,0
8301,"Using wearable technology to detect prescription opioid self-administration. Appropriate monitoring of opioid use in patients with pain conditions is paramount, yet it remains a very challenging task. The current work examined the use of a wearable sensor to detect self-administration of opioids after dental surgery using machine learning. Participants were recruited from an oral and maxillofacial surgery clinic. Participants were 46 adult patients (26 female) receiving opioids after dental surgery. Participants wore Empatica E4 sensors during the period they self-administered opioids. The E4 collected physiological parameters including accelerometer x-, y-, and z-axes, heart rate, and electrodermal activity. Four machine learning models provided validation accuracies greater than 80%, but the bagged-tree model provided the highest combination of validation accuracy (83.7%) and area under the receiver operating characteristic curve (0.92). The trained model had a validation sensitivity of 82%, a specificity of 85%, a positive predictive value of 85%, and a negative predictive value of 83%. A subsequent test of the trained model on withheld data had a sensitivity of 81%, a specificity of 88%, a positive predictive value of 87%, and a negative predictive value of 82%. Results from training and testing model of machine learning indicated that opioid self-administration could be identified with reasonable accuracy, leading to considerable possibilities of the use of wearable technology to advance prevention and treatment.",0,0
8303,Radiomics-Based Machine Learning Classification for Glioma Grading Using Diffusion- and Perfusion-Weighted Magnetic Resonance Imaging. The aim of this study was to evaluate various radiomics-based machine learning classification models using the apparent diffusion coefficient (ADC) and cerebral blood flow (CBF) maps for differentiating between low-grade gliomas (LGGs) and high-grade gliomas (HGGs).,0,0
8306,"Machine learning algorithms vs. thresholding to segment ischemic regions in patients with acute ischemic stroke. Computed tomography (CT) scan is a fast and widely used modality for early assessment in patients with symptoms of a cerebral ischemic stroke. CT perfusion (CTP) is often added to the protocol and is used by radiologists for assessing the severity of the stroke. Standard parametric maps are calculated from the CTP datasets. Based on parametric value combinations, ischemic regions are separated into presumed infarct core (irreversibly damaged tissue) and penumbra (tissue-at-risk). Different thresholding approaches have been suggested to segment the parametric maps into these areas. The purpose of this study is to compare fully-automated methods based on machine learning and thresholding approaches to segment the hypoperfused regions in patients with ischemic stroke.",0,0
8322,Identification of Anterior Cervical Spinal Instrumentation Using A Smartphone Application Powered by Machine Learning. Cross-sectional Study.,0,0
8324,"Depression Detection on Reddit With an Emotion-Based Attention Network: Algorithm Development and Validation. As a common mental disease, depression seriously affects people's physical and mental health. According to the statistics of the World Health Organization, depression is one of the main reasons for suicide and self-harm events in the world. Therefore, strengthening depression detection can effectively reduce the occurrence of suicide or self-harm events so as to save more people and families. With the development of computer technology, some researchers are trying to apply natural language processing techniques to detect people who are depressed automatically. Many existing feature engineering methods for depression detection are based on emotional characteristics, but these methods do not consider high-level emotional semantic information. The current deep learning methods for depression detection cannot accurately extract effective emotional semantic information.",0,0
8326,"Ensemble Learning for Multiple Sclerosis Disability Estimation Using Brain Structural Connectivity. <b><i>Background:</i></b> Multiple sclerosis (MS) is an autoimmune inflammatory disease of the central nervous system characterized by demyelination and neurodegeneration processes. It leads to different clinical courses and degrees of disability that need to be anticipated by the neurologist for personalized therapy. Recently, machine learning (ML) techniques have reached a high level of performance in brain disease diagnosis and/or prognosis, but the decision process of a trained ML system is typically nontransparent. Using brain structural connectivity data, a fully automatic ensemble learning model, augmented with an interpretable model, is proposed for the estimation of MS patients' disability, measured by the Expanded Disability Status Scale (EDSS). <b><i>Materials and Methods:</i></b> An ensemble of four boosting-based models (GBM, XGBoost, CatBoost, and LightBoost) organized following a stacking generalization scheme was developed using diffusion tensor imaging (DTI)-based structural connectivity data. In addition, an interpretable model based on conditional logistic regression was developed to explain the best performances in terms of white matter (WM) links for three classes of EDSS (low, medium, and high). <b><i>Results:</i></b> The ensemble model reached excellent level of performance (root mean squared error of 0.92â€‰Â±â€‰0.28) compared with single-based models and provided a better EDSS estimation using DTI-based structural connectivity data compared with conventional magnetic resonance imaging measures associated with patient data (age, gender, and disease duration). Used for interpretation of the estimation process, the counterfactual method showed the importance of certain brain networks, corresponding mainly to left hemisphere WM links, connecting the left superior temporal with the left posterior cingulate and the right precuneus gray matter regions, and the interhemispheric WM links constituting the corpus callosum. Also, a better accuracy estimation was found for the high disability class. <b><i>Conclusion:</i></b> The combination of advanced ML models and sensitive techniques such as DTI-based structural connectivity demonstrated to be useful for the estimation of MS patients' disability and to point out the most important brain WM networks involved in disability. Impact statement An ensemble of ""boosting"" machine learning (ML) models was more performant than single models to estimate disability in multiple sclerosis. Diffusion tensor imaging (DTI)-based structural connectivity led to better performance than conventional magnetic resonance imaging. An interpretable model, based on counterfactual perturbation, highlighted the most relevant white matter fiber links for disability estimation. These findings demonstrated the clinical interest of combining DTI, graph modeling, and ML techniques.",0,0
8328,"Machine Learning Evidence for Sex Differences Consistently Influences Resting-State Functional Magnetic Resonance Imaging Fluctuations Across Multiple Independently Acquired Data Sets. <b><i>Background/Introduction:</i></b> Sex classification using functional connectivity from resting-state functional magnetic resonance imaging (rs-fMRI) has shown promising results. This suggested that sex difference might also be embedded in the blood-oxygen-level-dependent properties such as the amplitude of low-frequency fluctuation (ALFF) and the fraction of ALFF (fALFF). This study comprehensively investigates sex differences using a reliable and explainable machine learning (ML) pipeline. Five independent cohorts of rs-fMRI with over than 5500 samples were used to assess sex classification performance and map the spatial distribution of the important brain regions. <b><i>Methods:</i></b> Five rs-fMRI samples were used to extract ALFF and fALFF features from predefined brain parcellations and then were fed into an unbiased and explainable ML pipeline with a wide range of methods. The pipeline comprehensively assessed unbiased performance for within-sample and across-sample validation. In addition, the parcellation effect, classifier selection, scanning length, spatial distribution, reproducibility, and feature importance were analyzed and evaluated thoroughly in the study. <b><i>Results:</i></b> The results demonstrated high sex classification accuracies from healthy adults (area under the curve >0.89), while degrading for nonhealthy subjects. Sex classification showed moderate to good intraclass correlation coefficient based on parcellation. Linear classifiers outperform nonlinear classifiers. Sex differences could be detected even with a short rs-fMRI scan (e.g., 2â€‰min). The spatial distribution of important features overlaps with previous results from studies. <b><i>Discussion:</i></b> Sex differences are consistent in rs-fMRI and should be considered seriously in any study design, analysis, or interpretation. Features that discriminate males and females were found to be distributed across several different brain regions, suggesting a complex mosaic for sex differences in rs-fMRI.",0,0
8334,"Seizure detection using wearable sensors and machine learning: Setting a benchmark. Tracking seizures is crucial for epilepsy monitoring and treatment evaluation. Current epilepsy care relies on caretaker seizure diaries, but clinical seizure monitoring may miss seizures. Wearable devices may be better tolerated and more suitable for long-term ambulatory monitoring. This study evaluates the seizure detection performance of custom-developed machine learning (ML) algorithms across a broad spectrum of epileptic seizures utilizing wrist- and ankle-worn multisignal biosensors.",0,0
8339,"Decoding Clinical Biomarker Space of COVID-19: Exploring Matrix Factorization-based Feature Selection Methods. One of the most critical challenges in managing complex diseases like COVID-19 is to establish an intelligent triage system that can optimize the clinical decision-making at the time of a global pandemic. The clinical presentation and patientsÃ¢â‚¬â„¢ characteristics are usually utilized to identify those patients who need more critical care. However, the clinical evidence shows an unmet need to determine more accurate and optimal clinical biomarkers to triage patients under a condition like the COVID-19 crisis. Here we have presented a machine learning approach to find a group of clinical indicators from the blood tests of a set of COVID-19 patients that are predictive of poor prognosis and morbidity. Our approach consists of two interconnected schemes: Feature Selection and Prognosis Classification. The former is based on different Matrix Factorization (MF)-based methods, and the latter is performed using Random Forest algorithm. Our model reveals that Arterial Blood Gas (ABG) O <sub>2</sub> Saturation and C-Reactive Protein (CRP) are the most important clinical biomarkers determining the poor prognosis in these patients. Our approach paves the path of building quantitative and optimized clinical management systems for COVID-19 and similar diseases.",0,0
8340,"AI-DRIVEN QUANTIFICATION OF GROUND GLASS OPACITIES IN LUNGS OF COVID-19 PATIENTS USING 3D COMPUTED TOMOGRAPHY IMAGING. Ground-glass opacity (GGO) - a hazy, gray appearing density on computed tomography (CT) of lungs - is one of the hallmark features of SARS-CoV-2 in COVID-19 patients. This AI-driven study is focused on segmentation, morphology, and distribution patterns of GGOs.",0,0
8343,"Deep Learning-Based COVID-19 Pneumonia Classification Using Chest CT Images: Model Generalizability. Since the outbreak of the COVID-19 pandemic, worldwide research efforts have focused on using artificial intelligence (AI) technologies on various medical data of COVID-19-positive patients in order to identify or classify various aspects of the disease, with promising reported results. However, concerns have been raised over their generalizability, given the heterogeneous factors in training datasets. This study aims to examine the severity of this problem by evaluating deep learning (DL) classification models trained to identify COVID-19-positive patients on 3D computed tomography (CT) datasets from different countries. We collected one dataset at UT Southwestern (UTSW) and three external datasets from different countries: CC-CCII Dataset (China), COVID-CTset (Iran), and MosMedData (Russia). We divided the data into two classes: COVID-19-positive and COVID-19-negative patients. We trained nine identical DL-based classification models by using combinations of datasets with a 72% train, 8% validation, and 20% test data split. The models trained on a single dataset achieved accuracy/area under the receiver operating characteristic curve (AUC) values of 0.87/0.826 (UTSW), 0.97/0.988 (CC-CCCI), and 0.86/0.873 (COVID-CTset) when evaluated on their own dataset. The models trained on multiple datasets and evaluated on a test set from one of the datasets used for training performed better. However, the performance dropped close to an AUC of 0.5 (random guess) for all models when evaluated on a different dataset outside of its training datasets. Including MosMedData, which only contained positive labels, into the training datasets did not necessarily help the performance of other datasets. Multiple factors likely contributed to these results, such as patient demographics and differences in image acquisition or reconstruction, causing a data shift among different study cohorts.",0,0
8352,Decision-support for treatment with <sup>177</sup>Lu-PSMA: machine learning predicts response with high accuracy based on PSMA-PET/CT and clinical parameters. Treatment with radiolabeled ligands to prostate-specific membrane antigen (PSMA) is gaining importance in the treatment of patients with advanced prostate carcinoma. Previous imaging with positron emission tomography/computed tomography (PET/CT) is mandatory. The aim of this study was to investigate the role of radiomics features in PSMA-PET/CT scans and clinical parameters to predict response to <sup>177</sup>Lu-PSMA treatment given just baseline PSMA scans using state-of-the-art machine learning (ML) methods.,0,0
8354,"Mortality prediction for patients with acute respiratory distress syndrome based on machine learning: a population-based study. Traditional scoring systems for patients' outcome prediction in intensive care units such as Oxygenation Saturation Index (OSI) and Oxygenation Index (OI) may not reliably predict the clinical prognosis of patients with acute respiratory distress syndrome (ARDS). Thus, none of them have been widely accepted for mortality prediction in ARDS. This study aimed to develop and validate a mortality prediction method for patients with ARDS based on machine learning using the Medical Information Mart for Intensive Care (MIMIC-III) and Telehealth Intensive Care Unit (eICU) Collaborative Research Database (eICU-CRD) databases.",0,0
8355,Probabilistic ratiocination of hepatocellular carcinoma after resection: evaluation of expected to be promising approaches. Precise prediction of survival after treatment is of great importance for patients with diseases with high mortality. RNA sequencing data and deep learning (DL) methods are expected to become promising approaches in the development of prediction models in the future. We aimed to evaluate the optimal covariates and methodology for patients with hepatocellular carcinoma (HCC) undergoing surgical resection.,0,0
8356,Artificial intelligence in digital cariology: a new tool for the diagnosis of deep caries and pulpitis using convolutional neural networks. An accurate diagnosis of deep caries and pulpitis on periapical radiographs is a clinical challenge.,0,0
8359,"Machine Learning for Predicting the 3-Year Risk of Incident Diabetes in Chinese Adults. <b>Purpose:</b> We aimed to establish and validate a risk assessment system that combines demographic and clinical variables to predict the 3-year risk of incident diabetes in Chinese adults. <b>Methods:</b> A 3-year cohort study was performed on 15,928 Chinese adults without diabetes at baseline. All participants were randomly divided into a training set (<i>n</i> = 7,940) and a validation set (<i>n</i> = 7,988). XGBoost method is an effective machine learning technique used to select the most important variables from candidate variables. And we further established a stepwise model based on the predictors chosen by the XGBoost model. The area under the receiver operating characteristic curve (AUC), decision curve and calibration analysis were used to assess discrimination, clinical use and calibration of the model, respectively. The external validation was performed on a cohort of 11,113 Japanese participants. <b>Result:</b> In the training and validation sets, 148 and 145 incident diabetes cases occurred. XGBoost methods selected the 10 most important variables from 15 candidate variables. Fasting plasma glucose (FPG), body mass index (BMI) and age were the top 3 important variables. And we further established a stepwise model and a prediction nomogram. The AUCs of the stepwise model were 0.933 and 0.910 in the training and validation sets, respectively. The Hosmer-Lemeshow test showed a perfect fit between the predicted diabetes risk and the observed diabetes risk (<i>p</i> = 0.068 for the training set, <i>p</i> = 0.165 for the validation set). Decision curve analysis presented the clinical use of the stepwise model and there was a wide range of alternative threshold probability spectrum. And there were almost no the interactions between these predictors (most <i>P</i>-values for interaction >0.05). Furthermore, the AUC for the external validation set was 0.830, and the Hosmer-Lemeshow test for the external validation set showed no statistically significant difference between the predicted diabetes risk and observed diabetes risk (<i>P</i> = 0.824). <b>Conclusion:</b> We established and validated a risk assessment system for characterizing the 3-year risk of incident diabetes.",0,0
8360,"Developing a clinical decision support system based on the fuzzy logic and decision tree to predict colorectal cancer. <b>Background:</b> Colorectal Cancer (CRC) is the most prevalent digestive system- related cancer and has become one of the deadliest diseases worldwide. Given the poor prognosis of CRC, it is of great importance to make a more accurate prediction of this disease. Early CRC detection using computational technologies can significantly improve the overall survival possibility of patients. Hence this study was aimed to develop a fuzzy logic-based clinical decision support system (FL-based CDSS) for the detection of CRC patients. <b>Methods:</b> This study was conducted in 2020 using the data related to CRC and non-CRC patients, which included the 1162 cases in the Masoud internal clinic, Tehran, Iran. The chi-square method was used to determine the most important risk factors in predicting CRC. Furthermore, the C4.5 decision tree was used to extract the rules. Finally, the FL-based CDSS was designed in a MATLAB environment and its performance was evaluated by a confusion matrix. <b>Results:</b> Eleven features were selected as the most important factors. After fuzzification of the qualitative variables and evaluation of the decision support system (DSS) using the confusion matrix, the accuracy, specificity, and sensitivity of the system was yielded 0.96, 0.97, and 0.96, respectively. <b>Conclusion:</b> We concluded that developing the CDSS in this field can provide an earlier diagnosis of CRC, leading to a timely treatment, which could decrease the CRC mortality rate in the community.",0,0
8362,"Cervical Cancer Prediction by Merging Features of Different Colposcopic Images and Using Ensemble Classifier. Cervical cancer is a significant cause of cancer mortality in women, particularly in low-income countries. In regular cervical screening methods, such as colposcopy, an image is taken from the cervix of a patient. The particular image can be used by computer-aided diagnosis (CAD) systems that are trained using artificial intelligence algorithms to predict the possibility of cervical cancer. Artificial intelligence models had been highlighted in a number of cervical cancer studies. However, there are a limited number of studies that investigate the simultaneous use of three colposcopic screening modalities including Greenlight, Hinselmann, and Schiller.",0,0
8364,"Constructing high-order functional connectivity network based on central moment features for diagnosis of autism spectrum disorder. The sliding-window-based dynamic functional connectivity network (D-FCN) has been becoming an increasingly useful tool for understanding the changes of brain connectivity patterns and the association of neurological diseases with these dynamic variations. However, conventional D-FCN is essentially low-order network, which only reflects the pairwise interaction pattern between brain regions and thus overlooking the high-order interactions among multiple brain regions. In addition, D-FCN is innate with temporal sensitivity issue, i.e., D-FCN is sensitive to the chronological order of its subnetworks. To deal with the above issues, we propose a novel high-order functional connectivity network framework based on the central moment feature of D-FCN. Specifically, we firstly adopt a central moment approach to extract multiple central moment feature matrices from D-FCN. Furthermore, we regard the matrices as the profiles to build multiple high-order functional connectivity networks which further capture the higher level and more complex interaction relationships among multiple brain regions. Finally, we use the voting strategy to combine the high-order networks with D-FCN for autism spectrum disorder diagnosis. Experimental results show that the combination of multiple functional connectivity networks achieves accuracy of 88.06%, and the best single network achieves accuracy of 79.5%.",0,0
8368,"Classification of Microglial Morphological Phenotypes Using Machine Learning. Microglia are the brain's immunocompetent macrophages with a unique feature that allows surveillance of the surrounding microenvironment and subsequent reactions to tissue damage, infection, or homeostatic perturbations. Thereby, microglia's striking morphological plasticity is one of their prominent characteristics and the categorization of microglial cell function based on morphology is well established. Frequently, automated classification of microglial morphological phenotypes is performed by using quantitative parameters. As this process is typically limited to a few and especially manually chosen criteria, a relevant selection bias may compromise the resulting classifications. In our study, we describe a novel microglial classification method by morphological evaluation using a convolutional neuronal network on the basis of manually selected cells in addition to classical morphological parameters. We focused on four microglial morphologies, ramified, rod-like, activated and amoeboid microglia within the murine hippocampus and cortex. The developed method for the classification was confirmed in a mouse model of ischemic stroke which is already known to result in microglial activation within affected brain regions. In conclusion, our classification of microglial morphological phenotypes using machine learning can serve as a time-saving and objective method for post-mortem characterization of microglial changes in healthy and disease mouse models, and might also represent a useful tool for human brain autopsy samples.",0,0
8370,"Role of Red Cell Indices in Screening for Beta Thalassemia Trait: an Assessment of the Individual Indices and Application of Machine Learning Algorithm. Antenatal screening for beta thalassemia trait (BTT) followed by counseling of couples is an efficient way of thalassemia control. Since high performance liquid chromatography (HPLC) is costly, other cost-effective screening methods need to be devised for this purpose. The present study was aimed at evaluating the utility of red cell indices and machine learning algorithms including an artificial neural network (ANN) in detection of BTT among antenatal women. This cross-sectional study included all antenatal women undergoing thalassemia screening at a tertiary care hospital. Complete blood count followed by HPLC was performed. Receiver operating characteristicÂ (ROC)Â curve analysis was performed for obtaining optimal cutoff for each of the indices with determination of test characteristics for detection of BTT. Machine learning algorithms including C4.5 and NaÃ¯ve Bayes (NB) classifier and a back-propagation type ANN including the red cell indices was designed and tested. Over a period of 15Â months, 3947 patients underwent thalassemia screening. BTT was diagnosed in 5.98% of women on the basis of HPLC. ROC analysis yielded the maximum accuracy of 63.8%, sensitivity and specificity of 66.2% and 63.7%, respectively for Mean corpuscular hemoglobin concentration (MCHC). The C4.5 and NB classifier had accuracy of 88.56%-82.49% respectively while ANN had an overall accuracy of 85.95%, sensitivity of 83.81%, and specificity of 88.10% in detection of BTT. The present study highlights that none of the red cell parameters standalone is useful for screening for BTT. However, ANN with combination of all the red cell indices had an appreciable sensitivity and specificity for this purpose. Further refinements of the neural network can provide an appropriate tool for use in peripheral settings for thalassemia screening.",0,0
8373,Enhancement of prostate cancer diagnosis by machine learning techniques: an algorithm development and validation study. To investigate the value of machine learning(ML) in enhancing prostate cancer(PCa) diagnosis.,0,0
8374,"Systems biology informed neural networks (SBINN) predict response and novel combinations for PD-1 checkpoint blockade. Anti-PD-1 immunotherapy has recently shown tremendous success for the treatment of several aggressive cancers. However, variability and unpredictability in treatment outcome have been observed, and are thought to be driven by patient-specific biology and interactions of the patient's immune system with the tumor. Here we develop an integrative systems biology and machine learning approach, built around clinical data, to predict patient response to anti-PD-1 immunotherapy and to improve the response rate. Using this approach, we determine biomarkers of patient response and identify potential mechanisms of drug resistance. We develop systems biology informed neural networks (SBINN) to calculate patient-specific kinetic parameter values and to predict clinical outcome. We show how transfer learning can be leveraged with simulated clinical data to significantly improve the response prediction accuracy of the SBINN. Further, we identify novel drug combinations and optimize the treatment protocol for triple combination therapy consisting of IL-6 inhibition, recombinant IL-12, and anti-PD-1 immunotherapy in order to maximize patient response. We also find unexpected differences in protein expression levels between response phenotypes which complement recent clinical findings. Our approach has the potential to aid in the development of targeted experiments for patient drug screening as well as identify novel therapeutic targets.",0,0
8381,"Noninvasive Machine Learning Screening Model for Dacryocystitis Based on Ocular Surface Indicators. Dacryocystitis is an orbital disease that can be easily misdiagnosed. The most common diagnostic tools for dacryocystitis are computed tomography, lacrimal duct angiography, and lacrimal tract irrigation. Yet, those are invasive methods, which are not conducive to extensive screening.",0,0
8384,"Machine learning approaches in predicting ambulatory same day discharge patients after total hip arthroplasty. With continuing financial and regulatory pressures, practice of ambulatory total hip arthroplasty is increasing. However, studies focusing on selection of optimal candidates are burdened by limitations related to traditional statistical approaches. Hereby we aimed to apply machine learning algorithm to identify characteristics associated with optimal candidates.",0,0
8386,"Artificial intelligence in CT for quantifying lung changes in the era of CFTR modulators. Chest computed tomography (CT) remains the imaging standard for demonstrating cystic fibrosis airway structural disease <i>in vivo</i>. However, visual scorings as an outcome measure are time-consuming, require training, and lack high reproducibility.",0,0
8388,Radiomic Phenotypes Distinguish Atypical Teratoid/Rhabdoid Tumors from Medulloblastoma. Atypical teratoid/rhabdoid tumors and medulloblastomas have similar imaging and histologic features but distinctly different outcomes. We hypothesized that they could be distinguished by MR imaging-based radiomic phenotypes.,0,0
8405,"Multicolor image classification using the multimodal information bottleneck network (MMIB-Net) for detecting diabetic retinopathy. Multicolor (MC) imaging is an imaging modality that records confocal scanning laser ophthalmoscope (cSLO) fundus images, which can be used for the diabetic retinopathy (DR) detection. By utilizing this imaging technique, multiple modal images can be obtained in a single case. Additional symptomatic features can be obtained if these images are considered during the diagnosis of DR. However, few studies have been carried out to classify MC Images using deep learning methods, let alone using multi modal features for analysis. In this work, we propose a novel model which uses the multimodal information bottleneck network (MMIB-Net) to classify the MC Images for the detection of DR. Our model can extract the features of multiple modalities simultaneously while finding concise feature representations of each modality using the information bottleneck theory. MC Images classification can be achieved by picking up the combined representations and features of all modalities. In our experiments, it is shown that the proposed method can achieve an accurate classification of MC Images. Comparative experiments also demonstrate that the use of multimodality and information bottleneck improves the performance of MC Images classification. To the best of our knowledge, this is the first report of DR identification utilizing the multimodal information bottleneck convolutional neural network in MC Images.",0,0
8413,Predicting suicide attempts and suicide deaths among adolescents following outpatient visits. Few studies report on machine learning models for suicide risk prediction in adolescents and their utility in identifying those in need of further evaluation. This study examined whether a model trained and validated using data from all age groups works as well for adolescents or whether it could be improved.,0,0
8416,"Development of a generalizable natural language processing pipeline to extract physician-reported pain from clinical reports: Generated using publicly-available datasets and tested on institutional clinical reports for cancer patients with bone metastases. The majority of cancer patients suffer from severe pain at the advanced stage of their illness. In most cases, cancer pain is underestimated by clinical staff and is not properly managed until it reaches a critical stage. Therefore, detecting and addressing cancer pain early can potentially improve the quality of life of cancer patients. The objective of this research project was to develop a generalizable Natural Language Processing (NLP) pipeline to find and classify physician-reported pain in the radiation oncology consultation notes of cancer patients with bone metastases.",0,0
8417,"Low-frequency oscillations in cortical level to help diagnose task-specific dystonia. Task-specific dystonia is a neurological movement disorder that abnormal contractions of muscles result in the twisting of fixed postures or muscle spasm during specific tasks. Due to the rareness and the pathophysiology of the disease, there is no test to confirm the diagnosis of task-specific dystonia, except comprehensive observations by the experts. Evidence from neural electrophysiological data suggests that enhanced low frequency (4-12Â Hz) oscillations in the subcortical structure of the globus pallidus were associated with the pathological abnormalities concerning Î² and Î³ rhythms in motor areas and motor cortical network in patients with task-specific dystonia. However, whether patients with task-specific dystonia have any low-frequency abnormalities in motor cortical areas remains unclear. In this study, we hypothesized that low-frequency abnormalities are present in core motor areas and motor cortical networks in patients with task-specific dystonia during performing the non-symptomatic movements and those low-frequency abnormalities can help the diagnosis of this disease. We tested this hypothesis by using EEG, effective connectivity analysis, and a machine learning method. Fifteen patients with task-specific dystonia and 15 healthy controls were recruited. The machine learning method identified 8 aberrant movement-related network connections concerning low frequency, Î² and Î³ frequencies, which enabled the separation of the data of patients from those of controls with an accuracy of 90%. Importantly, 7 of the 8 aberrant connections engaged the premotor area contralateral to the affected hand, suggesting an important role of the premotor area in the pathological abnormities. The patients exhibited significantly lower low frequency activities during the movement preparation and significantly lower Î² rhythms during movements compared with healthy controls in the core motor areas. Our findings of low frequency- and Î²-related abnormalities at the cortical level and aberrant motor network could help diagnose task-specific dystonia in the clinical setting, and the importance of the contralesional premotor area suggests its diagnostic potential for task-specific dystonia.",0,0
8420,"Deep Learning for Basal Cell Carcinoma Detection for Reflectance Confocal Microscopy. Basal cell carcinoma (BCC) is the most common skin cancer, with over 2 million cases diagnosed annually in the United States. Conventionally, BCC is diagnosed by naked eye examination and dermoscopy. Suspicious lesions are either removed or biopsied for histopathological confirmation, thus lowering the specificity of noninvasive BCC diagnosis. Recently, reflectance confocal microscopy, a noninvasive diagnostic technique that can image skin lesions at cellular level resolution, has shown to improve specificity in BCC diagnosis and reduced the number needed to biopsy by 2-3 times. In this study, we developed and evaluated a deep learning-based artificial intelligence model to automatically detect BCC in reflectance confocal microscopy images. The proposed model achieved an area under the curve for the receiver operator characteristic curve of 89.7% (stack level) and 88.3% (lesion level), a performance on par with that of reflectance confocal microscopy experts. Furthermore, the model achieved an area under the curve of 86.1% on a held-out test set from international collaborators, demonstrating the reproducibility and generalizability of the proposed automated diagnostic approach. These results provide a clear indication that the clinical deployment of decision support systems for the detection of BCC in reflectance confocal microscopy images has the potential for optimizing the evaluation and diagnosis of patients with skin cancer.",1,1
8423,"Prediction of Nonalcoholic Fatty Liver Disease by Anthropometric Indices and Bioelectrical Impedance Analysis in Children. <b><i>Background:</i></b> Nonalcoholic fatty liver disease (NAFLD) is highly prevalent in children and is associated with obesity. <b><i>Objectives:</i></b> To test whether addition of bioelectrical impedance analysis (BIA) parameters to BMI and anthropometric indices improves the prediction performance of NAFLD than BMI <i>z</i> score (BAZ) alone. <b><i>Methods:</i></b> This cross-sectional study recruited 933 children 6-12 years of age for anthropometric measure, BIA, and liver ultrasound. Prediction models of the BAZ, anthropometric, and BIA sets were built in children with obesity using machine learning algorithms. <b><i>Results:</i></b> Prevalences of NAFLD were 44.4% (59/133) and 20% (12/60) in boys and girls with obesity, respectively. In both sexes, BAZ set performed worst; adding anthropometric indices into the model improved the model performance, whereas BIA parameters were the best approach for predicting NAFLD. The best result in boys achieved had an accuracy of 75.9% and area under receiver operating characteristic curve of 0.854. In girls, the best result achieved had an <i>F</i>-measure score of 0.615, Matthews correlation coefficient of 0.512, and area under precision-recalled curve of 0.697. <b><i>Conclusion:</i></b> BIA is a simple and highly precise tool that yields better NAFLD prediction model than anthropometric indices, and much better performance than BAZ. This study suggests BIA as a potential predictor for pediatric NAFLD.",0,0
8424,"Prediction of well-being and insight into work-life integration among physicians using machine learning approach. There has been increasing interest in examining physician well-being and its predictive factors. However, few studies have revealed the characteristics associated with physician well-being and work-life integration using a machine learning approach. To investigate predictive factors of well-being and obtain insights into work-life integration, the survey was conducted by letter mail in a sample of Japanese physicians. A total of 422 responses were collected from 846 physicians. The mean age was 47.9 years, males constituted 83.3% of the physicians, and 88.6% were considered to be well. The most accurate machine learning model showed a mean area under the curve of 0.72. The mean permutation importance of career satisfaction, work hours per week, existence of family support, gender, and existence of power harassment were 0.057, 0.022, 0.009, 0.01, and 0.006, respectively. Using a machine learning model, physician well-being could be predicted. It seems to be influenced by multiple factors, such as career satisfaction, work hours per week, family support, gender, and power harassment. Career satisfaction has the highest impact, while long work hours have a negative effect on well-being. These findings support the need for organizational interventions to promote physician well-being and improve the quality of medical care.",0,0
8427,"Lung Nodule Malignancy Prediction in Sequential CT Scans: Summary of ISBI 2018 Challenge. Lung cancer is by far the leading cause of cancer death in the US. Recent studies have demonstrated the effectiveness of screening using low dose CT (LDCT) in reducing lung cancer related mortality. While lung nodules are detected with a high rate of sensitivity, this exam has a low specificity rate and it is still difficult to separate benign and malignant lesions. The ISBI 2018 Lung Nodule Malignancy Prediction Challenge, developed by a team from the Quantitative Imaging Network of the National Cancer Institute, was focused on the prediction of lung nodule malignancy from two sequential LDCT screening exams using automated (non-manual) algorithms. We curated a cohort of 100 subjects who participated in the National Lung Screening Trial and had established pathological diagnoses. Data from 30 subjects were randomly selected for training and the remaining was used for testing. Participants were evaluated based on the area under the receiver operating characteristic curve (AUC) of nodule-wise malignancy scores generated by their algorithms on the test set. The challenge had 17 participants, with 11 teams submitting reports with method description, mandated by the challenge rules. Participants used quantitative methods, resulting in a reporting test AUC ranging from 0.698 to 0.913. The top five contestants used deep learning approaches, reporting an AUC between 0.87 -0.91. The team's predictor did not achieve significant differences from each other nor from a volume change estimate (p=.05 with Bonferroni-Holm's correction).",0,0
8428,"Weakly Supervised Deep Ordinal Cox Model for Survival Prediction from Whole-slide Pathological Images. Whole-Slide Histopathology Image (WSI) is generally considered the gold standard for cancer diagnosis and prognosis. Given the large inter-operator variation among pathologists, there is an imperative need to develop machine learning models based on WSIs for consistently predicting patient prognosis. The existing WSI-based prediction methods do not utilize the ordinal ranking loss to train the prognosis model, and thus cannot model the strong ordinal information among different patients in an efficient way. Another challenge is that a WSI is of large size (e.g., 100,000-by-100,000 pixels) with heterogeneous patterns but often only annotated with a single WSI-level label, which further complicates the training process. To address these challenges, we consider the ordinal characteristic of the survival process by adding a ranking-based regularization term on the Cox model and propose a weakly supervised deep ordinal Cox model (BDOCOX) for survival prediction from WSIs. Here, we generate amounts of bags from WSIs, and each bag is comprised of the image patches representing the heterogeneous patterns of WSIs, which is assumed to match the WSI-level labels for training the proposed model. The effectiveness of the proposed method is well validated by theoretical analysis as well as the prognosis and patient stratification results on three cancer datasets from The Cancer Genome Atlas (TCGA).",0,0
8430,"Machine Learning Radiomics Model for Early Identification of Small-Cell Lung Cancer on Computed Tomography Scans. Small-cell lung cancer (SCLC) is the deadliest form of lung cancer, partly because of its short doubling time. Delays in imaging identification and diagnosis of nodules create a risk for stage migration. The purpose of our study was to determine if a machine learning radiomics model can detect SCLC on computed tomography (CT) among all nodules at least 1 cm in size.",0,0
8434,"An artificial intelligence-assisted diagnostic platform for rapid near-patient hematology. Hematology analyzers capable of performing complete blood count (CBC) have lagged in their prevalence at the point-of-care. Sight OLO (Sight Diagnostics, Israel) is a novel hematological platform which provides a 19-parameter, five-part differential CBC, and is designed to address the limitations in current point-of-care hematology analyzers using recent advances in artificial intelligence (AI) and computer vision. Accuracy, repeatability, and flagging capabilities of OLO were compared with the Sysmex XN-Series System (Sysmex, Japan). Matrix studies compared performance using venous, capillary and direct-from-fingerprick blood samples. Regression analysis shows strong concordance between OLO and the Sysmex XN, demonstrating that OLO performs with high accuracy for all CBC parameters. High repeatability and reproducibility were demonstrated for most of the testing parameters. The analytical performance of the OLO hematology analyzer was validated in a multicenter clinical laboratory setting, demonstrating its accuracy and comparability to clinical laboratory-based hematology analyzers. Furthermore, the study demonstrated the validity of CBC analysis of samples collected directly from fingerpricks.",1,1
8440,Value of a deep learning-based algorithm for detecting Lung-RADS category 4 nodules on chest radiographs in a health checkup population: estimation of the sample size for a randomized controlled trial. To explore the value of a deep learning-based algorithm in detecting Lung CT Screening Reporting and Data System category 4 nodules on chest radiographs from an asymptomatic health checkup population.,0,0
8443,"Comparing different CT, PET and MRI multi-modality image combinations for deep learning-based head and neck tumor segmentation. Manual delineation of gross tumor volume (GTV) is essential for radiotherapy treatment planning, but it is time-consuming and suffers inter-observer variability (IOV). In clinics, CT, PET, and MRI are used to inform delineation accuracy due to their different complementary characteristics. This study aimed to investigate deep learning to assist GTV delineation in head and neck squamous cell carcinoma (HNSCC) by comparing various modality combinations.",0,0
8445,"Automatic classification of autism spectrum disorder in children using cortical thickness and support vector machine. Autism spectrum disorder (ASD) is a neurodevelopmental condition with a heterogeneous phenotype. The role of biomarkers in ASD diagnosis has been highlighted; cortical thickness has proved to be involved in the etiopathogenesis of ASD core symptoms. We apply support vector machine, a supervised machine learning method, in order to identify specific cortical thickness alterations in ASD subjects.",0,0
8452,A human-computer collaboration for COVID-19 differentiation: combining a radiomics model with deep learning and human auditing. This study aimed to build a radiomics model with deep learning (DL) and human auditing and examine its diagnostic value in differentiating between coronavirus disease 2019 (COVID-19) and community-acquired pneumonia (CAP).,0,0
8457,"Artificial intelligence for identification and characterization of colonic polyps. Colonoscopy remains the gold standard exam for colorectal cancer screening due to its ability to detect and resect pre-cancerous lesions in the colon. However, its performance is greatly operator dependent. Studies have shown that up to one-quarter of colorectal polyps can be missed on a single colonoscopy, leading to high rates of interval colorectal cancer. In addition, the American Society for Gastrointestinal Endoscopy has proposed the ""resect-and-discard"" and ""diagnose-and-leave"" strategies for diminutive colorectal polyps to reduce the costs of unnecessary polyp resection and pathology evaluation. However, the performance of optical biopsy has been suboptimal in community practice. With recent improvements in machine-learning techniques, artificial intelligence-assisted computer-aided detection and diagnosis have been increasingly utilized by endoscopists. The application of computer-aided design on real-time colonoscopy has been shown to increase the adenoma detection rate while decreasing the withdrawal time and improve endoscopists' optical biopsy accuracy, while reducing the time to make the diagnosis. These are promising steps toward standardization and improvement of colonoscopy quality, and implementation of ""resect-and-discard"" and ""diagnose-and-leave"" strategies. Yet, issues such as real-world applications and regulatory approval need to be addressed before artificial intelligence models can be successfully implemented in clinical practice. In this review, we summarize the recent literature on the application of artificial intelligence for detection and characterization of colorectal polyps and review the limitation of existing artificial intelligence technologies and future directions for this field.",0,0
8459,"Development and Validation of a Random Forest Diagnostic Model of Acute Myocardial Infarction Based on Ferroptosis-Related Genes in Circulating Endothelial Cells. The high incidence and mortality of acute myocardial infarction (MI) drastically threaten human life and health. In the past few decades, the rise of reperfusion therapy has significantly reduced the mortality rate, but the MI diagnosis is still by means of the identification of myocardial injury markers without highly specific biomarkers of microcirculation disorders. Ferroptosis is a novel reported type of programmed cell death, which plays an important role in cancer development. Maintaining iron homeostasis in cells is essential for heart function, and its role in the pathological process of ischemic organ damages remains unclear. Being quickly detected through blood tests, circulating endothelial cells (CECs) have the potential for early judgment of early microcirculation disorders. In order to explore the role of ferroptosis-related genes in the early diagnosis of acute MI, we relied on two data sets from the GEO database to first detect eight ferroptosis-related genes differentially expressed in CECs between the MI and healthy groups in this study. After comparing different supervised learning algorithms, we constructed a random forest diagnosis model for acute MI based on these ferroptosis-related genes with a compelling diagnostic performance in both the validation (AUC = 0.8550) and test set (AUC = 0.7308), respectively. These results suggest that the ferroptosis-related genes might play an important role in the early stage of MI and have the potential as specific diagnostic biomarkers for MI.",0,0
8460,"Acute Myocardial Infarction Detection Using Deep Learning-Enabled Electrocardiograms. <b>Background:</b> Acute myocardial infarction (AMI) is associated with a poor prognosis. Therefore, accurate diagnosis and early intervention of the culprit lesion are of extreme importance. Therefore, we developed a neural network algorithm in this study to automatically diagnose AMI from 12-lead electrocardiograms (ECGs). <b>Methods:</b> We used the open-source PTB-XL database as the training and validation sets, with a 7:3 sample size ratio. Twenty-One thousand, eight hundred thirty-seven clinical 12-lead ECGs from the PTB-XL dataset were available for training and validation (15,285 were used in the training set and 6,552 in the validation set). Additionally, we randomly selected 205 ECGs from a dataset built by Chapman University, CA, USA and Shaoxing People's Hospital, China, as the testing set. We used a residual network for training and validation. The model performance was experimentally verified in terms of area under the curve (AUC), precision, sensitivity, specificity, and F1 score. <b>Results:</b> The AUC of the training, validation, and testing sets were 0.964 [95% confidence interval (CI): 0.961-0.966], 0.944 (95% CI: 0.939-0.949), and 0.977 (95% CI: 0.961-0.991), respectively. The precision, sensitivity, specificity, and F1 score of the deep learning model for AMI diagnosis from ECGs were 0.827, 0.824, 0.950, and 0.825, respectively, in the training set, 0.789, 0.818, 0.913, and 0.803, respectively, in the validation set, and 0.830, 0.951, 0.951, and 0.886, respectively, in the testing set. The AUC for automatic AMI location diagnosis of LMI, IMI, ASMI, AMI, ALMI were 0.969 (95% CI: 0.959-0.979), 0.973 (95% CI: 0.962-0.978), 0.987 (95% CI: 0.963-0.989), 0.961 (95% CI: 0.956-0.989), and 0.996 (95% CI: 0.957-0.997), respectively. <b>Conclusions:</b> The residual network-based algorithm can effectively automatically diagnose AMI and MI location from 12-lead ECGs.",0,0
8463,MRI texture features from tumor core and margin in the prediction of response to neoadjuvant chemotherapy in patients with locally advanced breast cancer. Radiomics involving quantitative analysis of imaging has shown promises in oncology to serve as non-invasive biomarkers. We investigated whether pre-treatment T2-weighted magnetic resonance imaging (MRI) can be used to predict response to neoadjuvant chemotherapy (NAC) in breast cancer.,0,0
8465,"Identification of Clinically Relevant Subgroups of Chronic Lymphocytic Leukemia Through Discovery of Abnormal Molecular Pathways. Chronic lymphocytic leukemia (CLL) is the most common form of adult leukemia in the Western world with a highly variable clinical course. Its striking genetic heterogeneity is not yet fully understood. Although the CLL genetic landscape has been well-described, patient stratification based on mutation profiles remains elusive mainly due to the heterogeneity of data. Here we attempted to decrease the heterogeneity of somatic mutation data by mapping mutated genes in the respective biological processes. From the sequencing data gathered by the International Cancer Genome Consortium for 506 CLL patients, we generated pathway mutation scores, applied ensemble clustering on them, and extracted abnormal molecular pathways with a machine learning approach. We identified four clusters differing in pathway mutational profiles and time to first treatment. Interestingly, common CLL drivers such as ATM or TP53 were associated with particular subtypes, while others like NOTCH1 or SF3B1 were not. This study provides an important step in understanding mutational patterns in CLL.",0,0
8466,"Immune-Based Prediction of COVID-19 Severity and Chronicity Decoded Using Machine Learning. Expression of CCR5 and its cognate ligands have been implicated in COVID-19 pathogenesis, consequently therapeutics directed against CCR5 are being investigated. Here, we explored the role of CCR5 and its ligands across the immunologic spectrum of COVID-19. We used a bioinformatics approach to predict and model the immunologic phases of COVID so that effective treatment strategies can be devised and monitored. We investigated 224 individuals including healthy controls and patients spanning the COVID-19 disease continuum. We assessed the plasma and isolated peripheral blood mononuclear cells (PBMCs) from 29 healthy controls, 26 Mild-Moderate COVID-19 individuals, 48 Severe COVID-19 individuals, and 121 individuals with post-acute sequelae of COVID-19 (PASC) symptoms. Immune subset profiling and a 14-plex cytokine panel were run on all patients from each group. B-cells were significantly elevated compared to healthy control individuals (P<0.001) as was the CD14+, CD16+, CCR5+ monocytic subset (P<0.001). CD4 and CD8 positive T-cells expressing PD-1 as well as T-regulatory cells were significantly lower than healthy controls (P<0.001 and P=0.01 respectively). CCL5/RANTES, IL-2, IL-4, CCL3, IL-6, IL-10, IFN-Î³, and VEGF were all significantly elevated compared to healthy controls (all P<0.001). Conversely GM-CSF and CCL4 were in significantly lower levels than healthy controls (P=0.01). Data were further analyzed and the classes were balanced using SMOTE. With a balanced working dataset, we constructed 3 random forest classifiers: a multi-class predictor, a Severe disease group binary classifier and a PASC binary classifier. Models were also analyzed for feature importance to identify relevant cytokines to generate a disease score. Multi-class models generated a score specific for the PASC patients and defined as S1 = (IFN-Î³ + IL-2)/CCL4-MIP-1Î². Second, a score for the Severe COVID-19 patients was defined as S2 = (IL-6+sCD40L/1000 + VEGF/10 + 10*IL-10)/(IL-2 + IL-8). Severe COVID-19 patients are characterized by excessive inflammation and dysregulated T cell activation, recruitment, and counteracting activities. While PASC patients are characterized by a profile able to induce the activation of effector T cells with pro-inflammatory properties and the capacity of generating an effective immune response to eliminate the virus but without the proper recruitment signals to attract activated T cells.",0,0
8467,The Immune Subtypes and Landscape of Gastric Cancer and to Predict Based on the Whole-Slide Images Using Deep Learning. Gastric cancer (GC) is a highly heterogeneous tumor with different responses to immunotherapy. Identifying immune subtypes and landscape of GC could improve immunotherapeutic strategies.,0,0
8468,"Optimized Projection and Fisher Discriminative Dictionary Learning for EEG Emotion Recognition. Electroencephalogram (EEG)-based emotion recognition (ER) has drawn increasing attention in the brain-computer interface (BCI) due to its great potentials in human-machine interaction applications. According to the characteristics of rhythms, EEG signals usually can be divided into several different frequency bands. Most existing methods concatenate multiple frequency band features together and treat them as a single feature vector. However, it is often difficult to utilize band-specific information in this way. In this study, an optimized projection and Fisher discriminative dictionary learning (OPFDDL) model is proposed to efficiently exploit the specific discriminative information of each frequency band. Using subspace projection technology, EEG signals of all frequency bands are projected into a subspace. The shared dictionary is learned in the projection subspace such that the specific discriminative information of each frequency band can be utilized efficiently, and simultaneously, the shared discriminative information among multiple bands can be preserved. In particular, the Fisher discrimination criterion is imposed on the atoms to minimize within-class sparse reconstruction error and maximize between-class sparse reconstruction error. Then, an alternating optimization algorithm is developed to obtain the optimal solution for the projection matrix and the dictionary. Experimental results on two EEG-based ER datasets show that this model can achieve remarkable results and demonstrate its effectiveness.",0,0
8469,"Deep Learning Framework for Real-Time Estimation of <i>in-silico</i> Thrombotic Risk Indices in the Left Atrial Appendage. Patient-specific computational fluid dynamics (CFD) simulations can provide invaluable insight into the interaction of left atrial appendage (LAA) morphology, hemodynamics, and the formation of thrombi in atrial fibrillation (AF) patients. Nonetheless, CFD solvers are notoriously time-consuming and computationally demanding, which has sparked an ever-growing body of literature aiming to develop surrogate models of fluid simulations based on neural networks. The present study aims at developing a deep learning (DL) framework capable of predicting the endothelial cell activation potential (ECAP), an <i>in-silico</i> index linked to the risk of thrombosis, typically derived from CFD simulations, solely from the patient-specific LAA morphology. To this end, a set of popular DL approaches were evaluated, including fully connected networks (FCN), convolutional neural networks (CNN), and geometric deep learning. While the latter directly operated over non-Euclidean domains, the FCN and CNN approaches required previous registration or 2D mapping of the input LAA mesh. First, the superior performance of the graph-based DL model was demonstrated in a dataset consisting of 256 synthetic and real LAA, where CFD simulations with simplified boundary conditions were run. Subsequently, the adaptability of the geometric DL model was further proven in a more realistic dataset of 114 cases, which included the complete patient-specific LA and CFD simulations with more complex boundary conditions. The resulting DL framework successfully predicted the overall distribution of the ECAP in both datasets, based solely on anatomical features, while reducing computational times by orders of magnitude compared to conventional CFD solvers.",0,0
8470,"3D Segmentation of Perivascular Spaces on T1-Weighted 3 Tesla MR Images With a Convolutional Autoencoder and a U-Shaped Neural Network. We implemented a deep learning (DL) algorithm for the 3-dimensional segmentation of perivascular spaces (PVSs) in deep white matter (DWM) and basal ganglia (BG). This algorithm is based on an autoencoder and a U-shaped network (U-net), and was trained and tested using T1-weighted magnetic resonance imaging (MRI) data from a large database of 1,832 healthy young adults. An important feature of this approach is the ability to learn from relatively sparse data, which gives the present algorithm a major advantage over other DL algorithms. Here, we trained the algorithm with 40 T1-weighted MRI datasets in which all ""visible"" PVSs were manually annotated by an experienced operator. After learning, performance was assessed using another set of 10 MRI scans from the same database in which PVSs were also traced by the same operator and were checked by consensus with another experienced operator. The Sorensen-Dice coefficients for PVS voxel detection in DWM (resp. BG) were 0.51 (resp. 0.66), and 0.64 (resp. 0.71) for PVS cluster detection (volume threshold of 0.5 within a range of 0 to 1). Dice values above 0.90 could be reached for detecting PVSs larger than 10 mm<sup>3</sup> and 0.95 for PVSs larger than 15 mm<sup>3</sup>. We then applied the trained algorithm to the rest of the database (1,782 individuals). The individual PVS load provided by the algorithm showed a high agreement with a semi-quantitative visual rating done by an independent expert rater, both for DWM and for BG. Finally, we applied the trained algorithm to an age-matched sample from another MRI database acquired using a different scanner. We obtained a very similar distribution of PVS load, demonstrating the interoperability of this algorithm.",1,1
8478,"Clinical subphenotypes in COVID-19: derivation, validation, prediction, temporal patterns, and interaction with social determinants of health. The coronavirus disease 2019 (COVID-19) is heterogeneous and our understanding of the biological mechanisms of host response to the viral infection remains limited. Identification of meaningful clinical subphenotypes may benefit pathophysiological study, clinical practice, and clinical trials. Here, our aim was to derive and validate COVID-19 subphenotypes using machine learning and routinely collected clinical data, assess temporal patterns of these subphenotypes during the pandemic course, and examine their interaction with social determinants of health (SDoH). We retrospectively analyzed 14418 COVID-19 patients in five major medical centers in New York City (NYC), between March 1 and June 12, 2020. Using clustering analysis, 4 biologically distinct subphenotypes were derived in the development cohort (Nâ€‰=â€‰8199). Importantly, the identified subphenotypes were highly predictive of clinical outcomes (especially 60-day mortality). Sensitivity analyses in the development cohort, and rederivation and prediction in the internal (Nâ€‰=â€‰3519) and external (Nâ€‰=â€‰3519) validation cohorts confirmed the reproducibility and usability of the subphenotypes. Further analyses showed varying subphenotype prevalence across the peak of the outbreak in NYC. We also found that SDoH specifically influenced mortality outcome in Subphenotype IV, which is associated with older age, worse clinical manifestation, and high comorbidity burden. Our findings may lead to a better understanding of how COVID-19 causes disease in different populations and potentially benefit clinical trial development. The temporal patterns and SDoH implications of the subphenotypes may add insights to health policy to reduce social disparity in the pandemic.",0,0
8479,"Deep transfer learning and data augmentation improve glucose levels prediction in type 2 diabetes patients. Accurate prediction of blood glucose variations in type 2 diabetes (T2D) will facilitate better glycemic control and decrease the occurrence of hypoglycemic episodes as well as the morbidity and mortality associated with T2D, hence increasing the quality of life of patients. Owing to the complexity of the blood glucose dynamics, it is difficult to design accurate predictive models in every circumstance, i.e., hypo/normo/hyperglycemic events. We developed deep-learning methods to predict patient-specific blood glucose during various time horizons in the immediate future using patient-specific every 30-min long glucose measurements by the continuous glucose monitoring (CGM) to predict future glucose levels in 5â€‰min to 1â€‰h. In general, the major challenges to address are (1) the dataset of each patient is often too small to train a patient-specific deep-learning model, and (2) the dataset is usually highly imbalanced given that hypo- and hyperglycemic episodes are usually much less common than normoglycemia. We tackle these two challenges using transfer learning and data augmentation, respectively. We systematically examined three neural network architectures, different loss functions, four transfer-learning strategies, and four data augmentation techniques, including mixup and generative models. Taken together, utilizing these methodologies we achieved over 95% prediction accuracy and 90% sensitivity for a time period within the clinically useful 1â€‰h prediction horizon that would allow a patient to react and correct either hypoglycemia and/or hyperglycemia. We have also demonstrated that the same network architecture and transfer-learning methods perform well for the type 1 diabetes OhioT1DM public dataset.",0,0
8480,"Predicting mortality risk for preterm infants using deep learning models with time-series vital sign data. Mortality remains an exceptional burden of extremely preterm birth. Current clinical mortality prediction scores are calculated using a few static variable measurements, such as gestational age, birth weight, temperature, and blood pressure at admission. While these models do provide some insight, numerical and time-series vital sign data are also available for preterm babies admitted to the NICU and may provide greater insight into outcomes. Computational models that predict the mortality risk of preterm birth in the NICU by integrating vital sign data and static clinical variables in real time may be clinically helpful and potentially superior to static prediction models. However, there is a lack of established computational models for this specific task. In this study, we developed a novel deep learning model, DeepPBSMonitor (Deep Preterm Birth Survival Risk Monitor), to predict the mortality risk of preterm infants during initial NICU hospitalization. The proposed deep learning model can effectively integrate time-series vital sign data and fixed variables while resolving the influence of noise and imbalanced data. The proposed model was evaluated and compared with other approaches using data from 285 infants. Results showed that the DeepPBSMonitor model outperforms other approaches, with an accuracy, recall, and AUC score of 0.888, 0.780, and 0.897, respectively. In conclusion, the proposed model has demonstrated efficacy in predicting the real-time mortality risk of preterm infants in initial NICU hospitalization.",0,0
8482,"Distinct tumor signatures using deep learning-based characterization of the peritumoral microenvironment in glioblastomas and brain metastases. Tumor types are classically distinguished based on biopsies of the tumor itself, as well as a radiological interpretation using diverse MRI modalities. In the current study, the overarching goal is to demonstrate that primary (glioblastomas) and secondary (brain metastases) malignancies can be differentiated based on the microstructure of the peritumoral region. This is achieved by exploiting the extracellular water differences between vasogenic edema and infiltrative tissue and training a convolutional neural network (CNN) on the Diffusion Tensor Imaging (DTI)-derived free water volume fraction. We obtained 85% accuracy in discriminating extracellular water differences between local patches in the peritumoral area of 66 glioblastomas and 40 metastatic patients in a cross-validation setting. On an independent test cohort consisting of 20 glioblastomas and 10 metastases, we got 93% accuracy in discriminating metastases from glioblastomas using majority voting on patches. This level of accuracy surpasses CNNs trained on other conventional DTI-based measures such as fractional anisotropy (FA) and mean diffusivity (MD), that have been used in other studies. Additionally, the CNN captures the peritumoral heterogeneity better than conventional texture features, including Gabor and radiomic features. Our results demonstrate that the extracellular water content of the peritumoral tissue, as captured by the free water volume fraction, is best able to characterize the differences between infiltrative and vasogenic peritumoral regions, paving the way for its use in classifying and benchmarking peritumoral tissue with varying degrees of infiltration.",0,0
8490,Deep learning-assisted (automatic) diagnosis of glaucoma using a smartphone. To validate a deep learning algorithm to diagnose glaucoma from fundus photography obtained with a smartphone.,0,0
8491,"DeepProg: an ensemble of deep-learning and machine-learning models for prognosis prediction using multi-omics data. Multi-omics data are good resources for prognosis and survival prediction; however, these are difficult to integrate computationally. We introduce DeepProg, a novel ensemble framework of deep-learning and machine-learning approaches that robustly predicts patient survival subtypes using multi-omics data. It identifies two optimal survival subtypes in most cancers and yields significantly better risk-stratification than other multi-omics integration methods. DeepProg is highly predictive, exemplified by two liver cancer (C-index 0.73-0.80) and five breast cancer datasets (C-index 0.68-0.73). Pan-cancer analysis associates common genomic signatures in poor survival subtypes with extracellular matrix modeling, immune deregulation, and mitosis processes. DeepProg is freely available at https://github.com/lanagarmire/DeepProg.",0,0
